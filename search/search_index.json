{"config":{"lang":["en"],"separator":"[\\s\\-\\.]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"MARSYS - Multi-Agent Reasoning Systems","text":""},{"location":"#build-powerful-ai-systems-with-collaborative-agents","title":"\ud83e\udd16 Build Powerful AI Systems with Collaborative Agents","text":"<p>A beta Python framework for creating, orchestrating, and training multiple AI agents that work together to solve complex tasks.</p> \ud83d\ude80 Get Started \ud83d\udcbb View on GitHub \u26a1 Quick Start"},{"location":"#what-is-marsys","title":"What is MARSYS?","text":"<p>MARSYS (Multi-Agent Reasoning Systems) is a beta framework for building intelligent systems where multiple AI agents collaborate to solve complex problems. Unlike single-agent approaches, MARSYS enables:</p> <ul> <li>\ud83d\udd04 Dynamic Agent Coordination: Runtime parallel execution with automatic convergence</li> <li>\ud83e\udde0 Intelligent Routing: Graph-based agent communication and permission management</li> <li>\ud83d\udcbe State Persistence: Pause, resume, and checkpoint long-running workflows</li> <li>\ud83d\udd0c Universal Model Support: Works with OpenAI, Anthropic, Google, and local models</li> <li>\ud83c\udf10 Browser Automation: Built-in web interaction capabilities with Playwright</li> <li>\ud83d\udc65 Human-in-the-Loop: Seamless integration of human feedback and decisions</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li> <p> Error Recovery &amp; Observability</p> <p>Comprehensive error handling, automatic retries, detailed logging, and execution observability</p> </li> <li> <p> Flexible Workflows</p> <p>Support for virtually any multi-agent pattern with runtime modification and dynamic branching</p> </li> <li> <p> Concurrent Agents</p> <p>Run multiple agents concurrently with isolated instances and automatic resource management</p> </li> <li> <p> Workflow Persistence</p> <p>Save, pause, and resume long-running workflows with automatic checkpointing and recovery</p> </li> <li> <p> Automatic Tool Integration</p> <p>Convert any Python function to an agent tool with automatic schema generation from signatures</p> </li> <li> <p> Human-in-the-Loop</p> <p>Integrate human feedback and decisions at any point in the workflow with rich interfaces</p> </li> </ul>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#1-install-marsys","title":"1\ufe0f\u20e3 Install MARSYS","text":"<pre><code>pip install marsys\n# or from source\ngit clone https://github.com/rezaho/MARSYS.git\ncd MARSYS\npip install -e .\n</code></pre>"},{"location":"#2-run-your-first-multi-agent-system","title":"2\ufe0f\u20e3 Run Your First Multi-Agent System","text":"<pre><code>from marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\n# Create specialized agents\nmodel_config = ModelConfig(\n    type=\"api\",\n    name=\"anthropic/claude-opus-4.6\",\n    provider=\"openrouter\"\n)\n\ncoordinator = Agent(\n    model_config=model_config,\n    name=\"Coordinator\",\n    goal=\"Coordinate the ideation process and synthesize final results\",\n    instruction=\"Expert coordinator who manages collaboration between brainstorming and critique phases\",\n    allowed_peers=[\"Brainstormer\", \"Critic\"]  # Can invoke both agents\n)\n\nbrainstormer = Agent(\n    model_config=model_config,\n    name=\"Brainstormer\",\n    goal=\"Generate creative ideas and innovative solutions\",\n    instruction=\"Creative thinker who produces diverse and imaginative concepts\"\n)\n\ncritic = Agent(\n    model_config=model_config,\n    name=\"Critic\",\n    goal=\"Evaluate ideas for feasibility and provide constructive feedback\",\n    instruction=\"Analytical evaluator who assesses practicality and identifies improvements\"\n)\n\n# Run the multi-agent system\nresult = await coordinator.auto_run(\n    task=\"Generate and refine ideas for a sustainable transportation app\"\n)\n\nprint(result)\n</code></pre>"},{"location":"#architecture-overview","title":"Architecture Overview","text":"<pre><code>%%{init: {\n  'theme':'base',\n  'themeVariables': {\n    'primaryColor':'#fff',\n    'primaryBorderColor':'#808080',\n    'fontFamily': 'Inter, -apple-system, BlinkMacSystemFont, \"Segoe UI\", Roboto, sans-serif',\n    'fontSize': '14px'\n  },\n  'flowchart': {\n    'subGraphTitleMargin': {'top': 20, 'bottom': 30}\n  }\n}}%%\ngraph LR\n    subgraph OL[\"&amp;nbsp;&amp;nbsp;&amp;nbsp;Orchestration Layer&amp;nbsp;&amp;nbsp;&amp;nbsp;\"]\n        direction TB\n        O[Orchestra]:::orchestrator\n        TC[Topology&lt;br/&gt;Controller]:::orchestrator\n        EC[Execution&lt;br/&gt;Coordinator]:::orchestrator\n        SM[State&lt;br/&gt;Manager]:::orchestrator\n\n        O --&gt; TC\n        O --&gt; EC\n        O --&gt; SM\n    end\n\n    subgraph EL[\"&amp;nbsp;&amp;nbsp;&amp;nbsp;Execution Layer&amp;nbsp;&amp;nbsp;&amp;nbsp;\"]\n        direction TB\n        BE[Branch&lt;br/&gt;Executor]:::executor\n        SE[Step&lt;br/&gt;Executor]:::executor\n        DBS[Dynamic Branch&lt;br/&gt;Spawner]:::executor\n\n        BE --&gt; SE\n        BE --&gt; DBS\n    end\n\n    subgraph AL[\"&amp;nbsp;&amp;nbsp;&amp;nbsp;Agent Layer&amp;nbsp;&amp;nbsp;&amp;nbsp;\"]\n        direction TB\n        AP[Agent&lt;br/&gt;Pools]:::agent\n        AR[Agent&lt;br/&gt;Registry]:::agent\n        A1[Agent 1]:::agentInstance\n        A2[Agent 2]:::agentInstance\n        A3[Agent N]:::agentInstance\n\n        AP --&gt; A1\n        AP --&gt; A2\n        AP --&gt; A3\n    end\n\n    subgraph COM[\"&amp;nbsp;&amp;nbsp;&amp;nbsp;Communication&amp;nbsp;&amp;nbsp;&amp;nbsp;\"]\n        direction TB\n        CM[Communication&lt;br/&gt;Manager]:::comm\n        USER[User&lt;br/&gt;Interface]:::comm\n\n        CM --&gt; USER\n    end\n\n    %% Inter-subgraph connections\n    EC --&gt; BE\n    SE --&gt; AP\n    SE --&gt; AR\n    SE --&gt; CM\n\n    %% Node styling with soft colors and rounded corners\n    classDef orchestrator fill:#E3F2FD,stroke:#64B5F6,stroke-width:2px,color:#333,rx:5,ry:5\n    classDef executor fill:#E8F5E9,stroke:#81C784,stroke-width:2px,color:#333,rx:5,ry:5\n    classDef agent fill:#FFF3E0,stroke:#FFB74D,stroke-width:2px,color:#333,rx:5,ry:5\n    classDef agentInstance fill:#FFECB3,stroke:#FFA726,stroke-width:1.5px,color:#333,rx:5,ry:5\n    classDef comm fill:#FCE4EC,stroke:#F06292,stroke-width:2px,color:#333,rx:5,ry:5\n\n    %% Highlight key components with rounded corners\n    style O fill:#E3F2FD,stroke:#2196F3,stroke-width:3px,color:#333,rx:5,ry:5,font-weight:bold\n    style EC fill:#E8F5E9,stroke:#66BB6A,stroke-width:3px,color:#333,rx:5,ry:5,font-weight:bold\n    style AP fill:#FFF3E0,stroke:#FF9800,stroke-width:3px,color:#333,rx:5,ry:5,font-weight:bold\n\n    %% Subgraph container styling with bigger font - light gray with dashed borders and gray text\n    style OL fill:#FAFAFA,stroke:#808080,stroke-width:3px,stroke-dasharray:8 4,rx:10,ry:10,color:#666,font-size:16px,font-weight:bold\n    style EL fill:#FAFAFA,stroke:#808080,stroke-width:3px,stroke-dasharray:8 4,rx:10,ry:10,color:#666,font-size:16px,font-weight:bold\n    style AL fill:#FAFAFA,stroke:#808080,stroke-width:3px,stroke-dasharray:8 4,rx:10,ry:10,color:#666,font-size:16px,font-weight:bold\n    style COM fill:#FAFAFA,stroke:#808080,stroke-width:3px,stroke-dasharray:8 4,rx:10,ry:10,color:#666,font-size:16px,font-weight:bold\n\n    %% Arrow styling - gray color\n    linkStyle default stroke:#808080,stroke-width:2px,fill:none</code></pre>"},{"location":"#documentation","title":"Documentation","text":"<p>New to MARSYS?</p> <p>Start with our Quick Start Guide to build your first multi-agent system in minutes!</p> Section Description Best For Getting Started Installation, setup, first steps New users Concepts Core ideas and architecture Understanding the framework Tutorials Step-by-step guides Learning by doing API Reference Complete API documentation Implementation details Use Cases Real-world examples Inspiration and patterns Contributing Development guide Contributors"},{"location":"#why-marsys","title":"Why MARSYS?","text":""},{"location":"#for-developers","title":"For Developers","text":"<ul> <li>\ud83c\udfaf Simple API: Start with one line, scale to complex workflows</li> <li>\ud83d\udd27 Extensible: Custom agents, tools, and communication channels</li> <li>\ud83d\udcdd Well-Documented: Comprehensive guides with real examples</li> <li>\ud83e\uddea Tested: Comprehensive test suite with integration tests</li> </ul>"},{"location":"#for-teams","title":"For Teams","text":"<ul> <li>\ud83d\udcbc Robust Error Handling: Recovery mechanisms, retries, and monitoring built-in</li> <li>\ud83d\udcca Observable: Rich status updates and event broadcasting</li> <li>\ud83d\udd10 Secure: Permission-based agent communication</li> <li>\ud83d\udcc8 Scalable: From single agents to complex multi-agent systems</li> </ul>"},{"location":"#for-research","title":"For Research","text":"<ul> <li>\ud83e\udde0 Learning Capabilities: PEFT fine-tuning support</li> <li>\ud83d\udd2c Experimentation: Multiple workflow patterns to test</li> <li>\ud83d\udcca Metrics: Built-in performance tracking</li> <li>\ud83d\udd04 Reproducible: State persistence and checkpointing</li> </ul>"},{"location":"#community-support","title":"Community &amp; Support","text":"<ul> <li> <p> GitHub</p> <p>Report issues, request features, and contribute</p> </li> <li> <p> Discord</p> <p>Join our community for discussions and help</p> </li> <li> <p> Documentation</p> <p>Comprehensive guides and API reference</p> </li> </ul>"},{"location":"#ready-to-build","title":"Ready to Build?","text":"\ud83d\udce6 Install MARSYS \u26a1 Quick Start Guide \ud83d\udcda Learn Concepts <p>Built with \u2764\ufe0f by the MARSYS Team | Apache License 2.0 | v0.1-beta</p>"},{"location":"CLA/","title":"Marsys Individual Contributor License Agreement","text":"<p>Thank you for your interest in contributing to the Marsys Multi-Agent Coordination Framework (\"the Project\").</p> <p>Project Owner: Marsys Project Copyright Holder: rezaho Contact: reza@marsys.ai</p> <p>This Contributor License Agreement (\"Agreement\") documents the rights granted by contributors to the Project Owner and clarifies copyright ownership.</p>"},{"location":"CLA/#important-copyright-ownership","title":"Important: Copyright Ownership","text":"<p>By signing this Agreement, you acknowledge and agree that:</p> <ol> <li> <p>No Copyright Transfer: Your contribution does NOT transfer copyright ownership to you. The Project Owner retains sole copyright ownership of the Marsys codebase.</p> </li> <li> <p>License Grant Only: You grant a copyright and patent license (as detailed below) but you do NOT become a copyright holder through your contribution.</p> </li> <li> <p>Original Author Rights: The original author retains the exclusive right to:</p> </li> <li>Relicense the project</li> <li>Transfer copyright if needed for the project's sustainability</li> <li>Offer commercial or alternative licenses</li> <li> <p>Make all ownership and licensing decisions</p> </li> <li> <p>Successors and Assigns: All rights granted under this Agreement may be assigned to successors and assigns of the copyright holder, including to a corporate entity, without requiring additional consent from you.</p> </li> </ol>"},{"location":"CLA/#terms-and-conditions","title":"Terms and Conditions","text":""},{"location":"CLA/#1-definitions","title":"1. Definitions","text":"<p>\"You\" (or \"Your\") means the copyright owner or legal entity authorized by the copyright owner that is exercising rights under this Agreement.</p> <p>\"Contribution\" means any original work of authorship, including any modifications or additions to an existing work, that is intentionally submitted by You for inclusion in, or documentation of, the Project.</p> <p>\"Submitted\" means any form of electronic, verbal, or written communication sent to the Project Owner or their representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems.</p>"},{"location":"CLA/#2-grant-of-copyright-license","title":"2. Grant of Copyright License","text":"<p>Subject to the terms and conditions of this Agreement, You hereby grant to the Marsys Project copyright holder, their successors, and assigns, and to recipients of software distributed by the Project Owner:</p> <p>A perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to:</p> <ul> <li>Reproduce Your Contributions</li> <li>Prepare derivative works of Your Contributions</li> <li>Publicly display and publicly perform Your Contributions</li> <li>Sublicense Your Contributions (including to commercial and proprietary licensees)</li> <li>Distribute Your Contributions and derivative works in Source or Object form</li> </ul> <p>This license allows the Project Owner to include Your Contributions in both open-source and commercial/proprietary versions of the Project.</p>"},{"location":"CLA/#3-grant-of-patent-license","title":"3. Grant of Patent License","text":"<p>Subject to the terms and conditions of this Agreement, You hereby grant to the Marsys Project copyright holder, their successors, and assigns, and to recipients of software distributed by the Project Owner:</p> <p>A perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to:</p> <ul> <li>Make, have made, use, offer to sell, sell, import, and otherwise transfer Your Contributions</li> </ul> <p>This license applies only to those patent claims licensable by You that are necessarily infringed by Your Contribution(s) alone or by combination of Your Contribution(s) with the Project.</p> <p>If You or any entity You represent institutes patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Project or a Contribution incorporated within the Project constitutes direct or contributory patent infringement, then any patent licenses granted to You under this Agreement for that Project shall terminate as of the date such litigation is filed.</p>"},{"location":"CLA/#4-you-retain-authorship-credit","title":"4. You Retain Authorship Credit","text":"<p>You will be credited in the AUTHORS file for your contribution. This credit does NOT constitute copyright ownership. You retain the right to use Your Contributions for any purpose.</p>"},{"location":"CLA/#5-employer-rights-and-representations","title":"5. Employer Rights and Representations","text":"<p>You represent that:</p> <p>a) You are legally entitled to grant the above licenses.</p> <p>b) If Your employer(s) has rights to intellectual property that You create that includes Your Contributions, You represent that:    - You have received permission to make Contributions on behalf of that employer, OR    - Your employer has waived such rights for Your Contributions to the Project, OR    - Your employer has executed a separate Corporate Contributor License Agreement with the Project Owner.</p>"},{"location":"CLA/#6-original-work","title":"6. Original Work","text":"<p>You represent that:</p> <p>a) Each of Your Contributions is Your original creation (see Section 8 for submissions on behalf of others).</p> <p>b) Your Contribution submissions include complete details of any third-party license or other restriction (including, but not limited to, related patents and trademarks) of which You are personally aware and which are associated with any part of Your Contributions.</p>"},{"location":"CLA/#7-no-support-obligation","title":"7. No Support Obligation","text":"<p>You are not expected to provide support for Your Contributions, except to the extent You desire to provide support. You may provide support for free, for a fee, or not at all.</p>"},{"location":"CLA/#8-third-party-submissions","title":"8. Third-Party Submissions","text":"<p>Should You wish to submit work that is not Your original creation, You may submit it to the Project Owner separately from any Contribution, identifying the complete details of its source and of any license or other restriction (including, but not limited to, related patents, trademarks, and license agreements) of which You are personally aware, and conspicuously marking the work as:</p> <p>\"Submitted on behalf of a third-party: [named here]\"</p>"},{"location":"CLA/#9-notification-of-changes","title":"9. Notification of Changes","text":"<p>You agree to notify the Project Owner of any facts or circumstances of which You become aware that would make these representations inaccurate in any respect.</p>"},{"location":"CLA/#10-no-warranty","title":"10. No Warranty","text":"<p>Unless required by applicable law or agreed to in writing, You provide Your Contributions on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE.</p>"},{"location":"CLA/#how-to-sign-this-agreement","title":"How to Sign This Agreement","text":"<p>This CLA is signed electronically via CLA Assistant when you submit your first pull request to the Marsys repository.</p> <p>By clicking \"I Agree\" via CLA Assistant, you accept this Agreement, including the acknowledgment that: - You do NOT acquire copyright ownership through your contribution - The original author retains sole copyright ownership - All rights granted may be assigned to successors and assigns (including corporate entities)</p>"},{"location":"CLA/#questions","title":"Questions?","text":"<p>For questions about this Contributor License Agreement:</p> <p>Email: reza@marsys.ai GitHub: @rezaho</p> <p>For more information, see: - COPYRIGHT - Copyright ownership details - CONTRIBUTING.md - Contribution guidelines - LICENSE - Apache License 2.0 full text</p>"},{"location":"CLA_SETUP_GUIDE/","title":"CLA Assistant Setup Guide","text":"<p>This guide will walk you through setting up automated CLA signing for the Marsys project using GitHub Gist and CLA Assistant.</p>"},{"location":"CLA_SETUP_GUIDE/#overview","title":"Overview","text":"<p>When contributors submit their first pull request, they'll be automatically asked to sign the CLA. This is a one-time process that ensures you have the necessary rights to use their contributions in both open-source and commercial versions of Marsys.</p>"},{"location":"CLA_SETUP_GUIDE/#step-1-create-github-gist-with-cla-text","title":"Step 1: Create GitHub Gist with CLA Text","text":""},{"location":"CLA_SETUP_GUIDE/#11-navigate-to-github-gist","title":"1.1 Navigate to GitHub Gist","text":"<ol> <li>Go to gist.github.com</li> <li>Make sure you're logged in to your GitHub account (rezaho)</li> </ol>"},{"location":"CLA_SETUP_GUIDE/#12-create-new-gist","title":"1.2 Create New Gist","text":"<ol> <li>Click the \"+\" button in the top-right corner (or go directly to gist.github.com/new)</li> <li> <p>In the \"Gist description\" field, enter:    <pre><code>Marsys Individual Contributor License Agreement\n</code></pre></p> </li> <li> <p>In the \"Filename including extension\" field, enter:    <pre><code>CLA.md\n</code></pre></p> </li> <li> <p>In the text editor below, copy and paste the entire content from your <code>docs/CLA.md</code> file:</p> </li> <li>Open <code>/home/rezaho/research_projects/Multi-agent_AI_Learning/docs/CLA.md</code></li> <li>Copy all content (from \"# Marsys Individual Contributor License Agreement\" to the end)</li> <li> <p>Paste into the Gist editor</p> </li> <li> <p>Make sure \"Create public gist\" is selected (NOT secret)</p> </li> <li> <p>Public gists are required for CLA Assistant to work</p> </li> <li> <p>Click \"Create public gist\"</p> </li> </ol>"},{"location":"CLA_SETUP_GUIDE/#13-copy-gist-url","title":"1.3 Copy Gist URL","text":"<p>After creation, you'll see a URL like: <pre><code>https://gist.github.com/rezaho/a1b2c3d4e5f6g7h8i9j0\n</code></pre></p> <p>Important: Copy this full URL - you'll need it in the next step.</p> <p>Alternative Short URL: You can also use the shorter format: <pre><code>https://gist.github.com/a1b2c3d4e5f6g7h8i9j0\n</code></pre></p>"},{"location":"CLA_SETUP_GUIDE/#step-2-set-up-cla-assistant","title":"Step 2: Set Up CLA Assistant","text":""},{"location":"CLA_SETUP_GUIDE/#21-navigate-to-cla-assistant","title":"2.1 Navigate to CLA Assistant","text":"<ol> <li>Go to cla-assistant.io</li> <li>You'll see a landing page explaining the service</li> </ol>"},{"location":"CLA_SETUP_GUIDE/#22-sign-in-with-github","title":"2.2 Sign In with GitHub","text":"<ol> <li>Click \"Sign in with GitHub\"</li> <li>Authorize CLA Assistant to access your GitHub account</li> <li>It will request permissions to:<ul> <li>Read organization membership</li> <li>Access public repositories</li> <li>Access pull request information</li> <li>Add status checks</li> </ul> </li> <li>Click \"Authorize cla-assistant\"</li> </ol>"},{"location":"CLA_SETUP_GUIDE/#23-configure-your-repository","title":"2.3 Configure Your Repository","text":"<ol> <li>After authorization, you'll be redirected to the CLA Assistant dashboard</li> <li>Click \"Configure CLA\" or \"Link a repository\"</li> <li> <p>In the repository selection, enter:    <pre><code>rezaho/MARSYS\n</code></pre>    (Or select it from the dropdown if it appears)</p> </li> <li> <p>In the \"Gist URL\" field, paste the Gist URL you copied in Step 1.3:    <pre><code>https://gist.github.com/rezaho/a1b2c3d4e5f6g7h8i9j0\n</code></pre></p> </li> <li> <p>Optional Settings (recommended defaults):</p> </li> <li>\u2705 Enable CLA Assistant for this repository</li> <li>\u2705 Require all contributors to sign</li> <li>\u2705 Add comment to PRs</li> <li> <p>\u2705 Add status check to PRs</p> </li> <li> <p>Click \"Link\" or \"Save\"</p> </li> </ol>"},{"location":"CLA_SETUP_GUIDE/#24-verify-configuration","title":"2.4 Verify Configuration","text":"<p>You should see a confirmation message: <pre><code>\u2713 CLA Assistant is now active for rezaho/MARSYS\n</code></pre></p>"},{"location":"CLA_SETUP_GUIDE/#step-3-add-cla-assistant-badge-optional-but-recommended","title":"Step 3: Add CLA Assistant Badge (Optional but Recommended)","text":"<p>Add this badge to your <code>README.md</code> to show CLA status:</p> <pre><code>[![CLA assistant](https://cla-assistant.io/readme/badge/rezaho/MARSYS)](https://cla-assistant.io/rezaho/MARSYS)\n</code></pre> <p>This displays a badge showing CLA compliance status.</p>"},{"location":"CLA_SETUP_GUIDE/#step-4-test-the-setup","title":"Step 4: Test the Setup","text":""},{"location":"CLA_SETUP_GUIDE/#41-create-a-test-pr-optional","title":"4.1 Create a Test PR (Optional)","text":"<p>To verify everything works, you can:</p> <ol> <li> <p>Create a test branch:    <pre><code>git checkout -b test-cla-setup\n</code></pre></p> </li> <li> <p>Make a trivial change (e.g., add a comment to README.md)</p> </li> <li> <p>Commit and push:    <pre><code>git add .\ngit commit -m \"test: Verify CLA Assistant setup\"\ngit push origin test-cla-setup\n</code></pre></p> </li> <li> <p>Open a pull request from this branch</p> </li> <li> <p>Expected Behavior:</p> </li> <li>CLA Assistant bot will comment on the PR</li> <li>You'll see a status check: \"cla/cla-assistant \u2014 Waiting for all contributors to sign CLA\"</li> <li>A comment will appear with a link to sign the CLA</li> </ol>"},{"location":"CLA_SETUP_GUIDE/#42-what-contributors-will-see","title":"4.2 What Contributors Will See","text":"<p>When a new contributor opens a PR, they'll see:</p> <p>Comment from CLA Assistant Bot: <pre><code>Thank you for your submission! We ask that all contributors sign our\nContributor License Agreement before we can accept your contribution.\n\n1 out of 1 committers have signed the CLA.\n\n[\u2717] @username: You have not signed the CLA yet.\n\nPlease click here to review and sign the CLA.\n\nOnce you've signed, the status will update automatically.\n</code></pre></p> <p>Signing Process for Contributors: 1. Click the \"review and sign\" link 2. Redirected to CLA Assistant page showing the full CLA text 3. Scroll to bottom and click \"I Agree\" 4. Redirected back to GitHub 5. PR status updates automatically to \u2713</p>"},{"location":"CLA_SETUP_GUIDE/#step-5-monitor-cla-signatures","title":"Step 5: Monitor CLA Signatures","text":""},{"location":"CLA_SETUP_GUIDE/#51-view-all-signatures","title":"5.1 View All Signatures","text":"<ol> <li>Go to cla-assistant.io</li> <li>Sign in (if not already)</li> <li>Click on your repository: <code>rezaho/MARSYS</code></li> <li>You'll see a list of all contributors who have signed the CLA</li> </ol>"},{"location":"CLA_SETUP_GUIDE/#52-download-signature-records","title":"5.2 Download Signature Records","text":"<ul> <li>Click \"Download CSV\" to get a record of all signatures</li> <li>Store this securely for legal records</li> </ul>"},{"location":"CLA_SETUP_GUIDE/#troubleshooting","title":"Troubleshooting","text":""},{"location":"CLA_SETUP_GUIDE/#issue-cla-assistant-bot-doesnt-comment-on-pr","title":"Issue: CLA Assistant Bot Doesn't Comment on PR","text":"<p>Possible Causes: 1. Repository not linked correctly    - Solution: Go to cla-assistant.io and verify repository is listed</p> <ol> <li>Gist URL incorrect</li> <li> <p>Solution: Double-check Gist URL in CLA Assistant settings</p> </li> <li> <p>GitHub permissions not granted</p> </li> <li>Solution: Re-authorize CLA Assistant with necessary permissions</li> </ol>"},{"location":"CLA_SETUP_GUIDE/#issue-contributors-cant-sign-cla","title":"Issue: Contributors Can't Sign CLA","text":"<p>Possible Causes: 1. Gist is private instead of public    - Solution: Make Gist public or create a new public Gist</p> <ol> <li>Gist URL changed</li> <li>Solution: Update CLA Assistant configuration with new URL</li> </ol>"},{"location":"CLA_SETUP_GUIDE/#issue-status-check-not-updating-after-signing","title":"Issue: Status Check Not Updating After Signing","text":"<p>Possible Causes: 1. Contributor signed with different GitHub account    - Solution: Ensure they sign with the same account used for commits</p> <ol> <li>CLA Assistant needs refresh</li> <li>Solution: Close and reopen the PR, or post a new comment</li> </ol>"},{"location":"CLA_SETUP_GUIDE/#maintenance","title":"Maintenance","text":""},{"location":"CLA_SETUP_GUIDE/#updating-the-cla-text","title":"Updating the CLA Text","text":"<p>If you need to update the CLA:</p> <ol> <li>Edit the Gist:</li> <li>Go to your Gist at gist.github.com</li> <li>Click \"Edit\"</li> <li>Make changes to the CLA text</li> <li> <p>Click \"Update public gist\"</p> </li> <li> <p>Important: Existing signatures remain valid unless you explicitly invalidate them</p> </li> <li> <p>Versioning (Optional):</p> </li> <li>Add version number to CLA.md (e.g., \"Version 1.1\")</li> <li>Track changes in Gist revision history</li> <li>For major changes, consider creating a new Gist and updating CLA Assistant configuration</li> </ol>"},{"location":"CLA_SETUP_GUIDE/#managing-existing-contributors","title":"Managing Existing Contributors","text":"<p>Revoking a Signature: 1. Go to CLA Assistant dashboard 2. Find the contributor 3. Click \"Revoke\" (they'll need to re-sign)</p> <p>Manually Adding a Signature: 1. Use if contributor can't sign via web interface 2. Go to CLA Assistant dashboard 3. Click \"Add signature manually\" 4. Enter GitHub username 5. Record manual signature separately for legal records</p>"},{"location":"CLA_SETUP_GUIDE/#security-best-practices","title":"Security Best Practices","text":"<ol> <li>Backup Gist Content:</li> <li>Keep a local copy of <code>docs/CLA.md</code></li> <li> <p>Version control all CLA changes</p> </li> <li> <p>Download Signature Records Regularly:</p> </li> <li>Monthly download of CSV from CLA Assistant</li> <li> <p>Store securely for legal purposes</p> </li> <li> <p>Document Everything:</p> </li> <li>Keep records of when CLA was introduced</li> <li>Track any changes to CLA terms</li> <li> <p>Maintain audit trail for company transfer</p> </li> <li> <p>Monitor for Unusual Activity:</p> </li> <li>Check CLA Assistant dashboard weekly</li> <li>Verify legitimate signatures</li> <li>Report any suspicious activity to CLA Assistant support</li> </ol>"},{"location":"CLA_SETUP_GUIDE/#legal-considerations","title":"Legal Considerations","text":""},{"location":"CLA_SETUP_GUIDE/#when-company-is-established","title":"When Company Is Established","text":"<p>Once you establish your Swiss company (AG/GmbH):</p> <ol> <li>Update Copyright Holder:</li> <li>Option 1: Assign all rights to company (update LICENSE and CLA)</li> <li> <p>Option 2: Keep individual ownership, license to company</p> </li> <li> <p>Update CLA (if needed):</p> </li> <li>Change \"Marsys Project\" to company legal name</li> <li>Add company registration details</li> <li> <p>Existing CLAs remain valid due to \"successors and assigns\" clause</p> </li> <li> <p>Founder IP Assignment:</p> </li> <li>Draft agreement assigning personal IP to company</li> <li>Include all contributions before company formation</li> <li> <p>Have this reviewed by Swiss IP attorney</p> </li> <li> <p>Notify Contributors:</p> </li> <li>Inform about company formation</li> <li>Explain that existing CLAs cover this scenario</li> <li>No re-signing needed due to CLA language</li> </ol>"},{"location":"CLA_SETUP_GUIDE/#record-keeping","title":"Record Keeping","text":"<p>Maintain these records for legal compliance:</p> <ol> <li>CLA Signature Records:</li> <li>CSV exports from CLA Assistant</li> <li> <p>Store for 7+ years (Swiss record retention)</p> </li> <li> <p>CLA Version History:</p> </li> <li>All Gist revisions</li> <li>Dates of any changes</li> <li> <p>Rationale for modifications</p> </li> <li> <p>Founder Records:</p> </li> <li>Proof of sole authorship before open-sourcing</li> <li>Development timeline</li> <li>Initial commit records</li> </ol>"},{"location":"CLA_SETUP_GUIDE/#support","title":"Support","text":""},{"location":"CLA_SETUP_GUIDE/#cla-assistant-support","title":"CLA Assistant Support","text":"<ul> <li>Documentation: cla-assistant.io/documentation</li> <li>GitHub Issues: github.com/cla-assistant/cla-assistant</li> <li>Email: support@cla-assistant.io</li> </ul>"},{"location":"CLA_SETUP_GUIDE/#quick-reference","title":"Quick Reference","text":""},{"location":"CLA_SETUP_GUIDE/#key-urls","title":"Key URLs","text":"<ul> <li>CLA Assistant: https://cla-assistant.io</li> <li>Your CLA Gist: https://gist.github.com/rezaho/[YOUR-GIST-ID]</li> <li>Repository CLA Dashboard: https://cla-assistant.io/rezaho/MARSYS</li> </ul>"},{"location":"CLA_SETUP_GUIDE/#important-files-in-marsys-repo","title":"Important Files in Marsys Repo","text":"<ul> <li><code>/LICENSE</code> - Apache 2.0 license</li> <li><code>/COPYRIGHT</code> - Copyright ownership clarification</li> <li><code>/AUTHORS</code> - Contributor attribution</li> <li><code>/docs/CLA.md</code> - Full CLA text (source of truth)</li> <li><code>/CONTRIBUTING.md</code> - Contribution guidelines</li> </ul>"},{"location":"CLA_SETUP_GUIDE/#cla-signature-process","title":"CLA Signature Process","text":"<ol> <li>Contributor opens PR \u2192 CLA bot comments</li> <li>Contributor clicks link \u2192 Reviews CLA</li> <li>Contributor clicks \"I Agree\" \u2192 Signature recorded</li> <li>PR status updates to \u2713 \u2192 Contribution can be merged</li> </ol>"},{"location":"CLA_SETUP_GUIDE/#checklist","title":"Checklist","text":"<p>Use this checklist to verify setup:</p> <ul> <li> Created public GitHub Gist with CLA.md content</li> <li> Copied Gist URL</li> <li> Signed in to CLA Assistant with GitHub</li> <li> Linked MARSYS repository</li> <li> Configured Gist URL in CLA Assistant</li> <li> Enabled CLA requirement for all contributors</li> <li> Added CLA badge to README.md (optional)</li> <li> Tested with sample PR (optional)</li> <li> Verified CLA Assistant bot comments on PR</li> <li> Downloaded initial signature record</li> <li> Documented Gist URL in secure location</li> <li> Backed up CLA.md locally</li> </ul> <p>Setup Complete! Your CLA process is now automated. New contributors will be prompted to sign before their first contribution can be merged.</p> <p>For questions about this setup, contact: reza@marsys.ai</p>"},{"location":"api/agent-class/","title":"Agent Class API Reference","text":"<p>Complete API documentation for the Agent classes in MARSYS, including BaseAgent, Agent, BrowserAgent, CodeExecutionAgent, DataAnalysisAgent, and AgentPool.</p> <p>Architecture &amp; Patterns</p> <p>For architectural overview, design patterns, and best practices, see Agents Concept Guide.</p>"},{"location":"api/agent-class/#baseagent","title":"\ud83d\udce6 BaseAgent","text":"<p>Abstract base class that all agents must inherit from.</p>"},{"location":"api/agent-class/#class-definition","title":"Class Definition","text":"<pre><code>from abc import ABC, abstractmethod\nfrom typing import Optional, Dict, List, Any, Union, Callable\nfrom marsys.agents.memory import ConversationMemory, Message\nfrom marsys.agents.planning import PlanningConfig\n\nclass BaseAgent(ABC):\n    \"\"\"Abstract base class for all agents.\"\"\"\n\n    def __init__(\n        self,\n        model: Union[BaseLocalModel, BaseAPIModel],\n        name: str,\n        goal: str,\n        instruction: str,\n        tools: Optional[Dict[str, Callable]] = None,\n        max_tokens: Optional[int] = 10000,\n        allowed_peers: Optional[List[str]] = None,\n        bidirectional_peers: bool = False,\n        is_convergence_point: Optional[bool] = None,\n        input_schema: Optional[Any] = None,\n        output_schema: Optional[Any] = None,\n        memory_retention: str = \"session\",\n        memory_storage_path: Optional[str] = None,\n        plan_config: Optional[Union[PlanningConfig, Dict, bool]] = None\n    ):\n        \"\"\"\n        Initialize base agent.\n\n        Args:\n            model: Language model instance (BaseLocalModel or BaseAPIModel)\n            goal: 1-2 sentence summary of what the agent accomplishes\n            instruction: Detailed instructions on how the agent should behave\n            tools: Dictionary of tool functions\n            max_tokens: Maximum response tokens\n            name: Unique agent identifier\n            allowed_peers: List of agents this can invoke\n            memory_retention: Memory policy (single_run, session, persistent)\n            input_schema: Pydantic schema for input validation\n            output_schema: Pydantic schema for output validation\n            plan_config: Planning configuration. PlanningConfig instance, dict of\n                config values, True/None (enabled with defaults), or False (disabled).\n                Planning is enabled by default. See [Task Planning](../concepts/planning.md).\n        \"\"\"\n</code></pre>"},{"location":"api/agent-class/#abstract-methods","title":"Abstract Methods","text":"<pre><code>@abstractmethod\nasync def _run(\n    self,\n    prompt: Any,\n    context: Dict[str, Any],\n    **kwargs\n) -&gt; Message:\n    \"\"\"\n    Pure execution logic - must be implemented by subclasses.\n\n    Args:\n        prompt: Input prompt or message\n        context: Execution context\n        **kwargs: Additional parameters\n\n    Returns:\n        Message object with response\n\n    Note:\n        This method must be pure - no side effects allowed!\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/agent-class/#public-methods","title":"Public Methods","text":""},{"location":"api/agent-class/#runprompt-contextnone-kwargs-message","title":"<code>run(prompt, context=None, **kwargs) -&gt; Message</code>","text":"<p>Public interface for agent execution.</p> <pre><code>async def run(\n    self,\n    prompt: Union[str, Message, Dict],\n    context: Optional[Dict[str, Any]] = None,\n    **kwargs\n) -&gt; Message:\n    \"\"\"\n    Execute agent with automatic context management.\n\n    Args:\n        prompt: Input prompt, message, or structured data\n        context: Optional execution context\n        **kwargs: Additional parameters\n\n    Returns:\n        Message with agent response\n    \"\"\"\n</code></pre>"},{"location":"api/agent-class/#cleanup-none","title":"<code>cleanup() -&gt; None</code>","text":"<p>Clean up agent resources (model sessions, tools, browser handles, etc.).</p> <pre><code>async def cleanup(self) -&gt; None:\n    \"\"\"\n    Clean up agent resources.\n\n    Called automatically by Orchestra at end of run if auto_cleanup_agents=True.\n    Can be overridden by subclasses for custom cleanup logic.\n\n    Default implementation:\n    1. Closes model async resources (aiohttp sessions, etc.)\n    2. Calls agent-specific close() if available (e.g., BrowserAgent.close())\n\n    Example override:\n        async def cleanup(self):\n            # Custom cleanup\n            await self.custom_resource.close()\n            # Call parent cleanup\n            await super().cleanup()\n    \"\"\"\n</code></pre> <p>Automatic Cleanup:</p> <p>The framework automatically calls <code>cleanup()</code> on all topology agents after <code>Orchestra.run()</code> completes (unless <code>auto_cleanup_agents=False</code>).</p> <p>Manual Cleanup:</p> <pre><code># Create agent\nagent = Agent(\n    name=\"my_agent\",\n    model_config=config,\n    goal=\"Process data efficiently\",\n    instruction=\"You are a data processing agent. Handle data operations as requested.\"\n)\n\n# Use agent\nresult = await agent.run(\"Process data\")\n\n# Manual cleanup when done\nawait agent.cleanup()\n\n# Unregister from registry (identity-safe)\nfrom marsys.agents.registry import AgentRegistry\nAgentRegistry.unregister_if_same(\"my_agent\", agent)\n</code></pre>"},{"location":"api/agent-class/#save_statefilepath-str-none","title":"<code>save_state(filepath: str) -&gt; None</code>","text":"<p>Save agent state to disk, including memory and planning state.</p> <pre><code>agent.save_state(\"./state/agent_state.json\")\n</code></pre> <p>What gets saved: - Memory contents - Planning state (current plan + planning config) - Tool schema version for cache invalidation</p>"},{"location":"api/agent-class/#load_statefilepath-str-none","title":"<code>load_state(filepath: str) -&gt; None</code>","text":"<p>Load agent state from disk. This restores memory and planning state.</p> <pre><code>agent.load_state(\"./state/agent_state.json\")\n</code></pre> <p>Notes: - Planning state temporarily unsubscribes from <code>MemoryResetEvent</code> during load to avoid race conditions. - If planning is disabled (<code>plan_config=False</code>), only memory is restored.</p>"},{"location":"api/agent-class/#agent","title":"\ud83e\udd16 Agent","text":"<p>Standard agent implementation with built-in capabilities.</p>"},{"location":"api/agent-class/#class-definition_1","title":"Class Definition","text":"<pre><code>from marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\nclass Agent(BaseAgent):\n    \"\"\"Standard agent with full framework capabilities.\"\"\"\n\n    def __init__(\n        self,\n        model_config: ModelConfig,\n        goal: str,\n        instruction: str,\n        tools: Optional[Dict[str, Callable[..., Any]]] = None,\n        memory_type: Optional[str] = \"managed_conversation\",\n        memory_config: Optional[ManagedMemoryConfig] = None,\n        compaction_model_config: Optional[ModelConfig] = None,\n        max_tokens: Optional[int] = None,\n        name: Optional[str] = None,\n        allowed_peers: Optional[List[str]] = None,\n        bidirectional_peers: bool = False,\n        input_schema: Optional[Any] = None,\n        output_schema: Optional[Any] = None,\n        memory_retention: str = \"session\",\n        memory_storage_path: Optional[str] = None,\n        plan_config: Optional[Union[PlanningConfig, Dict, bool]] = None\n    ):\n        \"\"\"\n        Initialize agent with model configuration.\n\n        Args:\n            model_config: ModelConfig instance\n            goal: 1-2 sentence summary of what this agent accomplishes\n            instruction: Detailed instructions on how the agent should behave\n            tools: Dictionary of tool functions\n            memory_type: Type of memory module to use (default: managed_conversation)\n            memory_config: Optional configuration for managed memory behavior\n            compaction_model_config: Optional ModelConfig for a separate compaction model\n            max_tokens: Maximum response tokens (None uses ModelConfig default)\n            name: Unique identifier for registration\n            allowed_peers: List of agent names this agent can invoke\n            bidirectional_peers: If True, creates bidirectional edges with allowed_peers\n            input_schema: Input validation schema\n            output_schema: Output validation schema\n            memory_retention: Memory persistence policy (single_run, session, persistent)\n            memory_storage_path: Path for persistent memory storage\n            plan_config: Planning configuration. PlanningConfig instance, dict of\n                config values, True/None (enabled with defaults), or False (disabled).\n                Planning is enabled by default. See [Task Planning](../concepts/planning.md).\n        \"\"\"\n</code></pre>"},{"location":"api/agent-class/#key-methods","title":"Key Methods","text":""},{"location":"api/agent-class/#auto_runinitial_prompt-contextnone-max_steps10-kwargs","title":"<code>auto_run(initial_prompt, context=None, max_steps=10, **kwargs)</code>","text":"<p>Execute agent autonomously with tool and agent invocation.</p> <pre><code>async def auto_run(\n    self,\n    initial_prompt: str,\n    context: Optional[RequestContext] = None,\n    max_steps: int = 10,\n    max_re_prompts: int = 3,\n    run_async: bool = False,\n    **kwargs\n) -&gt; Union[Message, str]:\n    \"\"\"\n    Run agent autonomously with automatic tool/agent invocation.\n\n    Args:\n        initial_prompt: Starting prompt\n        context: Request context for tracking\n        max_steps: Maximum execution steps\n        max_re_prompts: Maximum reprompt attempts\n        run_async: Enable async execution\n        **kwargs: Additional parameters\n\n    Returns:\n        Final response as Message or string\n\n    Example:\n        response = await agent.auto_run(\n            \"Research and summarize recent AI breakthroughs\",\n            max_steps=5\n        )\n    \"\"\"\n</code></pre>"},{"location":"api/agent-class/#usage-examples","title":"Usage Examples","text":"<pre><code>from marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\n# Basic agent\nassistant = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        provider=\"openrouter\",\n        name=\"anthropic/claude-opus-4.6\",\n        temperature=0.7,\n        max_tokens=12000\n    ),\n    name=\"assistant\",\n    goal=\"Provide helpful assistance to users\",\n    instruction=\"A helpful AI assistant that responds thoughtfully to queries\"\n)\n\n# Agent with tools\ndef calculate(expression: str) -&gt; float:\n    \"\"\"Evaluate mathematical expression.\"\"\"\n    return eval(expression)\n\ncalculator = Agent(\n    model_config=config,\n    goal=\"Perform mathematical calculations accurately\",\n    instruction=\"You are a precise calculator. Always use the calculate tool for math.\",\n    tools={\"calculate\": calculate},\n    name=\"calculator\"\n)\n\n# Multi-agent coordinator\ncoordinator = Agent(\n    model_config=config,\n    name=\"coordinator\",\n    goal=\"Coordinate tasks between specialized agents\",\n    instruction=\"I coordinate tasks between specialized agents and synthesize results\",\n    allowed_peers=[\"researcher\", \"writer\", \"calculator\"]\n)\n\n# Agent with separate compaction model\nagent_with_compaction_model = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        provider=\"openrouter\",\n        name=\"anthropic/claude-opus-4.6\",\n    ),\n    compaction_model_config=ModelConfig(\n        type=\"api\",\n        provider=\"openrouter\",\n        name=\"anthropic/claude-haiku-4.5\",\n    ),\n    goal=\"Long-running research and synthesis\",\n    instruction=\"You are a research assistant.\"\n)\n</code></pre>"},{"location":"api/agent-class/#browseragent","title":"\ud83c\udf10 BrowserAgent","text":"<p>Specialized agent for web automation and scraping.</p>"},{"location":"api/agent-class/#class-definition_2","title":"Class Definition","text":"<pre><code>from marsys.agents import BrowserAgent\nfrom marsys.models import ModelConfig\n\nclass BrowserAgent(Agent):\n    \"\"\"Agent with browser automation capabilities.\"\"\"\n\n    def __init__(\n        self,\n        model_config: ModelConfig,\n        name: str,\n        goal: Optional[str] = None,\n        instruction: Optional[str] = None,\n        mode: str = \"advanced\",\n        headless: bool = True,\n        viewport_width: Optional[int] = None,\n        viewport_height: Optional[int] = None,\n        tmp_dir: Optional[str] = None,\n        vision_model_config: Optional[ModelConfig] = None,\n        auto_screenshot: bool = False,\n        element_detection_mode: str = \"auto\",\n        timeout: int = 5000,\n        show_mouse_helper: bool = True,\n        session_path: Optional[str] = None,\n        filesystem: Optional[\"RunFileSystem\"] = None,\n        downloads_subdir: str = \"downloads\",\n        downloads_virtual_dir: str = \"./downloads\",\n        fetch_file_tool_name: str = \"download_file\",\n        plan_config: Optional[Union[PlanningConfig, Dict, bool]] = None,\n        **kwargs\n    ):\n        \"\"\"\n        Initialize browser agent.\n\n        Args:\n            model_config: Model configuration\n            name: Unique identifier\n            goal: Agent's purpose (defaults to web automation)\n            instruction: Detailed behavior instructions\n            mode: Browser mode (\"primitive\" for extraction, \"advanced\" for visual interaction)\n            headless: Run without UI\n            viewport_width: Optional viewport width (auto-detected if omitted)\n            viewport_height: Optional viewport height (auto-detected if omitted)\n            tmp_dir: Run root directory for downloads/screenshots/artifacts\n            vision_model_config: Optional dedicated vision model config\n            auto_screenshot: Auto-screenshot after actions (advanced mode only)\n            element_detection_mode: \"auto\", \"rule_based\", \"vision\", or \"both\"\n            timeout: Browser operation timeout in milliseconds\n            show_mouse_helper: Visual cursor helper in advanced mode\n            session_path: Optional storage-state JSON for restoring browser session\n            filesystem: Optional shared RunFileSystem for unified path resolution\n            downloads_subdir: Host downloads subdirectory under tmp_dir\n            downloads_virtual_dir: Virtual path returned to the agent for downloads\n            fetch_file_tool_name: Tool name alias for file-download action\n            plan_config: Planning configuration. PlanningConfig instance, dict of\n                config values, True/None (enabled with defaults), or False (disabled).\n                Planning is enabled by default. See [Task Planning](../concepts/planning.md).\n            **kwargs: Additional parameters\n        \"\"\"\n</code></pre>"},{"location":"api/agent-class/#creation-methods","title":"Creation Methods","text":"<pre><code>@classmethod\nasync def create_safe(\n    cls,\n    model_config: ModelConfig,\n    name: str,\n    goal: Optional[str] = None,\n    instruction: Optional[str] = None,\n    mode: str = \"advanced\",\n    headless: bool = True,\n    viewport_width: Optional[int] = None,\n    viewport_height: Optional[int] = None,\n    tmp_dir: Optional[str] = None,\n    vision_model_config: Optional[ModelConfig] = None,\n    auto_screenshot: bool = False,\n    element_detection_mode: str = \"auto\",\n    timeout: int = 5000,\n    session_path: Optional[str] = None,\n    filesystem: Optional[\"RunFileSystem\"] = None,\n    show_mouse_helper: bool = True,\n    downloads_subdir: str = \"downloads\",\n    downloads_virtual_dir: str = \"./downloads\",\n    fetch_file_tool_name: str = \"download_file\",\n    **kwargs\n) -&gt; \"BrowserAgent\":\n    \"\"\"\n    Safely create browser agent with initialization.\n\n    Returns:\n        Initialized BrowserAgent instance\n\n    Example:\n        browser = await BrowserAgent.create_safe(\n            model_config=config,\n            name=\"web_scraper\",\n            headless=True\n        )\n    \"\"\"\n</code></pre> <p>Artifact path notes: - <code>tmp_dir</code> acts as the run root for browser artifacts. - <code>downloads_subdir</code> controls host folder placement under <code>tmp_dir</code>. - <code>downloads_virtual_dir</code> controls the virtual path shown to agents. - <code>fetch_file_tool_name</code> lets you expose <code>download_file</code> under a custom tool name.</p> <p>Viewport auto-detection (when width/height are omitted): - Google/Gemini models: <code>1000x1000</code> - Anthropic/Claude models: <code>1344x896</code> - OpenAI/GPT models: <code>1024x768</code> - Fallback: <code>1536x1536</code></p>"},{"location":"api/agent-class/#browser-specific-methods","title":"Browser-Specific Methods","text":"<pre><code># Navigation\nawait browser.browser_tool.goto(\"https://example.com\")\nawait browser.browser_tool.go_back()\nawait browser.browser_tool.reload()\n\n# Interaction\nawait browser.browser_tool.mouse_click(450, 300)\nawait browser.browser_tool.keyboard_input(\"search term\")\nawait browser.browser_tool.keyboard_press(\"Enter\")\n\n# Extraction\nmetadata = await browser.browser_tool.get_page_metadata()\nelements = await browser.browser_tool.get_page_elements()\n\n# Downloads and screenshots\ndownloads = await browser.browser_tool.list_downloads()\nshot = await browser.browser_tool.screenshot()\n\n# Cleanup\nawait browser.cleanup()\n</code></pre>"},{"location":"api/agent-class/#usage-example","title":"Usage Example","text":"<pre><code>browser_agent = await BrowserAgent.create_safe(\n    model_config=config,\n    name=\"scraper\",\n    mode=\"primitive\",\n    headless=True,\n    tmp_dir=\"./runs/run-20260206\",\n    downloads_virtual_dir=\"./downloads\",\n    fetch_file_tool_name=\"fetch_file\",\n)\n\ntry:\n    result = await browser_agent.auto_run(\"Go to example.com and summarize key content\", max_steps=3)\nfinally:\n    await browser_agent.cleanup()\n</code></pre>"},{"location":"api/agent-class/#codeexecutionagent","title":"\ud83d\udcbb CodeExecutionAgent","text":"<p>Specialized agent that combines file operations with controlled Python/shell execution.</p>"},{"location":"api/agent-class/#class-definition_3","title":"Class Definition","text":"<pre><code>from marsys.agents import CodeExecutionAgent\nfrom marsys.environment.code import CodeExecutionConfig\n\nclass CodeExecutionAgent(Agent):\n    def __init__(\n        self,\n        model_config: ModelConfig,\n        name: str,\n        goal: Optional[str] = None,\n        instruction: Optional[str] = None,\n        working_directory: Optional[str] = None,  # Deprecated\n        base_directory: Optional[Path] = None,\n        code_config: Optional[CodeExecutionConfig] = None,\n        filesystem: Optional[\"RunFileSystem\"] = None,\n        **kwargs\n    ):\n        ...\n</code></pre> <p>Behavior notes: - Combines <code>FileOperationTools</code> with <code>CodeExecutionTools</code>. - Exposes <code>python_execute</code> and <code>shell_execute</code>. - Uses shared <code>RunFileSystem</code> when <code>filesystem</code> is provided.</p>"},{"location":"api/agent-class/#usage-example_1","title":"Usage Example","text":"<pre><code>agent = CodeExecutionAgent(\n    model_config=config,\n    name=\"CodeRunner\",\n    code_config=CodeExecutionConfig(\n        timeout_default=30,\n        max_memory_mb=1024,\n        allow_network=False,\n    ),\n)\n\nresult = await agent.auto_run(\"Run unit tests and summarize failures\", max_steps=6)\nawait agent.cleanup()\n</code></pre>"},{"location":"api/agent-class/#dataanalysisagent","title":"\ud83d\udcca DataAnalysisAgent","text":"<p>Specialized agent for iterative data-science style workflows.</p>"},{"location":"api/agent-class/#class-definition_4","title":"Class Definition","text":"<pre><code>from marsys.agents import DataAnalysisAgent\nfrom marsys.environment.code import CodeExecutionConfig\n\nclass DataAnalysisAgent(Agent):\n    def __init__(\n        self,\n        model_config: ModelConfig,\n        name: str,\n        goal: Optional[str] = None,\n        instruction: Optional[str] = None,\n        working_directory: Optional[str] = None,  # Deprecated\n        base_directory: Optional[Path] = None,\n        code_config: Optional[CodeExecutionConfig] = None,\n        filesystem: Optional[\"RunFileSystem\"] = None,\n        **kwargs\n    ):\n        ...\n</code></pre> <p>Behavior notes: - Forces persistent Python session (<code>session_persistent_python=True</code>). - Keeps notebook-like state across <code>python_execute</code> calls. - Includes file and shell tools alongside persistent Python execution.</p>"},{"location":"api/agent-class/#usage-example_2","title":"Usage Example","text":"<pre><code>agent = DataAnalysisAgent(\n    model_config=config,\n    name=\"Analyst\",\n)\n\nresult = await agent.auto_run(\n    \"Load sales.csv, find trends, and save a chart to ./outputs\",\n    max_steps=8\n)\nawait agent.cleanup()\n</code></pre>"},{"location":"api/agent-class/#agentpool","title":"\ud83c\udfca AgentPool","text":"<p>Manages multiple agent instances for parallel execution.</p>"},{"location":"api/agent-class/#class-definition_5","title":"Class Definition","text":"<pre><code>from marsys.agents import AgentPool\nfrom typing import Type, Optional, Any\nimport asyncio\n\nclass AgentPool:\n    \"\"\"Pool of agent instances for parallel execution.\"\"\"\n\n    def __init__(\n        self,\n        agent_class: Type,\n        num_instances: int,\n        *args,\n        **kwargs\n    ):\n        \"\"\"\n        Initialize agent pool.\n\n        Args:\n            agent_class: Agent class to instantiate\n            num_instances: Number of pool instances\n            *args: Positional constructor arguments passed to each agent instance\n            **kwargs: Keyword constructor arguments passed to each agent instance\n        \"\"\"\n</code></pre>"},{"location":"api/agent-class/#key-methods_1","title":"Key Methods","text":""},{"location":"api/agent-class/#acquirebranch_idnone","title":"<code>acquire(branch_id=None)</code>","text":"<p>Acquire agent instance from pool.</p> <pre><code>async def acquire(\n    self,\n    branch_id: Optional[str] = None,\n    timeout: float = 30.0\n) -&gt; AsyncContextManager[BaseAgent]:\n    \"\"\"\n    Acquire agent from pool with context manager.\n\n    Args:\n        branch_id: Optional branch identifier\n        timeout: Acquisition timeout in seconds\n\n    Returns:\n        Context manager yielding agent instance\n\n    Example:\n        async with pool.acquire(\"branch_1\") as agent:\n            result = await agent.run(\"Task description\")\n    \"\"\"\n</code></pre>"},{"location":"api/agent-class/#get_statistics","title":"<code>get_statistics()</code>","text":"<p>Get pool usage statistics.</p> <pre><code>def get_statistics(self) -&gt; Dict[str, Any]:\n    \"\"\"\n    Get pool statistics.\n\n    Returns:\n        Dictionary with:\n        - total_instances: Pool size\n        - available: Available instances\n        - in_use: Currently allocated\n        - total_allocations: Historical count\n        - average_wait_time: Avg acquisition wait\n    \"\"\"\n</code></pre>"},{"location":"api/agent-class/#usage-example_3","title":"Usage Example","text":"<pre><code>from marsys.agents import AgentPool, BrowserAgent\n\n# Create pool of browser agents\nbrowser_pool = AgentPool(\n    agent_class=BrowserAgent,\n    num_instances=3,\n    model_config=config,\n    name=\"BrowserPool\",\n    headless=True\n)\n\n# Parallel scraping\nasync def scrape_url(url: str, branch_id: str):\n    async with browser_pool.acquire(branch_id) as agent:\n        return await agent.run(f\"Scrape content from {url}\")\n\n# Execute in parallel\nurls = [\"http://site1.com\", \"http://site2.com\", \"http://site3.com\"]\ntasks = [\n    scrape_url(url, f\"branch_{i}\")\n    for i, url in enumerate(urls)\n]\nresults = await asyncio.gather(*tasks)\n\n# Cleanup pool\nawait browser_pool.cleanup()\n\n# Check statistics\nstats = browser_pool.get_statistics()\nprint(f\"Total allocations: {stats['total_allocations']}\")\n</code></pre>"},{"location":"api/agent-class/#custom-agents","title":"\ud83e\udde9 Custom Agents","text":"<p>Create specialized agents by subclassing BaseAgent.</p>"},{"location":"api/agent-class/#example-custom-agent","title":"Example Custom Agent","text":"<pre><code>from marsys.agents import BaseAgent\nfrom marsys.agents.memory import Message\nfrom typing import Dict, Any\n\nclass AnalysisAgent(BaseAgent):\n    \"\"\"Custom agent for data analysis.\"\"\"\n\n    def __init__(self, model, **kwargs):\n        super().__init__(\n            model=model,\n            goal=\"Analyze data and provide insights\",\n            instruction=\"Data analysis specialist with multiple analysis methods\",\n            **kwargs\n        )\n        self.analysis_methods = [\"statistical\", \"trend\", \"anomaly\"]\n\n    async def _run(\n        self,\n        prompt: Any,\n        context: Dict[str, Any],\n        **kwargs\n    ) -&gt; Message:\n        \"\"\"\n        Pure execution logic for analysis.\n\n        Note: Must be pure - no side effects!\n        \"\"\"\n        # Prepare messages\n        messages = self._prepare_messages(prompt)\n\n        # Add analysis context\n        analysis_type = context.get(\"analysis_type\", \"statistical\")\n        if analysis_type in self.analysis_methods:\n            messages.append({\n                \"role\": \"system\",\n                \"content\": f\"Perform {analysis_type} analysis\"\n            })\n\n        # Execute model\n        response = await self.model.run(messages)\n\n        # Return pure Message\n        return Message(\n            role=\"assistant\",\n            content=response[\"content\"]\n        )\n\n    async def analyze_dataset(\n        self,\n        data: List[float],\n        method: str = \"statistical\"\n    ) -&gt; Dict[str, Any]:\n        \"\"\"\n        High-level analysis method.\n        \"\"\"\n        prompt = f\"Analyze this dataset: {data}\"\n        context = {\"analysis_type\": method}\n\n        result = await self.run(prompt, context)\n\n        # Parse and structure results\n        return {\n            \"method\": method,\n            \"results\": result.content\n        }\n</code></pre>"},{"location":"api/agent-class/#agent-configuration","title":"\ud83d\udcca Agent Configuration","text":""},{"location":"api/agent-class/#memory-retention-policies","title":"Memory Retention Policies","text":"Policy Description Use Case <code>single_run</code> Clear after each run Stateless operations <code>session</code> Maintain for workflow Multi-step tasks <code>persistent</code> Save to disk Long-term memory"},{"location":"api/agent-class/#tool-registration","title":"Tool Registration","text":"<pre><code># Function with proper docstring\ndef search(query: str, limit: int = 5) -&gt; List[str]:\n    \"\"\"\n    Search for information.\n\n    Args:\n        query: Search query\n        limit: Maximum results\n\n    Returns:\n        List of results\n    \"\"\"\n    return [\"result1\", \"result2\"]\n\n# Auto-schema generation\nagent = Agent(\n    model_config=config,\n    goal=\"Search for relevant information\",\n    instruction=\"Use search for retrieval requests.\",\n    tools={\"search\": search}  # Schema auto-generated\n)\n\n# Or with custom names\nagent = Agent(\n    model_config=config,\n    goal=\"Search the web for evidence\",\n    instruction=\"Use web_search for web retrieval requests.\",\n    tools={\"web_search\": search}\n)\n</code></pre>"},{"location":"api/agent-class/#error-handling","title":"\ud83d\udee1\ufe0f Error Handling","text":"<pre><code>from marsys.agents.exceptions import (\n    AgentError,\n    AgentNotFoundError,\n    AgentPermissionError,\n    AgentExecutionError\n)\n\ntry:\n    result = await agent.run(prompt)\n\nexcept AgentPermissionError as e:\n    print(f\"Permission denied: {e.target_agent}\")\n\nexcept AgentExecutionError as e:\n    print(f\"Execution failed: {e.message}\")\n\nexcept AgentError as e:\n    print(f\"Agent error: {e}\")\n</code></pre>"},{"location":"api/agent-class/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>Concepts: Agents - Agent architecture</li> <li>Models API - Model configuration</li> <li>Memory - Memory management</li> <li>Tools - Tool integration</li> </ul>"},{"location":"api/communication/","title":"Communication API","text":"<p>Complete API reference for the user interaction and communication system in multi-agent workflows.</p>"},{"location":"api/communication/#overview","title":"\ud83c\udfaf Overview","text":"<p>The Communication API provides bi-directional user interaction capabilities, supporting synchronous terminal interactions, asynchronous web interfaces, and event-driven communication patterns.</p>"},{"location":"api/communication/#core-classes","title":"\ud83d\udce6 Core Classes","text":""},{"location":"api/communication/#communicationmanager","title":"CommunicationManager","text":"<p>Central manager for user communication across different channels.</p> <p>Import: <pre><code>from marsys.coordination.communication import CommunicationManager\nfrom marsys.coordination.config import CommunicationConfig\n</code></pre></p> <p>Constructor: <pre><code>CommunicationManager(\n    config: Optional[CommunicationConfig] = None\n)\n</code></pre></p> <p>Key Methods:</p>"},{"location":"api/communication/#register_channel","title":"register_channel","text":"<p><pre><code>def register_channel(channel: CommunicationChannel) -&gt; None\n</code></pre> Register a communication channel.</p>"},{"location":"api/communication/#request_user_input","title":"request_user_input","text":"<p><pre><code>async def request_user_input(\n    prompt: str,\n    session_id: str,\n    channel_id: Optional[str] = None,\n    timeout: Optional[float] = None,\n    metadata: Optional[Dict[str, Any]] = None\n) -&gt; str\n</code></pre> Request input from user.</p> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>prompt</code> | <code>str</code> | Prompt to display | Required | | <code>session_id</code> | <code>str</code> | Session identifier | Required | | <code>channel_id</code> | <code>str</code> | Target channel | Auto-select | | <code>timeout</code> | <code>float</code> | Input timeout | From config | | <code>metadata</code> | <code>Dict</code> | Additional metadata | <code>None</code> |</p>"},{"location":"api/communication/#send_message","title":"send_message","text":"<p><pre><code>async def send_message(\n    message: str,\n    session_id: str,\n    channel_id: Optional[str] = None,\n    message_type: str = \"info\"\n) -&gt; None\n</code></pre> Send message to user.</p>"},{"location":"api/communication/#subscribe","title":"subscribe","text":"<p><pre><code>def subscribe(\n    topic: str,\n    callback: Callable[[Any], None]\n) -&gt; str\n</code></pre> Subscribe to communication events.</p> <p>Example: <pre><code># Initialize manager\nconfig = CommunicationConfig(\n    use_rich_formatting=True,\n    theme_name=\"modern\"\n)\nmanager = CommunicationManager(config)\n\n# Request user input\nresponse = await manager.request_user_input(\n    prompt=\"What would you like to analyze?\",\n    session_id=\"session_123\"\n)\n\n# Send message\nawait manager.send_message(\n    message=\"Analysis complete!\",\n    session_id=\"session_123\",\n    message_type=\"success\"\n)\n</code></pre></p>"},{"location":"api/communication/#usernodehandler","title":"UserNodeHandler","text":"<p>Handles execution when control reaches a User node in topology.</p> <p>Import: <pre><code>from marsys.coordination.communication import UserNodeHandler\n</code></pre></p> <p>Constructor: <pre><code>UserNodeHandler(\n    communication_manager: CommunicationManager,\n    event_bus: Optional[EventBus] = None\n)\n</code></pre></p> <p>Key Methods:</p>"},{"location":"api/communication/#handle_user_node","title":"handle_user_node","text":"<p><pre><code>async def handle_user_node(\n    branch: ExecutionBranch,\n    incoming_message: Any,\n    context: Dict[str, Any]\n) -&gt; StepResult\n</code></pre> Handle User node execution.</p> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>branch</code> | <code>ExecutionBranch</code> | Current execution branch | Required | | <code>incoming_message</code> | <code>Any</code> | Message from calling agent | Required | | <code>context</code> | <code>Dict</code> | Execution context | Required |</p> <p>Returns: <code>StepResult</code> with user response and routing decision</p> <p>Example: <pre><code>handler = UserNodeHandler(communication_manager)\n\n# Handle user interaction\nresult = await handler.handle_user_node(\n    branch=current_branch,\n    incoming_message=\"Please approve the analysis results\",\n    context={\"session_id\": \"session_123\"}\n)\n\n# Process result\nif result.success:\n    user_response = result.data[\"response\"]\n    next_agent = result.data.get(\"next_agent\")\n</code></pre></p>"},{"location":"api/communication/#communicationchannel-abstract","title":"CommunicationChannel (Abstract)","text":"<p>Base class for communication channels.</p> <p>Import: <pre><code>from marsys.coordination.communication import CommunicationChannel\n</code></pre></p> <p>Abstract Methods:</p> Method Description Returns <code>send(message, metadata)</code> Send message to user <code>None</code> <code>receive(timeout)</code> Receive user input <code>str</code> <code>is_available()</code> Check if channel available <code>bool</code> <code>close()</code> Close channel <code>None</code>"},{"location":"api/communication/#terminalchannel","title":"TerminalChannel","text":"<p>Basic terminal I/O channel.</p> <p>Import: <pre><code>from marsys.coordination.communication.channels import TerminalChannel\n</code></pre></p> <p>Constructor: <pre><code>TerminalChannel(\n    channel_id: str = \"terminal\",\n    use_colors: bool = True\n)\n</code></pre></p> <p>Example: <pre><code>channel = TerminalChannel()\n\n# Send message\nawait channel.send(\"Enter your choice:\")\n\n# Receive input\nresponse = await channel.receive(timeout=30.0)\n</code></pre></p>"},{"location":"api/communication/#enhancedterminalchannel","title":"EnhancedTerminalChannel","text":"<p>Rich terminal with advanced formatting.</p> <p>Import: <pre><code>from marsys.coordination.communication.channels import EnhancedTerminalChannel\n</code></pre></p> <p>Constructor: <pre><code>EnhancedTerminalChannel(\n    channel_id: str = \"terminal\",\n    use_rich: bool = True,\n    theme_name: str = \"modern\",\n    prefix_width: int = 20,\n    show_timestamps: bool = True\n)\n</code></pre></p> <p>Features: - Rich text formatting - Color themes - Progress indicators - Tables and panels - Markdown rendering</p> <p>Example: <pre><code>channel = EnhancedTerminalChannel(\n    theme_name=\"modern\",\n    use_rich=True\n)\n\n# Send formatted message\nawait channel.send({\n    \"content\": \"## Analysis Results\",\n    \"format\": \"markdown\",\n    \"style\": \"success\"\n})\n</code></pre></p>"},{"location":"api/communication/#prefixedclichannel","title":"PrefixedCLIChannel","text":"<p>CLI channel with agent name prefixes.</p> <p>Import: <pre><code>from marsys.coordination.communication.channels import PrefixedCLIChannel\n</code></pre></p> <p>Constructor: <pre><code>PrefixedCLIChannel(\n    channel_id: str = \"cli\",\n    prefix_width: int = 20,\n    show_timestamps: bool = False,\n    prefix_alignment: str = \"left\"\n)\n</code></pre></p> <p>Example: <pre><code>channel = PrefixedCLIChannel(\n    prefix_width=25,\n    show_timestamps=True\n)\n\n# Send with prefix\nawait channel.send(\n    message=\"Processing data...\",\n    metadata={\"agent_name\": \"DataProcessor\"}\n)\n# Output: [DataProcessor]     Processing data...\n</code></pre></p>"},{"location":"api/communication/#communication-modes","title":"\ud83c\udfa8 Communication Modes","text":""},{"location":"api/communication/#communicationmode","title":"CommunicationMode","text":"<p>Enumeration of communication patterns.</p> <p>Import: <pre><code>from marsys.coordination.communication import CommunicationMode\n</code></pre></p> <p>Values: | Mode | Description | Use Case | |------|-------------|----------| | <code>SYNC</code> | Synchronous blocking | Terminal input | | <code>ASYNC_PUBSUB</code> | Event-driven async | Web interfaces | | <code>ASYNC_QUEUE</code> | Queue-based async | Message systems |</p>"},{"location":"api/communication/#mode-selection","title":"Mode Selection","text":"<pre><code># Sync mode (terminal)\nmanager = CommunicationManager(\n    config=CommunicationConfig(\n        mode=CommunicationMode.SYNC\n    )\n)\n\n# Async pub/sub (web)\nmanager = CommunicationManager(\n    config=CommunicationConfig(\n        mode=CommunicationMode.ASYNC_PUBSUB\n    )\n)\n</code></pre>"},{"location":"api/communication/#user-interaction-patterns","title":"\ud83d\udd27 User Interaction Patterns","text":""},{"location":"api/communication/#simple-user-input","title":"Simple User Input","text":"<pre><code># In topology\ntopology = {\n    \"agents\": [\"Agent1\", \"User\", \"Agent2\"],\n    \"flows\": [\n        \"Agent1 -&gt; User\",\n        \"User -&gt; Agent2\"\n    ]\n}\n\n# Agent1 response triggers user interaction\nresponse = {\n    \"next_action\": \"invoke_agent\",\n    \"action_input\": \"User\",\n    \"message\": \"Please review the results\"\n}\n\n# User sees message and provides input\n# System routes response to Agent2\n</code></pre>"},{"location":"api/communication/#error-recovery","title":"Error Recovery","text":"<pre><code># Agent triggers error recovery\nresponse = {\n    \"next_action\": \"error_recovery\",\n    \"error_details\": {\n        \"type\": \"api_quota_exceeded\",\n        \"message\": \"OpenAI API quota exceeded\"\n    },\n    \"suggested_action\": \"retry_with_different_model\"\n}\n\n# Routes to User node for intervention\n# User can:\n# - Retry with same settings\n# - Change model\n# - Skip operation\n# - Abort workflow\n</code></pre>"},{"location":"api/communication/#approval-workflow","title":"Approval Workflow","text":"<pre><code># Configure approval interaction\ninteraction = UserInteraction(\n    id=\"approval_123\",\n    prompt=\"Approve deployment to production?\",\n    options=[\"approve\", \"reject\", \"review\"],\n    metadata={\n        \"changes\": [\"Update API\", \"Database migration\"],\n        \"risk_level\": \"medium\"\n    }\n)\n\n# Request approval\nresponse = await manager.request_structured_input(interaction)\n\nif response == \"approve\":\n    # Continue with deployment\n    pass\nelif response == \"review\":\n    # Show detailed changes\n    pass\n</code></pre>"},{"location":"api/communication/#event-system","title":"\ud83d\udd04 Event System","text":""},{"location":"api/communication/#eventbus","title":"EventBus","text":"<p>Event bus for communication events.</p> <p>Import: <pre><code>from marsys.coordination.event_bus import EventBus\n</code></pre></p> <p>Methods:</p>"},{"location":"api/communication/#emit","title":"emit","text":"<p><pre><code>async def emit(event: Any) -&gt; None\n</code></pre> Emit an event object to subscribers (async).</p>"},{"location":"api/communication/#emit_nowait","title":"emit_nowait","text":"<p><pre><code>def emit_nowait(event: Any) -&gt; None\n</code></pre> Emit an event from synchronous contexts (fire-and-forget).</p>"},{"location":"api/communication/#subscribe_1","title":"subscribe","text":"<p><pre><code>def subscribe(event_type: str, listener: Callable) -&gt; None\n</code></pre> Subscribe to events.</p>"},{"location":"api/communication/#unsubscribe","title":"unsubscribe","text":"<p><pre><code>def unsubscribe(event_type: str, listener: Callable) -&gt; None\n</code></pre> Unsubscribe from events.</p> <p>Event Types: Event types are the class names of the emitted event objects (e.g., <code>\"PlanCreatedEvent\"</code>).</p> <p>Example: <pre><code>from dataclasses import dataclass\n\n@dataclass\nclass CustomEvent:\n    session_id: str\n    payload: str\n\nbus = EventBus()\n\nasync def on_custom_event(event: CustomEvent):\n    print(event.payload)\n\nbus.subscribe(\"CustomEvent\", on_custom_event)\n\n# Emit events\nawait bus.emit(CustomEvent(session_id=\"123\", payload=\"hello\"))\nbus.emit_nowait(CustomEvent(session_id=\"123\", payload=\"background\"))\n</code></pre></p>"},{"location":"api/communication/#webchannel-status-events","title":"WebChannel Status Events","text":"<p><code>WebChannel</code> can deliver status and planning events to web clients via WebSocket push or REST polling.</p> <p>Methods:</p>"},{"location":"api/communication/#push_status_event","title":"push_status_event","text":"<p><pre><code>async def push_status_event(event_data: Dict[str, Any]) -&gt; None\n</code></pre> Push a serialized status event to WebSocket clients and the polling queue.</p>"},{"location":"api/communication/#subscribe_status_events","title":"subscribe_status_events","text":"<p><pre><code>def subscribe_status_events(callback: Callable[[Dict[str, Any]], None]) -&gt; None\n</code></pre> Subscribe to status event callbacks.</p>"},{"location":"api/communication/#get_status_events","title":"get_status_events","text":"<p><pre><code>async def get_status_events(limit: int = 100, timeout: float = 0.0) -&gt; List[Dict[str, Any]]\n</code></pre> Poll for status events (useful for REST APIs).</p> <p>StatusWebChannel Bridge: <pre><code>from marsys.coordination.communication.channels import WebChannel\nfrom marsys.coordination.status.channels import StatusWebChannel\n\nweb_channel = WebChannel()\nstatus_web = StatusWebChannel(web_channel)\nstatus_manager.add_channel(status_web)\n</code></pre></p> <p>This forwards <code>StatusManager</code> events (including planning events) into <code>WebChannel</code>.</p>"},{"location":"api/communication/#custom-channels","title":"\ud83c\udfa8 Custom Channels","text":""},{"location":"api/communication/#creating-custom-channel","title":"Creating Custom Channel","text":"<pre><code>from marsys.coordination.communication import CommunicationChannel\n\nclass WebSocketChannel(CommunicationChannel):\n    \"\"\"WebSocket-based communication channel.\"\"\"\n\n    def __init__(self, ws_url: str):\n        super().__init__(channel_id=\"websocket\")\n        self.ws_url = ws_url\n        self.ws = None\n\n    async def connect(self):\n        self.ws = await websocket.connect(self.ws_url)\n\n    async def send(self, message: str, metadata: Dict = None):\n        await self.ws.send(json.dumps({\n            \"message\": message,\n            \"metadata\": metadata\n        }))\n\n    async def receive(self, timeout: float = None):\n        try:\n            data = await asyncio.wait_for(\n                self.ws.receive(),\n                timeout=timeout\n            )\n            return json.loads(data)[\"response\"]\n        except asyncio.TimeoutError:\n            return None\n\n    def is_available(self) -&gt; bool:\n        return self.ws and not self.ws.closed\n\n    async def close(self):\n        if self.ws:\n            await self.ws.close()\n</code></pre>"},{"location":"api/communication/#best-practices","title":"\ud83d\udccb Best Practices","text":""},{"location":"api/communication/#do","title":"\u2705 DO:","text":"<ul> <li>Set appropriate timeouts for user input</li> <li>Provide clear prompts and options</li> <li>Handle timeout gracefully</li> <li>Store interaction history</li> <li>Use structured interactions for complex inputs</li> </ul>"},{"location":"api/communication/#dont","title":"\u274c DON'T:","text":"<ul> <li>Block indefinitely on user input</li> <li>Mix communication channels in same session</li> <li>Ignore channel availability</li> <li>Send sensitive data unencrypted</li> <li>Assume user always provides valid input</li> </ul>"},{"location":"api/communication/#themes-and-formatting","title":"\ud83d\udea6 Themes and Formatting","text":""},{"location":"api/communication/#available-themes","title":"Available Themes","text":"<pre><code># Modern theme (default)\nconfig = CommunicationConfig(theme_name=\"modern\")\n\n# Classic terminal\nconfig = CommunicationConfig(theme_name=\"classic\")\n\n# Minimal\nconfig = CommunicationConfig(theme_name=\"minimal\")\n\n# Custom theme\nconfig = CommunicationConfig(\n    theme_name=\"custom\",\n    custom_theme={\n        \"primary\": \"#007ACC\",\n        \"success\": \"#4CAF50\",\n        \"error\": \"#F44336\",\n        \"warning\": \"#FF9800\"\n    }\n)\n</code></pre>"},{"location":"api/communication/#message-formatting","title":"Message Formatting","text":"<pre><code># Rich formatting\nawait channel.send({\n    \"content\": \"# Results\\n- Item 1\\n- Item 2\",\n    \"format\": \"markdown\",\n    \"style\": \"panel\",\n    \"title\": \"Analysis\"\n})\n\n# Table display\nawait channel.send({\n    \"content\": [\n        [\"Metric\", \"Value\"],\n        [\"Accuracy\", \"95%\"],\n        [\"Speed\", \"1.2s\"]\n    ],\n    \"format\": \"table\"\n})\n</code></pre>"},{"location":"api/communication/#related-documentation","title":"\ud83d\udea6 Related Documentation","text":"<ul> <li>User Node Guide - User node patterns</li> <li>Configuration API - Communication configuration</li> <li>Orchestra API - Integration with Orchestra</li> <li>Interactive Workflows - Interactive patterns</li> </ul> <p>Pro Tip</p> <p>Use <code>EnhancedTerminalChannel</code> for better user experience with colors, formatting, and progress indicators. It automatically falls back to basic terminal if Rich is unavailable.</p> <p>Timeout Handling</p> <p>Always set reasonable timeouts for user input to prevent indefinite blocking. Consider offering a retry option if timeout occurs.</p>"},{"location":"api/configuration/","title":"Configuration API","text":"<p>Complete API reference for the MARSYS configuration system, including execution, status, communication, and error handling configurations.</p>"},{"location":"api/configuration/#overview","title":"\ud83c\udfaf Overview","text":"<p>The configuration system provides hierarchical settings for all aspects of multi-agent orchestration, with sensible defaults and granular override capabilities.</p>"},{"location":"api/configuration/#core-classes","title":"\ud83d\udce6 Core Classes","text":""},{"location":"api/configuration/#executionconfig","title":"ExecutionConfig","text":"<p>Main configuration for orchestration execution.</p> <p>Import: <pre><code>from marsys.coordination.config import ExecutionConfig, StatusConfig, ErrorHandlingConfig\n</code></pre></p> <p>Constructor: <pre><code>ExecutionConfig(\n    # Timeouts\n    convergence_timeout: float = 300.0,\n    branch_timeout: float = 600.0,\n    agent_acquisition_timeout: float = 240.0,\n    step_timeout: float = 600.0,\n    tool_execution_timeout: float = 120.0,\n    user_interaction_timeout: float = 300.0,\n\n    # Convergence behavior\n    dynamic_convergence_enabled: bool = True,\n    parent_completes_on_spawn: bool = True,\n    auto_detect_convergence: bool = True,\n\n    # Steering\n    steering_mode: Literal[\"auto\", \"always\", \"error\"] = \"error\",\n\n    # User interaction\n    user_first: bool = False,\n    initial_user_msg: Optional[str] = None,\n    user_interaction: str = \"terminal\",\n\n    # Agent lifecycle management\n    auto_cleanup_agents: bool = True,\n    cleanup_scope: Literal[\"topology_nodes\", \"used_agents\"] = \"topology_nodes\",\n\n    # Response format\n    response_format: str = \"json\",\n\n    # Sub-configurations\n    status: StatusConfig = field(default_factory=StatusConfig),\n    error_handling: Optional[ErrorHandlingConfig] = None\n)\n</code></pre></p> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>convergence_timeout</code> | <code>float</code> | Max wait at convergence points (seconds) | <code>300.0</code> | | <code>branch_timeout</code> | <code>float</code> | Overall branch execution timeout | <code>600.0</code> | | <code>agent_acquisition_timeout</code> | <code>float</code> | Timeout for acquiring from pool | <code>240.0</code> | | <code>step_timeout</code> | <code>float</code> | Individual step timeout | <code>600.0</code> | | <code>tool_execution_timeout</code> | <code>float</code> | Tool call timeout | <code>120.0</code> | | <code>user_interaction_timeout</code> | <code>float</code> | User input timeout | <code>300.0</code> | | <code>dynamic_convergence_enabled</code> | <code>bool</code> | Enable runtime convergence detection | <code>True</code> | | <code>parent_completes_on_spawn</code> | <code>bool</code> | Parent completes when spawning children | <code>True</code> | | <code>auto_detect_convergence</code> | <code>bool</code> | Automatic convergence point detection | <code>True</code> | | <code>steering_mode</code> | <code>str</code> | Retry guidance mode (<code>auto</code>, <code>always</code>, <code>error</code>) | <code>\"error\"</code> | | <code>user_first</code> | <code>bool</code> | Show message to user before task | <code>False</code> | | <code>initial_user_msg</code> | <code>str</code> | Custom initial message for user | <code>None</code> | | <code>user_interaction</code> | <code>str</code> | User interaction type | <code>\"terminal\"</code> | | <code>auto_cleanup_agents</code> | <code>bool</code> | Automatically cleanup agents after run | <code>True</code> | | <code>cleanup_scope</code> | <code>str</code> | Which agents to cleanup | <code>\"topology_nodes\"</code> | | <code>response_format</code> | <code>str</code> | Response format for agent outputs | <code>\"json\"</code> | | <code>status</code> | <code>StatusConfig</code> | Status configuration | <code>StatusConfig()</code> |</p> <p>Methods:</p> Method Description Returns <code>should_apply_steering(is_retry)</code> Determine if steering should be applied <code>bool</code> <p>Example: <pre><code># Production configuration\nconfig = ExecutionConfig(\n    convergence_timeout=600.0,\n    step_timeout=300.0,\n    steering_mode=\"auto\",\n    status=StatusConfig.from_verbosity(1)\n)\n\n# Development configuration\ndev_config = ExecutionConfig(\n    step_timeout=30.0,\n    steering_mode=\"always\",\n    status=StatusConfig.from_verbosity(2)\n)\n\n# Interactive configuration\ninteractive_config = ExecutionConfig(\n    user_first=True,\n    initial_user_msg=\"Hello! How can I help?\",\n    user_interaction_timeout=300.0\n)\n\n# Long-running workflow (disable auto-cleanup)\nlong_running_config = ExecutionConfig(\n    auto_cleanup_agents=False,  # Keep agents alive between runs\n    convergence_timeout=3600.0\n)\n</code></pre></p>"},{"location":"api/configuration/#statusconfig","title":"StatusConfig","text":"<p>Configuration for monitoring and output display.</p> <p>Import: <pre><code>from marsys.coordination.config import StatusConfig, VerbosityLevel\n</code></pre></p> <p>Constructor: <pre><code>StatusConfig(\n    enabled: bool = False,\n    verbosity: Optional[VerbosityLevel] = None,\n    cli_output: bool = True,\n    cli_colors: bool = True,\n    show_thoughts: bool = True,\n    show_tool_calls: bool = True,\n    show_timings: bool = True,\n    aggregation_window_ms: int = 500,\n    aggregate_parallel: bool = True,\n    max_events_per_session: int = 10000,\n    session_cleanup_after_s: int = 3600,\n    channels: List[str] = field(default_factory=lambda: [\"cli\"]),\n    show_agent_prefixes: bool = True,\n    prefix_width: int = 20,\n    prefix_alignment: str = \"left\",\n    follow_up_timeout: float = 30.0\n)\n</code></pre></p> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>enabled</code> | <code>bool</code> | Enable status output | <code>False</code> | | <code>verbosity</code> | <code>VerbosityLevel</code> | Output verbosity level | <code>None</code> | | <code>cli_output</code> | <code>bool</code> | Show CLI output | <code>True</code> | | <code>cli_colors</code> | <code>bool</code> | Use colored output | <code>True</code> | | <code>show_thoughts</code> | <code>bool</code> | Show agent reasoning | <code>True</code> | | <code>show_tool_calls</code> | <code>bool</code> | Show tool usage | <code>True</code> | | <code>show_timings</code> | <code>bool</code> | Show execution times | <code>True</code> | | <code>aggregation_window_ms</code> | <code>int</code> | Group updates within window | <code>500</code> | | <code>aggregate_parallel</code> | <code>bool</code> | Aggregate parallel updates | <code>True</code> | | <code>show_agent_prefixes</code> | <code>bool</code> | Show agent names in output | <code>True</code> | | <code>prefix_width</code> | <code>int</code> | Width of agent name prefix | <code>20</code> | | <code>prefix_alignment</code> | <code>str</code> | Prefix alignment | <code>\"left\"</code> |</p> <p>Class Methods:</p> Method Description Returns <code>from_verbosity(level)</code> Create from verbosity level <code>StatusConfig</code> <p>Instance Methods:</p> Method Description Returns <code>should_show_event(event_type)</code> Check if event should be shown <code>bool</code> <p>VerbosityLevel Enum: <pre><code>class VerbosityLevel(IntEnum):\n    QUIET = 0     # Minimal output (no thinking, no tool calls)\n    NORMAL = 1    # Standard output (agent thinking, tool calls with reasoning)\n    VERBOSE = 2   # Detailed output (all of above + tool arguments, completion timings)\n</code></pre></p> <p>What Shows at Each Level:</p> Event Type QUIET NORMAL VERBOSE Agent start/complete \u2713 \u2713 \u2713 Agent thinking \u2717 \u2713 \u2713 Tool call name \u2717 \u2713 \u2713 Tool reasoning \u2717 \u2713 \u2713 Tool arguments \u2717 \u2717 \u2713 Tool completion \u2717 \u2717 \u2713 Action type details \u2717 \u2717 \u2713 <p>Example: <pre><code># Create from verbosity level\nstatus = StatusConfig.from_verbosity(1)\n\n# Custom configuration\ncustom_status = StatusConfig(\n    enabled=True,\n    verbosity=VerbosityLevel.NORMAL,\n    show_thoughts=True,\n    show_tool_calls=True,\n    cli_colors=False  # Disable colors for logs\n)\n\n# Quiet mode with timing\ntiming_only = StatusConfig(\n    enabled=True,\n    verbosity=VerbosityLevel.QUIET,\n    show_timings=True\n)\n</code></pre></p>"},{"location":"api/configuration/#communicationconfig","title":"CommunicationConfig","text":"<p>Configuration for user interaction and communication channels.</p> <p>Import: <pre><code>from marsys.coordination.config import CommunicationConfig\n</code></pre></p> <p>Constructor: <pre><code>CommunicationConfig(\n    use_rich_formatting: bool = True,\n    theme_name: str = \"modern\",\n    prefix_width: int = 20,\n    show_timestamps: bool = True,\n    enable_history: bool = True,\n    history_size: int = 1000,\n    enable_tab_completion: bool = True,\n    use_colors: bool = True,\n    color_depth: str = \"truecolor\",\n    input_timeout: Optional[float] = None,\n    show_typing_indicator: bool = False,\n    use_enhanced_terminal: bool = True,\n    fallback_on_error: bool = True\n)\n</code></pre></p> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>use_rich_formatting</code> | <code>bool</code> | Use rich text formatting | <code>True</code> | | <code>theme_name</code> | <code>str</code> | Theme name | <code>\"modern\"</code> | | <code>prefix_width</code> | <code>int</code> | Width for agent name prefixes | <code>20</code> | | <code>show_timestamps</code> | <code>bool</code> | Show timestamps in interactions | <code>True</code> | | <code>enable_history</code> | <code>bool</code> | Keep interaction history | <code>True</code> | | <code>history_size</code> | <code>int</code> | Maximum history entries | <code>1000</code> | | <code>enable_tab_completion</code> | <code>bool</code> | Tab completion for inputs | <code>True</code> | | <code>use_colors</code> | <code>bool</code> | Enable colored output | <code>True</code> | | <code>color_depth</code> | <code>str</code> | Color depth setting | <code>\"truecolor\"</code> | | <code>input_timeout</code> | <code>float</code> | Timeout for user input | <code>None</code> | | <code>use_enhanced_terminal</code> | <code>bool</code> | Use enhanced terminal features | <code>True</code> | | <code>fallback_on_error</code> | <code>bool</code> | Fallback to basic mode on error | <code>True</code> |</p> <p>Theme Options: - <code>\"modern\"</code> - Modern theme with gradients - <code>\"classic\"</code> - Traditional terminal colors - <code>\"minimal\"</code> - Minimal styling</p> <p>Color Depth Options: - <code>\"truecolor\"</code> - 24-bit true color - <code>\"256\"</code> - 256-color palette - <code>\"16\"</code> - 16-color basic palette - <code>\"none\"</code> - No colors</p> <p>Example: <pre><code># Rich terminal configuration\nrich_config = CommunicationConfig(\n    use_rich_formatting=True,\n    theme_name=\"modern\",\n    use_colors=True,\n    color_depth=\"truecolor\"\n)\n\n# Basic terminal configuration\nbasic_config = CommunicationConfig(\n    use_rich_formatting=False,\n    use_colors=False,\n    use_enhanced_terminal=False\n)\n\n# Web interface configuration\nweb_config = CommunicationConfig(\n    use_rich_formatting=False,  # Web handles formatting\n    use_colors=False,            # Web handles colors\n    input_timeout=0              # Non-blocking\n)\n</code></pre></p>"},{"location":"api/configuration/#errorhandlingconfig","title":"ErrorHandlingConfig","text":"<p>Advanced error handling and recovery configuration.</p> <p>Import: <pre><code>from marsys.coordination.config import ErrorHandlingConfig\n</code></pre></p> <p>Constructor: <pre><code>ErrorHandlingConfig(\n    use_error_classification: bool = True,\n    notify_on_critical_errors: bool = True,\n    enable_error_routing: bool = True,\n    preserve_error_context: bool = True,\n    auto_retry_on_rate_limits: bool = True,\n    max_rate_limit_retries: int = 3,\n    pool_retry_attempts: int = 2,\n    pool_retry_delay: float = 5.0,\n    timeout_seconds: float = 300.0,\n    timeout_retry_enabled: bool = False,\n    provider_settings: Dict[str, Dict[str, Any]] = field(default_factory=dict)\n)\n</code></pre></p> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>use_error_classification</code> | <code>bool</code> | Enable intelligent error classification | <code>True</code> | | <code>notify_on_critical_errors</code> | <code>bool</code> | Send notifications for critical errors | <code>True</code> | | <code>enable_error_routing</code> | <code>bool</code> | Route errors to User node for intervention | <code>True</code> | | <code>preserve_error_context</code> | <code>bool</code> | Include full error context in responses | <code>True</code> | | <code>auto_retry_on_rate_limits</code> | <code>bool</code> | Automatically retry rate-limited requests | <code>True</code> | | <code>max_rate_limit_retries</code> | <code>int</code> | Maximum retries for rate limit errors | <code>3</code> | | <code>pool_retry_attempts</code> | <code>int</code> | Number of retries for pool exhaustion | <code>2</code> | | <code>pool_retry_delay</code> | <code>float</code> | Delay between pool retry attempts | <code>5.0</code> | | <code>timeout_seconds</code> | <code>float</code> | Default timeout for operations | <code>300.0</code> | | <code>timeout_retry_enabled</code> | <code>bool</code> | Retry after timeout | <code>False</code> | | <code>provider_settings</code> | <code>Dict</code> | Provider-specific settings | <code>{}</code> |</p> <p>Methods:</p> Method Description Returns <code>get_provider_setting(provider, setting, default)</code> Get provider-specific setting <code>Any</code> <p>Provider Settings Structure: <pre><code>provider_settings = {\n    \"openai\": {\n        \"max_retries\": 3,\n        \"base_retry_delay\": 60,\n        \"insufficient_quota_action\": \"raise\"  # \"raise\", \"notify\", \"fallback\"\n    },\n    \"anthropic\": {\n        \"max_retries\": 3,\n        \"base_retry_delay\": 30,\n        \"insufficient_quota_action\": \"raise\"\n    }\n}\n</code></pre></p> <p>Example: <pre><code># Aggressive retry strategy\naggressive = ErrorHandlingConfig(\n    auto_retry_on_rate_limits=True,\n    max_rate_limit_retries=10,\n    timeout_retry_enabled=True,\n    pool_retry_attempts=5\n)\n\n# Conservative strategy\nconservative = ErrorHandlingConfig(\n    auto_retry_on_rate_limits=False,\n    max_rate_limit_retries=0,\n    timeout_retry_enabled=False,\n    enable_error_routing=True  # Route to user\n)\n\n# Custom provider settings\ncustom = ErrorHandlingConfig(\n    provider_settings={\n        \"openai\": {\"max_retries\": 5, \"base_retry_delay\": 30},\n        \"anthropic\": {\"max_retries\": 3, \"base_retry_delay\": 60}\n    }\n)\n</code></pre></p>"},{"location":"api/configuration/#configuration-patterns","title":"\ud83c\udfa8 Configuration Patterns","text":""},{"location":"api/configuration/#development-configuration","title":"Development Configuration","text":"<pre><code>def create_dev_config() -&gt; ExecutionConfig:\n    \"\"\"Development configuration with verbose output.\"\"\"\n    return ExecutionConfig(\n        status=StatusConfig(\n            enabled=True,\n            verbosity=VerbosityLevel.VERBOSE,\n            show_thoughts=True,\n            show_tool_calls=True\n        ),\n        step_timeout=30.0,\n        steering_mode=\"always\"\n    )\n</code></pre>"},{"location":"api/configuration/#production-configuration","title":"Production Configuration","text":"<pre><code>def create_prod_config() -&gt; ExecutionConfig:\n    \"\"\"Production configuration with minimal output.\"\"\"\n    return ExecutionConfig(\n        status=StatusConfig.from_verbosity(0),\n        step_timeout=600.0,\n        convergence_timeout=1200.0,\n        steering_mode=\"auto\",\n        error_handling=ErrorHandlingConfig(\n            auto_retry_on_rate_limits=True,\n            max_rate_limit_retries=5\n        )\n    )\n</code></pre>"},{"location":"api/configuration/#testing-configuration","title":"Testing Configuration","text":"<pre><code>def create_test_config() -&gt; ExecutionConfig:\n    \"\"\"Testing configuration with fast failure.\"\"\"\n    return ExecutionConfig(\n        status=StatusConfig.from_verbosity(1),\n        step_timeout=5.0,\n        convergence_timeout=10.0,\n        steering_mode=\"error\"\n    )\n</code></pre>"},{"location":"api/configuration/#interactive-configuration","title":"Interactive Configuration","text":"<pre><code>def create_interactive_config() -&gt; ExecutionConfig:\n    \"\"\"User-interactive configuration.\"\"\"\n    return ExecutionConfig(\n        user_first=True,\n        initial_user_msg=\"Hello! How can I help?\",\n        user_interaction_timeout=300.0,\n        status=StatusConfig(\n            enabled=True,\n            cli_colors=True,\n            show_agent_prefixes=True\n        )\n    )\n</code></pre>"},{"location":"api/configuration/#advanced-features","title":"\ud83d\udd27 Advanced Features","text":""},{"location":"api/configuration/#agent-lifecycle-management","title":"Agent Lifecycle Management","text":"<p>The framework provides automatic agent cleanup to prevent resource leaks and registry collisions.</p> <p>How It Works:</p> <pre><code># Default behavior - auto-cleanup enabled\nresult = await Orchestra.run(\n    task=\"Analyze data\",\n    topology=topology,\n    execution_config=ExecutionConfig(\n        auto_cleanup_agents=True  # Default\n    )\n)\n# After run completes:\n# 1. Closes model resources (aiohttp sessions, etc.)\n# 2. Closes agent-specific resources (browsers, playwright, etc.)\n# 3. Unregisters agents from registry (frees names for reuse)\n</code></pre> <p>Cleanup Scopes:</p> <ul> <li><code>topology_nodes</code> (default): Cleanup all agents defined in the topology</li> <li><code>used_agents</code>: Cleanup only agents that were actually invoked during execution</li> </ul> <p>When to Disable:</p> <pre><code># Scenario 1: Multiple runs with same agents\nconfig = ExecutionConfig(auto_cleanup_agents=False)\n\nfor task in tasks:\n    result = await Orchestra.run(task, topology, execution_config=config)\n    # Agents stay alive, registry intact\n\n# Scenario 2: Long-lived agent pools\npool = await create_browser_agent_pool(num_instances=3, register=False)\nAgentRegistry.register_pool(pool)\n\n# Pool manages its own lifecycle\nresult = await Orchestra.run(\n    task=\"Scrape websites\",\n    topology=topology,\n    execution_config=ExecutionConfig(auto_cleanup_agents=False)\n)\n\nawait pool.cleanup()  # Manual cleanup when done\n</code></pre> <p>Benefits:</p> <ul> <li>No Resource Leaks: aiohttp sessions, browser instances closed deterministically</li> <li>No Registry Collisions: Agent names freed for reuse in subsequent runs</li> <li>No Manual Cleanup: Works \"out of the box\" without user intervention</li> <li>Identity-Safe: Uses instance identity checks to prevent race conditions</li> </ul> <p>Low-Level Control:</p> <pre><code>from marsys.agents.registry import AgentRegistry\n\n# Manual cleanup for specific agent\nagent = AgentRegistry.get(\"my_agent\")\nif agent:\n    await agent.cleanup()  # Close resources\n    AgentRegistry.unregister_if_same(\"my_agent\", agent)  # Identity-safe unregister\n</code></pre>"},{"location":"api/configuration/#response-format-configuration","title":"Response Format Configuration","text":"<p>The <code>response_format</code> parameter controls how agents structure their outputs and how the system builds agent system prompts.</p> <p>Available Formats:</p> Format Description <code>json</code> Default JSON format with <code>next_action</code>/<code>action_input</code> structure <p>How It Works:</p> <ol> <li>System Prompt Building: The format determines how coordination instructions are included in agent system prompts</li> <li>Response Parsing: Each format has an associated processor for parsing agent responses</li> <li>Parallel Invocation Examples: Format-specific examples guide agents on correct parallel invocation patterns</li> </ol> <p>Example: <pre><code># Default JSON format (recommended)\nconfig = ExecutionConfig(response_format=\"json\")\n\n# The JSON format produces system prompts with instructions like:\n# --- STRICT JSON OUTPUT FORMAT ---\n# Your response MUST be a single, valid JSON object...\n# ```json\n# {\n#   \"thought\": \"reasoning...\",\n#   \"next_action\": \"invoke_agent\",\n#   \"action_input\": [...]\n# }\n# ```\n</code></pre></p> <p>Custom Formats:</p> <p>To implement a custom format (e.g., XML):</p> <pre><code>from marsys.coordination.formats import BaseResponseFormat, register_format\n\nclass XMLResponseFormat(BaseResponseFormat):\n    def get_format_name(self) -&gt; str:\n        return \"xml\"\n\n    def build_format_instructions(self, actions, descriptions) -&gt; str:\n        # Build XML-specific instructions\n        ...\n\n    def get_parallel_invocation_examples(self, context) -&gt; str:\n        # Provide XML examples for parallel invocation\n        ...\n\n    def create_processor(self):\n        return XMLProcessor()\n\n# Register and use\nregister_format(\"xml\", XMLResponseFormat)\nconfig = ExecutionConfig(response_format=\"xml\")\n</code></pre>"},{"location":"api/configuration/#configuration-merging","title":"Configuration Merging","text":"<pre><code>from dataclasses import replace\n\n# Base configuration\nbase_config = ExecutionConfig(\n    step_timeout=300.0,\n    status=StatusConfig.from_verbosity(1)\n)\n\n# Override specific settings\ncustom_config = replace(\n    base_config,\n    step_timeout=60.0,\n    steering_mode=\"always\"\n)\n</code></pre>"},{"location":"api/configuration/#dynamic-configuration","title":"Dynamic Configuration","text":"<pre><code>def get_config_for_task(task_type: str) -&gt; ExecutionConfig:\n    \"\"\"Get configuration based on task type.\"\"\"\n    configs = {\n        \"research\": ExecutionConfig(\n            convergence_timeout=600.0,\n            max_steps=200\n        ),\n        \"quick_query\": ExecutionConfig(\n            step_timeout=30.0,\n            max_steps=10\n        )\n    }\n    return configs.get(task_type, ExecutionConfig())\n</code></pre>"},{"location":"api/configuration/#environment-variable-integration","title":"Environment Variable Integration","text":"<pre><code>import os\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nconfig = ExecutionConfig(\n    step_timeout=float(os.getenv(\"MARSYS_TIMEOUT\", \"300\")),\n    status=StatusConfig(\n        verbosity=int(os.getenv(\"MARSYS_VERBOSITY\", \"1\"))\n    )\n)\n</code></pre>"},{"location":"api/configuration/#configuration-lifecycle","title":"\ud83d\udd04 Configuration Lifecycle","text":""},{"location":"api/configuration/#configuration-priority","title":"Configuration Priority","text":"<ol> <li>Explicit parameters (highest priority)</li> <li>Configuration objects</li> <li>Environment variables</li> <li>Default values (lowest priority)</li> </ol>"},{"location":"api/configuration/#runtime-updates","title":"Runtime Updates","text":"<pre><code># Start with base config\norchestra = Orchestra(execution_config=base_config)\n\n# Override for specific run\nresult = await orchestra.execute(\n    task=task,\n    topology=topology,\n    execution_config=ExecutionConfig(\n        step_timeout=60.0  # Override just this setting\n    )\n)\n</code></pre>"},{"location":"api/configuration/#best-practices","title":"\ud83d\udccb Best Practices","text":""},{"location":"api/configuration/#do","title":"\u2705 DO:","text":"<ul> <li>Start with defaults and override as needed</li> <li>Use verbosity levels appropriately</li> <li>Configure timeouts based on expected task duration</li> <li>Enable error routing for critical workflows</li> <li>Use provider-specific settings for API optimization</li> </ul>"},{"location":"api/configuration/#dont","title":"\u274c DON'T:","text":"<ul> <li>Set timeouts too short (&lt; 10 seconds)</li> <li>Disable all retries in production</li> <li>Use VERBOSE mode in production</li> <li>Ignore error handling configuration</li> <li>Mix incompatible settings (e.g., retries with \"never\" steering)</li> </ul>"},{"location":"api/configuration/#related-documentation","title":"\ud83d\udea6 Related Documentation","text":"<ul> <li>Orchestra API - Main orchestration interface</li> <li>Execution API - Execution system using configs</li> <li>Validation API - Response format system and processors</li> <li>Status System - Status and monitoring details</li> <li>Error Handling - Error recovery patterns</li> </ul> <p>Pro Tip</p> <p>Use <code>StatusConfig.from_verbosity()</code> for quick setup. It automatically configures all related settings appropriately for the chosen verbosity level.</p> <p>Configuration Validation</p> <p>Always validate custom configurations, especially when merging multiple sources. Invalid configurations can cause runtime failures.</p>"},{"location":"api/execution/","title":"Execution API","text":"<p>Complete API reference for the execution system that manages branch execution, step processing, and dynamic parallelism.</p>"},{"location":"api/execution/#overview","title":"\ud83c\udfaf Overview","text":"<p>The Execution API handles the runtime execution of multi-agent workflows, including branch management, step execution, and dynamic parallel invocation.</p>"},{"location":"api/execution/#core-classes","title":"\ud83d\udce6 Core Classes","text":""},{"location":"api/execution/#branchexecutor","title":"BranchExecutor","text":"<p>Manages the execution of different branch patterns in the workflow.</p> <p>Import: <pre><code>from marsys.coordination.execution import BranchExecutor\n</code></pre></p> <p>Constructor: <pre><code>BranchExecutor(\n    validation_processor: ValidationProcessor,\n    router: Router,\n    step_executor: StepExecutor,\n    context_manager: ContextManager,\n    config: ExecutionConfig\n)\n</code></pre></p> <p>Key Methods:</p>"},{"location":"api/execution/#execute_branch","title":"execute_branch","text":"<pre><code>async def execute_branch(\n    branch: ExecutionBranch,\n    initial_request: Any,\n    context: Dict[str, Any],\n    resume_with_results: Optional[Dict] = None\n) -&gt; BranchResult\n</code></pre> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>branch</code> | <code>ExecutionBranch</code> | Branch to execute | Required | | <code>initial_request</code> | <code>Any</code> | Initial task/prompt | Required | | <code>context</code> | <code>Dict[str, Any]</code> | Execution context | Required | | <code>resume_with_results</code> | <code>Optional[Dict]</code> | Child branch results | <code>None</code> |</p> <p>Returns: <code>BranchResult</code> with execution outcome</p> <p>Example: <pre><code>executor = BranchExecutor(\n    validation_processor=validator,\n    router=router,\n    step_executor=step_exec,\n    context_manager=ctx_mgr,\n    config=exec_config\n)\n\nresult = await executor.execute_branch(\n    branch=main_branch,\n    initial_request=\"Analyze this data\",\n    context={\"session_id\": \"123\"}\n)\n</code></pre></p>"},{"location":"api/execution/#executionbranch","title":"ExecutionBranch","text":"<p>Represents a branch of execution in the workflow.</p> <p>Import: <pre><code>from marsys.coordination.branches.types import ExecutionBranch, BranchType, BranchStatus\n</code></pre></p> <p>Attributes: | Attribute | Type | Description | |-----------|------|-------------| | <code>branch_id</code> | <code>str</code> | Unique branch identifier | | <code>branch_type</code> | <code>BranchType</code> | Type of branch | | <code>status</code> | <code>BranchStatus</code> | Current status | | <code>parent_branch_id</code> | <code>Optional[str]</code> | Parent branch if nested | | <code>agent_sequence</code> | <code>List[str]</code> | Agents to execute | | <code>current_step</code> | <code>int</code> | Current execution step | | <code>memory</code> | <code>Dict[str, List]</code> | Per-agent memory | | <code>metadata</code> | <code>Dict[str, Any]</code> | Branch metadata |</p> <p>BranchType Enum: <pre><code>class BranchType(Enum):\n    SIMPLE = \"simple\"                    # Sequential execution\n    CONVERSATION = \"conversation\"        # Bidirectional dialogue\n    NESTED = \"nested\"                   # Has child branches\n    USER_INTERACTION = \"user_interaction\"  # Human-in-the-loop\n</code></pre></p> <p>BranchStatus Enum: <pre><code>class BranchStatus(Enum):\n    PENDING = \"pending\"      # Not started\n    RUNNING = \"running\"      # Currently executing\n    WAITING = \"waiting\"      # Waiting for child branches\n    COMPLETED = \"completed\"  # Successfully finished\n    FAILED = \"failed\"       # Terminated with error\n</code></pre></p> <p>Example: <pre><code>from marsys.coordination.branches.types import ExecutionBranch, BranchType\n\nbranch = ExecutionBranch(\n    branch_id=\"main_001\",\n    branch_type=BranchType.SIMPLE,\n    agent_sequence=[\"Coordinator\", \"Worker\"],\n    metadata={\"priority\": \"high\"}\n)\n</code></pre></p>"},{"location":"api/execution/#stepexecutor","title":"StepExecutor","text":"<p>Executes individual steps within a branch.</p> <p>Import: <pre><code>from marsys.coordination.execution import StepExecutor\n</code></pre></p> <p>Constructor: <pre><code>StepExecutor(\n    config: Optional[ExecutionConfig] = None,\n    tool_executor: Optional[ToolExecutor] = None,\n    user_node_handler: Optional[UserNodeHandler] = None,\n    event_bus: Optional[EventBus] = None,\n    system_prompt_builder: Optional[SystemPromptBuilder] = None,\n    max_retries: int = 5,\n    retry_delay: float = 1.0\n)\n</code></pre></p> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>config</code> | <code>Optional[ExecutionConfig]</code> | Execution configuration | <code>None</code> | | <code>tool_executor</code> | <code>Optional[ToolExecutor]</code> | Tool execution handler | <code>None</code> | | <code>user_node_handler</code> | <code>Optional[UserNodeHandler]</code> | User interaction handler | <code>None</code> | | <code>event_bus</code> | <code>Optional[EventBus]</code> | Event bus for status updates | <code>None</code> | | <code>system_prompt_builder</code> | <code>Optional[SystemPromptBuilder]</code> | Builds agent system prompts using response format | <code>None</code> | | <code>max_retries</code> | <code>int</code> | Maximum retry attempts | <code>5</code> | | <code>retry_delay</code> | <code>float</code> | Delay between retries (seconds) | <code>1.0</code> |</p> <p>Key Methods:</p>"},{"location":"api/execution/#execute_step","title":"execute_step","text":"<pre><code>async def execute_step(\n    agent: Union[BaseAgent, str],\n    request: Any,\n    memory: List[Dict[str, Any]],\n    context: Dict[str, Any]\n) -&gt; StepResult\n</code></pre> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>agent</code> | <code>Union[BaseAgent, str]</code> | Agent instance or name to execute | Required | | <code>request</code> | <code>Any</code> | Input for agent | Required | | <code>memory</code> | <code>List[Dict[str, Any]]</code> | Conversation memory | Required | | <code>context</code> | <code>Dict[str, Any]</code> | Execution context | Required |</p> <p>Returns: <code>StepResult</code> with step outcome</p> <p>StepResult: <pre><code>@dataclass\nclass StepResult:\n    \"\"\"Result of executing a single step within a branch.\"\"\"\n    # Core execution fields (set by StepExecutor)\n    agent_name: str\n    success: bool\n    response: Any = None\n\n    # Execution metadata (set by StepExecutor)\n    step_id: Optional[str] = None\n    memory_updates: List[Dict[str, Any]] = field(default_factory=list)\n    tool_calls: List[Dict[str, Any]] = field(default_factory=list)\n    tool_results: List[Dict[str, Any]] = field(default_factory=list)\n    error: Optional[str] = None\n    requires_retry: bool = False\n    context_selection: Optional[Dict[str, Any]] = None\n    metadata: Dict[str, Any] = field(default_factory=dict)\n\n    # Routing decision fields (set by BranchExecutor ONLY)\n    action_type: Optional[str] = None\n    parsed_response: Optional[Dict[str, Any]] = None\n    next_agent: Optional[str] = None\n    should_end_branch: bool = False\n    waiting_for_children: bool = False\n    child_branch_ids: List[str] = field(default_factory=list)\n    convergence_target: Optional[str] = None\n</code></pre></p> <p>Example: <pre><code>from marsys.coordination.formats import SystemPromptBuilder\n\nstep_executor = StepExecutor(\n    config=exec_config,\n    system_prompt_builder=SystemPromptBuilder(response_format=\"json\")\n)\n\nresult = await step_executor.execute_step(\n    agent=\"Analyzer\",\n    request=\"Analyze sales data\",\n    memory=conversation_memory,\n    context={\"session\": \"123\"}\n)\n</code></pre></p>"},{"location":"api/execution/#dynamicbranchspawner","title":"DynamicBranchSpawner","text":"<p>Handles runtime creation of parallel branches.</p> <p>Import: <pre><code>from marsys.coordination.execution import DynamicBranchSpawner\n</code></pre></p> <p>Constructor: <pre><code>DynamicBranchSpawner(\n    branch_executor: BranchExecutor,\n    context_manager: ContextManager,\n    config: ExecutionConfig\n)\n</code></pre></p> <p>Key Methods:</p>"},{"location":"api/execution/#handle_parallel_invocation","title":"handle_parallel_invocation","text":"<pre><code>async def handle_parallel_invocation(\n    agents: List[str],\n    requests: Dict[str, Any],\n    parent_branch: ExecutionBranch,\n    context: Dict[str, Any]\n) -&gt; List[asyncio.Task]\n</code></pre> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>agents</code> | <code>List[str]</code> | Agents to invoke in parallel | Required | | <code>requests</code> | <code>Dict[str, Any]</code> | Per-agent requests | Required | | <code>parent_branch</code> | <code>ExecutionBranch</code> | Parent branch | Required | | <code>context</code> | <code>Dict[str, Any]</code> | Execution context | Required |</p> <p>Returns: List of async tasks for parallel execution</p> <p>Example: <pre><code>spawner = DynamicBranchSpawner(\n    branch_executor=branch_exec,\n    context_manager=ctx_mgr,\n    config=exec_config\n)\n\n# Spawn parallel branches\ntasks = await spawner.handle_parallel_invocation(\n    agents=[\"Worker1\", \"Worker2\", \"Worker3\"],\n    requests={\n        \"Worker1\": \"Task 1\",\n        \"Worker2\": \"Task 2\",\n        \"Worker3\": \"Task 3\"\n    },\n    parent_branch=main_branch,\n    context={\"parallel\": True}\n)\n\n# Wait for completion\nresults = await asyncio.gather(*tasks)\n</code></pre></p>"},{"location":"api/execution/#branchresult","title":"BranchResult","text":"<p>Result of branch execution.</p> <p>Import: <pre><code>from marsys.coordination.branches.types import BranchResult\n</code></pre></p> <p>Attributes: | Attribute | Type | Description | |-----------|------|-------------| | <code>branch_id</code> | <code>str</code> | Branch identifier | | <code>status</code> | <code>BranchStatus</code> | Final status | | <code>final_agent</code> | <code>Optional[str]</code> | Last agent executed | | <code>final_response</code> | <code>Any</code> | Final output | | <code>steps_executed</code> | <code>int</code> | Number of steps | | <code>execution_time</code> | <code>float</code> | Total time in seconds | | <code>metadata</code> | <code>Dict[str, Any]</code> | Result metadata | | <code>error</code> | <code>Optional[str]</code> | Error if failed |</p> <p>Example: <pre><code>if result.status == BranchStatus.COMPLETED:\n    print(f\"Success: {result.final_response}\")\n    print(f\"Executed {result.steps_executed} steps\")\n    print(f\"Time: {result.execution_time:.2f}s\")\nelse:\n    print(f\"Failed: {result.error}\")\n</code></pre></p>"},{"location":"api/execution/#toolexecutor","title":"ToolExecutor","text":"<p>Executes tool calls within agent steps.</p> <p>Import: <pre><code>from marsys.coordination.execution import ToolExecutor\n</code></pre></p> <p>Constructor: <pre><code>ToolExecutor(\n    agent_registry: Optional[Any] = None,\n    config: Optional[ExecutionConfig] = None\n)\n</code></pre></p> <p>Key Methods:</p>"},{"location":"api/execution/#execute_tool_calls","title":"execute_tool_calls","text":"<pre><code>async def execute_tool_calls(\n    tool_calls: List[ToolCall],\n    agent_name: str,\n    context: Dict[str, Any]\n) -&gt; List[ToolResult]\n</code></pre> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>tool_calls</code> | <code>List[ToolCall]</code> | Tools to execute | Required | | <code>agent_name</code> | <code>str</code> | Agent making calls | Required | | <code>context</code> | <code>Dict[str, Any]</code> | Execution context | Required |</p> <p>Example: <pre><code>tool_executor = ToolExecutor(\n    agent_registry=AgentRegistry,\n    config=exec_config\n)\n\nresults = await tool_executor.execute_tool_calls(\n    tool_calls=[\n        ToolCall(name=\"search\", arguments={\"query\": \"AI news\"}),\n        ToolCall(name=\"summarize\", arguments={\"text\": \"...\"})\n    ],\n    agent_name=\"Researcher\",\n    context={}\n)\n</code></pre></p> <p>Agent invocation note: - <code>execute_tool_calls</code> is for tools only. - If a name matches a peer agent, it must be invoked through agent action JSON (<code>next_action=\"invoke_agent\"</code>), not through <code>tool_calls</code>.</p>"},{"location":"api/execution/#execution-flow","title":"\ud83d\udd04 Execution Flow","text":""},{"location":"api/execution/#sequential-execution","title":"Sequential Execution","text":"<pre><code># Simple sequential branch\nbranch = ExecutionBranch(\n    branch_type=BranchType.SIMPLE,\n    agent_sequence=[\"Agent1\", \"Agent2\", \"Agent3\"]\n)\n\nresult = await executor.execute_branch(\n    branch=branch,\n    initial_request=\"Process this\",\n    context={}\n)\n</code></pre>"},{"location":"api/execution/#conversation-execution","title":"Conversation Execution","text":"<pre><code># Bidirectional conversation\nbranch = ExecutionBranch(\n    branch_type=BranchType.CONVERSATION,\n    agent_sequence=[\"Agent1\", \"Agent2\"],\n    metadata={\"max_turns\": 5}\n)\n\nresult = await executor.execute_branch(\n    branch=branch,\n    initial_request=\"Let's discuss\",\n    context={}\n)\n</code></pre>"},{"location":"api/execution/#nested-execution","title":"Nested Execution","text":"<pre><code># Branch with child branches\nparent_branch = ExecutionBranch(\n    branch_type=BranchType.NESTED,\n    agent_sequence=[\"Coordinator\"]\n)\n\n# Coordinator spawns child branches dynamically\nresult = await executor.execute_branch(\n    branch=parent_branch,\n    initial_request=\"Coordinate tasks\",\n    context={\"allow_parallel\": True}\n)\n</code></pre>"},{"location":"api/execution/#parallel-execution","title":"\u26a1 Parallel Execution","text":""},{"location":"api/execution/#creating-parallel-branches","title":"Creating Parallel Branches","text":"<pre><code># Response that triggers parallel execution\nresponse = {\n    \"next_action\": \"parallel_invoke\",\n    \"agents\": [\"Worker1\", \"Worker2\", \"Worker3\"],\n    \"agent_requests\": {\n        \"Worker1\": \"Analyze segment A\",\n        \"Worker2\": \"Analyze segment B\",\n        \"Worker3\": \"Analyze segment C\"\n    }\n}\n\n# DynamicBranchSpawner handles this automatically\n</code></pre>"},{"location":"api/execution/#convergence-points","title":"Convergence Points","text":"<pre><code># Wait for all parallel branches\nresults = await spawner.wait_for_convergence(\n    child_branch_ids=[\"branch_1\", \"branch_2\", \"branch_3\"],\n    timeout=300.0  # 5 minutes\n)\n\n# Resume parent with aggregated results\nparent_result = await executor.execute_branch(\n    branch=parent_branch,\n    initial_request=None,\n    context=context,\n    resume_with_results=results\n)\n</code></pre>"},{"location":"api/execution/#best-practices","title":"\ud83d\udccb Best Practices","text":""},{"location":"api/execution/#do","title":"\u2705 DO:","text":"<ul> <li>Set appropriate timeouts for branches</li> <li>Handle errors gracefully</li> <li>Use branch metadata for tracking</li> <li>Monitor memory usage in long conversations</li> <li>Implement convergence points for parallel execution</li> </ul>"},{"location":"api/execution/#dont","title":"\u274c DON'T:","text":"<ul> <li>Create infinite loops without limits</li> <li>Skip error handling</li> <li>Ignore memory management</li> <li>Forget to set convergence timeouts</li> </ul>"},{"location":"api/execution/#related-documentation","title":"\ud83d\udea6 Related Documentation","text":"<ul> <li>Orchestra API - High-level execution orchestration</li> <li>Validation API - Response validation system</li> <li>Topology API - Workflow structure definition</li> <li>Execution Flow Concepts - Conceptual overview</li> </ul> <p>Pro Tip</p> <p>Use <code>BranchType.CONVERSATION</code> for agent dialogues and <code>BranchType.NESTED</code> for dynamic parallelism. The executor handles the complexity automatically.</p>"},{"location":"api/memory/","title":"Memory API","text":"<p>API reference for the memory system that manages agent conversation history.</p>"},{"location":"api/memory/#core-classes","title":"Core Classes","text":""},{"location":"api/memory/#conversationmemory","title":"ConversationMemory","text":"<p>Stores conversation history as a list of Message objects.</p> <p>Import: <pre><code>from marsys.agents.memory import ConversationMemory\n</code></pre></p> <p>Constructor: <pre><code>ConversationMemory(description: Optional[str] = None)\n</code></pre></p> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>description</code> | <code>str</code> | Initial system message content | <code>None</code> |</p> <p>Methods:</p> Method Signature Description <code>add</code> <code>add(message=None, *, role=None, content=None, name=None, tool_calls=None, agent_calls=None, images=None, tool_call_id=None) -&gt; str</code> Add message, returns message_id <code>update</code> <code>update(message_id, *, role=None, content=None, ...) -&gt; None</code> Update existing message by ID <code>retrieve_all</code> <code>retrieve_all() -&gt; List[Dict[str, Any]]</code> Get all messages as dicts <code>retrieve_recent</code> <code>retrieve_recent(n: int = 1) -&gt; List[Dict[str, Any]]</code> Get last n messages as dicts <code>get_messages</code> <code>get_messages() -&gt; List[Dict[str, Any]]</code> Get messages for LLM (same as retrieve_all) <code>retrieve_by_id</code> <code>retrieve_by_id(message_id: str) -&gt; Optional[Dict]</code> Get message by ID <code>retrieve_by_role</code> <code>retrieve_by_role(role: str, n: Optional[int] = None) -&gt; List[Dict]</code> Filter by role <code>remove_by_id</code> <code>remove_by_id(message_id: str) -&gt; bool</code> Delete message by ID <code>replace_memory</code> <code>replace_memory(idx: int, ...) -&gt; None</code> Replace message at index <code>delete_memory</code> <code>delete_memory(idx: int) -&gt; None</code> Delete message at index <code>reset_memory</code> <code>reset_memory() -&gt; None</code> Clear all (keeps system prompt) <p>Example: <pre><code>memory = ConversationMemory(description=\"You are helpful\")\n\n# Add messages\nmsg_id = memory.add(role=\"user\", content=\"Hello\")\nmemory.add(role=\"assistant\", content=\"Hi there!\")\n\n# Retrieve messages\nall_msgs = memory.retrieve_all()  # List[Dict]\nrecent = memory.retrieve_recent(5)\n\n# Clear\nmemory.reset_memory()  # Keeps system prompt\n</code></pre></p>"},{"location":"api/memory/#managedconversationmemory","title":"ManagedConversationMemory","text":"<p>Conversation memory with automatic token management.</p> <p>Import: <pre><code>from marsys.agents.memory import ManagedConversationMemory, ManagedMemoryConfig\n</code></pre></p> <p>Constructor: <pre><code>ManagedConversationMemory(\n    config: Optional[ManagedMemoryConfig] = None,\n    trigger_strategy: Optional[TriggerStrategy] = None,\n    process_strategy: Optional[ProcessStrategy] = None,\n    retrieval_strategy: Optional[RetrievalStrategy] = None,\n    description: Optional[str] = None\n)\n</code></pre></p> <p>Methods: Same as ConversationMemory, plus:</p> Method Description <code>get_raw_messages()</code> Get full raw message history <code>get_cache_stats()</code> Get cache statistics <code>compact_for_payload_error(runtime: Optional[Dict[str, Any]] = None) -&gt; bool</code> Run payload-too-large recovery compaction. Returns <code>True</code> only when serialized payload bytes are reduced <p>Payload Error Recovery (<code>compact_for_payload_error</code>)</p> <p>When an LLM/API call fails with payload-too-large classification, <code>Agent.run_step()</code> can call this method to compact memory and retry.</p> <p>Behavior: - Splits messages into <code>prefix</code> and protected <code>tail</code> using assistant-round boundary semantics (<code>grace_recent_messages = n</code> protects from the n-th most recent assistant message onward) - Runs summarization on the prefix using the same summarization config as normal compaction - Re-appends the protected tail unchanged - Preserves conversation structure (including leading system message) instead of flattening into a single user message - Retains only selected images with a provider-aware byte budget (50% of payload limit) and optional <code>max_retained_images</code> cap - Applies safety guards (minimum viable output and at least one <code>user</code> message) - Treats compaction as successful only if estimated serialized payload bytes decrease - Emits <code>CompactionEvent</code> lifecycle events (<code>started</code>, <code>completed</code>, <code>failed</code>)</p> <p>ManagedMemoryConfig: <pre><code>@dataclass\nclass ManagedMemoryConfig:\n    threshold_tokens: int = 150_000\n    image_token_estimate: int = 800\n    trigger_events: List[str] = [\"add\", \"get_messages\"]\n    cache_invalidation_events: List[str] = [\"add\", \"remove_by_id\", \"delete_memory\"]\n    token_counter: Optional[Callable] = None\n    active_context: ActiveContextPolicyConfig = ...\n\n    @property\n    def compaction_target_tokens(self) -&gt; int:\n        \"\"\"Derived: threshold_tokens * (1 - min_reduction_ratio).\"\"\"\n</code></pre></p> <p>ActiveContextPolicyConfig (key fields): <pre><code>@dataclass\nclass ActiveContextPolicyConfig:\n    enabled: bool = True\n    mode: str = \"compaction\"  # \"compaction\" | \"sliding_window\"\n    processor_order: List[str] = [\"tool_truncation\", \"summarization\", \"backward_packing\"]\n    excluded_processors: List[str] = []\n    min_reduction_ratio: float = 0.4\n    tool_truncation: ToolTruncationConfig = ...\n    summarization: SummarizationConfig = ...\n    backward_packing: BackwardPackingConfig = ...\n</code></pre></p> <p>SummarizationConfig (key fields): <pre><code>@dataclass\nclass SummarizationConfig:\n    enabled: bool = True\n    grace_recent_messages: int = 1\n    output_max_tokens: int = 6000\n    include_original_instruction: bool = True\n    include_image_payload_bytes: bool = False\n    max_retained_images: Optional[int] = None  # Payload recovery defaults to 5 when unset\n</code></pre></p> <p>Notes: - <code>grace_recent_messages</code> uses assistant-round semantics (protect from the N-th most recent assistant message onward). - <code>max_retained_images</code> limits retained image count in summarization output. - Payload recovery compaction additionally enforces a provider-aware byte budget for retained images.</p>"},{"location":"api/memory/#kgmemory","title":"KGMemory","text":"<p>Knowledge graph memory storing facts as (Subject, Predicate, Object) triplets.</p> <p>Import: <pre><code>from marsys.agents.memory import KGMemory\n</code></pre></p> <p>Constructor: <pre><code>KGMemory(\n    model: Union[BaseLocalModel, BaseAPIModel, LocalProviderAdapter],\n    description: Optional[str] = None\n)\n</code></pre></p> <p>Methods: Same as BaseMemory, plus:</p> Method Description <code>add_fact(role, subject, predicate, obj)</code> Add fact directly <code>extract_and_update_from_text(input_text, role)</code> Extract facts from text using model"},{"location":"api/memory/#memorymanager","title":"MemoryManager","text":"<p>Factory that creates appropriate memory type.</p> <p>Import: <pre><code>from marsys.agents.memory import MemoryManager\n</code></pre></p> <p>Constructor: <pre><code>MemoryManager(\n    memory_type: str = \"conversation_history\",\n    description: Optional[str] = None,\n    model: Optional[Union[BaseLocalModel, LocalProviderAdapter]] = None,\n    memory_config: Optional[ManagedMemoryConfig] = None,\n    token_counter: Optional[Callable] = None\n)\n</code></pre></p> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>memory_type</code> | <code>str</code> | <code>\"conversation_history\"</code>, <code>\"managed_conversation\"</code>, or <code>\"kg\"</code> | <code>\"conversation_history\"</code> | | <code>description</code> | <code>str</code> | Initial system prompt | <code>None</code> | | <code>model</code> | <code>BaseLocalModel/LocalProviderAdapter</code> | Required for <code>\"kg\"</code> type | <code>None</code> | | <code>memory_config</code> | <code>ManagedMemoryConfig</code> | Config for managed memory | <code>None</code> | | <code>token_counter</code> | <code>Callable</code> | Custom token counter | <code>None</code> |</p> <p>Methods: Delegates to underlying memory type, plus:</p> Method Description <code>set_event_context(agent_name: str, event_bus: Optional[EventBus], session_id: Optional[str] = None)</code> Enable memory event emission (<code>MemoryResetEvent</code>, <code>CompactionEvent</code>) <code>compact_if_needed(runtime: Optional[Dict[str, Any]] = None)</code> Trigger token-threshold compaction when supported by the underlying memory module <code>compact_for_payload_error(runtime: Optional[Dict[str, Any]] = None) -&gt; bool</code> Trigger payload-too-large recovery compaction when supported by the underlying memory module <code>save_to_file(filepath: str, additional_state: Optional[Dict])</code> Save memory state to JSON (optionally with extra state) <code>load_from_file(filepath: str) -&gt; Optional[Dict]</code> Load memory state and return additional_state if present <p>Example: <pre><code># Standard memory\nmanager = MemoryManager(\n    memory_type=\"conversation_history\",\n    description=\"System prompt\"\n)\n\n# With token management\nmanager = MemoryManager(\n    memory_type=\"managed_conversation\",\n    memory_config=ManagedMemoryConfig(\n        threshold_tokens=100000\n    )\n)\n\n# Knowledge graph\nmanager = MemoryManager(\n    memory_type=\"kg\",\n    model=your_model\n)\n\n# Use it\nmanager.add(role=\"user\", content=\"Hello\")\nmsgs = manager.get_messages()\nmanager.save_to_file(\"memory.json\")\n</code></pre></p>"},{"location":"api/memory/#memoryresetevent","title":"MemoryResetEvent","text":"<p><code>MemoryResetEvent</code> is emitted when memory is cleared (e.g., <code>reset_memory()</code>), enabling planning state to auto-clear.</p> <p>Import: <pre><code>from marsys.agents.memory import MemoryResetEvent\n</code></pre></p> <p>Usage: <pre><code>from marsys.coordination.event_bus import EventBus\n\nbus = EventBus()\nmanager.set_event_context(agent_name=\"Researcher\", event_bus=bus, session_id=\"run_123\")\n</code></pre></p>"},{"location":"api/memory/#compactionevent","title":"CompactionEvent","text":"<p><code>CompactionEvent</code> is emitted by managed memory compaction to report lifecycle progress to status channels.</p> <p>Import: <pre><code>from marsys.coordination.status.events import CompactionEvent\n</code></pre></p> <p>Fields: <pre><code>CompactionEvent(\n    session_id: str,\n    agent_name: str,\n    status: str,              # \"started\" | \"completed\" | \"failed\"\n    pre_tokens: int = 0,\n    post_tokens: int = 0,\n    pre_messages: int = 0,\n    post_messages: int = 0,\n    duration: Optional[float] = None,\n    stages_run: Optional[List[str]] = None,\n)\n</code></pre></p>"},{"location":"api/memory/#message","title":"Message","text":"<p>Single message in conversation.</p> <p>Import: <pre><code>from marsys.agents.memory import Message\n</code></pre></p> <p>Constructor: <pre><code>Message(\n    role: str,\n    content: Optional[Union[str, Dict[str, Any], List[Dict[str, Any]]]] = None,\n    message_id: str = auto_generated,\n    name: Optional[str] = None,\n    tool_calls: Optional[List[ToolCallMsg]] = None,\n    agent_calls: Optional[List[AgentCallMsg]] = None,\n    structured_data: Optional[Dict[str, Any]] = None,\n    images: Optional[List[str]] = None,\n    tool_call_id: Optional[str] = None,\n    reasoning_details: Optional[List[Dict[str, Any]]] = None\n)\n</code></pre></p> <p>Reasoning Details</p> <p>The <code>reasoning_details</code> field preserves model thinking/reasoning traces (e.g., Gemini 3 thought signatures). This is critical for multi-turn tool calling with models that use extended thinking.</p> <p>Role Values: - <code>\"system\"</code> - System instructions - <code>\"user\"</code> - User input - <code>\"assistant\"</code> - Agent response - <code>\"tool\"</code> - Tool response</p> <p>Methods:</p> Method Description <code>to_llm_dict()</code> Convert to LLM API format dict <code>to_api_format()</code> Convert to OpenAI API format <code>from_response_dict(response_dict, ...)</code> Create from model response (classmethod) <code>from_harmonized_response(response, ...)</code> Create from HarmonizedResponse (classmethod) <p>Example: <pre><code># Simple message\nmsg = Message(role=\"user\", content=\"Hello\")\n\n# With tool calls\nmsg = Message(\n    role=\"assistant\",\n    content=None,\n    tool_calls=[\n        ToolCallMsg(\n            id=\"call_123\",\n            call_id=\"call_123\",\n            type=\"function\",\n            name=\"search\",\n            arguments='{\"query\": \"AI\"}'\n        )\n    ]\n)\n\n# Tool response\nmsg = Message(\n    role=\"tool\",\n    content='{\"result\": \"found\"}',\n    tool_call_id=\"call_123\",\n    name=\"search\"\n)\n\n# With images\nmsg = Message(\n    role=\"user\",\n    content=\"Describe this\",\n    images=[\"path/to/image.jpg\"]\n)\n</code></pre></p>"},{"location":"api/memory/#messagecontent","title":"MessageContent","text":"<p>Structured content for agent action responses.</p> <p>Import: <pre><code>from marsys.agents.memory import MessageContent\n</code></pre></p> <p>Constructor: <pre><code>MessageContent(\n    thought: Optional[str] = None,\n    next_action: Optional[str] = None,\n    action_input: Optional[Dict[str, Any]] = None\n)\n</code></pre></p> <p>Valid next_action values: - <code>\"call_tool\"</code> - <code>\"invoke_agent\"</code> - <code>\"final_response\"</code></p> <p>Methods:</p> Method Description <code>to_dict()</code> Convert to dictionary <code>from_dict(data)</code> Create from dictionary (classmethod)"},{"location":"api/memory/#toolcallmsg","title":"ToolCallMsg","text":"<p>Tool call request in a message.</p> <p>Import: <pre><code>from marsys.agents.memory import ToolCallMsg\n</code></pre></p> <p>Constructor: <pre><code>ToolCallMsg(\n    id: str,\n    call_id: str,\n    type: str,\n    name: str,\n    arguments: str\n)\n</code></pre></p> <p>Methods:</p> Method Description <code>to_dict()</code> Convert to OpenAI API format <code>from_dict(data)</code> Create from dict (classmethod)"},{"location":"api/memory/#agentcallmsg","title":"AgentCallMsg","text":"<p>Agent invocation request.</p> <p>Import: <pre><code>from marsys.agents.memory import AgentCallMsg\n</code></pre></p> <p>Constructor: <pre><code>AgentCallMsg(\n    agent_name: str,\n    request: Any\n)\n</code></pre></p> <p>Methods:</p> Method Description <code>to_dict()</code> Convert to dictionary <code>from_dict(data)</code> Create from dict (classmethod) <p>Example: <pre><code>agent_call = AgentCallMsg(\n    agent_name=\"DataProcessor\",\n    request=\"Process the sales data\"\n)\n</code></pre></p>"},{"location":"api/memory/#related-documentation","title":"Related Documentation","text":"<ul> <li>Agent API - Agent memory integration</li> <li>Memory Concepts - Memory usage patterns</li> </ul>"},{"location":"api/models/","title":"Models API Reference","text":"<p>Complete API documentation for the MARSYS model system, providing unified interfaces for local and API-based language models.</p> <p>Model Selection Guide</p> <p>For guidance on choosing models and when to use VLM, see Models Concept Guide.</p>"},{"location":"api/models/#modelconfig","title":"\ud83d\udce6 ModelConfig","text":"<p>Configuration schema for all model types using Pydantic validation.</p>"},{"location":"api/models/#class-definition","title":"Class Definition","text":"<pre><code>from pydantic import BaseModel, Field\nfrom typing import Literal, Optional, Dict, Any\n\nclass ModelConfig(BaseModel):\n    \"\"\"Unified configuration for all model types.\"\"\"\n\n    # Core settings\n    type: Literal[\"local\", \"api\"] = Field(\n        description=\"Model type - local or API-based\"\n    )\n    name: str = Field(\n        description=\"Model identifier or HuggingFace path\"\n    )\n\n    # API settings\n    provider: Optional[str] = Field(\n        default=None,\n        description=\"API provider (openai, anthropic, google, openrouter, xai, openai-oauth, anthropic-oauth)\"\n    )\n    base_url: Optional[str] = Field(\n        default=None,\n        description=\"Custom API endpoint URL\"\n    )\n    api_key: Optional[str] = Field(\n        default=None,\n        description=\"API key (auto-loaded from env if None)\"\n    )\n    oauth_profile: Optional[str] = Field(\n        default=None,\n        description=\"OAuth profile name for openai-oauth / anthropic-oauth\"\n    )\n\n    # Generation parameters\n    max_tokens: int = Field(\n        default=8192,\n        description=\"Maximum output tokens\"\n    )\n    temperature: float = Field(\n        default=0.7,\n        ge=0.0,\n        le=2.0,\n        description=\"Sampling temperature\"\n    )\n    top_p: float = Field(\n        default=1.0,\n        ge=0.0,\n        le=1.0,\n        description=\"Nucleus sampling parameter\"\n    )\n    frequency_penalty: float = Field(\n        default=0.0,\n        ge=-2.0,\n        le=2.0,\n        description=\"Frequency penalty\"\n    )\n    presence_penalty: float = Field(\n        default=0.0,\n        ge=-2.0,\n        le=2.0,\n        description=\"Presence penalty\"\n    )\n\n    # Reasoning parameters\n    thinking_budget: Optional[int] = Field(\n        default=1024,\n        description=\"Token budget for extended thinking (models with thinking support)\"\n    )\n    reasoning_effort: Optional[str] = Field(\n        default=\"low\",\n        description=\"Reasoning effort level (low, medium, high)\"\n    )\n\n    # Local model settings\n    model_class: Optional[Literal[\"llm\", \"vlm\"]] = Field(\n        default=None,\n        description=\"Local model class (required for type='local')\"\n    )\n    backend: Optional[Literal[\"huggingface\", \"vllm\"]] = Field(\n        default=\"huggingface\",\n        description=\"Backend: 'huggingface' (dev) or 'vllm' (production)\"\n    )\n    torch_dtype: str = Field(\n        default=\"auto\",\n        description=\"PyTorch dtype (auto, float16, bfloat16, float32)\"\n    )\n    device_map: str = Field(\n        default=\"auto\",\n        description=\"Device mapping strategy (HuggingFace only)\"\n    )\n\n    # vLLM-specific settings\n    tensor_parallel_size: Optional[int] = Field(\n        default=1,\n        description=\"Number of GPUs for tensor parallelism (vLLM only)\"\n    )\n    gpu_memory_utilization: Optional[float] = Field(\n        default=0.9,\n        description=\"GPU memory utilization fraction 0-1 (vLLM only)\"\n    )\n    quantization: Optional[Literal[\"awq\", \"gptq\", \"fp8\"]] = Field(\n        default=None,\n        description=\"Quantization method (vLLM only)\"\n    )\n\n    # Additional parameters\n    parameters: Dict[str, Any] = Field(\n        default_factory=dict,\n        description=\"Provider-specific parameters\"\n    )\n</code></pre>"},{"location":"api/models/#usage-examples","title":"Usage Examples","text":"<pre><code>from marsys.models import ModelConfig\n\n# OpenAI GPT-5 Codex\ngpt5_config = ModelConfig(\n    type=\"api\",\n    provider=\"openrouter\",\n    name=\"openai/gpt-5-codex\",\n    temperature=0.7,\n    max_tokens=12000\n)\n\n# Anthropic Claude Opus 4.6\nclaude_config = ModelConfig(\n    type=\"api\",\n    provider=\"openrouter\",\n    name=\"anthropic/claude-opus-4.6\",\n    temperature=0.5,\n    max_tokens=12000\n)\n\n# Local LLM (HuggingFace backend)\nllm_config = ModelConfig(\n    type=\"local\",\n    name=\"Qwen/Qwen3-4B-Instruct-2507\",\n    model_class=\"llm\",\n    backend=\"huggingface\",  # Default, can be omitted\n    torch_dtype=\"bfloat16\",\n    device_map=\"auto\",\n    max_tokens=4096\n)\n\n# Local VLM (vLLM backend for production)\nvlm_config = ModelConfig(\n    type=\"local\",\n    name=\"Qwen/Qwen3-VL-8B-Instruct\",\n    model_class=\"vlm\",\n    backend=\"vllm\",\n    tensor_parallel_size=2,\n    gpu_memory_utilization=0.9,\n    quantization=\"fp8\",\n    max_tokens=4096\n)\n\n# Custom API endpoint\ncustom_config = ModelConfig(\n    type=\"api\",\n    name=\"custom-model\",\n    base_url=\"https://api.mycompany.com/v1\",\n    api_key=\"custom-key\",\n    parameters={\"custom_param\": \"value\"}\n)\n</code></pre>"},{"location":"api/models/#oauth-providers-no-api-keys","title":"OAuth Providers (No API Keys)","text":"<p>MARSYS supports OAuth-backed providers that use local CLI credentials instead of API keys:</p> <ul> <li><code>openai-oauth</code>: ChatGPT subscription via Codex CLI (<code>codex login</code>)</li> <li><code>anthropic-oauth</code>: Claude Max subscription via Claude CLI (<code>claude login</code>)</li> </ul> <p>Credentials are read from local files and can be overridden with environment variables:</p> <ul> <li>OpenAI OAuth: <code>~/.codex/auth.json</code> (override with <code>CODEX_AUTH_PATH</code>)</li> <li>Anthropic OAuth: <code>~/.claude/.credentials.json</code> (override with <code>CLAUDE_AUTH_PATH</code>)</li> </ul> <p>OAuth profile resolution order: 1. Explicit <code>credentials_path</code> in <code>ModelConfig</code> 2. <code>oauth_profile</code> in <code>ModelConfig</code> 3. Provider default profile set via <code>marsys oauth set-default ...</code></p> <pre><code># OpenAI ChatGPT OAuth (Codex CLI)\nopenai_oauth = ModelConfig(\n    type=\"api\",\n    provider=\"openai-oauth\",\n    name=\"gpt-5.3-codex\",\n    credentials_path=\"~/.codex/auth.json\"  # Optional override\n)\n\n# Anthropic Claude OAuth (Claude CLI)\nanthropic_oauth = ModelConfig(\n    type=\"api\",\n    provider=\"anthropic-oauth\",\n    name=\"claude-opus-4-6\",\n    credentials_path=\"~/.claude/.credentials.json\"  # Optional override\n)\n</code></pre> <p>Use At Your Own Risk (Anthropic OAuth)</p> <p><code>anthropic-oauth</code> relies on a non-official integration path and may violate provider Terms of Service. Use at your own risk.</p> <p>OpenAI OAuth Compliance</p> <p>MARSYS does not make a legal determination about OpenAI ToS coverage for this OAuth path. Review OpenAI terms for your use case.</p>"},{"location":"api/models/#model-classes","title":"\ud83e\udd16 Model Classes","text":""},{"location":"api/models/#local-model-architecture","title":"Local Model Architecture","text":"<p>MARSYS uses an adapter pattern for local models, supporting two backends:</p> <pre><code>                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                     \u2502        BaseLocalModel        \u2502\n                     \u2502    (Unified Interface)       \u2502\n                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n                     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                     \u2502      LocalAdapterFactory     \u2502\n                     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                  \u2502\n          \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n          \u25bc                       \u25bc                       \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 HuggingFaceLLM   \u2502   \u2502 HuggingFaceVLM   \u2502   \u2502    VLLMAdapter   \u2502\n\u2502    Adapter       \u2502   \u2502    Adapter       \u2502   \u2502 (LLM &amp; VLM)      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"api/models/#baselocalmodel","title":"BaseLocalModel","text":"<p>Unified interface for local models. Recommended for most use cases.</p> <pre><code>from marsys.models import BaseLocalModel\n\nclass BaseLocalModel:\n    \"\"\"Base class for local models using adapter pattern.\"\"\"\n\n    def __init__(\n        self,\n        model_name: str,\n        model_class: str = \"llm\",\n        backend: str = \"huggingface\",\n        max_tokens: int = 1024,\n        thinking_budget: Optional[int] = None,\n        **kwargs\n    ):\n        \"\"\"\n        Initialize local model.\n\n        Args:\n            model_name: HuggingFace model identifier\n            model_class: \"llm\" or \"vlm\"\n            backend: \"huggingface\" or \"vllm\"\n            max_tokens: Maximum generation tokens\n            thinking_budget: Token budget for thinking models\n            **kwargs: Backend-specific parameters:\n                - HuggingFace: torch_dtype, device_map, trust_remote_code\n                - vLLM: tensor_parallel_size, gpu_memory_utilization, quantization\n        \"\"\"\n</code></pre>"},{"location":"api/models/#methods","title":"Methods","text":""},{"location":"api/models/#runmessages-kwargs-dictstr-any","title":"<code>run(messages, **kwargs) -&gt; Dict[str, Any]</code>","text":"<p>Execute the model synchronously.</p> <p>Parameters: - <code>messages</code> (List[Dict]): Conversation messages - <code>json_mode</code> (bool): Enable JSON output mode - <code>max_tokens</code> (Optional[int]): Override max tokens - <code>tools</code> (Optional[List[Dict]]): Tool definitions - <code>images</code> (Optional[List]): Images for VLM - <code>**kwargs</code>: Additional generation parameters</p> <p>Returns: <pre><code>{\n    \"role\": \"assistant\",\n    \"content\": \"Generated response text\",\n    \"thinking\": \"Optional thinking content for thinking models\",\n    \"tool_calls\": []\n}\n</code></pre></p>"},{"location":"api/models/#arunmessages-kwargs-harmonizedresponse","title":"<code>arun(messages, **kwargs) -&gt; HarmonizedResponse</code>","text":"<p>Execute the model asynchronously.</p> <p>Example: <pre><code>from marsys.models import BaseLocalModel\n\n# HuggingFace backend (development)\nmodel = BaseLocalModel(\n    model_name=\"Qwen/Qwen3-4B-Instruct-2507\",\n    model_class=\"llm\",\n    backend=\"huggingface\",\n    torch_dtype=\"bfloat16\",\n    device_map=\"auto\",\n    max_tokens=4096\n)\n\nresponse = model.run(\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n        {\"role\": \"user\", \"content\": \"Explain quantum computing\"}\n    ]\n)\nprint(response[\"content\"])\n\n# vLLM backend (production)\nvlm_model = BaseLocalModel(\n    model_name=\"Qwen/Qwen3-VL-8B-Instruct\",\n    model_class=\"vlm\",\n    backend=\"vllm\",\n    tensor_parallel_size=2,\n    gpu_memory_utilization=0.9,\n    max_tokens=4096\n)\n</code></pre></p>"},{"location":"api/models/#localprovideradapter","title":"LocalProviderAdapter","text":"<p>Abstract base class for local model adapters. Used internally by <code>BaseLocalModel</code>.</p> <pre><code>class LocalProviderAdapter(ABC):\n    \"\"\"Abstract base class for local model provider adapters.\"\"\"\n\n    # Training access (HuggingFace only)\n    model: Any = None      # Raw PyTorch model\n    tokenizer: Any = None  # HuggingFace tokenizer\n\n    @property\n    def supports_training(self) -&gt; bool:\n        \"\"\"True for HuggingFace adapters, False for vLLM.\"\"\"\n\n    @property\n    def backend(self) -&gt; str:\n        \"\"\"Backend name: 'huggingface' or 'vllm'.\"\"\"\n</code></pre>"},{"location":"api/models/#huggingfacellmadapter","title":"HuggingFaceLLMAdapter","text":"<p>Adapter for text-only language models using HuggingFace transformers.</p> <pre><code>from marsys.models import HuggingFaceLLMAdapter\n\nadapter = HuggingFaceLLMAdapter(\n    model_name=\"Qwen/Qwen3-4B-Instruct-2507\",\n    max_tokens=4096,\n    torch_dtype=\"bfloat16\",\n    device_map=\"auto\",\n    thinking_budget=256,\n    trust_remote_code=True\n)\n\n# Access for training\npytorch_model = adapter.model      # AutoModelForCausalLM\ntokenizer = adapter.tokenizer      # AutoTokenizer\n</code></pre>"},{"location":"api/models/#huggingfacevlmadapter","title":"HuggingFaceVLMAdapter","text":"<p>Adapter for vision-language models using HuggingFace transformers.</p> <pre><code>from marsys.models import HuggingFaceVLMAdapter\n\nadapter = HuggingFaceVLMAdapter(\n    model_name=\"Qwen/Qwen3-VL-8B-Instruct\",\n    max_tokens=4096,\n    torch_dtype=\"bfloat16\",\n    device_map=\"auto\",\n    thinking_budget=256\n)\n\n# Process images in messages\nresponse = adapter.run(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"text\", \"text\": \"What's in this image?\"},\n                {\"type\": \"image_url\", \"image_url\": {\"url\": \"path/to/image.jpg\"}}\n            ]\n        }\n    ]\n)\n</code></pre>"},{"location":"api/models/#vllmadapter","title":"VLLMAdapter","text":"<p>Adapter for high-throughput production inference using vLLM.</p> <pre><code>from marsys.models import VLLMAdapter\n\nadapter = VLLMAdapter(\n    model_name=\"Qwen/Qwen3-VL-8B-Instruct\",\n    model_class=\"vlm\",\n    max_tokens=4096,\n    tensor_parallel_size=2,       # Multi-GPU\n    gpu_memory_utilization=0.9,   # Memory fraction\n    quantization=\"fp8\",           # awq, gptq, fp8\n    trust_remote_code=True\n)\n\n# Note: vLLM doesn't support training\nassert not adapter.supports_training\n</code></pre>"},{"location":"api/models/#localadapterfactory","title":"LocalAdapterFactory","text":"<p>Factory to create the appropriate adapter.</p> <pre><code>from marsys.models import LocalAdapterFactory\n\n# Create HuggingFace LLM adapter\nadapter = LocalAdapterFactory.create_adapter(\n    backend=\"huggingface\",\n    model_name=\"Qwen/Qwen3-4B-Instruct-2507\",\n    model_class=\"llm\",\n    torch_dtype=\"bfloat16\",\n    device_map=\"auto\"\n)\n\n# Create vLLM VLM adapter\nadapter = LocalAdapterFactory.create_adapter(\n    backend=\"vllm\",\n    model_name=\"Qwen/Qwen3-VL-8B-Instruct\",\n    model_class=\"vlm\",\n    tensor_parallel_size=2\n)\n</code></pre>"},{"location":"api/models/#baseapimodel","title":"BaseAPIModel","text":"<p>Base class for API-based models.</p> <pre><code>class BaseAPIModel:\n    \"\"\"API model wrapper.\"\"\"\n\n    def __init__(\n        self,\n        provider: str,\n        model_name: str,\n        api_key: Optional[str] = None,\n        base_url: Optional[str] = None,\n        max_tokens: int = 1024,\n        **kwargs\n    ):\n        \"\"\"\n        Initialize API model.\n\n        Args:\n            provider: API provider name\n            model_name: Model identifier\n            api_key: API key (auto-loaded from env if None)\n            base_url: Custom endpoint URL\n            max_tokens: Maximum tokens\n            **kwargs: Provider-specific parameters\n        \"\"\"\n</code></pre>"},{"location":"api/models/#supported-providers","title":"Supported Providers","text":"Provider Models Environment Variable <code>openrouter</code> All major models <code>OPENROUTER_API_KEY</code> <code>openai</code> gpt-5-codex, etc. <code>OPENAI_API_KEY</code> <code>openai-oauth</code> gpt-5.3-codex <code>codex login</code> (<code>~/.codex/auth.json</code>) <code>anthropic</code> claude-opus-4-6, claude-opus-4.6 (alias), etc. <code>ANTHROPIC_API_KEY</code> <code>anthropic-oauth</code> claude-opus-4-6 <code>claude login</code> (<code>~/.claude/.credentials.json</code>) <code>google</code> gemini-3-flash-preview, gemini-3-pro-preview, etc. <code>GOOGLE_API_KEY</code> <code>xai</code> grok-4, grok-4-fast, grok-3, etc. <code>XAI_API_KEY</code>"},{"location":"api/models/#methods_1","title":"Methods","text":""},{"location":"api/models/#runmessages-kwargs-dictstr-any_1","title":"<code>run(messages, **kwargs) -&gt; Dict[str, Any]</code>","text":"<p>Execute API model.</p> <p>Parameters: - <code>messages</code> (List[Dict]): Conversation messages - <code>json_mode</code> (bool): Force JSON response (non-schema mode) - <code>response_schema</code> (Optional[Dict]): Strict JSON schema for structured output - <code>tools</code> (Optional[List[Dict]]): Function definitions - <code>tool_choice</code> (Optional[str]): Tool selection strategy - <code>**kwargs</code>: Provider-specific parameters</p> <p>Example: <pre><code>from marsys.models import BaseAPIModel\n\nmodel = BaseAPIModel(\n    provider=\"openrouter\",\n    model_name=\"anthropic/claude-opus-4.6\",\n    temperature=0.7,\n    max_tokens=12000\n)\n\nresponse = await model.run(\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hello!\"}\n    ],\n    tools=[{\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_weather\",\n            \"description\": \"Get weather for a location\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"location\": {\"type\": \"string\"}\n                },\n                \"required\": [\"location\"]\n            }\n        }\n    }]\n)\n\nif response.get(\"tool_calls\"):\n    for tool_call in response[\"tool_calls\"]:\n        print(f\"Tool: {tool_call['function']['name']}\")\n        print(f\"Args: {tool_call['function']['arguments']}\")\n</code></pre></p>"},{"location":"api/models/#model-factory","title":"\ud83c\udfed Model Factory","text":""},{"location":"api/models/#model-creation","title":"Model Creation","text":"<p>For API models, use <code>BaseAPIModel.from_config()</code>:</p> <pre><code>from marsys.models import BaseAPIModel, ModelConfig\n\nconfig = ModelConfig(\n    type=\"api\",\n    provider=\"openrouter\",\n    name=\"anthropic/claude-opus-4.6\",\n    max_tokens=12000\n)\n\nmodel = BaseAPIModel.from_config(config)\nresponse = await model.arun(messages=[{\"role\": \"user\", \"content\": \"Hello!\"}])\n</code></pre> <p>For local models, use <code>BaseLocalModel</code>:</p> <pre><code>from marsys.models import BaseLocalModel, ModelConfig\n\nconfig = ModelConfig(\n    type=\"local\",\n    model_class=\"llm\",\n    name=\"Qwen/Qwen3-4B-Instruct-2507\",\n    backend=\"huggingface\",\n    torch_dtype=\"bfloat16\",\n    device_map=\"auto\"\n)\n\nmodel = BaseLocalModel(\n    model_name=config.name,\n    model_class=config.model_class,\n    backend=config.backend,\n    torch_dtype=config.torch_dtype,\n    device_map=config.device_map,\n    max_tokens=config.max_tokens\n)\n\nresponse = model.run(messages=[{\"role\": \"user\", \"content\": \"Hello!\"}])\n</code></pre>"},{"location":"api/models/#localadapterfactory_1","title":"LocalAdapterFactory","text":"<p>For direct adapter creation:</p> <pre><code>from marsys.models import LocalAdapterFactory\n\n# Creates the appropriate adapter based on backend and model_class\nadapter = LocalAdapterFactory.create_adapter(\n    backend=\"huggingface\",  # or \"vllm\"\n    model_name=\"Qwen/Qwen3-4B-Instruct-2507\",\n    model_class=\"llm\",      # or \"vlm\"\n    torch_dtype=\"bfloat16\",\n    device_map=\"auto\"\n)\n</code></pre>"},{"location":"api/models/#advanced-features","title":"\ud83c\udfaf Advanced Features","text":""},{"location":"api/models/#tool-calling","title":"Tool Calling","text":"<p>Models support OpenAI-compatible function calling:</p> <pre><code>tools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"search_web\",\n            \"description\": \"Search the web for information\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"query\": {\n                        \"type\": \"string\",\n                        \"description\": \"Search query\"\n                    },\n                    \"max_results\": {\n                        \"type\": \"integer\",\n                        \"description\": \"Maximum results\",\n                        \"default\": 5\n                    }\n                },\n                \"required\": [\"query\"]\n            }\n        }\n    }\n]\n\nresponse = await model.run(\n    messages=[\n        {\"role\": \"user\", \"content\": \"Find information about Mars rovers\"}\n    ],\n    tools=tools,\n    tool_choice=\"auto\"  # auto, none, or specific function name\n)\n\n# Handle tool calls\nif response.get(\"tool_calls\"):\n    for call in response[\"tool_calls\"]:\n        if call[\"function\"][\"name\"] == \"search_web\":\n            args = json.loads(call[\"function\"][\"arguments\"])\n            results = search_web(args[\"query\"], args.get(\"max_results\", 5))\n\n            # Add tool result to conversation\n            messages.append({\n                \"role\": \"tool\",\n                \"content\": json.dumps(results),\n                \"tool_call_id\": call[\"id\"]\n            })\n</code></pre>"},{"location":"api/models/#json-mode","title":"JSON Mode","text":"<p>Force structured JSON output:</p> <pre><code>response = await model.run(\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"Always respond with JSON: {\\\"answer\\\": str, \\\"confidence\\\": float}\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"What is 2+2?\"\n        }\n    ],\n    json_mode=True\n)\n\ndata = json.loads(response[\"content\"])\nprint(f\"Answer: {data['answer']} (Confidence: {data['confidence']})\")\n</code></pre>"},{"location":"api/models/#structured-output-response_schema","title":"Structured Output (<code>response_schema</code>)","text":"<p>Use <code>response_schema</code> for strict schema-constrained JSON:</p> <pre><code>schema = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"answer\": {\"type\": \"string\"},\n        \"confidence\": {\"type\": \"number\"},\n    },\n    \"required\": [\"answer\", \"confidence\"],\n}\n\nresponse = await model.run(\n    messages=[{\"role\": \"user\", \"content\": \"What is 2+2?\"}],\n    response_schema=schema,\n)\n</code></pre> <p>Provider behavior:</p> <ul> <li>OpenAI / OpenRouter / OpenAI OAuth: native JSON schema mode</li> <li>Google: <code>responseSchema</code> in generation config</li> <li>Anthropic / Anthropic OAuth: native <code>output_config.format</code> JSON schema</li> <li><code>response_schema</code> takes precedence over <code>json_mode</code></li> </ul> <p>Strict schema note:</p> <ul> <li>MARSYS auto-normalizes schema objects with <code>additionalProperties: false</code> where required by strict providers.</li> </ul>"},{"location":"api/models/#streaming-responses","title":"Streaming Responses","text":"<p>Stream model output (when supported):</p> <pre><code>async for chunk in model.stream(\n    messages=[{\"role\": \"user\", \"content\": \"Write a story\"}]\n):\n    print(chunk[\"content\"], end=\"\", flush=True)\n</code></pre>"},{"location":"api/models/#error-handling","title":"\ud83d\udee1\ufe0f Error Handling","text":""},{"location":"api/models/#automatic-retry-for-server-errors","title":"Automatic Retry for Server Errors","text":"<p>Built-in Resilience</p> <p>API adapters automatically retry transient server errors with exponential backoff. No manual retry needed!</p> <p>Automatic Retry Behavior:</p> <ul> <li>Max Retries: 3 (total 4 attempts)</li> <li>Backoff: 1s \u2192 2s \u2192 4s (exponential)</li> <li>Retryable Status Codes:<ul> <li><code>500</code> - Internal Server Error</li> <li><code>502</code> - Bad Gateway</li> <li><code>503</code> - Service Unavailable</li> <li><code>504</code> - Gateway Timeout</li> <li><code>529</code> - Overloaded (Anthropic)</li> <li><code>408</code> - Request Timeout (OpenRouter)</li> <li><code>429</code> - Rate Limit (respects <code>retry-after</code> header)</li> </ul> </li> </ul> <p>Example: <pre><code>from marsys.models import BaseAPIModel\n\nmodel = BaseAPIModel(\n    provider=\"openrouter\",\n    model_name=\"anthropic/claude-opus-4.6\",\n    api_key=api_key\n)\n\n# API adapter automatically retries server errors (500, 502, 503, etc.)\n# No manual retry logic needed!\nresponse = await model.arun(messages)\n\n# Logs will show retry attempts:\n# WARNING - Server error 503 from claude-opus-4.6. Retry 1/3 after 1.0s\n# WARNING - Server error 503 from claude-opus-4.6. Retry 2/3 after 2.0s\n# INFO - Request successful after 2 retries\n</code></pre></p> <p>What Gets Retried Automatically:</p> Provider Retryable Errors Non-Retryable Errors OpenRouter 408, 429, 502, 503, 500+ 400, 401, 402, 403 OpenAI 429, 500, 502, 503 400, 401, 404 Anthropic 429, 500, 529 400, 401, 403, 413 Google 429, 500, 503, 504 400, 403, 404"},{"location":"api/models/#manual-error-handling","title":"Manual Error Handling","text":"<p>For errors that aren't automatically retried (client errors, quota issues, etc.):</p> <pre><code>from marsys.agents.exceptions import (\n    ModelError,\n    ModelAPIError,\n    ModelTimeoutError,\n    ModelRateLimitError,\n    ModelTokenLimitError\n)\n\ntry:\n    response = await model.run(messages)\n\nexcept ModelRateLimitError as e:\n    # Rate limits are auto-retried, but if exhausted:\n    logger.error(f\"Rate limit exceeded after {e.context.get('max_retries', 3)} retries\")\n    if e.retry_after:\n        logger.info(f\"Retry after {e.retry_after}s\")\n\nexcept ModelTokenLimitError as e:\n    # Token limit requires reducing input\n    logger.warning(f\"Token limit exceeded: {e.message}\")\n    messages = truncate_messages(messages, e.limit)\n    response = await model.run(messages)\n\nexcept ModelAPIError as e:\n    # Check if it's a server error (already auto-retried)\n    if e.status_code and e.status_code &gt;= 500:\n        logger.error(f\"Server error persisted after retries: {e.message}\")\n    else:\n        # Client error (400-level)\n        logger.error(f\"Client error: {e.status_code} - {e.message}\")\n        # Handle based on error classification\n        if e.classification == \"invalid_request\":\n            # Fix request and retry\n            pass\n        elif e.classification == \"insufficient_credits\":\n            # Handle quota\n            pass\n</code></pre>"},{"location":"api/models/#error-classification","title":"Error Classification","text":"<p>All <code>ModelAPIError</code> instances include classification:</p> <pre><code>except ModelAPIError as e:\n    print(f\"Error Code: {e.error_code}\")\n    print(f\"Classification: {e.classification}\")\n    print(f\"Is Retryable: {e.is_retryable}\")\n    print(f\"Retry After: {e.retry_after}s\")\n    print(f\"Suggested Action: {e.suggested_action}\")\n\n    # Example output for OpenRouter 503:\n    # Error Code: MODEL_API_SERVICE_UNAVAILABLE_ERROR\n    # Classification: service_unavailable\n    # Is Retryable: True\n    # Retry After: 10s\n    # Suggested Action: Service temporarily unavailable. Please try again later.\n</code></pre>"},{"location":"api/models/#usage-tracking","title":"\ud83d\udcca Usage Tracking","text":""},{"location":"api/models/#token-usage","title":"Token Usage","text":"<pre><code>response = await model.run(messages)\n\nusage = response.get(\"usage\", {})\nprint(f\"Prompt tokens: {usage.get('prompt_tokens', 0)}\")\nprint(f\"Completion tokens: {usage.get('completion_tokens', 0)}\")\nprint(f\"Total tokens: {usage.get('total_tokens', 0)}\")\n\n# Estimate cost (OpenAI pricing example)\ncost_per_1k_prompt = 0.03  # $0.03 per 1K tokens\ncost_per_1k_completion = 0.06  # $0.06 per 1K tokens\n\nprompt_cost = (usage.get('prompt_tokens', 0) / 1000) * cost_per_1k_prompt\ncompletion_cost = (usage.get('completion_tokens', 0) / 1000) * cost_per_1k_completion\ntotal_cost = prompt_cost + completion_cost\n\nprint(f\"Estimated cost: ${total_cost:.4f}\")\n</code></pre>"},{"location":"api/models/#best-practices","title":"\ud83d\udea6 Best Practices","text":""},{"location":"api/models/#1-configuration-management","title":"1. Configuration Management","text":"<pre><code># \u2705 GOOD - Environment-based config\nimport os\nfrom marsys.models import ModelConfig\n\nconfig = ModelConfig(\n    type=\"api\",\n    provider=\"openrouter\",\n    name=os.getenv(\"MODEL_NAME\", \"anthropic/claude-opus-4.6\"),\n    temperature=float(os.getenv(\"MODEL_TEMPERATURE\", \"0.7\")),\n    max_tokens=int(os.getenv(\"MAX_TOKENS\", \"12000\"))\n)\n\n# \u274c BAD - Hardcoded values\nconfig = ModelConfig(\n    type=\"api\",\n    provider=\"openrouter\",\n    name=\"anthropic/claude-opus-4.6\",\n    api_key=\"sk-...\"  # Never hardcode!\n)\n</code></pre>"},{"location":"api/models/#2-error-recovery","title":"2. Error Recovery","text":"<pre><code># \u2705 GOOD - Graceful degradation\nasync def robust_model_call(messages, fallback_model=None):\n    try:\n        return await primary_model.run(messages)\n    except ModelError as e:\n        if fallback_model:\n            logger.warning(f\"Primary failed, using fallback: {e}\")\n            return await fallback_model.run(messages)\n        raise\n\n# \u274c BAD - No error handling\nresponse = await model.run(messages)  # Can fail!\n</code></pre>"},{"location":"api/models/#3-resource-management","title":"3. Resource Management","text":"<pre><code># \u2705 GOOD - Proper cleanup for local models\nclass ModelManager:\n    def __init__(self):\n        self.models = {}\n\n    def get_model(self, config: ModelConfig):\n        key = f\"{config.type}:{config.name}\"\n        if key not in self.models:\n            self.models[key] = create_model(config)\n        return self.models[key]\n\n    def cleanup(self):\n        for model in self.models.values():\n            if hasattr(model, 'cleanup'):\n                model.cleanup()\n</code></pre>"},{"location":"api/models/#related-documentation","title":"\ud83d\udd17 Related Documentation","text":"<ul> <li>Agents - How agents use models</li> <li>Configuration - Model configuration guide</li> <li>Error Handling - Error management</li> <li>Examples - Model usage examples</li> </ul>"},{"location":"api/orchestra/","title":"Orchestra API","text":"<p>The high-level coordination API that orchestrates multi-agent workflows.</p>"},{"location":"api/orchestra/#import","title":"Import","text":"<pre><code>from marsys.coordination import Orchestra\nfrom marsys.coordination.orchestra import OrchestraResult\n</code></pre>"},{"location":"api/orchestra/#quick-start","title":"Quick Start","text":""},{"location":"api/orchestra/#one-line-execution","title":"One-Line Execution","text":"<pre><code>result = await Orchestra.run(\n    task=\"Research AI trends and write a report\",\n    topology=topology\n)\n</code></pre>"},{"location":"api/orchestra/#with-configuration","title":"With Configuration","text":"<pre><code>from marsys.coordination.config import ExecutionConfig, StatusConfig\n\nresult = await Orchestra.run(\n    task=\"Complex research task\",\n    topology=topology,\n    execution_config=ExecutionConfig(\n        convergence_timeout=300.0,\n        status=StatusConfig.from_verbosity(1)\n    ),\n    max_steps=50\n)\n</code></pre>"},{"location":"api/orchestra/#orchestra-class","title":"Orchestra Class","text":"<p>The main orchestration class for multi-agent workflows.</p>"},{"location":"api/orchestra/#constructor","title":"Constructor","text":"<pre><code>Orchestra(\n    agent_registry: AgentRegistry,\n    rule_factory_config: Optional[RuleFactoryConfig] = None,\n    state_manager: Optional[StateManager] = None,\n    communication_manager: Optional[CommunicationManager] = None,\n    execution_config: Optional[ExecutionConfig] = None\n)\n</code></pre>"},{"location":"api/orchestra/#orchestrarun-classmethod","title":"Orchestra.run() Classmethod","text":"<p>Main entry point for one-line execution:</p> <pre><code>@classmethod\nasync def run(\n    cls,\n    task: Union[str, Dict[str, Any]],\n    topology: Union[Dict, Topology, PatternConfig],\n    agent_registry: Optional[AgentRegistry] = None,\n    context: Optional[Dict[str, Any]] = None,\n    execution_config: Optional[ExecutionConfig] = None,\n    state_manager: Optional[StateManager] = None,\n    max_steps: int = 100,\n    allow_follow_ups: bool = False,\n    **kwargs\n) -&gt; OrchestraResult\n</code></pre> <p>Parameters:</p> Parameter Type Description Default <code>task</code> <code>Union[str, Dict]</code> Task description or structured request Required <code>topology</code> <code>Union[Dict, Topology, PatternConfig]</code> Agent interaction topology Required <code>agent_registry</code> <code>Optional[AgentRegistry]</code> Custom agent registry Global registry <code>context</code> <code>Optional[Dict]</code> Initial execution context <code>{}</code> <code>execution_config</code> <code>Optional[ExecutionConfig]</code> Execution configuration Default config <code>state_manager</code> <code>Optional[StateManager]</code> State persistence manager None <code>max_steps</code> <code>int</code> Maximum execution steps 100 <code>allow_follow_ups</code> <code>bool</code> Enable follow-up questions False"},{"location":"api/orchestra/#execute-instance-method","title":"execute() Instance Method","text":"<p>For more control, create an Orchestra instance and call execute:</p> <pre><code>orchestra = Orchestra(\n    agent_registry=registry,\n    execution_config=config,\n    state_manager=state_manager\n)\n\nresult = await orchestra.execute(\n    task=\"Process data\",\n    topology=topology,\n    context={\"session_id\": \"abc123\"},\n    max_steps=50\n)\n</code></pre>"},{"location":"api/orchestra/#task-formats","title":"Task Formats","text":""},{"location":"api/orchestra/#text-task","title":"Text Task","text":"<pre><code>task = \"Research the latest AI developments\"\n</code></pre>"},{"location":"api/orchestra/#structured-task","title":"Structured Task","text":"<pre><code>task = {\n    \"request\": \"Analyze market trends\",\n    \"sectors\": [\"tech\", \"finance\"]\n}\n</code></pre>"},{"location":"api/orchestra/#multimodal-task-images","title":"Multimodal Task (Images)","text":"<pre><code>task = {\n    \"content\": \"What is shown in these images?\",\n    \"images\": [\n        \"/path/to/image1.png\",\n        \"/path/to/image2.jpg\"\n    ]\n}\n</code></pre>"},{"location":"api/orchestra/#orchestraresult","title":"OrchestraResult","text":"<p>Result object returned by Orchestra:</p> <pre><code>@dataclass\nclass OrchestraResult:\n    success: bool\n    final_response: Any\n    branch_results: List[BranchResult]\n    total_steps: int\n    total_duration: float\n    metadata: Dict[str, Any] = field(default_factory=dict)\n    error: Optional[str] = None\n</code></pre>"},{"location":"api/orchestra/#properties","title":"Properties","text":"Property Type Description <code>success</code> <code>bool</code> Whether execution completed successfully <code>final_response</code> <code>Any</code> The final output from the workflow <code>branch_results</code> <code>List[BranchResult]</code> Results from each execution branch <code>total_steps</code> <code>int</code> Total number of steps executed <code>total_duration</code> <code>float</code> Total execution time in seconds <code>metadata</code> <code>Dict[str, Any]</code> Additional execution metadata <code>error</code> <code>Optional[str]</code> Error message if failed"},{"location":"api/orchestra/#helper-methods","title":"Helper Methods","text":"<pre><code># Get specific branch result by ID\nbranch = result.get_branch_by_id(\"branch_123\")\n\n# Get all successful branches\nsuccessful = result.get_successful_branches()\n\n# Get final response as formatted text\ntext = result.get_final_response_as_text()\n\n# Check if response is structured data\nis_structured = result.is_structured_response()\n</code></pre>"},{"location":"api/orchestra/#example-usage","title":"Example Usage","text":"<pre><code>result = await Orchestra.run(task, topology)\n\nif result.success:\n    print(f\"Success in {result.total_duration:.2f}s\")\n    print(f\"Response: {result.get_final_response_as_text()}\")\n\n    for branch in result.branch_results:\n        print(f\"Branch {branch.branch_id}: {branch.status}\")\nelse:\n    print(f\"Failed: {result.error}\")\n</code></pre>"},{"location":"api/orchestra/#topology-formats","title":"Topology Formats","text":"<p>Orchestra accepts three topology formats:</p>"},{"location":"api/orchestra/#string-notation","title":"String Notation","text":"<pre><code>topology = {\n    \"agents\": [\"Coordinator\", \"Worker1\", \"Worker2\"],\n    \"flows\": [\n        \"Coordinator -&gt; Worker1\",\n        \"Coordinator -&gt; Worker2\"\n    ]\n}\n</code></pre>"},{"location":"api/orchestra/#pattern-configuration","title":"Pattern Configuration","text":"<pre><code>from marsys.coordination.topology.patterns import PatternConfig\n\ntopology = PatternConfig.hub_and_spoke(\n    hub=\"Coordinator\",\n    spokes=[\"Worker1\", \"Worker2\"],\n    parallel_spokes=True\n)\n</code></pre>"},{"location":"api/orchestra/#topology-object","title":"Topology Object","text":"<pre><code>from marsys.coordination.topology import Topology, Node, Edge\n\ntopology = Topology(\n    nodes=[Node(\"Agent1\"), Node(\"Agent2\")],\n    edges=[Edge(\"Agent1\", \"Agent2\")]\n)\n</code></pre>"},{"location":"api/orchestra/#configuration","title":"Configuration","text":""},{"location":"api/orchestra/#execution-configuration","title":"Execution Configuration","text":"<pre><code>from marsys.coordination.config import ExecutionConfig, StatusConfig\n\nconfig = ExecutionConfig(\n    convergence_timeout=300.0,\n    branch_timeout=600.0,\n    step_timeout=120.0,\n    dynamic_convergence_enabled=True,\n    status=StatusConfig.from_verbosity(1)\n)\n</code></pre>"},{"location":"api/orchestra/#state-management","title":"State Management","text":"<pre><code>from marsys.coordination.state import StateManager, FileStorageBackend\n\nstate_manager = StateManager(\n    storage_backend=FileStorageBackend(\"./state\")\n)\n\nresult = await Orchestra.run(\n    task=task,\n    topology=topology,\n    state_manager=state_manager\n)\n</code></pre>"},{"location":"api/orchestra/#related-documentation","title":"Related Documentation","text":"<ul> <li>Topology System</li> <li>Configuration</li> <li>State Management</li> </ul>"},{"location":"api/overview/","title":"API Reference","text":"<p>Complete API documentation for the MARSYS framework with detailed class references, method signatures, and usage examples.</p>"},{"location":"api/overview/#api-organization","title":"\ud83d\udcda API Organization","text":"<p>The MARSYS API is organized into several key modules:</p> <ul> <li> <p> Orchestra API</p> <p>High-level coordination API for multi-agent workflows</p> <pre><code>from marsys.coordination import Orchestra\nresult = await Orchestra.run(task, topology)\n</code></pre> </li> <li> <p> Agent Classes</p> <p>Agent base classes and implementations</p> <pre><code>from marsys.agents import Agent, BaseAgent\nagent = Agent(\n    model_config=model_config,\n    name=\"Helper\",\n    goal=\"Provide general assistance\",\n    instruction=\"Respond helpfully and clearly to user requests.\",\n)\n</code></pre> </li> <li> <p> Model System</p> <p>Language model configurations and providers</p> <pre><code>from marsys.models import ModelConfig\nconfig = ModelConfig(type=\"api\", provider=\"openai\")\n</code></pre> </li> <li> <p> Topology API</p> <p>Topology definition and pattern configurations</p> <pre><code>from marsys.coordination.topology import Topology\nfrom marsys.coordination.topology.patterns import PatternConfig\n</code></pre> </li> </ul>"},{"location":"api/overview/#core-classes","title":"\ud83c\udfd7\ufe0f Core Classes","text":""},{"location":"api/overview/#coordination-layer","title":"Coordination Layer","text":"Class Module Description <code>Orchestra</code> <code>src.coordination</code> Main orchestration API <code>OrchestraResult</code> <code>src.coordination.orchestra</code> Execution result object <code>ExecutionConfig</code> <code>src.coordination.config</code> Execution configuration <code>StatusConfig</code> <code>src.coordination.config</code> Status output configuration"},{"location":"api/overview/#agent-layer","title":"Agent Layer","text":"Class Module Description <code>BaseAgent</code> <code>src.agents</code> Abstract base agent class <code>Agent</code> <code>src.agents</code> Standard agent implementation <code>BrowserAgent</code> <code>src.agents</code> Web automation agent <code>CodeExecutionAgent</code> <code>src.agents</code> Code execution + file operations agent <code>DataAnalysisAgent</code> <code>src.agents</code> Persistent Python analysis agent <code>FileOperationAgent</code> <code>src.agents</code> File and shell operations agent <code>WebSearchAgent</code> <code>src.agents</code> Multi-source search agent <code>LearnableAgent</code> <code>src.agents</code> Fine-tunable agent <code>AgentPool</code> <code>src.agents.agent_pool</code> Agent pool for parallelism <code>PlanningConfig</code> <code>src.agents.planning</code> Task planning configuration"},{"location":"api/overview/#model-layer","title":"Model Layer","text":"Class Module Description <code>ModelConfig</code> <code>src.models</code> Model configuration <code>BaseAPIModel</code> <code>src.models</code> API model base class <code>BaseLocalModel</code> <code>src.models</code> Local model (unified interface) <code>LocalProviderAdapter</code> <code>src.models</code> Local adapter base class <code>HuggingFaceLLMAdapter</code> <code>src.models</code> HuggingFace LLM adapter <code>HuggingFaceVLMAdapter</code> <code>src.models</code> HuggingFace VLM adapter <code>VLLMAdapter</code> <code>src.models</code> vLLM adapter (production)"},{"location":"api/overview/#topology-layer","title":"Topology Layer","text":"Class Module Description <code>Topology</code> <code>src.coordination.topology</code> Topology definition <code>Node</code> <code>src.coordination.topology</code> Graph node <code>Edge</code> <code>src.coordination.topology</code> Graph edge <code>PatternConfig</code> <code>src.coordination.topology.patterns</code> Pre-defined patterns"},{"location":"api/overview/#quick-reference","title":"\ud83d\udcd6 Quick Reference","text":""},{"location":"api/overview/#creating-agents","title":"Creating Agents","text":"<pre><code>from marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\n# Basic agent\nagent = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\",\n        max_tokens=12000\n    ),\n    name=\"Assistant\",\n    goal=\"A helpful assistant\",\n    instruction=\"Provide concise and accurate answers.\"\n)\n\n# Agent with tools\nagent = Agent(\n    model_config=config,\n    name=\"Researcher\",\n    goal=\"Research and analyze user questions\",\n    instruction=\"Use available tools when needed and synthesize findings.\",\n    tools={\"search_tool\": search_tool, \"analyze_tool\": analyze_tool}\n)\n\n# Browser agent\nfrom marsys.agents import BrowserAgent\n\nbrowser = await BrowserAgent.create_safe(\n    model_config=config,\n    name=\"WebScraper\",\n    mode=\"primitive\",\n    headless=True\n)\n</code></pre>"},{"location":"api/overview/#defining-topologies","title":"Defining Topologies","text":"<pre><code>from marsys.coordination.topology import Topology\nfrom marsys.coordination.topology.patterns import PatternConfig\n\n# Simple topology\ntopology = {\n    \"agents\": [\"A\", \"B\", \"C\"],\n    \"flows\": [\"A -&gt; B\", \"B -&gt; C\"]\n}\n\n# Pattern-based\ntopology = PatternConfig.hub_and_spoke(\n    hub=\"Coordinator\",\n    spokes=[\"Worker1\", \"Worker2\"],\n    parallel_spokes=True\n)\n\n# Object-based\ntopology = Topology(\n    nodes=[Node(\"A\"), Node(\"B\")],\n    edges=[Edge(\"A\", \"B\")],\n    rules=[TimeoutRule(300)]\n)\n</code></pre>"},{"location":"api/overview/#running-workflows","title":"Running Workflows","text":"<pre><code>from marsys.coordination import Orchestra\n\n# Simple execution\nresult = await Orchestra.run(\n    task=\"Analyze this data\",\n    topology=topology\n)\n\n# With configuration\nfrom marsys.coordination.config import ExecutionConfig\n\nresult = await Orchestra.run(\n    task=task,\n    topology=topology,\n    execution_config=ExecutionConfig(\n        convergence_timeout=300,\n        status=StatusConfig.from_verbosity(1)\n    )\n)\n\n# With state management\nfrom marsys.coordination.state import StateManager\n\nresult = await Orchestra.run(\n    task=task,\n    topology=topology,\n    state_manager=StateManager(storage)\n)\n</code></pre>"},{"location":"api/overview/#method-signatures","title":"\ud83d\udd27 Method Signatures","text":""},{"location":"api/overview/#orchestrarun","title":"Orchestra.run()","text":"<pre><code>@classmethod\nasync def run(\n    cls,\n    task: Union[str, Dict[str, Any]],\n    topology: Union[Dict, Topology, PatternConfig],\n    agent_registry: Optional[AgentRegistry] = None,\n    context: Optional[Dict[str, Any]] = None,\n    execution_config: Optional[ExecutionConfig] = None,\n    state_manager: Optional[StateManager] = None,\n    max_steps: int = 100,\n    allow_follow_ups: bool = False,\n    **kwargs\n) -&gt; OrchestraResult\n</code></pre>"},{"location":"api/overview/#agentrun","title":"Agent.run()","text":"<pre><code>async def run(\n    self,\n    prompt: Union[str, Dict],\n    context: Optional[Dict[str, Any]] = None,\n    stream: bool = False,\n    **kwargs\n) -&gt; Message\n</code></pre>"},{"location":"api/overview/#agentpoolacquire","title":"AgentPool.acquire()","text":"<pre><code>async def acquire(\n    self,\n    branch_id: str,\n    timeout: Optional[float] = None\n) -&gt; Agent\n</code></pre>"},{"location":"api/overview/#response-formats","title":"\ud83d\udcca Response Formats","text":""},{"location":"api/overview/#agent-response-format","title":"Agent Response Format","text":"<pre><code># Sequential invocation\n{\n    \"next_action\": \"invoke_agent\",\n    \"action_input\": \"AgentName\"\n}\n\n# Parallel invocation\n{\n    \"next_action\": \"parallel_invoke\",\n    \"agents\": [\"Agent1\", \"Agent2\"],\n    \"agent_requests\": {\n        \"Agent1\": \"Task 1\",\n        \"Agent2\": \"Task 2\"\n    }\n}\n\n# Tool call\n{\n    \"next_action\": \"call_tool\",\n    \"tool_calls\": [\n        {\n            \"id\": \"call_123\",\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"search\",\n                \"arguments\": \"{\\\"query\\\": \\\"AI\\\"}\"\n            }\n        }\n    ]\n}\n\n# Final response\n{\n    \"next_action\": \"final_response\",\n    \"content\": \"Result...\"\n}\n</code></pre>"},{"location":"api/overview/#orchestraresult-structure","title":"OrchestraResult Structure","text":"<pre><code>@dataclass\nclass OrchestraResult:\n    success: bool\n    final_response: Any\n    branch_results: List[BranchResult]\n    total_steps: int\n    total_duration: float\n    metadata: Dict[str, Any]\n    error: Optional[str] = None\n</code></pre>"},{"location":"api/overview/#common-patterns","title":"\ud83c\udfaf Common Patterns","text":""},{"location":"api/overview/#pattern-research-team","title":"Pattern: Research Team","text":"<pre><code># Create specialized agents\nresearcher = Agent(\n    model_config=config,\n    name=\"Researcher\",\n    goal=\"Gather and structure relevant information\",\n    instruction=\"Focus on evidence collection and concise synthesis.\"\n)\nanalyst = Agent(\n    model_config=config,\n    name=\"Analyst\",\n    goal=\"Analyze findings and identify patterns\",\n    instruction=\"Produce clear analytical conclusions from gathered evidence.\"\n)\nwriter = Agent(\n    model_config=config,\n    name=\"Writer\",\n    goal=\"Produce polished final output\",\n    instruction=\"Turn analyzed content into a coherent final response.\"\n)\n\n# Define topology\ntopology = PatternConfig.hub_and_spoke(\n    hub=\"Coordinator\",\n    spokes=[\"Researcher\", \"Analyst\", \"Writer\"],\n    parallel_spokes=True\n)\n\n# Execute\nresult = await Orchestra.run(\n    task=\"Research AI trends\",\n    topology=topology\n)\n</code></pre>"},{"location":"api/overview/#pattern-error-recovery","title":"Pattern: Error Recovery","text":"<pre><code>topology = {\n    \"agents\": [\"User\", \"Processor\", \"ErrorHandler\"],\n    \"flows\": [\n        \"User -&gt; Processor\",\n        \"Processor -&gt; User\",  # Success\n        \"Processor -&gt; ErrorHandler\",  # Error\n        \"ErrorHandler -&gt; User\"\n    ]\n}\n\nconfig = ErrorHandlingConfig(\n    enable_error_routing=True,\n    preserve_error_context=True\n)\n\nresult = await Orchestra.run(\n    task=task,\n    topology=topology,\n    error_config=config\n)\n</code></pre>"},{"location":"api/overview/#pattern-stateful-workflow","title":"Pattern: Stateful Workflow","text":"<pre><code>from marsys.coordination.state import StateManager, FileStorageBackend\n\n# Initialize state management\nstorage = FileStorageBackend(\"./state\")\nstate_manager = StateManager(storage)\n\n# Run with state\nresult = await Orchestra.run(\n    task=\"Long-running analysis\",\n    topology=topology,\n    state_manager=state_manager\n)\n\n# Pause if needed\nawait state_manager.pause_execution(session_id, state)\n\n# Resume later\nstate = await state_manager.resume_execution(session_id)\n</code></pre>"},{"location":"api/overview/#module-index","title":"\ud83d\udd17 Module Index","text":""},{"location":"api/overview/#core-modules","title":"Core Modules","text":"<ul> <li><code>src.coordination</code> - Orchestration and coordination</li> <li><code>src.agents</code> - Agent implementations</li> <li><code>src.models</code> - Language model integrations</li> <li><code>src.environment</code> - Tools and browser automation</li> <li><code>src.utils</code> - Utility functions</li> </ul>"},{"location":"api/overview/#coordination-submodules","title":"Coordination Submodules","text":"<ul> <li><code>src.coordination.orchestra</code> - Orchestra implementation</li> <li><code>src.coordination.topology</code> - Topology system</li> <li><code>src.coordination.execution</code> - Execution engine</li> <li><code>src.coordination.validation</code> - Response validation</li> <li><code>src.coordination.routing</code> - Request routing</li> <li><code>src.coordination.formats</code> - Response format handling (system prompts &amp; processors)</li> <li><code>src.coordination.state</code> - State management</li> <li><code>src.coordination.rules</code> - Rules engine</li> <li><code>src.coordination.communication</code> - User interaction</li> </ul>"},{"location":"api/overview/#agent-submodules","title":"Agent Submodules","text":"<ul> <li><code>src.agents.agents</code> - Core agent classes</li> <li><code>src.agents.memory</code> - Memory management</li> <li><code>src.agents.agent_pool</code> - Pool implementation</li> <li><code>src.agents.registry</code> - Agent registry</li> <li><code>src.agents.browser_agent</code> - Browser automation</li> <li><code>src.agents.planning</code> - Task planning system</li> </ul>"},{"location":"api/overview/#type-definitions","title":"\ud83d\udd0d Type Definitions","text":""},{"location":"api/overview/#common-types","title":"Common Types","text":"<pre><code>from typing import Union, Dict, Any, List, Optional\nfrom dataclasses import dataclass\nfrom enum import Enum\n\n# Task type\nTask = Union[str, Dict[str, Any]]\n\n# Context type\nContext = Dict[str, Any]\n\n# Configuration types\nclass VerbosityLevel(IntEnum):\n    QUIET = 0\n    NORMAL = 1\n    VERBOSE = 2\n\nclass NodeType(Enum):\n    USER = \"user\"\n    AGENT = \"agent\"\n    SYSTEM = \"system\"\n    TOOL = \"tool\"\n\nclass EdgeType(Enum):\n    INVOKE = \"invoke\"\n    NOTIFY = \"notify\"\n    QUERY = \"query\"\n    STREAM = \"stream\"\n\nclass BranchStatus(Enum):\n    PENDING = \"pending\"\n    RUNNING = \"running\"\n    WAITING = \"waiting\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n</code></pre>"},{"location":"api/overview/#error-handling","title":"\ud83d\udcdd Error Handling","text":""},{"location":"api/overview/#exception-hierarchy","title":"Exception Hierarchy","text":"<pre><code># Base exception\nclass MARSYSException(Exception):\n    pass\n\n# Specific exceptions\nclass AgentException(MARSYSException):\n    pass\n\nclass TopologyException(MARSYSException):\n    pass\n\nclass ValidationException(MARSYSException):\n    pass\n\nclass TimeoutException(MARSYSException):\n    pass\n\nclass ConfigurationException(MARSYSException):\n    pass\n</code></pre>"},{"location":"api/overview/#error-handling-example","title":"Error Handling Example","text":"<pre><code>try:\n    result = await Orchestra.run(task, topology)\nexcept TimeoutException as e:\n    logger.error(f\"Execution timed out: {e}\")\n    # Handle timeout\nexcept AgentException as e:\n    logger.error(f\"Agent error: {e}\")\n    # Handle agent error\nexcept MARSYSException as e:\n    logger.error(f\"Framework error: {e}\")\n    # Handle general error\n</code></pre>"},{"location":"api/overview/#next-steps","title":"\ud83d\udea6 Next Steps","text":"<p>Dive deeper into specific APIs:</p> <ul> <li> <p> Orchestra API</p> <p>Complete Orchestra API documentation</p> </li> <li> <p> Agent Classes</p> <p>Detailed agent class reference</p> </li> <li> <p> Model System</p> <p>Model configuration and providers</p> </li> <li> <p> Topology API</p> <p>Topology system reference</p> </li> </ul> <p>API Stability</p> <p>All documented APIs are in beta. We aim to maintain backward compatibility for all public methods and classes in future releases.</p>"},{"location":"api/rules/","title":"Rules API","text":"<p>Complete API reference for the rules engine system that controls multi-agent execution flow through flexible constraints and policies.</p>"},{"location":"api/rules/#overview","title":"\ud83c\udfaf Overview","text":"<p>The Rules API provides a powerful system for enforcing execution constraints, implementing business logic, and managing control flow in multi-agent workflows.</p>"},{"location":"api/rules/#core-classes","title":"\ud83d\udce6 Core Classes","text":""},{"location":"api/rules/#rulesengine","title":"RulesEngine","text":"<p>Central engine for rule evaluation and enforcement.</p> <p>Import: <pre><code>from marsys.coordination.rules import RulesEngine\n</code></pre></p> <p>Constructor: <pre><code>RulesEngine(\n    rules: Optional[List[Rule]] = None,\n    enable_conflict_resolution: bool = True,\n    enable_caching: bool = True\n)\n</code></pre></p> <p>Key Methods:</p>"},{"location":"api/rules/#add_rule","title":"add_rule","text":"<p><pre><code>def add_rule(rule: Rule) -&gt; None\n</code></pre> Add a rule to the engine.</p>"},{"location":"api/rules/#remove_rule","title":"remove_rule","text":"<p><pre><code>def remove_rule(rule_name: str) -&gt; bool\n</code></pre> Remove a rule by name.</p>"},{"location":"api/rules/#check_rules","title":"check_rules","text":"<p><pre><code>async def check_rules(\n    context: RuleContext,\n    rule_type: Optional[RuleType] = None\n) -&gt; RuleResult\n</code></pre> Check all applicable rules for the given context.</p> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>context</code> | <code>RuleContext</code> | Evaluation context | Required | | <code>rule_type</code> | <code>RuleType</code> | Filter by rule type | <code>None</code> |</p> <p>Returns: Aggregated <code>RuleResult</code> from all checked rules</p> <p>Example: <pre><code>engine = RulesEngine()\n\n# Add rules\nengine.add_rule(TimeoutRule(max_duration_seconds=300))\nengine.add_rule(MaxAgentsRule(max_agents=10))\n\n# Check rules\ncontext = RuleContext(\n    rule_type=RuleType.PRE_EXECUTION,\n    session_id=\"session_123\",\n    elapsed_time=150.0\n)\n\nresult = await engine.check_rules(context)\nif not result.passed:\n    print(f\"Rule violation: {result.reason}\")\n</code></pre></p>"},{"location":"api/rules/#rule-abstract-base","title":"Rule (Abstract Base)","text":"<p>Abstract base class for all rules.</p> <p>Import: <pre><code>from marsys.coordination.rules import Rule, RuleType, RulePriority\n</code></pre></p> <p>Constructor: <pre><code>Rule(\n    name: str,\n    rule_type: RuleType,\n    priority: RulePriority = RulePriority.NORMAL,\n    enabled: bool = True\n)\n</code></pre></p> <p>Abstract Methods:</p> Method Description Returns <code>check(context)</code> Evaluate rule against context <code>RuleResult</code> <code>description()</code> Get human-readable description <code>str</code> <p>Properties: | Property | Type | Description | |----------|------|-------------| | <code>name</code> | <code>str</code> | Rule identifier | | <code>rule_type</code> | <code>RuleType</code> | Type of rule | | <code>priority</code> | <code>RulePriority</code> | Execution priority | | <code>enabled</code> | <code>bool</code> | Whether rule is active |</p> <p>Example Custom Rule: <pre><code>class CustomRule(Rule):\n    def __init__(self, threshold: int):\n        super().__init__(\n            name=\"custom_rule\",\n            rule_type=RuleType.PRE_EXECUTION,\n            priority=RulePriority.NORMAL\n        )\n        self.threshold = threshold\n\n    async def check(self, context: RuleContext) -&gt; RuleResult:\n        if context.total_steps &gt; self.threshold:\n            return RuleResult(\n                rule_name=self.name,\n                passed=False,\n                action=\"block\",\n                reason=f\"Steps exceed threshold {self.threshold}\"\n            )\n        return RuleResult(\n            rule_name=self.name,\n            passed=True,\n            action=\"allow\"\n        )\n\n    def description(self) -&gt; str:\n        return f\"Custom rule with threshold {self.threshold}\"\n</code></pre></p>"},{"location":"api/rules/#ruletype","title":"RuleType","text":"<p>Types of rules in the system.</p> <p>Import: <pre><code>from marsys.coordination.rules import RuleType\n</code></pre></p> <p>Values: | Value | Description | When Applied | |-------|-------------|--------------| | <code>PRE_EXECUTION</code> | Before branch/step execution | Validation phase | | <code>POST_EXECUTION</code> | After branch/step execution | Cleanup phase | | <code>SPAWN_CONTROL</code> | Control branch spawning | Before parallel spawn | | <code>RESOURCE_LIMIT</code> | Resource constraints | Continuous monitoring | | <code>FLOW_CONTROL</code> | Execution flow rules | Routing decisions | | <code>VALIDATION</code> | Data validation rules | Input/output validation |</p>"},{"location":"api/rules/#rulepriority","title":"RulePriority","text":"<p>Rule execution priority levels.</p> <p>Import: <pre><code>from marsys.coordination.rules import RulePriority\n</code></pre></p> <p>Values: | Value | Priority | Use Case | |-------|----------|----------| | <code>CRITICAL</code> | 100 | Security, safety rules | | <code>HIGH</code> | 75 | Resource limits, timeouts | | <code>NORMAL</code> | 50 | Standard business logic | | <code>LOW</code> | 25 | Logging, metrics |</p>"},{"location":"api/rules/#rulecontext","title":"RuleContext","text":"<p>Context passed to rules for evaluation.</p> <p>Import: <pre><code>from marsys.coordination.rules import RuleContext\n</code></pre></p> <p>Attributes: | Attribute | Type | Description | |-----------|------|-------------| | <code>rule_type</code> | <code>RuleType</code> | Type of rule being evaluated | | <code>session_id</code> | <code>str</code> | Current session identifier | | <code>branch</code> | <code>ExecutionBranch</code> | Current branch (if applicable) | | <code>agent_name</code> | <code>str</code> | Current agent (if applicable) | | <code>current_step</code> | <code>int</code> | Current execution step | | <code>total_steps</code> | <code>int</code> | Total steps executed | | <code>elapsed_time</code> | <code>float</code> | Elapsed time in seconds | | <code>active_agents</code> | <code>int</code> | Number of active agents | | <code>active_branches</code> | <code>int</code> | Number of active branches | | <code>metadata</code> | <code>Dict</code> | Additional metadata | | <code>memory_usage_mb</code> | <code>float</code> | Current memory usage | | <code>cpu_usage_percent</code> | <code>float</code> | Current CPU usage |</p> <p>Example: <pre><code>context = RuleContext(\n    rule_type=RuleType.PRE_EXECUTION,\n    session_id=\"session_123\",\n    branch=current_branch,\n    name=\"Analyzer\",\n    current_step=5,\n    total_steps=10,\n    elapsed_time=120.5,\n    active_agents=3\n)\n</code></pre></p>"},{"location":"api/rules/#ruleresult","title":"RuleResult","text":"<p>Result of rule evaluation.</p> <p>Import: <pre><code>from marsys.coordination.rules import RuleResult\n</code></pre></p> <p>Attributes: | Attribute | Type | Description | |-----------|------|-------------| | <code>rule_name</code> | <code>str</code> | Name of evaluated rule | | <code>passed</code> | <code>bool</code> | Whether rule passed | | <code>action</code> | <code>str</code> | Action to take | | <code>reason</code> | <code>str</code> | Explanation of result | | <code>modifications</code> | <code>Dict</code> | Suggested modifications | | <code>severity</code> | <code>str</code> | Severity level | | <code>metadata</code> | <code>Dict</code> | Additional metadata | | <code>suggestions</code> | <code>Dict</code> | Improvement suggestions |</p> <p>Action Values: - <code>\"allow\"</code> - Continue execution - <code>\"block\"</code> - Stop execution - <code>\"modify\"</code> - Continue with modifications - <code>\"terminate\"</code> - Terminate immediately</p> <p>Properties: | Property | Type | Description | |----------|------|-------------| | <code>should_continue</code> | <code>bool</code> | Whether to continue execution | | <code>should_block</code> | <code>bool</code> | Whether to block execution |</p>"},{"location":"api/rules/#built-in-rules","title":"\ud83d\udcda Built-in Rules","text":""},{"location":"api/rules/#timeoutrule","title":"TimeoutRule","text":"<p>Enforces execution time limits.</p> <pre><code>from marsys.coordination.rules import TimeoutRule\n\nrule = TimeoutRule(\n    name=\"timeout_rule\",\n    max_duration_seconds=300.0,  # 5 minutes\n    priority=RulePriority.HIGH\n)\n</code></pre>"},{"location":"api/rules/#maxagentsrule","title":"MaxAgentsRule","text":"<p>Limits concurrent agent count.</p> <pre><code>from marsys.coordination.rules import MaxAgentsRule\n\nrule = MaxAgentsRule(\n    name=\"max_agents_rule\",\n    max_agents=10,\n    priority=RulePriority.HIGH\n)\n</code></pre>"},{"location":"api/rules/#maxstepsrule","title":"MaxStepsRule","text":"<p>Limits total execution steps.</p> <pre><code>from marsys.coordination.rules import MaxStepsRule\n\nrule = MaxStepsRule(\n    name=\"max_steps_rule\",\n    max_steps=100,\n    priority=RulePriority.NORMAL\n)\n</code></pre>"},{"location":"api/rules/#memorylimitrule","title":"MemoryLimitRule","text":"<p>Enforces memory usage limits.</p> <pre><code>from marsys.coordination.rules import MemoryLimitRule\n\nrule = MemoryLimitRule(\n    name=\"memory_limit_rule\",\n    max_memory_mb=1024,  # 1GB\n    priority=RulePriority.HIGH\n)\n</code></pre>"},{"location":"api/rules/#conditionalrule","title":"ConditionalRule","text":"<p>Executes based on custom condition.</p> <pre><code>from marsys.coordination.rules import ConditionalRule\n\nrule = ConditionalRule(\n    name=\"conditional_rule\",\n    condition=lambda ctx: ctx.metadata.get(\"premium_user\", False),\n    action_if_true=\"allow\",\n    action_if_false=\"block\",\n    priority=RulePriority.NORMAL\n)\n</code></pre>"},{"location":"api/rules/#agenttimeoutrule","title":"AgentTimeoutRule","text":"<p>Per-agent timeout enforcement.</p> <pre><code>from marsys.coordination.rules import AgentTimeoutRule\n\nrule = AgentTimeoutRule(\n    name=\"agent_timeout_rule\",\n    timeouts={\n        \"DataProcessor\": 60.0,\n        \"Analyzer\": 120.0,\n        \"Reporter\": 30.0\n    },\n    default_timeout=45.0\n)\n</code></pre>"},{"location":"api/rules/#patternrule","title":"PatternRule","text":"<p>Enforces execution patterns.</p> <pre><code>from marsys.coordination.rules import PatternRule, ExecutionPattern\n\nrule = PatternRule(\n    name=\"pattern_rule\",\n    pattern=ExecutionPattern.ALTERNATING,\n    agents=[\"Agent1\", \"Agent2\"]\n)\n</code></pre>"},{"location":"api/rules/#custom-rules","title":"\ud83c\udfa8 Custom Rules","text":""},{"location":"api/rules/#creating-custom-rules","title":"Creating Custom Rules","text":"<pre><code>from marsys.coordination.rules import Rule, RuleResult, RuleContext\n\nclass BusinessHoursRule(Rule):\n    \"\"\"Only allow execution during business hours.\"\"\"\n\n    def __init__(self):\n        super().__init__(\n            name=\"business_hours\",\n            rule_type=RuleType.PRE_EXECUTION,\n            priority=RulePriority.NORMAL\n        )\n\n    async def check(self, context: RuleContext) -&gt; RuleResult:\n        from datetime import datetime\n\n        hour = datetime.now().hour\n        if 9 &lt;= hour &lt; 17:  # 9 AM to 5 PM\n            return RuleResult(\n                rule_name=self.name,\n                passed=True,\n                action=\"allow\"\n            )\n        else:\n            return RuleResult(\n                rule_name=self.name,\n                passed=False,\n                action=\"block\",\n                reason=\"Outside business hours\",\n                suggestions={\"retry_after\": \"9:00 AM\"}\n            )\n\n    def description(self) -&gt; str:\n        return \"Business hours enforcement (9 AM - 5 PM)\"\n</code></pre>"},{"location":"api/rules/#composite-rules","title":"Composite Rules","text":"<pre><code>class CompositeRule(Rule):\n    \"\"\"Combine multiple rules with AND/OR logic.\"\"\"\n\n    def __init__(self, rules: List[Rule], operator: str = \"AND\"):\n        super().__init__(\n            name=\"composite_rule\",\n            rule_type=RuleType.PRE_EXECUTION\n        )\n        self.rules = rules\n        self.operator = operator\n\n    async def check(self, context: RuleContext) -&gt; RuleResult:\n        results = []\n        for rule in self.rules:\n            results.append(await rule.check(context))\n\n        if self.operator == \"AND\":\n            passed = all(r.passed for r in results)\n        else:  # OR\n            passed = any(r.passed for r in results)\n\n        return RuleResult(\n            rule_name=self.name,\n            passed=passed,\n            action=\"allow\" if passed else \"block\",\n            metadata={\"sub_results\": results}\n        )\n</code></pre>"},{"location":"api/rules/#rule-patterns","title":"\ud83d\udd27 Rule Patterns","text":""},{"location":"api/rules/#resource-management-pattern","title":"Resource Management Pattern","text":"<pre><code># Create resource management rules\nrules = [\n    MemoryLimitRule(max_memory_mb=2048),\n    CPULimitRule(max_cpu_percent=80),\n    MaxAgentsRule(max_agents=20),\n    MaxBranchesRule(max_branches=50)\n]\n\nengine = RulesEngine(rules=rules)\n</code></pre>"},{"location":"api/rules/#time-based-pattern","title":"Time-based Pattern","text":"<pre><code># Create time-based rules\nrules = [\n    TimeoutRule(max_duration_seconds=600),\n    AgentTimeoutRule(timeouts={\"slow_agent\": 120}),\n    BusinessHoursRule(),\n    RateLimitRule(max_per_minute=60)\n]\n</code></pre>"},{"location":"api/rules/#security-pattern","title":"Security Pattern","text":"<pre><code># Create security rules\nrules = [\n    AuthorizationRule(required_roles=[\"admin\"]),\n    IPWhitelistRule(allowed_ips=[\"192.168.1.0/24\"]),\n    InputValidationRule(max_input_size=10000),\n    OutputSanitizationRule()\n]\n</code></pre>"},{"location":"api/rules/#rule-lifecycle","title":"\ud83d\udd04 Rule Lifecycle","text":""},{"location":"api/rules/#rule-evaluation-flow","title":"Rule Evaluation Flow","text":"<pre><code># 1. Create context\ncontext = RuleContext(\n    rule_type=RuleType.PRE_EXECUTION,\n    session_id=session_id,\n    branch=branch,\n    elapsed_time=elapsed_time\n)\n\n# 2. Check rules\nresult = await engine.check_rules(context)\n\n# 3. Handle result\nif result.should_block:\n    # Terminate or handle error\n    raise RuleViolation(result.reason)\nelif result.modifications:\n    # Apply modifications\n    apply_modifications(result.modifications)\n\n# 4. Continue execution\nawait continue_execution()\n</code></pre>"},{"location":"api/rules/#dynamic-rule-management","title":"Dynamic Rule Management","text":"<pre><code># Add rules at runtime\nif user.is_premium:\n    engine.add_rule(PremiumFeaturesRule())\n\n# Disable rules temporarily\nengine.get_rule(\"strict_timeout\").enabled = False\n\n# Remove rules\nengine.remove_rule(\"development_only_rule\")\n</code></pre>"},{"location":"api/rules/#best-practices","title":"\ud83d\udccb Best Practices","text":""},{"location":"api/rules/#do","title":"\u2705 DO:","text":"<ul> <li>Use appropriate rule priorities</li> <li>Provide clear reason messages in results</li> <li>Cache expensive rule evaluations</li> <li>Use rule metadata for debugging</li> <li>Combine related rules into composite rules</li> </ul>"},{"location":"api/rules/#dont","title":"\u274c DON'T:","text":"<ul> <li>Create rules with side effects in <code>check()</code></li> <li>Use blocking I/O in rule evaluation</li> <li>Ignore rule priorities</li> <li>Hard-code values in rules</li> <li>Create circular rule dependencies</li> </ul>"},{"location":"api/rules/#related-documentation","title":"\ud83d\udea6 Related Documentation","text":"<ul> <li>Execution API - Execution system using rules</li> <li>Configuration API - Rule configuration</li> <li>Topology API - Topology-based rules</li> <li>Rules Patterns - Common rule patterns</li> </ul> <p>Pro Tip</p> <p>Rules are evaluated in priority order. Use <code>CRITICAL</code> priority for security and safety rules that must always execute first.</p> <p>Performance</p> <p>Keep rule evaluation fast. Expensive operations should be cached or computed asynchronously.</p>"},{"location":"api/state/","title":"State Management API","text":"<p>Complete API reference for state persistence, checkpointing, and session management in multi-agent workflows.</p>"},{"location":"api/state/#overview","title":"\ud83c\udfaf Overview","text":"<p>The State Management API provides comprehensive support for persisting execution state, enabling pause/resume capabilities, checkpointing, and recovery from failures.</p>"},{"location":"api/state/#core-classes","title":"\ud83d\udce6 Core Classes","text":""},{"location":"api/state/#statemanager","title":"StateManager","text":"<p>Main interface for state persistence and recovery.</p> <p>Import: <pre><code>from marsys.coordination.state import StateManager, FileStorageBackend\n</code></pre></p> <p>Constructor: <pre><code>StateManager(\n    storage_backend: StorageBackend,\n    enable_compression: bool = True,\n    enable_checksum: bool = True,\n    max_checkpoints_per_session: int = 10\n)\n</code></pre></p> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>storage_backend</code> | <code>StorageBackend</code> | Storage implementation | Required | | <code>enable_compression</code> | <code>bool</code> | Compress state data | <code>True</code> | | <code>enable_checksum</code> | <code>bool</code> | Validate state integrity | <code>True</code> | | <code>max_checkpoints_per_session</code> | <code>int</code> | Max checkpoints per session | <code>10</code> |</p> <p>Key Methods:</p>"},{"location":"api/state/#save_state","title":"save_state","text":"<p><pre><code>async def save_state(\n    session_id: str,\n    snapshot: StateSnapshot\n) -&gt; None\n</code></pre> Save execution state for a session.</p>"},{"location":"api/state/#load_state","title":"load_state","text":"<p><pre><code>async def load_state(\n    session_id: str\n) -&gt; Optional[StateSnapshot]\n</code></pre> Load execution state for a session.</p>"},{"location":"api/state/#pause_execution","title":"pause_execution","text":"<p><pre><code>async def pause_execution(\n    session_id: str,\n    state: Dict[str, Any]\n) -&gt; None\n</code></pre> Pause execution and save current state.</p>"},{"location":"api/state/#resume_execution","title":"resume_execution","text":"<p><pre><code>async def resume_execution(\n    session_id: str\n) -&gt; Optional[Dict[str, Any]]\n</code></pre> Resume execution from saved state.</p>"},{"location":"api/state/#create_checkpoint","title":"create_checkpoint","text":"<p><pre><code>async def create_checkpoint(\n    session_id: str,\n    checkpoint_name: Optional[str] = None,\n    metadata: Optional[Dict[str, Any]] = None\n) -&gt; str\n</code></pre> Create a checkpoint of current state.</p>"},{"location":"api/state/#restore_checkpoint","title":"restore_checkpoint","text":"<p><pre><code>async def restore_checkpoint(\n    checkpoint_id: str\n) -&gt; Optional[StateSnapshot]\n</code></pre> Restore state from checkpoint.</p>"},{"location":"api/state/#list_sessions","title":"list_sessions","text":"<p><pre><code>async def list_sessions() -&gt; List[str]\n</code></pre> List all saved sessions.</p>"},{"location":"api/state/#list_checkpoints","title":"list_checkpoints","text":"<p><pre><code>async def list_checkpoints(\n    session_id: str\n) -&gt; List[Dict[str, Any]]\n</code></pre> List checkpoints for a session.</p> <p>Example: <pre><code>from pathlib import Path\n\n# Initialize with file storage\nstorage = FileStorageBackend(Path(\"./state\"))\nstate_manager = StateManager(storage)\n\n# Save state\nsnapshot = StateSnapshot(\n    session_id=\"session_123\",\n    timestamp=time.time(),\n    branches=serialized_branches,\n    active_branches={\"branch_1\", \"branch_2\"},\n    completed_branches={\"branch_0\"}\n)\nawait state_manager.save_state(\"session_123\", snapshot)\n\n# Create checkpoint\ncheckpoint_id = await state_manager.create_checkpoint(\n    \"session_123\",\n    checkpoint_name=\"before_critical_section\"\n)\n\n# Resume later\nstate = await state_manager.resume_execution(\"session_123\")\n</code></pre></p>"},{"location":"api/state/#statesnapshot","title":"StateSnapshot","text":"<p>Snapshot of execution state at a point in time.</p> <p>Import: <pre><code>from marsys.coordination.state import StateSnapshot\n</code></pre></p> <p>Attributes: | Attribute | Type | Description | |-----------|------|-------------| | <code>session_id</code> | <code>str</code> | Session identifier | | <code>timestamp</code> | <code>float</code> | Snapshot timestamp | | <code>branches</code> | <code>Dict[str, Dict]</code> | Serialized branch data | | <code>active_branches</code> | <code>Set[str]</code> | Currently active branch IDs | | <code>completed_branches</code> | <code>Set[str]</code> | Completed branch IDs | | <code>waiting_branches</code> | <code>Dict[str, Set[str]]</code> | Parent to waiting children | | <code>branch_results</code> | <code>Dict[str, Dict]</code> | Branch results | | <code>parent_child_map</code> | <code>Dict[str, List[str]]</code> | Parent to children mapping | | <code>child_parent_map</code> | <code>Dict[str, str]</code> | Child to parent mapping | | <code>metadata</code> | <code>Dict[str, Any]</code> | Additional metadata | | <code>checksum</code> | <code>str</code> | Integrity checksum |</p> <p>Methods:</p> Method Description Returns <code>calculate_checksum()</code> Calculate state checksum <code>str</code> <code>validate_checksum()</code> Validate integrity <code>bool</code> <p>Example: <pre><code>snapshot = StateSnapshot(\n    session_id=\"session_123\",\n    timestamp=time.time(),\n    branches={\n        \"branch_1\": {\"id\": \"branch_1\", \"status\": \"running\"},\n        \"branch_2\": {\"id\": \"branch_2\", \"status\": \"pending\"}\n    },\n    active_branches={\"branch_1\"},\n    completed_branches=set(),\n    waiting_branches={},\n    branch_results={},\n    parent_child_map={},\n    child_parent_map={}\n)\n\n# Calculate integrity checksum\nsnapshot.checksum = snapshot.calculate_checksum()\n\n# Validate later\nif not snapshot.validate_checksum():\n    raise StateError(\"State corruption detected\")\n</code></pre></p>"},{"location":"api/state/#storagebackend-abstract","title":"StorageBackend (Abstract)","text":"<p>Abstract base class for storage implementations.</p> <p>Import: <pre><code>from marsys.coordination.state import StorageBackend\n</code></pre></p> <p>Abstract Methods:</p> Method Description Returns <code>save(key, data)</code> Save data with key <code>None</code> <code>load(key)</code> Load data by key <code>Optional[Dict]</code> <code>delete(key)</code> Delete data by key <code>None</code> <code>list_keys(prefix)</code> List keys with prefix <code>List[str]</code> <code>exists(key)</code> Check if key exists <code>bool</code>"},{"location":"api/state/#filestoragebackend","title":"FileStorageBackend","text":"<p>File-based storage implementation.</p> <p>Import: <pre><code>from marsys.coordination.state import FileStorageBackend\nfrom pathlib import Path\n</code></pre></p> <p>Constructor: <pre><code>FileStorageBackend(\n    base_path: Path,\n    compression: Optional[str] = None,\n    encryption_key: Optional[str] = None\n)\n</code></pre></p> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>base_path</code> | <code>Path</code> | Base directory for storage | Required | | <code>compression</code> | <code>str</code> | Compression type | <code>None</code> | | <code>encryption_key</code> | <code>str</code> | Encryption key | <code>None</code> |</p> <p>Directory Structure: <pre><code>base_path/\n\u251c\u2500\u2500 sessions/       # Active session states\n\u251c\u2500\u2500 checkpoints/    # Named checkpoints\n\u2514\u2500\u2500 metadata/       # Session metadata\n</code></pre></p> <p>Example: <pre><code>storage = FileStorageBackend(\n    base_path=Path(\"./state\"),\n    compression=\"gzip\"\n)\n\n# Save data\nawait storage.save(\"session_123\", state_data)\n\n# Load data\ndata = await storage.load(\"session_123\")\n\n# List sessions\nsessions = await storage.list_keys(prefix=\"session_\")\n\n# Check existence\nif await storage.exists(\"session_123\"):\n    print(\"Session exists\")\n</code></pre></p>"},{"location":"api/state/#storage-patterns","title":"\ud83c\udfa8 Storage Patterns","text":""},{"location":"api/state/#custom-storage-backend","title":"Custom Storage Backend","text":"<pre><code>class RedisStorageBackend(StorageBackend):\n    \"\"\"Redis-based storage backend.\"\"\"\n\n    def __init__(self, redis_client):\n        self.client = redis_client\n\n    async def save(self, key: str, data: Dict[str, Any]) -&gt; None:\n        serialized = json.dumps(data)\n        await self.client.set(key, serialized)\n\n    async def load(self, key: str) -&gt; Optional[Dict[str, Any]]:\n        data = await self.client.get(key)\n        return json.loads(data) if data else None\n\n    async def delete(self, key: str) -&gt; None:\n        await self.client.delete(key)\n\n    async def list_keys(self, prefix: str = \"\") -&gt; List[str]:\n        pattern = f\"{prefix}*\" if prefix else \"*\"\n        return await self.client.keys(pattern)\n\n    async def exists(self, key: str) -&gt; bool:\n        return await self.client.exists(key)\n</code></pre>"},{"location":"api/state/#database-storage-backend","title":"Database Storage Backend","text":"<pre><code>class DatabaseStorageBackend(StorageBackend):\n    \"\"\"Database-based storage backend.\"\"\"\n\n    def __init__(self, db_connection):\n        self.db = db_connection\n\n    async def save(self, key: str, data: Dict[str, Any]) -&gt; None:\n        await self.db.execute(\n            \"INSERT OR REPLACE INTO state (key, data, timestamp) VALUES (?, ?, ?)\",\n            (key, json.dumps(data), datetime.now())\n        )\n\n    async def load(self, key: str) -&gt; Optional[Dict[str, Any]]:\n        row = await self.db.fetchone(\n            \"SELECT data FROM state WHERE key = ?\", (key,)\n        )\n        return json.loads(row[0]) if row else None\n</code></pre>"},{"location":"api/state/#state-serialization","title":"\ud83d\udd27 State Serialization","text":""},{"location":"api/state/#branch-serialization","title":"Branch Serialization","text":"<pre><code>def serialize_branch(branch: ExecutionBranch) -&gt; Dict[str, Any]:\n    \"\"\"Serialize execution branch for storage.\"\"\"\n    return {\n        \"id\": branch.id,\n        \"type\": branch.branch_type.value,\n        \"status\": branch.status.value,\n        \"agent_sequence\": branch.agent_sequence,\n        \"current_step\": branch.current_step,\n        \"memory\": serialize_memory(branch.memory),\n        \"metadata\": branch.metadata,\n        \"created_at\": branch.created_at,\n        \"updated_at\": branch.updated_at\n    }\n\ndef deserialize_branch(data: Dict[str, Any]) -&gt; ExecutionBranch:\n    \"\"\"Deserialize execution branch from storage.\"\"\"\n    return ExecutionBranch(\n        id=data[\"id\"],\n        branch_type=BranchType(data[\"type\"]),\n        status=BranchStatus(data[\"status\"]),\n        agent_sequence=data[\"agent_sequence\"],\n        current_step=data[\"current_step\"],\n        memory=deserialize_memory(data[\"memory\"]),\n        metadata=data[\"metadata\"]\n    )\n</code></pre>"},{"location":"api/state/#memory-serialization","title":"Memory Serialization","text":"<pre><code>def serialize_memory(memory: Dict[str, List[Message]]) -&gt; Dict[str, Any]:\n    \"\"\"Serialize agent memory for storage.\"\"\"\n    return {\n        agent_name: [msg.to_dict() for msg in messages]\n        for agent_name, messages in memory.items()\n    }\n\ndef deserialize_memory(data: Dict[str, Any]) -&gt; Dict[str, List[Message]]:\n    \"\"\"Deserialize agent memory from storage.\"\"\"\n    return {\n        agent_name: [Message.from_dict(msg) for msg in messages]\n        for agent_name, messages in data.items()\n    }\n</code></pre>"},{"location":"api/state/#checkpoint-management","title":"\ud83d\udd04 Checkpoint Management","text":""},{"location":"api/state/#creating-checkpoints","title":"Creating Checkpoints","text":"<pre><code># Manual checkpoint\ncheckpoint_id = await state_manager.create_checkpoint(\n    session_id=\"session_123\",\n    checkpoint_name=\"milestone_1\",\n    metadata={\n        \"progress\": 0.5,\n        \"stage\": \"data_processing\",\n        \"timestamp\": datetime.now().isoformat()\n    }\n)\n\nprint(f\"Checkpoint created: {checkpoint_id}\")\n</code></pre>"},{"location":"api/state/#automatic-checkpointing","title":"Automatic Checkpointing","text":"<pre><code>class AutoCheckpointManager:\n    \"\"\"Automatic checkpoint creation.\"\"\"\n\n    def __init__(self, state_manager, interval_seconds=300):\n        self.state_manager = state_manager\n        self.interval = interval_seconds\n        self.last_checkpoint = time.time()\n\n    async def maybe_checkpoint(self, session_id: str, state: StateSnapshot):\n        \"\"\"Create checkpoint if interval elapsed.\"\"\"\n        if time.time() - self.last_checkpoint &gt; self.interval:\n            await self.state_manager.create_checkpoint(\n                session_id,\n                checkpoint_name=f\"auto_{int(time.time())}\"\n            )\n            self.last_checkpoint = time.time()\n</code></pre>"},{"location":"api/state/#restoring-from-checkpoint","title":"Restoring from Checkpoint","text":"<pre><code># List available checkpoints\ncheckpoints = await state_manager.list_checkpoints(\"session_123\")\nfor cp in checkpoints:\n    print(f\"{cp['id']}: {cp['name']} - {cp['created_at']}\")\n\n# Restore specific checkpoint\nstate = await state_manager.restore_checkpoint(\"checkpoint_abc123\")\nif state:\n    print(f\"Restored from checkpoint: {state.session_id}\")\n</code></pre>"},{"location":"api/state/#best-practices","title":"\ud83d\udccb Best Practices","text":""},{"location":"api/state/#do","title":"\u2705 DO:","text":"<ul> <li>Create checkpoints before critical operations</li> <li>Validate checksums after loading state</li> <li>Clean up old sessions periodically</li> <li>Use compression for large states</li> <li>Include metadata in checkpoints</li> </ul>"},{"location":"api/state/#dont","title":"\u274c DON'T:","text":"<ul> <li>Store sensitive data unencrypted</li> <li>Ignore storage failures</li> <li>Keep unlimited checkpoints</li> <li>Serialize non-serializable objects</li> <li>Modify state after checksum calculation</li> </ul>"},{"location":"api/state/#session-lifecycle","title":"\ud83d\udea6 Session Lifecycle","text":""},{"location":"api/state/#complete-session-flow","title":"Complete Session Flow","text":"<pre><code># 1. Start session with state management\nstate_manager = StateManager(storage)\n\nresult = await Orchestra.run(\n    task=\"Long running task\",\n    topology=topology,\n    state_manager=state_manager,\n    context={\"session_id\": \"session_123\"}\n)\n\n# 2. Session can be paused (manually or on error)\nawait state_manager.pause_execution(\"session_123\", current_state)\n\n# 3. Resume later\nstate = await state_manager.resume_execution(\"session_123\")\nif state:\n    result = await Orchestra.resume(\n        state=state,\n        topology=topology\n    )\n\n# 4. Clean up completed session\nawait state_manager.delete_session(\"session_123\")\n</code></pre>"},{"location":"api/state/#related-documentation","title":"\ud83d\udea6 Related Documentation","text":"<ul> <li>Orchestra API - Main orchestration with state support</li> <li>Execution API - Branch execution and state</li> <li>Checkpointing Guide - Checkpoint strategies</li> <li>Recovery Patterns - Failure recovery</li> </ul> <p>Pro Tip</p> <p>Use automatic checkpointing with time or step intervals for long-running workflows. This provides recovery points without manual intervention.</p> <p>Storage Limits</p> <p>File storage backend creates one file per session/checkpoint. Monitor disk usage and implement cleanup for production deployments.</p>"},{"location":"api/tools/","title":"Tools API","text":"<p>Complete API reference for the tool system that enables agents to execute functions and interact with external services.</p>"},{"location":"api/tools/#overview","title":"\ud83c\udfaf Overview","text":"<p>The Tools API provides automatic schema generation, tool execution, and integration with agent capabilities, supporting OpenAI-compatible function calling.</p>"},{"location":"api/tools/#core-functions","title":"\ud83d\udce6 Core Functions","text":""},{"location":"api/tools/#generate_openai_tool_schema","title":"generate_openai_tool_schema","text":"<p>Generates OpenAI-compatible tool schema from Python functions.</p> <p>Import: <pre><code>from marsys.environment.utils import generate_openai_tool_schema\n</code></pre></p> <p>Signature: <pre><code>def generate_openai_tool_schema(\n    func: Callable,\n    func_name: str\n) -&gt; Dict[str, Any]\n</code></pre></p> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>func</code> | <code>Callable</code> | Function to generate schema for | Required | | <code>func_name</code> | <code>str</code> | Name for the tool in schema | Required |</p> <p>Returns: Dictionary with OpenAI tool schema format</p> <p>Example: <pre><code>def search_web(query: str, max_results: int = 5) -&gt; List[Dict]:\n    \"\"\"\n    Search the web for information.\n\n    Args:\n        query: Search query string\n        max_results: Maximum number of results to return\n\n    Returns:\n        List of search results\n    \"\"\"\n    # Implementation\n    pass\n\n# Generate schema\nschema = generate_openai_tool_schema(search_web, \"search_web\")\n\n# Result:\n{\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": \"search_web\",\n        \"description\": \"Search the web for information.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": {\n                    \"type\": \"string\",\n                    \"description\": \"Search query string\"\n                },\n                \"max_results\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Maximum number of results to return\",\n                    \"default\": 5\n                }\n            },\n            \"required\": [\"query\"]\n        }\n    }\n}\n</code></pre></p>"},{"location":"api/tools/#tool-schema-structure","title":"Tool Schema Structure","text":"<p>OpenAI-compatible tool schema format.</p> <pre><code>{\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": str,           # Function name\n        \"description\": str,     # Function description\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                # Parameter definitions\n                \"param_name\": {\n                    \"type\": str,        # JSON schema type\n                    \"description\": str,  # Parameter description\n                    \"default\": Any,     # Default value (optional)\n                    \"enum\": List[Any]   # Allowed values (optional)\n                }\n            },\n            \"required\": List[str]  # Required parameter names\n        }\n    }\n}\n</code></pre>"},{"location":"api/tools/#tool-creation-patterns","title":"\ud83c\udfa8 Tool Creation Patterns","text":""},{"location":"api/tools/#basic-tool-function","title":"Basic Tool Function","text":"<pre><code>def calculate_statistics(\n    data: List[float],\n    include_std: bool = True\n) -&gt; Dict[str, float]:\n    \"\"\"\n    Calculate statistics for numerical data.\n\n    Args:\n        data: List of numerical values\n        include_std: Whether to include standard deviation\n\n    Returns:\n        Dictionary with statistical measures\n    \"\"\"\n    import statistics\n\n    result = {\n        \"mean\": statistics.mean(data),\n        \"median\": statistics.median(data),\n        \"min\": min(data),\n        \"max\": max(data)\n    }\n\n    if include_std and len(data) &gt; 1:\n        result[\"std\"] = statistics.stdev(data)\n\n    return result\n</code></pre>"},{"location":"api/tools/#tool-with-complex-types","title":"Tool with Complex Types","text":"<pre><code>from typing import List, Dict, Optional, Literal\n\ndef process_data(\n    input_data: Dict[str, Any],\n    operation: Literal[\"transform\", \"filter\", \"aggregate\"],\n    options: Optional[Dict[str, Any]] = None\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Process data with specified operation.\n\n    Args:\n        input_data: Input data dictionary\n        operation: Type of operation to perform\n        options: Additional operation options\n\n    Returns:\n        Processed data result\n    \"\"\"\n    # Implementation\n    pass\n\n# Schema includes enum for operation\nschema = generate_openai_tool_schema(process_data, \"process_data\")\n</code></pre>"},{"location":"api/tools/#async-tool-function","title":"Async Tool Function","text":"<pre><code>async def fetch_api_data(\n    endpoint: str,\n    params: Optional[Dict[str, str]] = None,\n    timeout: int = 30\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Fetch data from API endpoint.\n\n    Args:\n        endpoint: API endpoint URL\n        params: Query parameters\n        timeout: Request timeout in seconds\n\n    Returns:\n        API response data\n    \"\"\"\n    import aiohttp\n\n    async with aiohttp.ClientSession() as session:\n        async with session.get(\n            endpoint,\n            params=params,\n            timeout=aiohttp.ClientTimeout(total=timeout)\n        ) as response:\n            return await response.json()\n</code></pre>"},{"location":"api/tools/#tool-integration-with-agents","title":"\ud83d\udd27 Tool Integration with Agents","text":""},{"location":"api/tools/#adding-tools-to-agent","title":"Adding Tools to Agent","text":"<pre><code>from marsys.agents import Agent\n\n# Define tools\ndef search_tool(query: str) -&gt; List[str]:\n    \"\"\"Search for information.\"\"\"\n    # Implementation\n    return [\"result1\", \"result2\"]\n\ndef calculate_tool(expression: str) -&gt; float:\n    \"\"\"Calculate mathematical expression.\"\"\"\n    # Implementation\n    return eval(expression)  # Simplified example\n\n# Create agent with tools\nagent = Agent(\n    model_config=model_config,\n    name=\"Assistant\",\n    goal=\"Assistant with search and calculation capabilities\",\n    instruction=\"Use search_tool for lookup tasks and calculate_tool for math.\",\n    tools={\"search_tool\": search_tool, \"calculate_tool\": calculate_tool},\n)\n\n# Tools are automatically available to the agent\n</code></pre>"},{"location":"api/tools/#custom-tool-name-mapping","title":"Custom Tool Name Mapping","text":"<pre><code>from typing import Literal\n\n# Define tool function\ndef custom_tool_func(input_text: str, mode: Literal[\"fast\", \"accurate\"] = \"fast\") -&gt; str:\n    \"\"\"Custom tool with explicit mode selection.\"\"\"\n    return f\"{mode}: {input_text}\"\n\n# Map to a custom public tool name\nagent = Agent(\n    model_config=model_config,\n    name=\"CustomAgent\",\n    goal=\"Run custom processing tasks\",\n    instruction=\"Use custom_tool when the request needs this specialized processing.\",\n    tools={\"custom_tool\": custom_tool_func}\n)\n</code></pre>"},{"location":"api/tools/#tool-execution","title":"\ud83d\udd04 Tool Execution","text":""},{"location":"api/tools/#toolexecutor","title":"ToolExecutor","text":"<p>Executes tool calls within the coordination system.</p> <p>Import: <pre><code>from marsys.coordination.execution import ToolExecutor\n</code></pre></p> <p>Key Methods:</p>"},{"location":"api/tools/#execute_tool_call","title":"execute_tool_call","text":"<pre><code>async def execute_tool_call(\n    tool_call: Dict[str, Any],\n    available_tools: Dict[str, Callable],\n    context: Dict[str, Any]\n) -&gt; Any\n</code></pre> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>tool_call</code> | <code>Dict</code> | Tool call specification | Required | | <code>available_tools</code> | <code>Dict[str, Callable]</code> | Available tool functions | Required | | <code>context</code> | <code>Dict</code> | Execution context | Required |</p> <p>Tool Call Format: <pre><code>tool_call = {\n    \"id\": \"call_123\",\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": \"search_web\",\n        \"arguments\": '{\"query\": \"AI trends\"}'\n    }\n}\n</code></pre></p> <p>Example: <pre><code>executor = ToolExecutor()\n\n# Execute tool call\nresult = await executor.execute_tool_call(\n    tool_call=tool_call,\n    available_tools={\"search_web\": search_web},\n    context={\"session_id\": \"123\"}\n)\n\n# Result is the tool's return value\n</code></pre></p>"},{"location":"api/tools/#advanced-tool-patterns","title":"\ud83c\udfa8 Advanced Tool Patterns","text":""},{"location":"api/tools/#tool-with-file-io","title":"Tool with File I/O","text":"<pre><code>def read_csv_file(\n    filepath: str,\n    encoding: str = \"utf-8\",\n    delimiter: str = \",\"\n) -&gt; List[Dict[str, str]]:\n    \"\"\"\n    Read CSV file and return as list of dictionaries.\n\n    Args:\n        filepath: Path to CSV file\n        encoding: File encoding\n        delimiter: CSV delimiter\n\n    Returns:\n        List of row dictionaries\n    \"\"\"\n    import csv\n\n    with open(filepath, 'r', encoding=encoding) as f:\n        reader = csv.DictReader(f, delimiter=delimiter)\n        return list(reader)\n</code></pre>"},{"location":"api/tools/#tool-with-external-api","title":"Tool with External API","text":"<pre><code>import os\nimport requests\n\ndef get_weather(\n    city: str,\n    units: Literal[\"metric\", \"imperial\"] = \"metric\"\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Get current weather for a city.\n\n    Args:\n        city: City name\n        units: Temperature units\n\n    Returns:\n        Weather data dictionary\n    \"\"\"\n    api_key = os.getenv(\"WEATHER_API_KEY\")\n    url = \"https://api.openweathermap.org/data/2.5/weather\"\n\n    response = requests.get(url, params={\n        \"q\": city,\n        \"units\": units,\n        \"appid\": api_key\n    })\n\n    if response.status_code == 200:\n        return response.json()\n    else:\n        raise Exception(f\"Weather API error: {response.status_code}\")\n</code></pre>"},{"location":"api/tools/#tool-with-state-management","title":"Tool with State Management","text":"<pre><code>class StatefulTool:\n    \"\"\"Tool that maintains state between calls.\"\"\"\n\n    def __init__(self):\n        self.history = []\n        self.cache = {}\n\n    def process_with_memory(\n        self,\n        input_data: str,\n        use_cache: bool = True\n    ) -&gt; Dict[str, Any]:\n        \"\"\"\n        Process data with memory of previous calls.\n\n        Args:\n            input_data: Input to process\n            use_cache: Whether to use cached results\n\n        Returns:\n            Processing result with context\n        \"\"\"\n        # Check cache\n        if use_cache and input_data in self.cache:\n            return {\n                \"result\": self.cache[input_data],\n                \"cached\": True,\n                \"history_length\": len(self.history)\n            }\n\n        # Process\n        result = self._process(input_data)\n\n        # Update state\n        self.history.append(input_data)\n        self.cache[input_data] = result\n\n        return {\n            \"result\": result,\n            \"cached\": False,\n            \"history_length\": len(self.history)\n        }\n\n    def _process(self, data: str) -&gt; str:\n        # Actual processing logic\n        return data.upper()\n\n# Create instance and use as tool\nstateful_tool = StatefulTool()\nagent = Agent(\n    model_config=config,\n    name=\"StatefulProcessor\",\n    goal=\"Process text with cached state\",\n    instruction=\"Use stateful_process for repeated inputs and report cache usage.\",\n    tools={\"stateful_process\": stateful_tool.process_with_memory},\n)\n</code></pre>"},{"location":"api/tools/#type-mapping","title":"\ud83d\udccb Type Mapping","text":""},{"location":"api/tools/#python-to-json-schema-type-mapping","title":"Python to JSON Schema Type Mapping","text":"Python Type JSON Schema Type Example <code>str</code> <code>\"string\"</code> <code>name: str</code> <code>int</code> <code>\"integer\"</code> <code>age: int</code> <code>float</code> <code>\"number\"</code> <code>price: float</code> <code>bool</code> <code>\"boolean\"</code> <code>active: bool</code> <code>List[T]</code> <code>\"array\"</code> <code>items: List[str]</code> <code>Dict[K, V]</code> <code>\"object\"</code> <code>data: Dict[str, Any]</code> <code>Optional[T]</code> <code>T</code> with nullable <code>value: Optional[int]</code> <code>Literal[...]</code> enum <code>mode: Literal[\"a\", \"b\"]</code> <code>Any</code> No type constraint <code>data: Any</code>"},{"location":"api/tools/#error-handling","title":"\ud83d\udea6 Error Handling","text":""},{"location":"api/tools/#tool-execution-errors","title":"Tool Execution Errors","text":"<pre><code>def safe_tool_wrapper(func: Callable) -&gt; Callable:\n    \"\"\"Wrap tool function with error handling.\"\"\"\n\n    async def wrapper(*args, **kwargs):\n        try:\n            if asyncio.iscoroutinefunction(func):\n                return await func(*args, **kwargs)\n            else:\n                return func(*args, **kwargs)\n        except Exception as e:\n            return {\n                \"error\": str(e),\n                \"error_type\": type(e).__name__,\n                \"tool_name\": func.__name__\n            }\n\n    # Preserve function metadata for schema generation\n    wrapper.__name__ = func.__name__\n    wrapper.__doc__ = func.__doc__\n    wrapper.__annotations__ = func.__annotations__\n\n    return wrapper\n\n# Use wrapper\n@safe_tool_wrapper\ndef risky_tool(data: str) -&gt; str:\n    \"\"\"Tool that might fail.\"\"\"\n    if not data:\n        raise ValueError(\"Empty data\")\n    return data.upper()\n</code></pre>"},{"location":"api/tools/#best-practices","title":"\ud83d\udccb Best Practices","text":""},{"location":"api/tools/#do","title":"\u2705 DO:","text":"<ul> <li>Add clear docstrings with parameter descriptions</li> <li>Use type hints for all parameters</li> <li>Provide default values where appropriate</li> <li>Handle errors gracefully</li> <li>Validate input parameters</li> <li>Return structured data (dicts/lists)</li> </ul>"},{"location":"api/tools/#dont","title":"\u274c DON'T:","text":"<ul> <li>Use <code>*args</code> or <code>**kwargs</code> (breaks schema generation)</li> <li>Return complex objects (use dicts instead)</li> <li>Perform long-running operations without timeout</li> <li>Modify global state without careful design</li> <li>Expose sensitive operations without validation</li> </ul>"},{"location":"api/tools/#related-documentation","title":"\ud83d\udea6 Related Documentation","text":"<ul> <li>Agent API - Agent tool integration</li> <li>Memory API - Tool call messages</li> <li>Execution API - Tool execution</li> <li>Tool Patterns - Common patterns</li> </ul> <p>Pro Tip</p> <p>Always include comprehensive docstrings with Google-style parameter descriptions. The schema generator extracts descriptions from docstrings to create helpful tool descriptions for the LLM.</p> <p>Security</p> <p>Be careful with tools that execute code, access files, or make network requests. Always validate inputs and implement appropriate access controls.</p>"},{"location":"api/topology/","title":"Topology API","text":"<p>Complete API reference for the topology system that defines agent communication patterns and workflow structures.</p>"},{"location":"api/topology/#overview","title":"\ud83c\udfaf Overview","text":"<p>The Topology API provides flexible ways to define multi-agent workflows through graph structures, pre-defined patterns, and string notation.</p>"},{"location":"api/topology/#core-classes","title":"\ud83d\udce6 Core Classes","text":""},{"location":"api/topology/#topology","title":"Topology","text":"<p>Main topology container that holds nodes, edges, and rules.</p> <p>Import: <pre><code>from marsys.coordination.topology import Topology\n</code></pre></p> <p>Constructor: <pre><code>Topology(\n    nodes: List[Union[Node, str]] = None,\n    edges: List[Union[Edge, str]] = None,\n    rules: List[Union[Rule, str]] = None,\n    metadata: Dict[str, Any] = None\n)\n</code></pre></p> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>nodes</code> | <code>List[Union[Node, str]]</code> | Graph nodes (agents) | <code>[]</code> | | <code>edges</code> | <code>List[Union[Edge, str]]</code> | Connections between nodes | <code>[]</code> | | <code>rules</code> | <code>List[Union[Rule, str]]</code> | Execution rules | <code>[]</code> | | <code>metadata</code> | <code>Dict[str, Any]</code> | Additional metadata | <code>{}</code> |</p> <p>Methods: | Method | Returns | Description | |--------|---------|-------------| | <code>add_node(node)</code> | <code>Node</code> | Add a node to topology | | <code>add_edge(edge)</code> | <code>Edge</code> | Add an edge to topology | | <code>add_rule(rule)</code> | <code>Rule</code> | Add a rule to topology | | <code>remove_node(name)</code> | <code>bool</code> | Remove node by name | | <code>remove_edge(source, target)</code> | <code>bool</code> | Remove specific edge | | <code>get_node(name)</code> | <code>Optional[Node]</code> | Get node by name | | <code>validate()</code> | <code>bool</code> | Validate topology consistency |</p> <p>Example: <pre><code>from marsys.coordination.topology import Topology, Node, Edge\n\ntopology = Topology(\n    nodes=[\n        Node(\"Coordinator\", node_type=NodeType.AGENT),\n        Node(\"Worker1\", node_type=NodeType.AGENT),\n        Node(\"Worker2\", node_type=NodeType.AGENT)\n    ],\n    edges=[\n        Edge(\"Coordinator\", \"Worker1\"),\n        Edge(\"Coordinator\", \"Worker2\"),\n        Edge(\"Worker1\", \"Coordinator\"),\n        Edge(\"Worker2\", \"Coordinator\")\n    ]\n)\n</code></pre></p>"},{"location":"api/topology/#node","title":"Node","text":"<p>Represents an agent or system component in the topology.</p> <p>Import: <pre><code>from marsys.coordination.topology import Node, NodeType\n</code></pre></p> <p>Constructor: <pre><code>Node(\n    name: str,\n    node_type: NodeType = NodeType.AGENT,\n    agent_ref: Optional[Any] = None,\n    is_convergence_point: bool = False,\n    metadata: Dict[str, Any] = None\n)\n</code></pre></p> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>name</code> | <code>str</code> | Unique node identifier | Required | | <code>node_type</code> | <code>NodeType</code> | Type of node | <code>AGENT</code> | | <code>agent_ref</code> | <code>Optional[Any]</code> | Reference to agent instance | <code>None</code> | | <code>is_convergence_point</code> | <code>bool</code> | Marks convergence point | <code>False</code> | | <code>metadata</code> | <code>Dict[str, Any]</code> | Additional node data | <code>{}</code> |</p> <p>NodeType Enum: <pre><code>class NodeType(Enum):\n    USER = \"user\"        # User interaction node\n    AGENT = \"agent\"      # AI agent node\n    SYSTEM = \"system\"    # System component\n    TOOL = \"tool\"        # Tool node\n</code></pre></p> <p>Example: <pre><code>from marsys.coordination.topology import Node, NodeType\n\n# Create different node types\nuser_node = Node(\"User\", node_type=NodeType.USER)\nagent_node = Node(\"Assistant\", node_type=NodeType.AGENT)\nconvergence = Node(\n    \"Aggregator\",\n    node_type=NodeType.AGENT,\n    is_convergence_point=True\n)\n</code></pre></p>"},{"location":"api/topology/#edge","title":"Edge","text":"<p>Defines connections and communication paths between nodes.</p> <p>Import: <pre><code>from marsys.coordination.topology import Edge, EdgeType, EdgePattern\n</code></pre></p> <p>Constructor: <pre><code>Edge(\n    source: str,\n    target: str,\n    edge_type: EdgeType = EdgeType.INVOKE,\n    bidirectional: bool = False,\n    pattern: Optional[EdgePattern] = None,\n    metadata: Dict[str, Any] = None\n)\n</code></pre></p> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>source</code> | <code>str</code> | Source node name | Required | | <code>target</code> | <code>str</code> | Target node name | Required | | <code>edge_type</code> | <code>EdgeType</code> | Type of connection | <code>INVOKE</code> | | <code>bidirectional</code> | <code>bool</code> | Two-way communication | <code>False</code> | | <code>pattern</code> | <code>Optional[EdgePattern]</code> | Communication pattern | <code>None</code> | | <code>metadata</code> | <code>Dict[str, Any]</code> | Additional edge data | <code>{}</code> |</p> <p>EdgeType Enum: <pre><code>class EdgeType(Enum):\n    INVOKE = \"invoke\"      # Agent invocation\n    NOTIFY = \"notify\"      # Notification only\n    QUERY = \"query\"        # Query/response\n    STREAM = \"stream\"      # Streaming data\n</code></pre></p> <p>EdgePattern Enum: <pre><code>class EdgePattern(Enum):\n    ALTERNATING = \"alternating\"  # Take turns\n    SYMMETRIC = \"symmetric\"      # Equal access\n</code></pre></p> <p>Example: <pre><code># One-way edge\nedge1 = Edge(\"Manager\", \"Worker\")\n\n# Bidirectional conversation\nedge2 = Edge(\n    \"Agent1\",\n    \"Agent2\",\n    bidirectional=True,\n    pattern=EdgePattern.ALTERNATING\n)\n\n# Notification edge\nedge3 = Edge(\n    \"Monitor\",\n    \"Logger\",\n    edge_type=EdgeType.NOTIFY\n)\n</code></pre></p>"},{"location":"api/topology/#patternconfig","title":"PatternConfig","text":"<p>Pre-defined topology patterns for common use cases.</p> <p>Import: <pre><code>from marsys.coordination.topology.patterns import PatternConfig\n</code></pre></p> <p>Static Methods:</p>"},{"location":"api/topology/#hub_and_spoke","title":"hub_and_spoke","text":"<pre><code>@staticmethod\ndef hub_and_spoke(\n    hub: str,\n    spokes: List[str],\n    parallel_spokes: bool = False,\n    bidirectional: bool = True\n) -&gt; Topology\n</code></pre> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>hub</code> | <code>str</code> | Central coordinator name | Required | | <code>spokes</code> | <code>List[str]</code> | Spoke agent names | Required | | <code>parallel_spokes</code> | <code>bool</code> | Execute spokes in parallel | <code>False</code> | | <code>bidirectional</code> | <code>bool</code> | Two-way communication | <code>True</code> |</p>"},{"location":"api/topology/#pipeline","title":"pipeline","text":"<pre><code>@staticmethod\ndef pipeline(\n    stages: List[Dict[str, Any]],\n    parallel_within_stage: bool = False\n) -&gt; Topology\n</code></pre> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>stages</code> | <code>List[Dict]</code> | Pipeline stages | Required | | <code>parallel_within_stage</code> | <code>bool</code> | Parallel execution in stages | <code>False</code> |</p>"},{"location":"api/topology/#mesh","title":"mesh","text":"<pre><code>@staticmethod\ndef mesh(\n    agents: List[str],\n    fully_connected: bool = True\n) -&gt; Topology\n</code></pre>"},{"location":"api/topology/#hierarchical","title":"hierarchical","text":"<pre><code>@staticmethod\ndef hierarchical(\n    tree: Dict[str, List[str]]\n) -&gt; Topology\n</code></pre> <p>Example: <pre><code>from marsys.coordination.topology.patterns import PatternConfig\n\n# Hub and spoke pattern\ntopology = PatternConfig.hub_and_spoke(\n    hub=\"Coordinator\",\n    spokes=[\"Worker1\", \"Worker2\", \"Worker3\"],\n    parallel_spokes=True\n)\n\n# Pipeline pattern\ntopology = PatternConfig.pipeline(\n    stages=[\n        {\"name\": \"extract\", \"agents\": [\"Extractor\"]},\n        {\"name\": \"transform\", \"agents\": [\"Transformer1\", \"Transformer2\"]},\n        {\"name\": \"load\", \"agents\": [\"Loader\"]}\n    ],\n    parallel_within_stage=True\n)\n\n# Hierarchical pattern\ntopology = PatternConfig.hierarchical(\n    tree={\n        \"CEO\": [\"VP1\", \"VP2\"],\n        \"VP1\": [\"Manager1\", \"Manager2\"],\n        \"VP2\": [\"Manager3\"],\n        \"Manager1\": [\"Worker1\", \"Worker2\"]\n    }\n)\n</code></pre></p>"},{"location":"api/topology/#topology-converters","title":"\ud83d\udd04 Topology Converters","text":""},{"location":"api/topology/#string-notation","title":"String Notation","text":"<p>Convert string-based topology definitions.</p> <p>Format: <pre><code>topology = {\n    \"agents\": [\"Agent1\", \"Agent2\", \"Agent3\"],\n    \"flows\": [\n        \"Agent1 -&gt; Agent2\",      # One-way\n        \"Agent2 &lt;-&gt; Agent3\",      # Bidirectional\n        \"Agent1 =&gt; Agent3\"        # Strong connection\n    ],\n    \"rules\": [\n        \"timeout(300)\",\n        \"max_agents(10)\"\n    ]\n}\n</code></pre></p>"},{"location":"api/topology/#object-notation","title":"Object Notation","text":"<p>Convert object-based topology definitions.</p> <p>Format: <pre><code>topology = {\n    \"agents\": [\n        {\"name\": \"Agent1\", \"type\": \"agent\"},\n        {\"name\": \"User\", \"type\": \"user\"}\n    ],\n    \"flows\": [\n        {\"source\": \"User\", \"target\": \"Agent1\"},\n        {\"source\": \"Agent1\", \"target\": \"User\"}\n    ],\n    \"rules\": [\n        {\"type\": \"timeout\", \"value\": 300}\n    ]\n}\n</code></pre></p>"},{"location":"api/topology/#topologygraph","title":"\ud83d\udcca TopologyGraph","text":"<p>Internal graph representation for routing decisions.</p> <p>Import: <pre><code>from marsys.coordination.topology.graph import TopologyGraph\n</code></pre></p> <p>Key Methods: | Method | Returns | Description | |--------|---------|-------------| | <code>get_entry_points()</code> | <code>List[str]</code> | Find nodes with no incoming edges | | <code>get_allowed_agents(node)</code> | <code>List[str]</code> | Get allowed targets from node | | <code>is_conversation_edge(s, t)</code> | <code>bool</code> | Check if edge is bidirectional | | <code>is_convergence_point(node)</code> | <code>bool</code> | Check if node is convergence point | | <code>get_convergence_points()</code> | <code>List[str]</code> | Get all convergence points |</p>"},{"location":"api/topology/#topologyanalyzer","title":"\ud83d\udcd0 TopologyAnalyzer","text":"<p>Analyzes and validates topology structures.</p> <p>Import: <pre><code>from marsys.coordination.topology.analyzer import TopologyAnalyzer\n</code></pre></p> <p>Constructor: <pre><code>analyzer = TopologyAnalyzer(topology: Topology)\n</code></pre></p> <p>Methods: | Method | Returns | Description | |--------|---------|-------------| | <code>create_graph()</code> | <code>TopologyGraph</code> | Create graph representation | | <code>validate()</code> | <code>Tuple[bool, List[str]]</code> | Validate topology | | <code>find_cycles()</code> | <code>List[List[str]]</code> | Detect cycles | | <code>get_execution_order()</code> | <code>List[str]</code> | Topological sort |</p> <p>Example: <pre><code>analyzer = TopologyAnalyzer(topology)\ngraph = analyzer.create_graph()\n\n# Validate topology\nis_valid, errors = analyzer.validate()\nif not is_valid:\n    print(f\"Topology errors: {errors}\")\n\n# Get execution order\norder = analyzer.get_execution_order()\n</code></pre></p>"},{"location":"api/topology/#best-practices","title":"\ud83d\udccb Best Practices","text":""},{"location":"api/topology/#do","title":"\u2705 DO:","text":"<ul> <li>Keep topologies simple and focused</li> <li>Use pre-defined patterns when possible</li> <li>Validate topology before execution</li> <li>Set convergence points for parallel branches</li> <li>Add timeout rules for safety</li> </ul>"},{"location":"api/topology/#dont","title":"\u274c DON'T:","text":"<ul> <li>Create cyclic dependencies without limits</li> <li>Mix too many patterns</li> <li>Forget error recovery paths</li> <li>Skip validation</li> </ul>"},{"location":"api/topology/#common-patterns","title":"\ud83c\udfa8 Common Patterns","text":""},{"location":"api/topology/#sequential-chain","title":"Sequential Chain","text":"<pre><code>topology = {\n    \"agents\": [\"A\", \"B\", \"C\"],\n    \"flows\": [\"A -&gt; B\", \"B -&gt; C\"]\n}\n</code></pre>"},{"location":"api/topology/#parallel-execution","title":"Parallel Execution","text":"<pre><code>topology = PatternConfig.hub_and_spoke(\n    hub=\"Coordinator\",\n    spokes=[\"Worker1\", \"Worker2\"],\n    parallel_spokes=True\n)\n</code></pre>"},{"location":"api/topology/#conversation-loop","title":"Conversation Loop","text":"<pre><code>topology = {\n    \"agents\": [\"Agent1\", \"Agent2\"],\n    \"flows\": [\"Agent1 &lt;-&gt; Agent2\"],\n    \"rules\": [\"max_turns(5)\"]\n}\n</code></pre>"},{"location":"api/topology/#related-documentation","title":"\ud83d\udea6 Related Documentation","text":"<ul> <li>Topology Concepts - Conceptual overview</li> <li>Orchestra API - Using topologies with Orchestra</li> <li>Execution API - How topologies are executed</li> <li>Rules API - Topology rules reference</li> </ul> <p>Pro Tip</p> <p>Start with pre-defined patterns from <code>PatternConfig</code> and customize as needed. This ensures proper structure and reduces errors.</p>"},{"location":"api/validation/","title":"Validation API","text":"<p>Complete API reference for the response validation and routing system that processes agent responses and determines execution flow.</p>"},{"location":"api/validation/#overview","title":"\ud83c\udfaf Overview","text":"<p>The Validation API provides centralized response processing and routing decisions, handling multiple response formats and ensuring all actions comply with topology permissions.</p>"},{"location":"api/validation/#core-classes","title":"\ud83d\udce6 Core Classes","text":""},{"location":"api/validation/#validationprocessor","title":"ValidationProcessor","text":"<p>Central hub for all response parsing in the coordination system.</p> <p>Import: <pre><code>from marsys.coordination.validation import ValidationProcessor\n</code></pre></p> <p>Constructor: <pre><code>ValidationProcessor(\n    topology_graph: TopologyGraph,\n    response_format: str = \"json\"\n)\n</code></pre></p> <p>Constructor Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>topology_graph</code> | <code>TopologyGraph</code> | The topology graph for permission validation | Required | | <code>response_format</code> | <code>str</code> | Response format name (e.g., \"json\") | <code>\"json\"</code> |</p> <p>Key Methods:</p>"},{"location":"api/validation/#process_response","title":"process_response","text":"<pre><code>async def process_response(\n    raw_response: Any,\n    agent: BaseAgent,\n    branch: ExecutionBranch,\n    exec_state: ExecutionState\n) -&gt; ValidationResult\n</code></pre> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>raw_response</code> | <code>Any</code> | Agent response to validate | Required | | <code>agent</code> | <code>BaseAgent</code> | The responding agent instance | Required | | <code>branch</code> | <code>ExecutionBranch</code> | Current execution branch | Required | | <code>exec_state</code> | <code>ExecutionState</code> | Current execution state | Required |</p> <p>Returns: <code>ValidationResult</code> with parsed action and validation status</p> <p>Example: <pre><code>processor = ValidationProcessor(topology_graph)\n\nresult = await processor.process_response(\n    raw_response={\"next_action\": \"invoke_agent\", \"action_input\": \"Analyzer\"},\n    agent=coordinator_agent,\n    branch=current_branch,\n    exec_state=execution_state\n)\n\nif result.is_valid:\n    print(f\"Action: {result.action_type}\")\n    print(f\"Next agents: {result.next_agents}\")\n</code></pre></p>"},{"location":"api/validation/#validationresult","title":"ValidationResult","text":"<p>Result of response validation.</p> <p>Import: <pre><code>from marsys.coordination.validation import ValidationResult\n</code></pre></p> <p>Attributes: | Attribute | Type | Description | |-----------|------|-------------| | <code>is_valid</code> | <code>bool</code> | Whether validation succeeded | | <code>action_type</code> | <code>ActionType</code> | Type of action to execute | | <code>parsed_response</code> | <code>Dict[str, Any]</code> | Parsed response data | | <code>error_message</code> | <code>str</code> | Error description if invalid | | <code>retry_suggestion</code> | <code>str</code> | Suggestion for retry | | <code>invocations</code> | <code>List[AgentInvocation]</code> | Agent invocation details | | <code>tool_calls</code> | <code>List[Dict]</code> | Tool call specifications |</p> <p>Properties: | Property | Type | Description | |----------|------|-------------| | <code>next_agents</code> | <code>List[str]</code> | Agent names to invoke |</p> <p>Example: <pre><code>if result.is_valid:\n    if result.action_type == ActionType.INVOKE_AGENT:\n        next_agent = result.next_agents[0]\n        print(f\"Invoking: {next_agent}\")\n    elif result.action_type == ActionType.PARALLEL_INVOKE:\n        print(f\"Parallel invoke: {result.next_agents}\")\n    elif result.action_type == ActionType.FINAL_RESPONSE:\n        print(f\"Final: {result.parsed_response['content']}\")\n</code></pre></p>"},{"location":"api/validation/#actiontype","title":"ActionType","text":"<p>Enumeration of supported action types.</p> <p>Import: <pre><code>from marsys.coordination.validation import ActionType\n</code></pre></p> <p>Values: | Value | Description | Response Format | |-------|-------------|-----------------| | <code>INVOKE_AGENT</code> | Sequential agent invocation | <code>{\"next_action\": \"invoke_agent\", \"action_input\": \"Agent\"}</code> | | <code>PARALLEL_INVOKE</code> | Parallel agent execution | <code>{\"next_action\": \"parallel_invoke\", \"agents\": [...], \"agent_requests\": {...}}</code> | | <code>CALL_TOOL</code> | Tool execution | <code>{\"next_action\": \"call_tool\", \"tool_calls\": [...]}</code> | | <code>FINAL_RESPONSE</code> | Complete execution | <code>{\"next_action\": \"final_response\", \"content\": \"...\"}</code> | | <code>END_CONVERSATION</code> | End conversation branch | <code>{\"next_action\": \"end_conversation\"}</code> | | <code>WAIT_AND_AGGREGATE</code> | Wait for parallel results | <code>{\"next_action\": \"wait_and_aggregate\"}</code> | | <code>ERROR_RECOVERY</code> | Route to user for recovery | <code>{\"next_action\": \"error_recovery\", \"error_details\": {...}}</code> | | <code>TERMINAL_ERROR</code> | Display terminal error | <code>{\"next_action\": \"terminal_error\", \"error\": \"...\"}</code> |</p>"},{"location":"api/validation/#router","title":"Router","text":"<p>Converts validation results into execution decisions.</p> <p>Import: <pre><code>from marsys.coordination.routing import Router\n</code></pre></p> <p>Constructor: <pre><code>Router(topology_graph: TopologyGraph)\n</code></pre></p> <p>Key Methods:</p>"},{"location":"api/validation/#route","title":"route","text":"<pre><code>async def route(\n    validation_result: ValidationResult,\n    current_branch: ExecutionBranch,\n    routing_context: RoutingContext\n) -&gt; RoutingDecision\n</code></pre> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>validation_result</code> | <code>ValidationResult</code> | Result from validation | Required | | <code>current_branch</code> | <code>ExecutionBranch</code> | Current execution branch | Required | | <code>routing_context</code> | <code>RoutingContext</code> | Additional routing context | Required |</p> <p>Returns: <code>RoutingDecision</code> with next steps and branch specifications</p> <p>Example: <pre><code>router = Router(topology_graph)\n\ndecision = await router.route(\n    validation_result=validation_result,\n    current_branch=current_branch,\n    routing_context=RoutingContext(\n        metadata={\"retry_count\": 0},\n        error_info=None\n    )\n)\n\n# Process routing decision\nfor step in decision.next_steps:\n    if step.step_type == StepType.AGENT_INVOCATION:\n        await invoke_agent(step.target)\n</code></pre></p>"},{"location":"api/validation/#routingdecision","title":"RoutingDecision","text":"<p>Decision about next execution steps.</p> <p>Import: <pre><code>from marsys.coordination.routing import RoutingDecision\n</code></pre></p> <p>Attributes: | Attribute | Type | Description | |-----------|------|-------------| | <code>next_steps</code> | <code>List[ExecutionStep]</code> | Steps to execute | | <code>should_continue</code> | <code>bool</code> | Whether to continue execution | | <code>branch_specs</code> | <code>List[BranchSpec]</code> | Specifications for new branches | | <code>metadata</code> | <code>Dict[str, Any]</code> | Additional metadata |</p> <p>Example: <pre><code>decision = RoutingDecision(\n    next_steps=[\n        ExecutionStep(\n            step_type=StepType.AGENT_INVOCATION,\n            target=\"Analyzer\",\n            data={\"request\": \"Analyze data\"}\n        )\n    ],\n    should_continue=True,\n    branch_specs=[],\n    metadata={\"step_count\": 5}\n)\n</code></pre></p>"},{"location":"api/validation/#routingcontext","title":"RoutingContext","text":"<p>Context information for routing decisions.</p> <p>Import: <pre><code>from marsys.coordination.routing import RoutingContext\n</code></pre></p> <p>Attributes: | Attribute | Type | Description | |-----------|------|-------------| | <code>metadata</code> | <code>Dict[str, Any]</code> | General metadata | | <code>error_info</code> | <code>Optional[Dict]</code> | Error information if present | | <code>retry_count</code> | <code>int</code> | Number of retry attempts | | <code>steering_enabled</code> | <code>bool</code> | Whether steering is enabled |</p>"},{"location":"api/validation/#executionstep","title":"ExecutionStep","text":"<p>Individual step to execute.</p> <p>Import: <pre><code>from marsys.coordination.routing import ExecutionStep, StepType\n</code></pre></p> <p>Attributes: | Attribute | Type | Description | |-----------|------|-------------| | <code>step_type</code> | <code>StepType</code> | Type of step | | <code>target</code> | <code>str</code> | Target agent or tool | | <code>data</code> | <code>Dict[str, Any]</code> | Step data | | <code>metadata</code> | <code>Dict[str, Any]</code> | Step metadata |</p> <p>StepType Enum: <pre><code>class StepType(Enum):\n    AGENT_INVOCATION = \"agent_invocation\"\n    TOOL_EXECUTION = \"tool_execution\"\n    PARALLEL_SPAWN = \"parallel_spawn\"\n    WAIT_FOR_CONVERGENCE = \"wait_for_convergence\"\n    FINAL_RESPONSE = \"final_response\"\n    ERROR_RECOVERY = \"error_recovery\"\n</code></pre></p>"},{"location":"api/validation/#response-formats","title":"\ud83c\udfa8 Response Formats","text":""},{"location":"api/validation/#standard-json-response","title":"Standard JSON Response","text":"<pre><code># Sequential invocation\n{\n    \"thought\": \"I need to analyze this data\",\n    \"next_action\": \"invoke_agent\",\n    \"action_input\": \"DataAnalyzer\"\n}\n\n# With request data\n{\n    \"next_action\": \"invoke_agent\",\n    \"action_input\": \"DataAnalyzer\",\n    \"request\": \"Analyze sales data for Q4\"\n}\n</code></pre>"},{"location":"api/validation/#parallel-invocation","title":"Parallel Invocation","text":"<pre><code>{\n    \"thought\": \"These can run in parallel\",\n    \"next_action\": \"parallel_invoke\",\n    \"agents\": [\"Worker1\", \"Worker2\", \"Worker3\"],\n    \"agent_requests\": {\n        \"Worker1\": \"Process segment A\",\n        \"Worker2\": \"Process segment B\",\n        \"Worker3\": \"Process segment C\"\n    }\n}\n</code></pre>"},{"location":"api/validation/#tool-calls","title":"Tool Calls","text":"<pre><code>{\n    \"next_action\": \"call_tool\",\n    \"tool_calls\": [\n        {\n            \"id\": \"call_123\",\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"search\",\n                \"arguments\": \"{\\\"query\\\": \\\"AI trends\\\"}\"\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"api/validation/#final-response","title":"Final Response","text":"<pre><code># Text response\n{\n    \"next_action\": \"final_response\",\n    \"content\": \"Here is the analysis result...\"\n}\n\n# Structured response\n{\n    \"next_action\": \"final_response\",\n    \"content\": {\n        \"title\": \"Analysis Report\",\n        \"sections\": [...],\n        \"conclusion\": \"...\"\n    }\n}\n</code></pre>"},{"location":"api/validation/#error-recovery","title":"Error Recovery","text":"<pre><code>{\n    \"next_action\": \"error_recovery\",\n    \"error_details\": {\n        \"type\": \"api_quota_exceeded\",\n        \"message\": \"OpenAI API quota exceeded\",\n        \"provider\": \"openai\"\n    },\n    \"suggested_action\": \"retry\"\n}\n</code></pre>"},{"location":"api/validation/#response-format-system","title":"\ud83d\udcd0 Response Format System","text":"<p>MARSYS uses a pluggable response format architecture that separates system prompt building from response parsing.</p>"},{"location":"api/validation/#architecture-overview","title":"Architecture Overview","text":"<p>The format system consists of: - BaseResponseFormat: Abstract base class defining the format interface - SystemPromptBuilder: Builds system prompts using the configured format - ResponseProcessor: Base class for response parsing - Format Registry: Registry for available formats</p> <pre><code>from marsys.coordination.formats import (\n    SystemPromptBuilder,\n    BaseResponseFormat,\n    JSONResponseFormat,\n    AgentContext,\n    CoordinationContext,\n)\n</code></pre>"},{"location":"api/validation/#systempromptbuilder","title":"SystemPromptBuilder","text":"<p>Builds system prompts for agents using the configured response format.</p> <p>Import: <pre><code>from marsys.coordination.formats import SystemPromptBuilder\n</code></pre></p> <p>Constructor: <pre><code>SystemPromptBuilder(response_format: str = \"json\")\n</code></pre></p> <p>Key Methods:</p>"},{"location":"api/validation/#build","title":"build","text":"<pre><code>def build(\n    agent_context: AgentContext,\n    coordination_context: CoordinationContext,\n    environmental: Optional[dict] = None\n) -&gt; str\n</code></pre> <p>Parameters: | Parameter | Type | Description | Default | |-----------|------|-------------|---------| | <code>agent_context</code> | <code>AgentContext</code> | Agent-specific context | Required | | <code>coordination_context</code> | <code>CoordinationContext</code> | Topology context | Required | | <code>environmental</code> | <code>Optional[dict]</code> | Environmental data (date, etc.) | <code>None</code> |</p> <p>Example: <pre><code>builder = SystemPromptBuilder(response_format=\"json\")\n\nsystem_prompt = builder.build(\n    agent_context=AgentContext(\n        name=\"Coordinator\",\n        goal=\"Coordinate tasks\",\n        instruction=\"You coordinate worker agents...\"\n    ),\n    coordination_context=CoordinationContext(\n        next_agents=[\"Worker1\", \"Worker2\"],\n        can_return_final_response=True\n    )\n)\n</code></pre></p>"},{"location":"api/validation/#agentcontext","title":"AgentContext","text":"<p>Context derived from the agent for prompt building.</p> <p>Import: <pre><code>from marsys.coordination.formats import AgentContext\n</code></pre></p> <p>Attributes: | Attribute | Type | Description | |-----------|------|-------------| | <code>name</code> | <code>str</code> | Agent name | | <code>goal</code> | <code>str</code> | Agent goal description | | <code>instruction</code> | <code>str</code> | Agent behavior instructions | | <code>tools</code> | <code>Optional[Dict]</code> | Available tools | | <code>tools_schema</code> | <code>Optional[List[Dict]]</code> | Tool schemas for prompt | | <code>input_schema</code> | <code>Optional[Dict]</code> | Expected input format | | <code>output_schema</code> | <code>Optional[Dict]</code> | Expected output format | | <code>memory_retention</code> | <code>str</code> | Memory retention policy |</p>"},{"location":"api/validation/#coordinationcontext","title":"CoordinationContext","text":"<p>Context from the coordination system for prompt building.</p> <p>Import: <pre><code>from marsys.coordination.formats import CoordinationContext\n</code></pre></p> <p>Attributes: | Attribute | Type | Description | |-----------|------|-------------| | <code>next_agents</code> | <code>List[str]</code> | Agents this agent can invoke | | <code>can_return_final_response</code> | <code>bool</code> | Whether agent can return final response |</p>"},{"location":"api/validation/#format-registry","title":"Format Registry","text":"<p>Functions for managing available response formats.</p> <p>Import: <pre><code>from marsys.coordination.formats import (\n    register_format,\n    get_format,\n    list_formats,\n    set_default_format,\n    is_format_registered\n)\n</code></pre></p> <p>Functions:</p> Function Description Returns <code>register_format(name, format_class)</code> Register a new format <code>None</code> <code>get_format(name)</code> Get format instance <code>BaseResponseFormat</code> <code>list_formats()</code> List registered formats <code>List[str]</code> <code>set_default_format(name)</code> Set default format <code>None</code> <code>is_format_registered(name)</code> Check if format exists <code>bool</code> <p>Example: <pre><code># List available formats\nformats = list_formats()  # [\"json\"]\n\n# Get specific format\njson_format = get_format(\"json\")\n\n# Register custom format\nregister_format(\"xml\", XMLResponseFormat)\n</code></pre></p>"},{"location":"api/validation/#baseresponseformat","title":"BaseResponseFormat","text":"<p>Abstract base class for implementing response formats.</p> <p>Import: <pre><code>from marsys.coordination.formats import BaseResponseFormat\n</code></pre></p> <p>Abstract Methods: | Method | Description | |--------|-------------| | <code>get_format_name()</code> | Return format name (e.g., \"json\") | | <code>build_format_instructions(actions, descriptions)</code> | Build format-specific instructions | | <code>build_action_descriptions(actions, context)</code> | Build action descriptions | | <code>get_examples(actions, context)</code> | Generate format-specific examples | | <code>get_parallel_invocation_examples(context)</code> | Examples for parallel invocation | | <code>create_processor()</code> | Create response processor for this format |</p> <p>Built-in Format: - <code>JSONResponseFormat</code> - Default JSON format with <code>next_action</code>/<code>action_input</code> structure</p>"},{"location":"api/validation/#response-processors","title":"\ud83d\udd27 Response Processors","text":""},{"location":"api/validation/#built-in-processors","title":"Built-in Processors","text":"<pre><code># Structured JSON Processor\nclass StructuredJSONProcessor(ResponseProcessor):\n    \"\"\"Handles JSON responses with next_action structure.\"\"\"\n\n    def can_process(self, response: Any) -&gt; bool:\n        return isinstance(response, dict) and \"next_action\" in response\n\n    def priority(self) -&gt; int:\n        return 80  # Below error and tool processors\n\n# Tool Call Processor\nclass ToolCallProcessor(ResponseProcessor):\n    \"\"\"Handles native tool call responses.\"\"\"\n\n    def can_process(self, response: Any) -&gt; bool:\n        return hasattr(response, 'tool_calls')\n\n    def priority(self) -&gt; int:\n        return 90\n\n# Error Message Processor\nclass ErrorMessageProcessor(ResponseProcessor):\n    \"\"\"Handles error Messages from agents.\"\"\"\n\n    def can_process(self, response: Any) -&gt; bool:\n        return isinstance(response, Message) and response.role == \"error\"\n\n    def priority(self) -&gt; int:\n        return 100  # Highest priority\n</code></pre>"},{"location":"api/validation/#custom-processor","title":"Custom Processor","text":"<pre><code>from marsys.coordination.formats import ResponseProcessor\n\nclass CustomFormatProcessor(ResponseProcessor):\n    \"\"\"Process custom response format.\"\"\"\n\n    def can_process(self, response: Any) -&gt; bool:\n        return isinstance(response, dict) and \"custom_action\" in response\n\n    def process(self, response: Any) -&gt; Optional[Dict[str, Any]]:\n        return {\n            \"next_action\": self._map_action(response[\"custom_action\"]),\n            \"content\": response.get(\"data\")\n        }\n\n    def priority(self) -&gt; int:\n        return 75  # Between JSON and tool processors\n\n# Register processor\nvalidation_processor.register_processor(CustomFormatProcessor())\n</code></pre>"},{"location":"api/validation/#validation-flow","title":"\ud83d\udd04 Validation Flow","text":""},{"location":"api/validation/#complete-validation-process","title":"Complete Validation Process","text":"<pre><code># 1. Receive agent response\nresponse = await agent.run(prompt)\n\n# 2. Process response\nvalidation_result = await validation_processor.process_response(\n    raw_response=response,\n    agent=agent,\n    branch=current_branch,\n    exec_state=execution_state\n)\n\n# 3. Route based on validation\nif validation_result.is_valid:\n    routing_decision = await router.route(\n        validation_result=validation_result,\n        current_branch=current_branch,\n        routing_context=context\n    )\n\n    # 4. Execute next steps\n    for step in routing_decision.next_steps:\n        await execute_step(step)\nelse:\n    # Handle validation error\n    logger.error(f\"Validation failed: {validation_result.error_message}\")\n    if validation_result.retry_suggestion:\n        # Apply steering for retry\n        await apply_steering(validation_result.retry_suggestion)\n</code></pre>"},{"location":"api/validation/#error-handling","title":"\ud83d\udea6 Error Handling","text":""},{"location":"api/validation/#validation-errors","title":"Validation Errors","text":"<pre><code>if not result.is_valid:\n    error_type = result.error_message\n\n    if \"not allowed\" in error_type:\n        # Permission denied - agent not in topology\n        logger.error(f\"Permission denied: {error_type}\")\n\n    elif \"format\" in error_type:\n        # Invalid response format\n        logger.error(f\"Format error: {error_type}\")\n\n        # Use retry suggestion\n        if result.retry_suggestion:\n            steering = f\"Please retry with: {result.retry_suggestion}\"\n\n    elif \"missing\" in error_type:\n        # Missing required fields\n        logger.error(f\"Missing fields: {error_type}\")\n</code></pre>"},{"location":"api/validation/#error-recovery_1","title":"Error Recovery","text":"<pre><code># Agent can trigger error recovery\nresponse = {\n    \"next_action\": \"error_recovery\",\n    \"error_details\": {\n        \"type\": \"rate_limit\",\n        \"message\": \"API rate limit exceeded\",\n        \"retry_after\": 60\n    },\n    \"suggested_action\": \"wait_and_retry\"\n}\n\n# Routes to User node for intervention\n</code></pre>"},{"location":"api/validation/#best-practices","title":"\ud83d\udccb Best Practices","text":""},{"location":"api/validation/#do","title":"\u2705 DO:","text":"<ul> <li>Validate all agent responses through ValidationProcessor</li> <li>Use structured response formats for clarity</li> <li>Include error recovery actions in critical workflows</li> <li>Check topology permissions before invocation</li> <li>Provide retry suggestions for recoverable errors</li> </ul>"},{"location":"api/validation/#dont","title":"\u274c DON'T:","text":"<ul> <li>Parse responses manually outside ValidationProcessor</li> <li>Skip validation for \"trusted\" agents</li> <li>Ignore validation errors</li> <li>Mix response formats within single agent</li> <li>Hard-code routing logic outside Router</li> </ul>"},{"location":"api/validation/#related-documentation","title":"\ud83d\udea6 Related Documentation","text":"<ul> <li>Execution API - Execution system using validation</li> <li>Topology API - Topology permissions</li> <li>Router Patterns - Routing patterns</li> <li>Error Handling - Error recovery</li> </ul> <p>Pro Tip</p> <p>The ValidationProcessor supports multiple response formats simultaneously. Processors are evaluated by priority, allowing fallback from structured to unstructured formats.</p> <p>Important</p> <p>All response parsing MUST go through ValidationProcessor to ensure consistency and topology compliance.</p>"},{"location":"concepts/agents/","title":"Agents","text":"<p>Agents are the fundamental building blocks of MARSYS - autonomous AI entities that can perceive, reason, and take actions to accomplish tasks.</p> <p>See Also</p> <p>For detailed class signatures, method parameters, and API reference, see Agent API Reference.</p>"},{"location":"concepts/agents/#overview","title":"\ud83c\udfaf Overview","text":"<p>Agents in MARSYS are designed with a pure execution model - they implement stateless <code>_run()</code> methods with no side effects, enabling:</p> <ul> <li>True Parallel Execution: Multiple instances run concurrently without conflicts</li> <li>Branch Isolation: Each execution branch maintains independent state</li> <li>State Persistence: Clean serialization for pause/resume capabilities</li> <li>Testability: Pure functions are easier to test and debug</li> </ul>"},{"location":"concepts/agents/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<pre><code>graph TB\n    subgraph \"Agent System\"\n        BA[BaseAgent&lt;br/&gt;Abstract Interface]\n        A[Agent&lt;br/&gt;Standard Implementation]\n        BA2[BrowserAgent&lt;br/&gt;Web Automation]\n        LA[LearnableAgent&lt;br/&gt;Fine-tunable]\n        AP[AgentPool&lt;br/&gt;Parallel Instances]\n    end\n\n    subgraph \"Core Components\"\n        M[Memory&lt;br/&gt;ConversationMemory]\n        T[Tools&lt;br/&gt;Function Registry]\n        MO[Model&lt;br/&gt;LLM/VLM/API]\n        AR[AgentRegistry&lt;br/&gt;Global Registry]\n    end\n\n    BA --&gt; A\n    A --&gt; BA2\n    A --&gt; LA\n    A --&gt; AP\n\n    A --&gt; M\n    A --&gt; T\n    A --&gt; MO\n    A --&gt; AR\n\n    style BA fill:#e1f5fe\n    style A fill:#4fc3f7\n    style AP fill:#29b6f6</code></pre>"},{"location":"concepts/agents/#agent-classes","title":"\ud83d\udce6 Agent Classes","text":""},{"location":"concepts/agents/#baseagent-abstract","title":"BaseAgent (Abstract)","text":"<p>The foundation interface all agents must implement:</p> <pre><code>from abc import ABC, abstractmethod\nfrom marsys.agents.memory import Message\n\nclass BaseAgent(ABC):\n    def __init__(\n        self,\n        model: Union[BaseLocalModel, BaseAPIModel],\n        name: str,\n        goal: str,\n        instruction: str,\n        tools: Optional[Dict[str, Callable]] = None,\n        max_tokens: Optional[int] = 10000,\n        allowed_peers: Optional[List[str]] = None,\n        bidirectional_peers: bool = False,\n        is_convergence_point: Optional[bool] = None,\n        input_schema: Optional[Any] = None,\n        output_schema: Optional[Any] = None,\n        memory_retention: str = \"session\",\n        memory_storage_path: Optional[str] = None\n    ):\n        # Auto-generates tool schemas from function signatures\n        # Registers with AgentRegistry\n        # Initializes memory manager\n        pass\n\n    @abstractmethod\n    async def _run(\n        self,\n        prompt: Any,\n        context: Dict[str, Any],\n        **kwargs\n    ) -&gt; Message:\n        \"\"\"Pure execution logic - NO side effects\"\"\"\n        pass\n</code></pre> <p>Pure Execution Rule</p> <p>The <code>_run()</code> method must be pure - no memory manipulation, no logging to files, no global state changes. All side effects are handled by the coordination layer.</p>"},{"location":"concepts/agents/#agent-standard-implementation","title":"Agent (Standard Implementation)","text":"<p>The standard agent with built-in capabilities:</p> <pre><code>from marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\nagent = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\",\n        api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n        parameters={\"temperature\": 0.7},\n        max_tokens=12000\n    ),\n    name=\"DataAnalyst\",\n    goal=\"Analyze data and extract meaningful trends and insights\",\n    instruction=\"You are a thorough data analyst...\",\n    tools={\"analyze_data\": analyze_data, \"create_chart\": create_chart},\n    memory_retention=\"session\"\n)\n</code></pre>"},{"location":"concepts/agents/#browseragent","title":"BrowserAgent","text":"<p>Specialized for web automation tasks:</p> <pre><code>from marsys.agents import BrowserAgent\n\nbrowser = await BrowserAgent.create_safe(\n    model_config=config,\n    name=\"WebResearcher\",\n    goal=\"Research and extract information from web pages\",\n    instruction=\"Web research specialist with browser access and automation capabilities\",\n    headless=True,\n    viewport_width=1920,\n    viewport_height=1080\n)\n\n# Browser-specific capabilities (via browser_tool)\nawait browser.browser_tool.goto(\"https://example.com\")\nawait browser.browser_tool.mouse_click(x=500, y=300)  # Click by coordinates\ncontent = await browser.browser_tool.fetch_url(\"https://example.com\")\n</code></pre>"},{"location":"concepts/agents/#learnableagent","title":"LearnableAgent","text":"<p>Supports fine-tuning with PEFT methods:</p> <pre><code>from marsys.agents import LearnableAgent\n\nlearnable = LearnableAgent(\n    model_config=config,\n    name=\"AdaptiveAssistant\",\n    goal=\"Learn from interactions and adapt to user preferences\",\n    instruction=\"Adaptive assistant that improves through fine-tuning\",\n    learning_config={\n        \"method\": \"lora\",\n        \"rank\": 8,\n        \"alpha\": 32,\n        \"dropout\": 0.1\n    }\n)\n\n# Fine-tune on examples\nawait learnable.learn_from_examples(training_data)\n</code></pre>"},{"location":"concepts/agents/#agentpool","title":"\ud83d\udd04 AgentPool","text":"<p>For true parallel execution with isolated instances:</p> <pre><code>from marsys.agents.agent_pool import AgentPool\n\n# Create pool of 3 browser agents\npool = AgentPool(\n    agent_class=BrowserAgent,\n    num_instances=3,\n    model_config=config,\n    name=\"BrowserPool\",\n    goal=\"Perform parallel web automation tasks\",\n    instruction=\"Browser automation agents for concurrent web operations\",\n    headless=True\n)\n\n# Acquire instance for branch (automatic queue management)\nasync with pool.acquire(branch_id=\"branch_123\") as agent:\n    result = await agent.run(task)\n\n# Pool handles:\n# - Instance creation with unique names (BrowserPool_0, BrowserPool_1, etc.)\n# - Fair allocation with queue-based waiting\n# - Automatic release after use\n# - Statistics tracking\n# - Cleanup on destruction\n</code></pre> <p>When to Use AgentPool</p> <p>Use AgentPool when you need: - True parallel execution of the same agent type - Resource isolation (browser instances, API connections) - Fair allocation across multiple branches - Prevent state conflicts between parallel executions</p>"},{"location":"concepts/agents/#creating-agents","title":"\ud83c\udfaf Creating Agents","text":""},{"location":"concepts/agents/#basic-agent","title":"Basic Agent","text":"<pre><code>from marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\n# Simple agent\nassistant = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\",\n        max_tokens=12000\n    ),\n    name=\"Assistant\",\n    goal=\"Provide helpful assistance to users\",\n    instruction=\"A helpful AI assistant that responds thoughtfully to queries\"\n)\n\n# Run the agent\nresponse = await assistant.run(\n    prompt=\"Explain quantum computing\",\n    context={\"user_id\": \"123\"}\n)\n</code></pre>"},{"location":"concepts/agents/#agent-with-tools","title":"Agent with Tools","text":"<pre><code>def search_web(query: str, max_results: int = 5) -&gt; List[Dict]:\n    \"\"\"\n    Search the web for information.\n\n    Args:\n        query: Search query string\n        max_results: Maximum number of results\n\n    Returns:\n        List of search results with title, url, snippet\n    \"\"\"\n    # Implementation here\n    return results\n\ndef analyze_data(data: List[float], method: str = \"mean\") -&gt; float:\n    \"\"\"\n    Analyze numerical data.\n\n    Args:\n        data: List of numerical values\n        method: Analysis method (mean, median, std)\n\n    Returns:\n        Analysis result\n    \"\"\"\n    # Implementation here\n    return result\n\nresearcher = Agent(\n    model_config=config,\n    name=\"Researcher\",\n    goal=\"Research specialist with web search and analysis capabilities\",\n    instruction=\"You are a research specialist. Use search_web to find information and analyze_data to process results.\",\n    tools={\"search_web\": search_web, \"analyze_data\": analyze_data}  # Auto-generates OpenAI-compatible schemas\n)\n</code></pre> <p>Automatic Schema Generation</p> <p>Tool schemas are automatically generated from function signatures and docstrings. Ensure your functions have proper type hints and docstrings for accurate schema generation.</p>"},{"location":"concepts/agents/#custom-agent-class","title":"Custom Agent Class","text":"<pre><code>from marsys.agents import BaseAgent\nfrom marsys.agents.memory import Message\n\nclass CustomAnalyzer(BaseAgent):\n    def __init__(self, model, **kwargs):\n        super().__init__(model, **kwargs)\n        # NO instance variables that change during execution\n        self.analysis_patterns = self._load_patterns()  # OK - static config\n\n    async def _run(self, prompt, context, **kwargs):\n        \"\"\"Pure execution - no side effects\"\"\"\n\n        # Prepare messages\n        messages = self._prepare_messages(prompt)\n\n        # Add analysis context\n        if context.get(\"analysis_type\") == \"detailed\":\n            messages.append({\n                \"role\": \"system\",\n                \"content\": \"Provide detailed analysis with examples\"\n            })\n\n        # Call model (pure)\n        response = await self.model.run(messages)\n\n        # Return pure Message\n        return Message(\n            role=\"assistant\",\n            content=response.content,\n            structured_data={\"analyzed\": True}\n        )\n</code></pre>"},{"location":"concepts/agents/#response-formats","title":"\ud83d\udcac Response Formats","text":"<p>Agents communicate using standardized response formats:</p>"},{"location":"concepts/agents/#sequential-agent-invocation","title":"Sequential Agent Invocation","text":"<pre><code>{\n    \"thought\": \"I need help from the DataAnalyzer\",\n    \"next_action\": \"invoke_agent\",\n    \"action_input\": \"DataAnalyzer\"\n}\n</code></pre>"},{"location":"concepts/agents/#parallel-agent-invocation","title":"Parallel Agent Invocation","text":"<pre><code>{\n    \"thought\": \"These analyses can run in parallel\",\n    \"next_action\": \"parallel_invoke\",\n    \"agents\": [\"Analyzer1\", \"Analyzer2\", \"Analyzer3\"],\n    \"agent_requests\": {\n        \"Analyzer1\": \"Analyze sales data for Q1\",\n        \"Analyzer2\": \"Analyze sales data for Q2\",\n        \"Analyzer3\": \"Analyze sales data for Q3\"\n    }\n}\n</code></pre>"},{"location":"concepts/agents/#tool-call","title":"Tool Call","text":"<pre><code>{\n    \"next_action\": \"call_tool\",\n    \"tool_calls\": [\n        {\n            \"id\": \"call_abc123\",\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"search_web\",\n                \"arguments\": \"{\\\"query\\\": \\\"latest AI research\\\", \\\"max_results\\\": 10}\"\n            }\n        }\n    ]\n}\n</code></pre>"},{"location":"concepts/agents/#final-response","title":"Final Response","text":"<pre><code>{\n    \"next_action\": \"final_response\",\n    \"content\": \"Here is my analysis...\"\n}\n\n# Or structured response\n{\n    \"next_action\": \"final_response\",\n    \"content\": {\n        \"summary\": \"Key findings\",\n        \"details\": [...],\n        \"recommendations\": [...]\n    }\n}\n</code></pre>"},{"location":"concepts/agents/#memory-management","title":"\ud83e\udde0 Memory Management","text":"<p>Each agent maintains its conversation history through a <code>ConversationMemory</code>:</p> <pre><code># Memory retention policies\nagent = Agent(\n    model_config=config,\n    name=\"Assistant\",\n    goal=\"Provide general assistance\",\n    instruction=\"Answer user requests clearly and accurately.\",\n    memory_retention=\"session\"  # Options: single_run, session, persistent\n)\n\n# Memory is automatically managed during execution\n# - single_run: Cleared after each run\n# - session: Maintained for workflow duration\n# - persistent: Saved to disk for long-term retention\n</code></pre> <p>For more details, see Memory Documentation.</p>"},{"location":"concepts/agents/#task-planning","title":"\ud83d\udccb Task Planning","text":"<p>Agents can use task planning to organize complex multi-step operations. Planning is enabled by default.</p> <pre><code>from marsys.agents import Agent\nfrom marsys.agents.planning import PlanningConfig\n\n# Default: planning enabled\nagent = Agent(\n    model_config=config,\n    name=\"Researcher\",\n    goal=\"Research and analyze topics\",\n    instruction=\"...\"\n)\n\n# Disable planning for simple agents\nsimple_agent = Agent(\n    model_config=config,\n    name=\"Calculator\",\n    goal=\"Perform calculations\",\n    instruction=\"...\",\n    plan_config=False  # Disable planning\n)\n\n# Custom configuration\ncustom_agent = Agent(\n    model_config=config,\n    name=\"Analyst\",\n    goal=\"Analyze data\",\n    instruction=\"...\",\n    plan_config=PlanningConfig(\n        min_plan_items=3,\n        max_plan_items=15,\n        compact_mode=True\n    )\n)\n</code></pre> <p>Planning provides:</p> <ul> <li>Progress tracking during multi-step tasks</li> <li>Error recovery context for retries</li> <li>Status visualization in CLI/web interfaces</li> <li>Automatic cleanup when memory resets</li> </ul> <p>When planning is enabled, agents have access to tools like <code>plan_create</code>, <code>plan_read</code>, <code>plan_update</code>, <code>plan_add_item</code>, <code>plan_remove_item</code>, and <code>plan_clear</code>.</p> <p>For detailed documentation, see Task Planning.</p>"},{"location":"concepts/agents/#agent-configuration","title":"\ud83d\udd27 Agent Configuration","text":""},{"location":"concepts/agents/#model-configuration","title":"Model Configuration","text":"<pre><code>from marsys.models import ModelConfig\n\n# API Model (OpenAI, Anthropic, Google)\napi_config = ModelConfig(\n    type=\"api\",\n    provider=\"openrouter\",\n    name=\"anthropic/claude-opus-4.6\",\n    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n    parameters={\n        \"temperature\": 0.7\n    },\n    max_tokens=12000\n)\n\n# Local LLM\nlocal_config = ModelConfig(\n    type=\"local\",\n    name=\"llama-2-7b\",\n    model_path=\"/models/llama-2-7b\",\n    device=\"cuda\",\n    parameters={\n        \"temperature\": 0.8,\n        \"max_length\": 1024\n    }\n)\n\n# Vision-Language Model\nvlm_config = ModelConfig(\n    type=\"api\",\n    provider=\"openrouter\",\n    name=\"google/gemini-3-pro-preview\",\n    max_tokens=12000\n)\n</code></pre>"},{"location":"concepts/agents/#agent-parameters","title":"Agent Parameters","text":"<pre><code>agent = Agent(\n    model_config=config,\n    name=\"Expert\",  # Unique identifier\n    goal=\"Domain expert in...\",  # Role definition\n    instruction=\"Detailed instructions...\",  # System message\n    tools={\"tool_name\": tool_func},  # Available functions (dict format)\n    max_tokens=2000,  # Response limit\n    allowed_peers=[\"Agent1\", \"Agent2\"],  # Can invoke these agents\n    memory_retention=\"session\",  # Memory policy\n    input_schema=InputSchema,  # Validate inputs\n    output_schema=OutputSchema  # Validate outputs\n)\n</code></pre>"},{"location":"concepts/agents/#best-practices","title":"\ud83d\udccb Best Practices","text":""},{"location":"concepts/agents/#1-keep-_run-pure","title":"1. Keep _run() Pure","text":"<pre><code># \u2705 GOOD - Pure function\nasync def _run(self, prompt, context, **kwargs):\n    messages = self._prepare_messages(prompt)\n    response = await self.model.run(messages)\n    return Message(role=\"assistant\", content=response.content)\n\n# \u274c BAD - Side effects\nasync def _run(self, prompt, context, **kwargs):\n    self.memory.add_message(...)  # NO! Memory handled externally\n    await self.save_to_database(...)  # NO! Side effects\n    self.state_counter += 1  # NO! Mutable state\n    return response\n</code></pre>"},{"location":"concepts/agents/#2-clear-agent-descriptions","title":"2. Clear Agent Descriptions","text":"<pre><code># \u2705 GOOD - Specific and actionable\ngoal=\"\"\"\nYou are a Python code reviewer specializing in security and performance.\nYour responsibilities:\n1. Identify security vulnerabilities (SQL injection, XSS, etc.)\n2. Suggest performance optimizations\n3. Ensure PEP 8 compliance\n4. Provide actionable feedback with code examples\nOutput format: Markdown with code blocks\n\"\"\"\n\n# \u274c BAD - Vague\ngoal=\"You review code\"\n</code></pre>"},{"location":"concepts/agents/#3-robust-tool-design","title":"3. Robust Tool Design","text":"<pre><code># \u2705 GOOD - Type hints, docstring, error handling\ndef fetch_data(\n    source: str,\n    filters: Optional[Dict[str, Any]] = None,\n    limit: int = 100\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Fetch data from specified source.\n\n    Args:\n        source: Data source identifier\n        filters: Optional filtering criteria\n        limit: Maximum records to return\n\n    Returns:\n        List of data records\n\n    Raises:\n        ValueError: If source is invalid\n        ConnectionError: If source is unreachable\n    \"\"\"\n    try:\n        # Implementation\n        return data\n    except Exception as e:\n        logger.error(f\"Failed to fetch data: {e}\")\n        raise\n\n# \u274c BAD - No types, poor docs, no error handling\ndef fetch_data(source, filters=None):\n    \"\"\"Get data\"\"\"\n    return get_from_db(source)\n</code></pre>"},{"location":"concepts/agents/#4-use-agentpool-for-parallelism","title":"4. Use AgentPool for Parallelism","text":"<pre><code># \u2705 GOOD - Pool for parallel execution\npool = AgentPool(BrowserAgent, num_instances=3, ...)\ntasks = [\"url1\", \"url2\", \"url3\"]\n\nasync def process_url(url, branch_id):\n    async with pool.acquire(branch_id) as agent:\n        return await agent.scrape(url)\n\nresults = await asyncio.gather(*[\n    process_url(url, f\"branch_{i}\")\n    for i, url in enumerate(tasks)\n])\n\n# \u274c BAD - Reusing single instance\nagent = await BrowserAgent.create_safe(\n    model_config=config,\n    name=\"SharedBrowser\",\n    mode=\"advanced\",\n    headless=True,\n)\n# This will have conflicts with parallel execution\nresults = await asyncio.gather(*[\n    agent.scrape(url) for url in tasks\n])\n</code></pre>"},{"location":"concepts/agents/#common-patterns","title":"\ud83c\udfaf Common Patterns","text":""},{"location":"concepts/agents/#research-team-pattern","title":"Research Team Pattern","text":"<pre><code># Specialized agents\ndata_collector = Agent(\n    model_config=config,\n    name=\"DataCollector\",\n    goal=\"Collect data from web sources\",\n    instruction=\"You collect data by searching the web and scraping pages.\",\n    tools={\"search_web\": search_web, \"scrape_page\": scrape_page}\n)\nanalyzer = Agent(\n    model_config=config,\n    name=\"Analyzer\",\n    goal=\"Analyze data statistically\",\n    instruction=\"You analyze data using statistical methods and create charts.\",\n    tools={\"statistical_analysis\": statistical_analysis, \"create_charts\": create_charts}\n)\nwriter = Agent(\n    model_config=config,\n    name=\"Writer\",\n    goal=\"Technical writer creating reports\",\n    instruction=\"You write clear technical reports based on analyzed data.\"\n)\n\n# Coordinator orchestrates them\ncoordinator = Agent(\n    model_config=config,\n    name=\"Coordinator\",\n    goal=\"Coordinate research projects between specialized agents\",\n    instruction=\"\"\"You coordinate research projects. Your workflow:\n    1. Ask DataCollector to gather information\n    2. Ask Analyzer to process the data\n    3. Ask Writer to create the report\"\"\",\n    allowed_peers=[\"DataCollector\", \"Analyzer\", \"Writer\"]\n)\n</code></pre>"},{"location":"concepts/agents/#error-recovery-pattern","title":"Error Recovery Pattern","text":"<pre><code>class ResilientAgent(BaseAgent):\n    async def _run(self, prompt, context, **kwargs):\n        try:\n            # Primary logic\n            response = await self.primary_approach(prompt)\n            return Message(role=\"assistant\", content=response)\n        except SpecificError as e:\n            # Fallback approach\n            response = await self.fallback_approach(prompt)\n            return Message(\n                role=\"assistant\",\n                content=response,\n                metadata={\"fallback_used\": True}\n            )\n</code></pre>"},{"location":"concepts/agents/#validation-pattern","title":"Validation Pattern","text":"<pre><code>from pydantic import BaseModel, Field\n\nclass AnalysisInput(BaseModel):\n    data: List[float] = Field(..., min_items=1)\n    method: str = Field(..., pattern=\"^(mean|median|std)$\")\n\nclass AnalysisOutput(BaseModel):\n    result: float\n    confidence: float = Field(..., ge=0, le=1)\n    metadata: Dict[str, Any]\n\nvalidator_agent = Agent(\n    model_config=config,\n    name=\"ValidatedAnalyzer\",\n    goal=\"Run validated statistical analysis\",\n    instruction=\"Validate inputs and return structured analysis outputs.\",\n    input_schema=AnalysisInput,\n    output_schema=AnalysisOutput\n)\n</code></pre>"},{"location":"concepts/agents/#next-steps","title":"\ud83d\udea6 Next Steps","text":"<ul> <li> <p> Memory System</p> <p>Learn how agents maintain context and conversation history</p> </li> <li> <p> Tool Integration</p> <p>Extend agent capabilities with custom functions</p> </li> <li> <p> Messages</p> <p>Understand the message format and types</p> </li> <li> <p> Agent API Reference</p> <p>Complete API documentation for agent classes</p> </li> </ul> <p>Agent System Ready!</p> <p>You now understand the agent architecture in MARSYS. Agents provide the intelligence, while the Orchestra provides the coordination.</p>"},{"location":"concepts/browser-automation/","title":"Browser Automation","text":"<p>MARSYS provides powerful browser automation capabilities through the BrowserAgent, enabling web scraping, interaction, and intelligent navigation for multi-agent workflows.</p>"},{"location":"concepts/browser-automation/#overview","title":"\ud83c\udfaf Overview","text":"<p>The browser automation system provides:</p> <ul> <li>Dual Operation Modes: PRIMITIVE for fast content extraction, ADVANCED for complex multi-step scenarios with visual interaction</li> <li>Web Navigation: Navigate, scrape, and interact with websites</li> <li>Intelligent Automation: LLM-guided browser control and decision making</li> <li>Dynamic Content Handling: JavaScript execution and async content loading</li> <li>Form Automation: Fill forms, click elements, and handle interactions</li> <li>Multimodal Capabilities: Screenshot-based visual understanding with element detection (ADVANCED mode)</li> <li>Robust Error Handling: Retry mechanisms and resilient operations</li> </ul>"},{"location":"concepts/browser-automation/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<pre><code>graph TB\n    subgraph \"Browser System\"\n        BA[BrowserAgent&lt;br/&gt;High-level Interface]\n        BT[BrowserTool&lt;br/&gt;Low-level Operations]over\n        PW[Playwright&lt;br/&gt;Browser Control]\n    end\n\n    subgraph \"Capabilities\"\n        NAV[Navigation&lt;br/&gt;URLs, History]\n        INT[Interaction&lt;br/&gt;Clicks, Forms]\n        EXT[Extraction&lt;br/&gt;Text, Data]\n        SCR[Screenshots&lt;br/&gt;Debugging]\n    end\n\n    subgraph \"Execution\"\n        Agent[Agent Logic] --&gt; Plan[Plan Actions]\n        Plan --&gt; Execute[Execute Tools]\n        Execute --&gt; Validate[Validate Results]\n    end\n\n    BA --&gt; BT\n    BT --&gt; PW\n    BA --&gt; NAV\n    BA --&gt; INT\n    BA --&gt; EXT\n\n    style BA fill:#4fc3f7\n    style BT fill:#29b6f6\n    style PW fill:#e1f5fe</code></pre>"},{"location":"concepts/browser-automation/#operation-modes","title":"\ud83c\udfad Operation Modes","text":"<p>BrowserAgent supports two distinct operation modes optimized for different use cases:</p>"},{"location":"concepts/browser-automation/#primitive-mode","title":"PRIMITIVE Mode","text":"<p>Purpose: Fast, efficient content extraction without visual interaction</p> <p>Characteristics: - High-level tools for quick content retrieval - No visual feedback or screenshots - No vision model required - Optimized for speed and simplicity - Single-step operations</p> <p>Available Tools (5): - <code>fetch_url</code> - Navigate and extract content in one step - <code>get_page_metadata</code> - Get page title, URL, and links - <code>download_file</code> - Download files from URLs - <code>list_downloads</code> - List files in the downloads directory - <code>get_page_elements</code> - Get interactive elements with selectors (token-efficient format) - <code>inspect_element</code> - Get element details by selector (truncated text preview)</p> <p>Best For: - Web scraping and data extraction - Content aggregation - Simple information retrieval - API-like web interactions</p>"},{"location":"concepts/browser-automation/#advanced-mode","title":"ADVANCED Mode","text":"<p>Purpose: Complex multi-step scenarios requiring visual interaction and coordinate-based control</p> <p>Characteristics: - Low-level coordinate-based tools - Visual feedback with auto-screenshot support - Vision model integration for visual understanding - Multi-step navigation and interaction - Form filling and complex workflows</p> <p>Available Tools (20+): - All PRIMITIVE mode tools, plus: - <code>goto</code> - Navigate to URL (auto-detects downloads) - <code>scroll_up</code> / <code>scroll_down</code> - Scroll the page - <code>mouse_click</code> - Click at specific coordinates (auto-detects downloads) - <code>keyboard_input</code> - Type text into focused input fields (search boxes, forms) - <code>keyboard_press</code> - Press special keys (Enter, Tab, arrows, etc.) (auto-detects downloads) - <code>search_page</code> - Find text on page with Chrome-like highlighting - <code>go_back</code> - Navigate back - <code>reload</code> - Reload current page - <code>get_url</code> / <code>get_title</code> - Get page information - <code>screenshot</code> - Take screenshot with element highlighting (returns multimodal ToolResponse) - <code>inspect_element</code> - Get element details by selector (truncated text preview) - <code>inspect_at_position</code> - Get element info at screen coordinates (x, y) - <code>list_tabs</code> - List all open browser tabs - <code>get_active_tab</code> - Get currently active tab info - <code>switch_to_tab</code> - Switch to a specific tab by index - <code>close_tab</code> - Close a tab by index - <code>save_session</code> - Save browser session state for persistence</p> <p>Best For: - Form automation with complex interactions - Multi-step workflows requiring visual confirmation - Handling cookie popups and modals - Sites with anti-bot protections - Tasks requiring precise element interaction</p>"},{"location":"concepts/browser-automation/#choosing-the-right-mode","title":"Choosing the Right Mode","text":"<pre><code>from marsys.agents import BrowserAgent, BrowserAgentMode\n\n# Mode selection with enum (type-safe)\nbrowser_agent = await BrowserAgent.create_safe(\n    model_config=config,\n    name=\"scraper\",\n    mode=BrowserAgentMode.PRIMITIVE,  # Using enum\n    goal=\"Efficiently fetch and extract content from web pages\"\n)\n\n# Mode selection with string (convenient)\nbrowser_agent = await BrowserAgent.create_safe(\n    model_config=config,\n    name=\"scraper\",\n    mode=\"primitive\",  # Using string\n    goal=\"Efficiently fetch and extract content from web pages\"\n)\n\n# ADVANCED mode - Visual interaction\nbrowser_agent = await BrowserAgent.create_safe(\n    model_config=config,  # Main agent model (Claude Haiku/Sonnet recommended)\n    name=\"navigator\",\n    mode=BrowserAgentMode.ADVANCED,  # or mode=\"advanced\"\n    auto_screenshot=True,  # Enable visual feedback\n    vision_model_config=ModelConfig(  # Vision model for screenshot analysis\n        type=\"api\",\n        provider=\"openrouter\",\n        name=\"google/gemini-3-flash-preview\",  # Recommended: fast and cost-effective\n        # For complex tasks, use: \"google/gemini-3-pro-preview\"\n        temperature=0,\n        thinking_budget=0  # Disable thinking for faster vision responses\n    ),\n    goal=\"Navigate and interact with web pages like a human\"\n)\n</code></pre>"},{"location":"concepts/browser-automation/#browseragent","title":"\ud83d\udce6 BrowserAgent","text":""},{"location":"concepts/browser-automation/#creating-a-browseragent","title":"Creating a BrowserAgent","text":"<pre><code>from marsys.agents import BrowserAgent\nfrom marsys.models import ModelConfig\n\n# PRIMITIVE Mode - Fast content extraction\nbrowser_agent = await BrowserAgent.create_safe(\n    model_config=ModelConfig(\n        type=\"api\",\n        provider=\"openrouter\",\n        name=\"anthropic/claude-opus-4.6\",\n        temperature=0.3\n    ),\n    name=\"web_scraper\",\n    mode=\"primitive\",  # Simple string mode selection\n    goal=\"Fast web scraping agent for content extraction\",\n    headless=True,\n    tmp_dir=\"./runs/run-20260206\"\n)\n\n# ADVANCED Mode - Visual interaction with auto-screenshot\nbrowser_agent_advanced = await BrowserAgent.create_safe(\n    model_config=ModelConfig(\n        type=\"api\",\n        provider=\"openrouter\",\n        name=\"anthropic/claude-opus-4.6\",  # Main agent for decision-making and planning\n        temperature=0.3\n    ),\n    name=\"web_navigator\",\n    mode=\"advanced\",  # Simple string mode selection\n    goal=\"Expert web automation agent for complex interactions\",\n    auto_screenshot=True,  # Enable visual feedback\n    vision_model_config=ModelConfig(  # Required for auto-screenshot\n        type=\"api\",\n        provider=\"openrouter\",\n        name=\"google/gemini-3-flash-preview\",  # Recommended: fast and cost-effective for browser vision\n        # For complex tasks, use: \"google/gemini-3-pro-preview\"\n        temperature=0,\n        thinking_budget=0  # Disable thinking for faster vision responses\n    ),\n    headless=False,\n    tmp_dir=\"./runs/run-20260206\"\n)\n\n# Always clean up\ntry:\n    # Use the agent\n    result = await browser_agent.run(\"Navigate to example.com and extract the main heading\")\nfinally:\n    if browser_agent.browser_tool:\n        await browser_agent.browser_tool.close()\n</code></pre> <p>Virtual paths: BrowserAgent returns virtual paths for artifacts such as <code>./downloads/report.pdf</code> and <code>./screenshots/step_1.png</code>. See Run Filesystem.</p>"},{"location":"concepts/browser-automation/#browseragent-artifact-configuration","title":"BrowserAgent Artifact Configuration","text":"<p><code>BrowserAgent.create_safe(...)</code> supports explicit download path behavior and tool naming:</p> <pre><code>browser_agent = await BrowserAgent.create_safe(\n    model_config=config,\n    name=\"web_scraper\",\n    mode=\"primitive\",\n    tmp_dir=\"./runs/run-20260206\",\n    downloads_subdir=\"downloads\",             # Host folder under tmp_dir\n    downloads_virtual_dir=\"./downloads\",      # Path shown to the agent\n    fetch_file_tool_name=\"fetch_file\",        # Expose download tool under custom name\n)\n</code></pre> <p>Notes: - <code>downloads_subdir</code> changes host-side layout under <code>tmp_dir</code>. - <code>downloads_virtual_dir</code> changes what agents see/return in tool outputs. - <code>fetch_file_tool_name</code> remaps the download tool name from the default <code>download_file</code>.</p>"},{"location":"concepts/browser-automation/#viewport-auto-detection","title":"Viewport Auto-Detection","text":"<p>If <code>viewport_width</code>/<code>viewport_height</code> are not provided, BrowserAgent picks defaults by model family:</p> <ul> <li>Google/Gemini: <code>1000x1000</code></li> <li>Anthropic/Claude: <code>1344x896</code></li> <li>OpenAI/GPT: <code>1024x768</code></li> <li>Fallback: <code>1536x1536</code></li> </ul>"},{"location":"concepts/browser-automation/#using-agentpool-for-parallel-browsing","title":"Using AgentPool for Parallel Browsing","text":"<pre><code>from marsys.agents import AgentPool\n\n# Create pool of browser agents\nbrowser_pool = AgentPool(\n    agent_class=BrowserAgent,\n    num_instances=3,\n    model_config=config,\n    agent_name=\"BrowserPool\",\n    headless=True\n)\n\n# Parallel scraping\nasync def scrape_urls(urls: List[str]):\n    tasks = []\n    for i, url in enumerate(urls):\n        async with browser_pool.acquire(f\"branch_{i}\") as agent:\n            task = agent.run(f\"Scrape content from {url}\")\n            tasks.append(task)\n\n    results = await asyncio.gather(*tasks)\n    return results\n\n# Cleanup pool\nawait browser_pool.cleanup()\n</code></pre>"},{"location":"concepts/browser-automation/#browser-tools","title":"\ud83d\udd27 Browser Tools","text":""},{"location":"concepts/browser-automation/#tool-overview-by-mode","title":"Tool Overview by Mode","text":"<p>PRIMITIVE Mode Tools (Fast content extraction): - <code>fetch_url</code> - Navigate and extract content in one step (returns Dict with markdown/text) - <code>get_page_metadata</code> - Get title, URL, and links quickly - <code>download_file</code> - Download files from URLs - <code>inspect_element</code> - Get element details by selector</p> <p>ADVANCED Mode Additional Tools (Visual interaction): - <code>goto</code>, <code>go_back</code>, <code>reload</code> - Navigation control - <code>scroll_up</code>, <code>scroll_down</code> - Page scrolling - <code>mouse_click</code> - Click at coordinates - <code>keyboard_input</code> - Type text into focused input fields (search boxes, forms) - <code>keyboard_press</code> - Press special keys (Enter, Tab, Escape, arrows, etc.) - <code>search_page</code> - Search for text on page with visual highlighting (Chrome-like find) - <code>screenshot</code> - Multimodal response with numbered element detection (ToolResponse format) - <code>get_url</code>, <code>get_title</code> - Current page information - <code>list_tabs</code>, <code>get_active_tab</code>, <code>switch_to_tab</code>, <code>close_tab</code> - Tab management - <code>save_session</code> - Save browser session state for persistence - <code>inspect_at_position</code> - Get element info at screen coordinates (x, y)</p>"},{"location":"concepts/browser-automation/#navigation-tools","title":"Navigation Tools","text":"<pre><code>class NavigationAgent(BrowserAgent):\n    \"\"\"Agent with navigation capabilities.\"\"\"\n\n    async def navigate_with_history(self, urls: List[str], context):\n        \"\"\"Navigate through multiple pages with history.\"\"\"\n        for url in urls:\n            await self.browser_tool.goto(url)\n            await self._log_progress(context, LogLevel.INFO, f\"Navigated to {url}\")\n\n            # Wait for page to load\n            await self.browser_tool.wait_for_navigation()\n\n            # Take screenshot for debugging\n            await self.browser_tool.screenshot(\n                filename=f\"{url.replace('/', '_')}.png\"\n            )\n\n        # Navigate back through history\n        for _ in range(len(urls) - 1):\n            await self.browser_tool.go_back()\n            current = await self.browser_tool.get_url()\n            await self._log_progress(context, LogLevel.INFO, f\"Back to {current}\")\n</code></pre>"},{"location":"concepts/browser-automation/#interaction-tools","title":"Interaction Tools","text":"<pre><code>class InteractionAgent(BrowserAgent):\n    \"\"\"Agent for web interactions.\"\"\"\n\n    async def smart_form_fill(self, form_data: Dict, context):\n        \"\"\"Intelligently fill forms based on field types.\"\"\"\n\n        for field_name, value in form_data.items():\n            # Try different selector strategies\n            selectors = [\n                f\"input[name='{field_name}']\",\n                f\"input[id='{field_name}']\",\n                f\"textarea[name='{field_name}']\",\n                f\"select[name='{field_name}']\"\n            ]\n\n            for selector in selectors:\n                try:\n                    # Determine field type and fill appropriately\n                    if selector.startswith(\"select\"):\n                        await self.browser_tool.select_option(selector, str(value))\n                    elif isinstance(value, bool):\n                        if value:  # Check if should be checked\n                            await self.browser_tool.click(selector)\n                    else:\n                        await self.browser_tool.fill(selector, str(value))\n\n                    await self._log_progress(\n                        context, LogLevel.DEBUG,\n                        f\"Filled {field_name} with {value}\"\n                    )\n                    break\n                except Exception:\n                    continue\n\n    async def smart_click(self, text: str, context, element_type: str = \"button\"):\n        \"\"\"Click element by text content.\"\"\"\n\n        # XPath to find element by text\n        xpath = f\"//{element_type}[contains(text(), '{text}')]\"\n\n        try:\n            await self.browser_tool.wait_for_selector(xpath, timeout=5000, state=\"visible\")\n            await self.browser_tool.click(xpath)\n            await self._log_progress(context, LogLevel.INFO, f\"Clicked '{text}' {element_type}\")\n        except Exception as e:\n            # Fallback to JavaScript click\n            script = f\"\"\"\n            Array.from(document.querySelectorAll('{element_type}')).\n                find(el =&gt; el.textContent.includes('{text}'))?.click()\n            \"\"\"\n            await self.browser_tool.evaluate_javascript(script)\n</code></pre>"},{"location":"concepts/browser-automation/#text-search-on-page","title":"Text Search on Page","text":"<p>New Feature: search_page()</p> <p>Find text on web pages with Chrome-like visual highlighting and navigation!</p> <pre><code># Search for text on the current page\nresult = await browser_tool.search_page(\"quantum computing\")\n# Returns: \"Match 1/5 found and highlighted\"\n# All matches highlighted in YELLOW, current match in ORANGE\n\n# Navigate to next match - call again with SAME term\nresult = await browser_tool.search_page(\"quantum computing\")\n# Returns: \"Match 2/5\"\n# Scrolls to and highlights next occurrence\n\n# Continue navigating\nresult = await browser_tool.search_page(\"quantum computing\")\n# Returns: \"Match 3/5\"\n# Wraps around after last match back to first\n</code></pre> <p>Features: - Visual Highlighting: All matches in YELLOW, current in ORANGE (Chrome-like) - Auto-scroll: Automatically scrolls to current match (centered in viewport) - Match Counter: Shows \"Match X/Y\" so you know your progress - Wrap-around: After last match, returns to first match - Case-insensitive: Finds text regardless of case</p> <p>Limitations: - \u274c Does NOT work with PDF files (PDFs are auto-downloaded, not displayed) - \u274c Does NOT search across multiple pages - \u2705 Works with regular web pages, including shadow DOM content</p> <p>Example - Finding Specific Information: <pre><code># Navigate to documentation page\nawait browser_tool.goto(\"https://docs.example.com/api\")\n\n# Search for specific API endpoint\nresult = await browser_tool.search_page(\"/api/v2/users\")\n# Match 1/3 found - scrolls to first occurrence\n\n# Check if it's the right one with screenshot\nscreenshot = await browser_tool.screenshot()\n# Visual: See highlighted text in orange\n\n# Not the right one? Navigate to next match\nresult = await browser_tool.search_page(\"/api/v2/users\")\n# Match 2/3 - scrolls to second occurrence\n</code></pre></p>"},{"location":"concepts/browser-automation/#automatic-download-detection","title":"Automatic Download Detection","text":"<p>Smart Download Handling</p> <p>Actions that trigger file downloads are automatically detected and reported!</p> <p>The browser automatically detects when actions (clicks, Enter key presses, navigation) trigger file downloads:</p> <pre><code># Clicking a download link automatically detects the download\nresult = await browser_tool.mouse_click(x=450, y=300)\n# Returns: \"Action 'mouse_click' triggered a file download.\n#          File 'report.pdf' has been downloaded to: ./downloads/report.pdf\"\n\n# Navigating to a PDF URL triggers automatic download\nresult = await browser_tool.goto(\"https://example.com/paper.pdf\")\n# Returns: \"Action 'goto' triggered a file download.\n#          File 'paper.pdf' has been downloaded to: ./downloads/paper.pdf\"\n\n# Pressing Enter on a download button\nawait browser_tool.mouse_click(x=500, y=400)  # Focus download button\nawait browser_tool.keyboard_press(\"Enter\")\n# Returns: \"Action 'keyboard_press' triggered a file download.\n#          File 'data.xlsx' has been downloaded to: ./downloads/data.xlsx\"\n</code></pre> <p>Automatic Detection Features: - \u2705 Detects downloads triggered by clicks, keyboard presses, or navigation - \u2705 Returns file path and filename in response - \u2705 Downloads saved under virtual <code>./downloads</code> (host default: <code>./tmp/downloads</code>) - \u2705 PDFs are always downloaded (never displayed in browser) - \u2705 Works with all file types (PDF, Excel, CSV, images, etc.)</p> <p><code>download_file</code> itself uses a dual strategy: - Primary: Playwright request context (inherits browser cookies/session) - Fallback: browser navigation + download-event detection</p> <p>If no file is detected but the page loads, it returns a message like \"No downloadable file detected from URL...\" with the loaded URL.</p> <p>Listing Downloads: <pre><code># List all files in the downloads directory\ndownloads = await browser_tool.list_downloads()\n# Returns a formatted list with sizes and paths\n</code></pre></p> <p>PDF-Specific Behavior: <pre><code># PDFs are NEVER displayed in browser - always downloaded\nawait browser_tool.goto(\"https://research.org/paper.pdf\")\n# Automatically downloads to ./downloads/paper.pdf\n# Browser stays on previous page\n\n# search_page() does NOT work with PDFs\n# Instead, use file operation tools on the downloaded file\n</code></pre></p> <p>Download Path Configuration: <pre><code>browser_tool = await BrowserTool.create_safe(\n    downloads_path=\"/custom/path/downloads\",  # Custom host download directory\n    temp_dir=\"/custom/tmp\",  # Custom temp directory (default: ./tmp)\n    downloads_virtual_dir=\"./downloads\",  # Virtual path returned to agents\n)\n</code></pre></p>"},{"location":"concepts/browser-automation/#data-extraction","title":"Data Extraction","text":"<pre><code>class ScraperAgent(BrowserAgent):\n    \"\"\"Advanced web scraping agent.\"\"\"\n\n    async def extract_structured_data(self, url: str, schema: Dict, context):\n        \"\"\"Extract data according to schema.\"\"\"\n\n        await self.browser_tool.goto(url)\n        await self.browser_tool.wait_for_navigation()\n\n        # Extract based on schema\n        extracted_data = {}\n\n        for field_name, config in schema.items():\n            selector = config.get('selector')\n            attribute = config.get('attribute')\n            multiple = config.get('multiple', False)\n\n            try:\n                if multiple:\n                    # Extract from multiple elements via JS\n                    if attribute:\n                        script = f\"\"\"\n                        Array.from(document.querySelectorAll({selector!r}))\n                            .map(el =&gt; el.getAttribute({attribute!r}))\n                        \"\"\"\n                    else:\n                        script = f\"\"\"\n                        Array.from(document.querySelectorAll({selector!r}))\n                            .map(el =&gt; (el.textContent || '').trim())\n                        \"\"\"\n                    extracted_data[field_name] = await self.browser_tool.evaluate_javascript(script)\n                else:\n                    # Extract from single element\n                    if attribute:\n                        value = await self.browser_tool.get_attribute(\n                            selector, attribute\n                        )\n                    else:\n                        value = await self.browser_tool.get_text(selector)\n\n                    extracted_data[field_name] = value\n\n            except Exception as e:\n                await self._log_progress(\n                    context, LogLevel.WARNING,\n                    f\"Failed to extract {field_name}: {e}\"\n                )\n                extracted_data[field_name] = None\n\n        return extracted_data\n\n    async def extract_table_data(self, table_selector: str, context):\n        \"\"\"Extract data from HTML tables.\"\"\"\n\n        script = f\"\"\"\n        () =&gt; {{\n            const table = document.querySelector('{table_selector}');\n            if (!table) return null;\n\n            const headers = Array.from(table.querySelectorAll('th'))\n                .map(th =&gt; th.textContent.trim());\n\n            const rows = Array.from(table.querySelectorAll('tbody tr'))\n                .map(tr =&gt; {{\n                    const cells = Array.from(tr.querySelectorAll('td'));\n                    const rowData = {{}};\n                    cells.forEach((td, i) =&gt; {{\n                        rowData[headers[i] || `col_${{i}}`] = td.textContent.trim();\n                    }});\n                    return rowData;\n                }});\n\n            return {{headers, rows}};\n        }}\n        \"\"\"\n\n        return await self.browser_tool.evaluate_javascript(script)\n</code></pre>"},{"location":"concepts/browser-automation/#advanced-patterns","title":"\ud83c\udfaf Advanced Patterns","text":""},{"location":"concepts/browser-automation/#pagination-handling","title":"Pagination Handling","text":"<pre><code>class PaginationAgent(BrowserAgent):\n    \"\"\"Handle paginated content.\"\"\"\n\n    async def scrape_all_pages(\n        self,\n        start_url: str,\n        item_selector: str,\n        next_button_selector: str,\n        max_pages: int = 10,\n        context = None\n    ):\n        \"\"\"Scrape data across multiple pages.\"\"\"\n\n        all_items = []\n        current_page = 1\n\n        await self.browser_tool.goto(start_url)\n\n        while current_page &lt;= max_pages:\n            # Wait for items to load\n            await self.browser_tool.wait_for_selector(\n                item_selector, timeout=10000, state=\"visible\"\n            )\n\n            # Extract items from current page\n            items = await self.browser_tool.evaluate_javascript(f\"\"\"\n                Array.from(document.querySelectorAll('{item_selector}'))\n                    .map(el =&gt; el.textContent.trim())\n            \"\"\")\n\n            all_items.extend(items)\n            await self._log_progress(\n                context, LogLevel.INFO,\n                f\"Page {current_page}: Extracted {len(items)} items\"\n            )\n\n            # Check for next page\n            try:\n                await self.browser_tool.wait_for_selector(\n                    next_button_selector, timeout=2000, state=\"visible\"\n                )\n                await self.browser_tool.click(next_button_selector)\n                await self.browser_tool.wait_for_navigation()\n                current_page += 1\n            except Exception:\n                break\n\n        return all_items\n</code></pre>"},{"location":"concepts/browser-automation/#dynamic-content-loading","title":"Dynamic Content Loading","text":"<pre><code>class DynamicContentAgent(BrowserAgent):\n    \"\"\"Handle JavaScript-heavy sites.\"\"\"\n\n    async def wait_for_ajax_content(\n        self,\n        content_selector: str,\n        timeout: int = 30,\n        context = None\n    ):\n        \"\"\"Wait for AJAX content to load.\"\"\"\n\n        # Wait for a selector that indicates content has loaded\n        await self.browser_tool.wait_for_selector(\n            content_selector, timeout=timeout * 1000, state=\"visible\"\n        )\n\n    async def infinite_scroll_scrape(\n        self,\n        item_selector: str,\n        target_count: int,\n        context = None\n    ):\n        \"\"\"Handle infinite scroll patterns.\"\"\"\n\n        items_found = 0\n        no_new_items_count = 0\n        max_no_new = 3\n\n        while items_found &lt; target_count:\n            # Count current items\n            current_items = await self.browser_tool.evaluate_javascript(\n                f\"document.querySelectorAll('{item_selector}').length\"\n            )\n\n            if current_items == items_found:\n                no_new_items_count += 1\n                if no_new_items_count &gt;= max_no_new:\n                    break\n            else:\n                no_new_items_count = 0\n                items_found = current_items\n\n            # Scroll to bottom\n            await self.browser_tool.evaluate_javascript(\n                \"window.scrollTo(0, document.body.scrollHeight)\"\n            )\n\n            # Wait for potential new content\n            await asyncio.sleep(2)\n\n            await self._log_progress(\n                context, LogLevel.DEBUG,\n                f\"Found {items_found} items, target: {target_count}\"\n            )\n\n        # Extract all items\n        return await self.browser_tool.evaluate_javascript(f\"\"\"\n            Array.from(document.querySelectorAll('{item_selector}'))\n                .map(el =&gt; el.textContent.trim())\n        \"\"\")\n</code></pre>"},{"location":"concepts/browser-automation/#session-persistence","title":"Session Persistence","text":"<p>Browser Session Persistence</p> <p>BrowserAgent supports saving and loading browser sessions (cookies, localStorage) using Playwright's <code>storage_state</code> feature. This enables persistent authentication across browser sessions.</p>"},{"location":"concepts/browser-automation/#loading-a-saved-session","title":"Loading a Saved Session","text":"<pre><code>from marsys.agents import BrowserAgent\n\n# Create agent with existing session state\nagent = await BrowserAgent.create_safe(\n    model_config=config,\n    name=\"AuthenticatedBrowser\",\n    mode=\"advanced\",\n    session_path=\"./sessions/linkedin_session.json\",  # Load existing session\n    headless=True\n)\n\n# Browser is now initialized with saved cookies and localStorage\n# Already logged in to LinkedIn, Google, etc.\nawait agent.run(\"Go to linkedin.com/feed and extract posts\")\n</code></pre>"},{"location":"concepts/browser-automation/#saving-a-session","title":"Saving a Session","text":"<pre><code># Save via BrowserAgent tool invocation\nresult = await agent.run(\"Save the current session to ./sessions/my_session.json\")\n# Returns a success message with cookie/origin counts\n\n# You can save additional checkpoints as needed\nresult = await agent.run(\"Save the current session to ./sessions/backup.json\")\n</code></pre>"},{"location":"concepts/browser-automation/#session-file-format","title":"Session File Format","text":"<p>The session file is a JSON file compatible with Playwright's <code>storage_state</code>:</p> <pre><code>{\n  \"cookies\": [\n    {\n      \"name\": \"session_id\",\n      \"value\": \"abc123\",\n      \"domain\": \".example.com\",\n      \"path\": \"/\",\n      \"expires\": 1735689600,\n      \"httpOnly\": true,\n      \"secure\": true\n    }\n  ],\n  \"origins\": [\n    {\n      \"origin\": \"https://example.com\",\n      \"localStorage\": [\n        {\"name\": \"user_token\", \"value\": \"xyz789\"}\n      ]\n    }\n  ]\n}\n</code></pre>"},{"location":"concepts/browser-automation/#authentication-handling","title":"Authentication Handling","text":"<pre><code>class AuthAgent(BrowserAgent):\n    \"\"\"Handle authentication flows.\"\"\"\n\n    async def login_with_cookies(\n        self,\n        login_url: str,\n        cookies: List[Dict],\n        context = None\n    ):\n        \"\"\"Login using saved cookies.\"\"\"\n\n        # Navigate to site\n        await self.browser_tool.goto(login_url)\n\n        # Set cookies\n        for cookie in cookies:\n            await self.browser_tool.context.add_cookies([cookie])\n\n        # Refresh to apply cookies\n        await self.browser_tool.reload()\n\n        # Verify login success\n        return await self.verify_login_status(context)\n\n    async def handle_2fa(\n        self,\n        code_input_selector: str,\n        get_2fa_code: Callable,\n        context = None\n    ):\n        \"\"\"Handle two-factor authentication.\"\"\"\n\n        # Wait for 2FA input\n        await self.browser_tool.wait_for_selector(\n            code_input_selector, timeout=30000, state=\"visible\"\n        )\n\n        # Get 2FA code (from email, SMS, authenticator, etc.)\n        code = await get_2fa_code()\n\n        # Enter code\n        await self.browser_tool.fill(code_input_selector, code)\n\n        # Submit (usually auto-submits, but can click submit if needed)\n        await self.browser_tool.press_key(\"Enter\")\n\n        # Wait for redirect after successful 2FA\n        await self.browser_tool.wait_for_navigation()\n</code></pre>"},{"location":"concepts/browser-automation/#error-handling","title":"\ud83d\udee1\ufe0f Error Handling","text":""},{"location":"concepts/browser-automation/#resilient-operations","title":"Resilient Operations","text":"<pre><code>class ResilientBrowserAgent(BrowserAgent):\n    \"\"\"Browser agent with enhanced error handling.\"\"\"\n\n    async def retry_operation(\n        self,\n        operation: Callable,\n        max_retries: int = 3,\n        backoff_factor: float = 2.0,\n        context = None\n    ):\n        \"\"\"Execute operation with exponential backoff retry.\"\"\"\n\n        last_error = None\n        wait_time = 1.0\n\n        for attempt in range(max_retries):\n            try:\n                result = await operation()\n                if attempt &gt; 0:\n                    await self._log_progress(\n                        context, LogLevel.INFO,\n                        f\"Operation succeeded on attempt {attempt + 1}\"\n                    )\n                return result\n\n            except Exception as e:\n                last_error = e\n                await self._log_progress(\n                    context, LogLevel.WARNING,\n                    f\"Attempt {attempt + 1} failed: {e}\"\n                )\n\n                if attempt &lt; max_retries - 1:\n                    await asyncio.sleep(wait_time)\n                    wait_time *= backoff_factor\n\n        raise Exception(f\"Operation failed after {max_retries} attempts: {last_error}\")\n\n    async def safe_extract(\n        self,\n        selector: str,\n        default: Any = None,\n        context = None\n    ):\n        \"\"\"Safely extract element with fallback.\"\"\"\n\n        try:\n            text = await self.browser_tool.get_text(selector)\n            if text:\n                return text.strip()\n        except Exception as e:\n            await self._log_progress(\n                context, LogLevel.DEBUG,\n                f\"Failed to extract {selector}: {e}\"\n            )\n\n        return default\n</code></pre>"},{"location":"concepts/browser-automation/#performance-optimization","title":"\ud83d\ude80 Performance Optimization","text":""},{"location":"concepts/browser-automation/#resource-blocking","title":"Resource Blocking","text":"<pre><code>class OptimizedBrowserAgent(BrowserAgent):\n    \"\"\"Optimized browser agent for faster scraping.\"\"\"\n\n    async def setup_fast_scraping(self, context = None):\n        \"\"\"Configure browser for fast text scraping.\"\"\"\n\n        # Block unnecessary resources\n        await self.browser_tool.context.route(\"**/*\", lambda route:\n            route.abort() if route.request.resource_type in\n            [\"image\", \"stylesheet\", \"font\", \"media\"]\n            else route.continue_()\n        )\n\n        # Disable JavaScript if not needed\n        await self.browser_tool.context.set_javascript_enabled(False)\n\n        await self._log_progress(\n            context, LogLevel.INFO,\n            \"Optimized browser for fast scraping\"\n        )\n\n    async def parallel_scrape(\n        self,\n        urls: List[str],\n        extractor: Callable,\n        max_concurrent: int = 5,\n        context = None\n    ):\n        \"\"\"Scrape multiple URLs in parallel.\"\"\"\n\n        semaphore = asyncio.Semaphore(max_concurrent)\n\n        async def scrape_with_limit(url):\n            async with semaphore:\n                try:\n                    await self.browser_tool.goto(url)\n                    return await extractor(self.browser_tool)\n                except Exception as e:\n                    await self._log_progress(\n                        context, LogLevel.ERROR,\n                        f\"Failed to scrape {url}: {e}\"\n                    )\n                    return None\n\n        tasks = [scrape_with_limit(url) for url in urls]\n        results = await asyncio.gather(*tasks)\n\n        return [r for r in results if r is not None]\n</code></pre>"},{"location":"concepts/browser-automation/#best-practices","title":"\ud83d\udccb Best Practices","text":""},{"location":"concepts/browser-automation/#1-explicit-waits","title":"1. Explicit Waits","text":"<pre><code># \u2705 GOOD - Wait for specific conditions\nawait browser_tool.wait_for_selector(\"#content\", timeout=10000, state=\"visible\")\nawait browser_tool.wait_for_navigation()\n\n# \u274c BAD - Fixed delays\nawait asyncio.sleep(5)  # Unreliable and slow\n</code></pre>"},{"location":"concepts/browser-automation/#2-robust-selectors","title":"2. Robust Selectors","text":"<pre><code># \u2705 GOOD - Specific, stable selectors\nawait browser_tool.click(\"[data-testid='submit-button']\")\nawait browser_tool.click(\"#unique-id\")\n\n# \u274c BAD - Fragile selectors\nawait browser_tool.click(\"div &gt; span:nth-child(3)\")\n</code></pre>"},{"location":"concepts/browser-automation/#3-resource-management","title":"3. Resource Management","text":"<pre><code># \u2705 GOOD - Always cleanup\nbrowser_agent = await BrowserAgent.create_safe(\n    model_config=config,\n    name=\"CleanupExample\",\n    mode=\"advanced\",\n    headless=True,\n)\ntry:\n    # Use agent\n    result = await browser_agent.run(task)\nfinally:\n    await browser_agent.browser_tool.close()\n\n# \u274c BAD - Leaving browsers open\nbrowser_agent = await BrowserAgent.create_safe(\n    model_config=config,\n    name=\"LeakyBrowser\",\n    mode=\"advanced\",\n    headless=True,\n)\nresult = await browser_agent.run(task)\n# Browser left running!\n</code></pre>"},{"location":"concepts/browser-automation/#4-error-context","title":"4. Error Context","text":"<pre><code># \u2705 GOOD - Detailed error context\ntry:\n    await browser_tool.click(selector)\nexcept Exception as e:\n    await self._log_progress(\n        context, LogLevel.ERROR,\n        f\"Failed to click {selector} on {await browser_tool.get_url()}: {e}\"\n    )\n    # Take screenshot for debugging\n    await browser_tool.screenshot(\"error_screenshot.png\")\n\n# \u274c BAD - Generic error handling\ntry:\n    await browser_tool.click(selector)\nexcept:\n    print(\"Click failed\")\n</code></pre>"},{"location":"concepts/browser-automation/#next-steps","title":"\ud83d\udea6 Next Steps","text":"<ul> <li> <p> Agents</p> <p>Learn about the agent system</p> </li> <li> <p> Tools</p> <p>Explore available tools</p> </li> <li> <p> Testing Guide</p> <p>Test browser automation</p> </li> <li> <p> API Reference</p> <p>Complete browser API</p> </li> </ul> <p>Browser Automation Ready!</p> <p>You now understand browser automation in MARSYS. The BrowserAgent provides powerful web interaction capabilities for your multi-agent workflows.</p>"},{"location":"concepts/communication/","title":"Communication","text":"<p>The communication system in MARSYS enables agents to coordinate, collaborate, and interact with users through structured messaging and event-driven patterns.</p>"},{"location":"concepts/communication/#overview","title":"\ud83c\udfaf Overview","text":"<p>MARSYS communication provides:</p> <ul> <li>User Interaction: Human-in-the-loop capabilities with multiple channels</li> <li>Agent Coordination: Inter-agent messaging and task delegation</li> <li>Event System: Pub/sub for decoupled communication</li> <li>Status Updates: Real-time progress and status reporting</li> <li>Error Routing: Intelligent error handling and recovery</li> </ul>"},{"location":"concepts/communication/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<pre><code>graph TB\n    subgraph \"Communication Layer\"\n        CM[CommunicationManager&lt;br/&gt;Central Hub]\n        UNH[UserNodeHandler&lt;br/&gt;User Interaction]\n        SM[StatusManager&lt;br/&gt;Status Updates]\n        EB[EventBus&lt;br/&gt;Event System]\n    end\n\n    subgraph \"Channels\"\n        TC[TerminalChannel&lt;br/&gt;CLI Interface]\n        ETC[EnhancedTerminal&lt;br/&gt;Rich Terminal]\n        PC[PrefixedCLI&lt;br/&gt;Agent Prefixes]\n        WC[WebChannel&lt;br/&gt;Web Interface]\n    end\n\n    subgraph \"Message Flow\"\n        User[User] --&gt; UNH\n        UNH --&gt; Agent[Agents]\n        Agent --&gt; Agent2[Other Agents]\n        Agent --&gt; SM\n        SM --&gt; User\n    end\n\n    CM --&gt; TC\n    CM --&gt; ETC\n    CM --&gt; PC\n    CM --&gt; WC\n\n    UNH --&gt; CM\n    SM --&gt; CM\n    EB --&gt; CM\n\n    style CM fill:#4fc3f7\n    style UNH fill:#29b6f6\n    style EB fill:#e1f5fe</code></pre>"},{"location":"concepts/communication/#core-components","title":"\ud83d\udce6 Core Components","text":""},{"location":"concepts/communication/#communicationmanager","title":"CommunicationManager","text":"<p>Central hub for all communication:</p> <pre><code>from marsys.coordination.communication import CommunicationManager\nfrom marsys.coordination.config import CommunicationConfig\n\n# Configure communication\ncomm_config = CommunicationConfig(\n    use_rich_formatting=True,\n    theme_name=\"modern\",\n    prefix_width=20,\n    show_timestamps=True,\n    enable_history=True,\n    use_colors=True\n)\n\n# Initialize manager\ncomm_manager = CommunicationManager(config=comm_config)\n\n# Register channels\ncomm_manager.register_channel(\"terminal\", TerminalChannel())\ncomm_manager.register_channel(\"web\", WebChannel())\n\n# CommunicationManager is used with Orchestra for user interaction\n# Direct send/receive is handled through channels internally\n\n# Use with Orchestra\nresult = await Orchestra.run(\n    task=\"Help me with a task\",\n    topology=topology,\n    execution_config=ExecutionConfig(\n        user_interaction=\"terminal\"  # Auto-creates CommunicationManager\n    )\n)\n</code></pre>"},{"location":"concepts/communication/#usernodehandler","title":"UserNodeHandler","text":"<p>Manages User node execution in topology:</p> <pre><code>from marsys.coordination.communication import UserNodeHandler\n\nclass UserNodeHandler:\n    \"\"\"Handles User node interactions in workflow.\"\"\"\n\n    async def handle_user_node(\n        self,\n        branch: ExecutionBranch,\n        incoming_message: Any,\n        context: Dict[str, Any]\n    ) -&gt; StepResult:\n        \"\"\"Process User node interaction.\"\"\"\n\n        # Format message for user\n        formatted = self._format_for_user(incoming_message)\n\n        # Get user response\n        user_response = await self._get_user_input(\n            prompt=formatted,\n            context=context\n        )\n\n        # Process response\n        return StepResult(\n            success=True,\n            result=user_response,\n            metadata={\"source\": \"user\", \"timestamp\": datetime.now()}\n        )\n\n    async def _get_user_input(\n        self,\n        prompt: str,\n        context: Dict[str, Any]\n    ) -&gt; str:\n        \"\"\"Get input from user with proper formatting.\"\"\"\n\n        # Show context if available\n        if context.get(\"show_context\"):\n            await self._display_context(context)\n\n        # Get input based on mode\n        if self.mode == \"sync\":\n            return await self._sync_input(prompt)\n        elif self.mode == \"async\":\n            return await self._async_input(prompt)\n</code></pre>"},{"location":"concepts/communication/#statusmanager","title":"StatusManager","text":"<p>Real-time status updates:</p> <pre><code>from marsys.coordination.communication import StatusManager\nfrom marsys.coordination.config import StatusConfig\n\nclass StatusManager:\n    \"\"\"Manages status updates and progress reporting.\"\"\"\n\n    def __init__(self, config: StatusConfig):\n        self.config = config\n        self.aggregator = MessageAggregator(\n            window_ms=config.aggregation_window_ms\n        )\n\n    async def update_status(\n        self,\n        agent_name: str,\n        status: str,\n        progress: Optional[float] = None,\n        metadata: Optional[Dict] = None\n    ):\n        \"\"\"Send status update.\"\"\"\n\n        if not self.config.enabled:\n            return\n\n        # Create status message\n        message = StatusMessage(\n            agent=agent_name,\n            status=status,\n            progress=progress,\n            timestamp=datetime.now(),\n            metadata=metadata or {}\n        )\n\n        # Aggregate if configured\n        if self.config.aggregate_parallel:\n            self.aggregator.add(message)\n            if self.aggregator.should_flush():\n                await self._flush_aggregated()\n        else:\n            await self._send_immediate(message)\n\n    def format_status(self, message: StatusMessage) -&gt; str:\n        \"\"\"Format status message for display.\"\"\"\n        if self.config.show_agent_prefixes:\n            prefix = f\"[{message.agent:&gt;{self.config.prefix_width}}]\"\n        else:\n            prefix = \"\"\n\n        if message.progress is not None:\n            progress_bar = self._create_progress_bar(message.progress)\n            return f\"{prefix} {message.status} {progress_bar}\"\n        else:\n            return f\"{prefix} {message.status}\"\n</code></pre>"},{"location":"concepts/communication/#communication-patterns","title":"\ud83c\udfaf Communication Patterns","text":""},{"location":"concepts/communication/#user-interaction-pattern","title":"User Interaction Pattern","text":"<p>Enable human-in-the-loop workflows:</p> <pre><code># Topology with User node\ntopology = {\n    \"agents\": [\"User\", \"Assistant\", \"Reviewer\"],\n    \"flows\": [\n        \"User -&gt; Assistant\",     # User provides input\n        \"Assistant -&gt; Reviewer\",  # Assistant processes\n        \"Reviewer -&gt; User\"        # User reviews result\n    ]\n}\n\n# Execution with user interaction\nresult = await Orchestra.run(\n    task=\"Help me write a report\",\n    topology=topology,\n    execution_config=ExecutionConfig(\n        user_interaction=\"terminal\",\n        user_first=True,  # Start with user\n        initial_user_msg=\"Welcome! What report would you like to write?\"\n    )\n)\n</code></pre>"},{"location":"concepts/communication/#event-driven-communication","title":"Event-Driven Communication","text":"<p>Decoupled pub/sub messaging:</p> <pre><code>from dataclasses import dataclass\nfrom marsys.coordination.event_bus import EventBus\n\n@dataclass\nclass CustomEvent:\n    session_id: str\n    payload: str\n\n# Usage\nevent_bus = EventBus()\n\n# Subscribe to events by class name\nasync def on_custom_event(event: CustomEvent):\n    print(f\"Event payload: {event.payload}\")\n\nevent_bus.subscribe(\"CustomEvent\", on_custom_event)\n\n# Emit events (async)\nawait event_bus.emit(CustomEvent(session_id=\"123\", payload=\"hello\"))\n\n# Emit from sync contexts (fire-and-forget)\nevent_bus.emit_nowait(CustomEvent(session_id=\"123\", payload=\"background\"))\n</code></pre>"},{"location":"concepts/communication/#web-status-streaming","title":"Web Status Streaming","text":"<p>Forward status and planning events to web clients via <code>WebChannel</code>:</p> <pre><code>from marsys.coordination.communication.channels import WebChannel\nfrom marsys.coordination.status.channels import StatusWebChannel\n\nweb_channel = WebChannel()\nstatus_web = StatusWebChannel(web_channel)\nstatus_manager.add_channel(status_web)\n</code></pre> <p>Web clients can receive updates via WebSocket or poll <code>WebChannel.get_status_events()</code>.</p>"},{"location":"concepts/communication/#status-aggregation-pattern","title":"Status Aggregation Pattern","text":"<p>Aggregate parallel status updates:</p> <pre><code>class MessageAggregator:\n    \"\"\"Aggregate status messages for cleaner output.\"\"\"\n\n    def __init__(self, window_ms: int = 500):\n        self.window_ms = window_ms\n        self.messages: List[StatusMessage] = []\n        self.last_flush = time.time() * 1000\n\n    def add(self, message: StatusMessage):\n        \"\"\"Add message to aggregation window.\"\"\"\n        self.messages.append(message)\n\n    def should_flush(self) -&gt; bool:\n        \"\"\"Check if window expired.\"\"\"\n        now = time.time() * 1000\n        return (now - self.last_flush) &gt;= self.window_ms\n\n    def flush(self) -&gt; List[StatusMessage]:\n        \"\"\"Get and clear aggregated messages.\"\"\"\n        messages = self.messages.copy()\n        self.messages.clear()\n        self.last_flush = time.time() * 1000\n        return messages\n\n# Usage in parallel execution\naggregator = MessageAggregator(window_ms=500)\n\n# Multiple agents updating in parallel\nfor agent in parallel_agents:\n    message = StatusMessage(agent=agent.name, status=\"Processing...\")\n    aggregator.add(message)\n\nif aggregator.should_flush():\n    # Display all updates together\n    messages = aggregator.flush()\n    display_aggregated(messages)\n</code></pre>"},{"location":"concepts/communication/#communication-channels","title":"\ud83d\udd27 Communication Channels","text":""},{"location":"concepts/communication/#terminalchannel","title":"TerminalChannel","text":"<p>Basic terminal I/O:</p> <pre><code>class TerminalChannel(Channel):\n    \"\"\"Basic terminal communication channel.\"\"\"\n\n    async def send(self, message: str, **kwargs):\n        \"\"\"Send message to terminal.\"\"\"\n        print(message)\n\n    async def receive(self, prompt: str = \"\", **kwargs) -&gt; str:\n        \"\"\"Receive input from terminal.\"\"\"\n        return input(prompt)\n\n    def format_message(self, message: str, metadata: Dict) -&gt; str:\n        \"\"\"Format message for terminal display.\"\"\"\n        if metadata.get(\"error\"):\n            return f\"ERROR: {message}\"\n        elif metadata.get(\"warning\"):\n            return f\"WARNING: {message}\"\n        else:\n            return message\n</code></pre>"},{"location":"concepts/communication/#enhancedterminalchannel","title":"EnhancedTerminalChannel","text":"<p>Rich terminal with colors and formatting:</p> <pre><code>from rich.console import Console\nfrom rich.prompt import Prompt\nfrom rich.progress import Progress\n\nclass EnhancedTerminalChannel(Channel):\n    \"\"\"Enhanced terminal with Rich formatting.\"\"\"\n\n    def __init__(self):\n        self.console = Console()\n        self.progress = Progress()\n\n    async def send(self, message: str, **kwargs):\n        \"\"\"Send formatted message.\"\"\"\n        style = kwargs.get(\"style\", \"default\")\n\n        if kwargs.get(\"is_error\"):\n            self.console.print(f\"[red]\u2717[/red] {message}\")\n        elif kwargs.get(\"is_success\"):\n            self.console.print(f\"[green]\u2713[/green] {message}\")\n        else:\n            self.console.print(message, style=style)\n\n    async def receive(self, prompt: str = \"\", **kwargs) -&gt; str:\n        \"\"\"Get input with enhanced prompt.\"\"\"\n        choices = kwargs.get(\"choices\")\n        if choices:\n            return Prompt.ask(prompt, choices=choices)\n        else:\n            return Prompt.ask(prompt)\n\n    def display_progress(self, task_id: str, total: int):\n        \"\"\"Show progress bar.\"\"\"\n        return self.progress.add_task(task_id, total=total)\n</code></pre>"},{"location":"concepts/communication/#prefixedclichannel","title":"PrefixedCLIChannel","text":"<p>Agent-prefixed output:</p> <pre><code>class PrefixedCLIChannel(Channel):\n    \"\"\"Terminal channel with agent prefixes.\"\"\"\n\n    def __init__(self, prefix_width: int = 20):\n        self.prefix_width = prefix_width\n        self.colors = {\n            \"Coordinator\": \"blue\",\n            \"Worker\": \"green\",\n            \"User\": \"yellow\",\n            \"Error\": \"red\"\n        }\n\n    def format_with_prefix(\n        self,\n        agent_name: str,\n        message: str\n    ) -&gt; str:\n        \"\"\"Format message with agent prefix.\"\"\"\n        # Create colored prefix\n        color = self.colors.get(agent_name, \"white\")\n        prefix = f\"[{agent_name:&gt;{self.prefix_width}}]\"\n\n        if self.use_colors:\n            from colorama import Fore, Style\n            color_code = getattr(Fore, color.upper(), Fore.WHITE)\n            prefix = f\"{color_code}{prefix}{Style.RESET_ALL}\"\n\n        # Split multi-line messages\n        lines = message.split('\\n')\n        formatted_lines = []\n\n        for i, line in enumerate(lines):\n            if i == 0:\n                formatted_lines.append(f\"{prefix} {line}\")\n            else:\n                # Indent continuation lines\n                indent = \" \" * (self.prefix_width + 3)\n                formatted_lines.append(f\"{indent}{line}\")\n\n        return '\\n'.join(formatted_lines)\n</code></pre>"},{"location":"concepts/communication/#configuration","title":"\ud83d\udccb Configuration","text":""},{"location":"concepts/communication/#communicationconfig","title":"CommunicationConfig","text":"<pre><code>from marsys.coordination.config import CommunicationConfig\n\nconfig = CommunicationConfig(\n    # Formatting\n    use_rich_formatting=True,\n    theme_name=\"modern\",  # modern, classic, minimal\n    prefix_width=20,\n    prefix_alignment=\"right\",  # left, center, right\n\n    # Display\n    show_timestamps=True,\n    timestamp_format=\"%H:%M:%S\",\n    use_colors=True,\n    color_depth=\"truecolor\",  # truecolor, 256, 16, none\n\n    # History\n    enable_history=True,\n    history_size=1000,\n    persist_history=False,\n    history_file=\".marsys_history\",\n\n    # Input\n    enable_tab_completion=True,\n    input_timeout=None,  # Seconds or None\n\n    # Channels\n    channels=[\"terminal\"],  # Active channels\n    default_channel=\"terminal\",\n\n    # Error handling\n    fallback_on_error=True,\n    use_enhanced_terminal=True\n)\n</code></pre>"},{"location":"concepts/communication/#advanced-patterns","title":"\ud83c\udfaf Advanced Patterns","text":""},{"location":"concepts/communication/#multi-channel-broadcasting","title":"Multi-Channel Broadcasting","text":"<p>Send to multiple channels simultaneously:</p> <pre><code>class MultiChannelManager:\n    \"\"\"Broadcast to multiple channels.\"\"\"\n\n    def __init__(self):\n        self.channels: Dict[str, Channel] = {}\n\n    def register(self, name: str, channel: Channel):\n        \"\"\"Register communication channel.\"\"\"\n        self.channels[name] = channel\n\n    async def broadcast(\n        self,\n        message: str,\n        channels: Optional[List[str]] = None,\n        **kwargs\n    ):\n        \"\"\"Broadcast message to channels.\"\"\"\n        target_channels = channels or list(self.channels.keys())\n\n        tasks = []\n        for channel_name in target_channels:\n            if channel_name in self.channels:\n                channel = self.channels[channel_name]\n                task = channel.send(message, **kwargs)\n                tasks.append(task)\n\n        await asyncio.gather(*tasks, return_exceptions=True)\n\n# Usage\nmanager = MultiChannelManager()\nmanager.register(\"terminal\", TerminalChannel())\nmanager.register(\"web\", WebChannel())\nmanager.register(\"log\", LogChannel())\n\n# Broadcast to all\nawait manager.broadcast(\"System starting...\")\n\n# Broadcast to specific channels\nawait manager.broadcast(\n    \"Error occurred\",\n    channels=[\"terminal\", \"log\"],\n    is_error=True\n)\n</code></pre>"},{"location":"concepts/communication/#interactive-prompts","title":"Interactive Prompts","text":"<p>Get structured input from users:</p> <pre><code>class InteractivePrompt:\n    \"\"\"Interactive user prompts.\"\"\"\n\n    async def choice(\n        self,\n        question: str,\n        options: List[str],\n        default: Optional[str] = None\n    ) -&gt; str:\n        \"\"\"Present multiple choice.\"\"\"\n        print(f\"\\n{question}\")\n        for i, option in enumerate(options, 1):\n            print(f\"  {i}. {option}\")\n\n        while True:\n            response = input(f\"Choice [1-{len(options)}]: \")\n            try:\n                index = int(response) - 1\n                if 0 &lt;= index &lt; len(options):\n                    return options[index]\n            except (ValueError, IndexError):\n                pass\n\n            print(\"Invalid choice. Please try again.\")\n\n    async def confirm(\n        self,\n        question: str,\n        default: bool = False\n    ) -&gt; bool:\n        \"\"\"Get yes/no confirmation.\"\"\"\n        default_str = \"Y/n\" if default else \"y/N\"\n        response = input(f\"{question} [{default_str}]: \").lower()\n\n        if not response:\n            return default\n\n        return response in ['y', 'yes', 'true', '1']\n\n    async def multi_input(\n        self,\n        prompt: str,\n        min_items: int = 1,\n        max_items: Optional[int] = None\n    ) -&gt; List[str]:\n        \"\"\"Get multiple inputs.\"\"\"\n        print(prompt)\n        print(\"Enter items (empty line to finish):\")\n\n        items = []\n        while True:\n            item = input(f\"  [{len(items) + 1}] \")\n            if not item:\n                if len(items) &gt;= min_items:\n                    break\n                print(f\"Need at least {min_items} items\")\n            else:\n                items.append(item)\n                if max_items and len(items) &gt;= max_items:\n                    break\n\n        return items\n</code></pre>"},{"location":"concepts/communication/#error-recovery-communication","title":"Error Recovery Communication","text":"<p>Route errors to User node for recovery:</p> <pre><code>class ErrorRoutingHandler:\n    \"\"\"Route errors to User for recovery.\"\"\"\n\n    async def handle_error(\n        self,\n        error: Exception,\n        context: Dict[str, Any],\n        topology: Topology\n    ) -&gt; Optional[str]:\n        \"\"\"Route error to User node if available.\"\"\"\n\n        # Check if User node exists in topology\n        if not topology.has_node(\"User\"):\n            return None\n\n        # Format error for user\n        error_msg = self._format_error(error, context)\n\n        # Create error recovery message\n        recovery_prompt = f\"\"\"\nAn error occurred during execution:\n\n{error_msg}\n\nHow would you like to proceed?\n1. Retry the operation\n2. Skip and continue\n3. Provide alternative input\n4. Abort execution\n\nYour choice: \"\"\"\n\n        # Get user decision\n        user_response = await self._get_user_input(recovery_prompt)\n\n        # Process decision\n        return self._process_recovery_decision(user_response, context)\n\n    def _format_error(self, error: Exception, context: Dict) -&gt; str:\n        \"\"\"Format error for user display.\"\"\"\n        agent = context.get(\"agent\", \"Unknown\")\n        operation = context.get(\"operation\", \"Unknown\")\n\n        return f\"\"\"\nAgent: {agent}\nOperation: {operation}\nError Type: {type(error).__name__}\nDetails: {str(error)}\n\"\"\"\n</code></pre>"},{"location":"concepts/communication/#next-steps","title":"\ud83d\udea6 Next Steps","text":"<ul> <li> <p> User Node Guide</p> <p>Complete guide to User node integration</p> </li> <li> <p> Event System</p> <p>Event-driven communication patterns</p> </li> <li> <p> Status Management</p> <p>Status updates and progress tracking</p> </li> <li> <p> Messages</p> <p>Message types and patterns</p> </li> </ul> <p>Communication System Ready!</p> <p>You now understand the communication system in MARSYS. Effective communication enables seamless coordination between agents and intuitive user interaction.</p>"},{"location":"concepts/custom-agents/","title":"Custom Agents","text":"<p>Learn how to create custom agents that extend the MARSYS framework with specialized capabilities and behaviors.</p>"},{"location":"concepts/custom-agents/#overview","title":"\ud83c\udfaf Overview","text":"<p>Custom agents enable you to:</p> <ul> <li>Extend BaseAgent: Create agents with specialized behavior</li> <li>Add Domain Knowledge: Incorporate specific expertise</li> <li>Implement State Machines: Complex multi-step workflows</li> <li>Custom Response Processing: Specialized output formats</li> <li>Advanced Memory Patterns: Sophisticated context management</li> </ul>"},{"location":"concepts/custom-agents/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<pre><code>graph TB\n    subgraph \"Custom Agent Hierarchy\"\n        BA[BaseAgent&lt;br/&gt;Abstract Base]\n        A[Agent&lt;br/&gt;Standard Implementation]\n        CA[CustomAgent&lt;br/&gt;Your Implementation]\n        SA[SpecializedAgent&lt;br/&gt;Domain-Specific]\n    end\n\n    subgraph \"Core Components\"\n        M[Model&lt;br/&gt;LLM/VLM]\n        Mem[Memory&lt;br/&gt;ConversationMemory]\n        T[Tools&lt;br/&gt;Functions]\n        V[Validation&lt;br/&gt;I/O Schemas]\n    end\n\n    BA --&gt; A\n    BA --&gt; CA\n    CA --&gt; SA\n\n    CA --&gt; M\n    CA --&gt; Mem\n    CA --&gt; T\n    CA --&gt; V\n\n    style BA fill:#e1f5fe\n    style CA fill:#4fc3f7\n    style SA fill:#29b6f6</code></pre>"},{"location":"concepts/custom-agents/#creating-custom-agents","title":"\ud83d\udce6 Creating Custom Agents","text":""},{"location":"concepts/custom-agents/#extending-baseagent","title":"Extending BaseAgent","text":"<p>The fundamental pattern for custom agents:</p> <pre><code>from marsys.agents import BaseAgent\nfrom marsys.agents.memory import Message\nfrom typing import Dict, Any, Optional\n\nclass CustomAgent(BaseAgent):\n    \"\"\"Custom agent with specialized behavior.\"\"\"\n\n    def __init__(\n        self,\n        model,\n        specialized_knowledge: Optional[Dict] = None,\n        **kwargs\n    ):\n        super().__init__(\n            model=model,\n            name=kwargs.pop(\"name\", \"CustomAgent\"),\n            goal=\"Custom specialized agent\",\n            instruction=\"A custom agent with specialized capabilities.\",\n            **kwargs\n        )\n        self.specialized_knowledge = specialized_knowledge or {}\n        self.processing_state = \"ready\"\n\n    async def _run(\n        self,\n        prompt: Any,\n        context: Dict[str, Any],\n        **kwargs\n    ) -&gt; Message:\n        \"\"\"\n        Pure execution logic - NO side effects!\n\n        Important: This method must be stateless and pure.\n        All state changes should happen outside this method.\n        \"\"\"\n\n        # Prepare messages with base functionality\n        messages = self._prepare_messages(prompt)\n\n        # Add custom logic\n        if self._should_use_knowledge(prompt):\n            messages.append(Message(\n                role=\"system\",\n                content=f\"Use this knowledge: {self.specialized_knowledge}\"\n            ))\n\n        # Call model\n        response = await self.model.run(messages)\n\n        # Return pure Message object\n        return Message(\n            role=\"assistant\",\n            content=response.content,\n            tool_calls=response.tool_calls if hasattr(response, 'tool_calls') else None,\n            structured_data={\"processing_state\": self.processing_state}\n        )\n\n    def _should_use_knowledge(self, prompt: str) -&gt; bool:\n        \"\"\"Determine if specialized knowledge is relevant.\"\"\"\n        # Your logic here\n        return True\n</code></pre>"},{"location":"concepts/custom-agents/#domain-specific-agents","title":"Domain-Specific Agents","text":"<p>Create agents with domain expertise:</p> <pre><code>class FinancialAnalyst(BaseAgent):\n    \"\"\"Financial analysis specialist.\"\"\"\n\n    def __init__(self, model, market_data_api=None, **kwargs):\n        super().__init__(\n            model=model,\n            name=kwargs.pop(\"name\", \"FinancialAnalyst\"),\n            goal=\"Expert financial analyst with real-time market access\",\n            instruction=\"You are a senior financial analyst specializing in market analysis.\",\n            tools={\n                \"get_stock_price\": self._get_stock_price,\n                \"calculate_metrics\": self._calculate_metrics\n            },\n            **kwargs\n        )\n        self.market_data_api = market_data_api\n\n        # Domain-specific prompting\n        self.system_prompt = \"\"\"You are a senior financial analyst with expertise in:\n        - Equity valuation and fundamental analysis\n        - Technical indicators and chart patterns\n        - Risk assessment and portfolio optimization\n        - Market trends and economic indicators\n\n        Always provide data-driven insights with confidence levels.\"\"\"\n\n    async def _run(self, prompt, context, **kwargs):\n        \"\"\"Analyze financial data with expertise.\"\"\"\n\n        # Check for financial context\n        if self._is_financial_query(prompt):\n            # Add market context\n            market_context = await self._get_market_context()\n            enriched_prompt = f\"{prompt}\\n\\nCurrent market: {market_context}\"\n        else:\n            enriched_prompt = prompt\n\n        messages = self._prepare_messages(enriched_prompt)\n        response = await self.model.run(messages)\n\n        # Structure financial responses\n        if self._should_structure_response(response.content):\n            structured = self._structure_financial_response(response.content)\n            return Message(\n                role=\"assistant\",\n                content=response.content,\n                structured_data=structured\n            )\n\n        return Message(role=\"assistant\", content=response.content)\n\n    def _get_stock_price(self, symbol: str) -&gt; Dict:\n        \"\"\"Get real-time stock price.\"\"\"\n        if self.market_data_api:\n            return self.market_data_api.get_price(symbol)\n        return {\"error\": \"No market data API configured\"}\n\n    def _calculate_metrics(self, data: Dict) -&gt; Dict:\n        \"\"\"Calculate financial metrics.\"\"\"\n        # Implementation\n        return {\"pe_ratio\": 15.2, \"roi\": 0.12}\n</code></pre>"},{"location":"concepts/custom-agents/#advanced-patterns","title":"\ud83c\udfaf Advanced Patterns","text":""},{"location":"concepts/custom-agents/#state-machine-agent","title":"State Machine Agent","text":"<p>Implement complex workflows with state transitions:</p> <pre><code>from enum import Enum\n\nclass ProcessingState(Enum):\n    INITIAL = \"initial\"\n    ANALYZING = \"analyzing\"\n    VALIDATING = \"validating\"\n    COMPLETE = \"complete\"\n    ERROR = \"error\"\n\nclass StateMachineAgent(BaseAgent):\n    \"\"\"Agent with state-based processing.\"\"\"\n\n    def __init__(self, model, **kwargs):\n        super().__init__(model, **kwargs)\n        self.state = ProcessingState.INITIAL\n        self.state_data = {}\n\n    async def _run(self, prompt, context, **kwargs):\n        \"\"\"Execute based on current state.\"\"\"\n\n        # State-based routing\n        handlers = {\n            ProcessingState.INITIAL: self._handle_initial,\n            ProcessingState.ANALYZING: self._handle_analyzing,\n            ProcessingState.VALIDATING: self._handle_validating,\n            ProcessingState.COMPLETE: self._handle_complete,\n            ProcessingState.ERROR: self._handle_error\n        }\n\n        handler = handlers.get(self.state, self._handle_error)\n        return await handler(prompt, context)\n\n    async def _handle_initial(self, prompt, context):\n        \"\"\"Initial state processing.\"\"\"\n\n        # Validate input\n        if not self._validate_input(prompt):\n            self.state = ProcessingState.ERROR\n            return Message(\n                role=\"error\",\n                content=\"Invalid input format\"\n            )\n\n        # Transition to analyzing\n        self.state = ProcessingState.ANALYZING\n        self.state_data[\"start_time\"] = time.time()\n\n        messages = self._prepare_messages(\n            f\"Starting analysis of: {prompt}\"\n        )\n        response = await self.model.run(messages)\n\n        return Message(\n            role=\"assistant\",\n            content=response.content,\n            metadata={\"state\": self.state.value}\n        )\n\n    async def _handle_analyzing(self, prompt, context):\n        \"\"\"Analysis state processing.\"\"\"\n\n        # Perform analysis\n        analysis_prompt = f\"\"\"Analyze this in detail: {prompt}\n\n        Consider:\n        1. Key components\n        2. Relationships\n        3. Potential issues\n        4. Recommendations\"\"\"\n\n        messages = self._prepare_messages(analysis_prompt)\n        response = await self.model.run(messages)\n\n        # Store analysis results\n        self.state_data[\"analysis\"] = response.content\n\n        # Transition to validation\n        self.state = ProcessingState.VALIDATING\n\n        return Message(\n            role=\"assistant\",\n            content=response.content,\n            metadata={\"state\": self.state.value}\n        )\n</code></pre>"},{"location":"concepts/custom-agents/#composite-agent","title":"Composite Agent","text":"<p>Combine multiple specialized agents:</p> <pre><code>class CompositeResearchAgent(BaseAgent):\n    \"\"\"Agent composed of multiple specialists.\"\"\"\n\n    def __init__(self, model, **kwargs):\n        super().__init__(model, **kwargs)\n\n        # Create internal specialists\n        self.specialists = {\n            \"web\": WebSearchSpecialist(model),\n            \"academic\": AcademicResearchSpecialist(model),\n            \"data\": DataAnalysisSpecialist(model)\n        }\n\n    async def _run(self, prompt, context, **kwargs):\n        \"\"\"Coordinate specialists for comprehensive research.\"\"\"\n\n        # Classify research type\n        research_type = self._classify_research(prompt)\n\n        if research_type == \"comprehensive\":\n            # Use all specialists\n            results = await self._parallel_research(prompt)\n            synthesis = await self._synthesize_results(results)\n\n            return Message(\n                role=\"assistant\",\n                content=synthesis,\n                structured_data={\"sources\": results}\n            )\n\n        elif research_type in self.specialists:\n            # Use specific specialist\n            specialist = self.specialists[research_type]\n            response = await specialist.run_step(prompt, context)\n\n            return Message(\n                role=\"assistant\",\n                content=response.response\n            )\n\n        else:\n            # Fallback to general research\n            return await super()._run(prompt, context, **kwargs)\n\n    async def _parallel_research(self, prompt):\n        \"\"\"Run all specialists in parallel.\"\"\"\n        tasks = []\n        for name, specialist in self.specialists.items():\n            task = specialist.run_step(prompt, {})\n            tasks.append((name, task))\n\n        results = {}\n        for name, task in tasks:\n            response = await task\n            results[name] = response.response\n\n        return results\n\n    async def _synthesize_results(self, results):\n        \"\"\"Synthesize findings from all specialists.\"\"\"\n        synthesis_prompt = f\"\"\"Synthesize these research findings:\n\n        {json.dumps(results, indent=2)}\n\n        Create a comprehensive summary that:\n        1. Identifies common themes\n        2. Resolves contradictions\n        3. Highlights key insights\n        4. Provides actionable conclusions\"\"\"\n\n        messages = self._prepare_messages(synthesis_prompt)\n        response = await self.model.run(messages)\n        return response.content\n</code></pre>"},{"location":"concepts/custom-agents/#learning-agent","title":"Learning Agent","text":"<p>Agent that improves over time:</p> <pre><code>class LearningAgent(BaseAgent):\n    \"\"\"Agent that learns from interactions.\"\"\"\n\n    def __init__(self, model, learning_rate=0.1, **kwargs):\n        super().__init__(model, **kwargs)\n        self.learning_rate = learning_rate\n        self.performance_history = []\n        self.learned_patterns = {}\n\n    async def _run(self, prompt, context, **kwargs):\n        \"\"\"Execute with learning.\"\"\"\n\n        # Check for learned patterns\n        pattern_match = self._find_pattern_match(prompt)\n        if pattern_match:\n            # Use learned response strategy\n            strategy = self.learned_patterns[pattern_match]\n            enhanced_prompt = self._apply_strategy(prompt, strategy)\n        else:\n            enhanced_prompt = prompt\n\n        # Execute\n        messages = self._prepare_messages(enhanced_prompt)\n        response = await self.model.run(messages)\n\n        # Learn from outcome (in post-processing, not here!)\n        # Note: Actual learning happens outside _run() to keep it pure\n\n        return Message(\n            role=\"assistant\",\n            content=response.content,\n            metadata={\n                \"pattern_used\": pattern_match,\n                \"confidence\": self._calculate_confidence()\n            }\n        )\n\n    def learn_from_feedback(self, prompt, response, feedback):\n        \"\"\"Update learned patterns based on feedback.\"\"\"\n        # This happens OUTSIDE _run() method\n\n        pattern = self._extract_pattern(prompt)\n\n        if feedback[\"success\"]:\n            # Reinforce successful patterns\n            if pattern not in self.learned_patterns:\n                self.learned_patterns[pattern] = {\n                    \"strategy\": self._extract_strategy(response),\n                    \"success_rate\": 1.0,\n                    \"usage_count\": 1\n                }\n            else:\n                # Update success rate\n                stats = self.learned_patterns[pattern]\n                stats[\"usage_count\"] += 1\n                stats[\"success_rate\"] = (\n                    stats[\"success_rate\"] * (1 - self.learning_rate) +\n                    1.0 * self.learning_rate\n                )\n        else:\n            # Adjust unsuccessful patterns\n            if pattern in self.learned_patterns:\n                stats = self.learned_patterns[pattern]\n                stats[\"success_rate\"] *= (1 - self.learning_rate)\n\n                # Remove if consistently unsuccessful\n                if stats[\"success_rate\"] &lt; 0.3:\n                    del self.learned_patterns[pattern]\n\n        # Record performance\n        self.performance_history.append({\n            \"timestamp\": time.time(),\n            \"pattern\": pattern,\n            \"success\": feedback[\"success\"]\n        })\n</code></pre>"},{"location":"concepts/custom-agents/#implementation-patterns","title":"\ud83d\udd27 Implementation Patterns","text":""},{"location":"concepts/custom-agents/#validation-and-error-handling","title":"Validation and Error Handling","text":"<pre><code>class ValidatedAgent(BaseAgent):\n    \"\"\"Agent with comprehensive validation.\"\"\"\n\n    def __init__(self, model, input_schema=None, output_schema=None, **kwargs):\n        super().__init__(model, **kwargs)\n        self.input_schema = input_schema\n        self.output_schema = output_schema\n\n    async def _run(self, prompt, context, **kwargs):\n        \"\"\"Execute with validation.\"\"\"\n\n        # Validate input\n        if self.input_schema:\n            try:\n                validated_input = self.input_schema.parse_obj(prompt)\n                prompt = validated_input.dict()\n            except ValidationError as e:\n                return Message(\n                    role=\"error\",\n                    content=f\"Input validation failed: {e}\",\n                    metadata={\"validation_errors\": e.errors()}\n                )\n\n        # Process\n        messages = self._prepare_messages(str(prompt))\n        response = await self.model.run(messages)\n\n        # Validate output\n        if self.output_schema:\n            try:\n                # Parse response as JSON\n                output_data = json.loads(response.content)\n                validated_output = self.output_schema.parse_obj(output_data)\n\n                return Message(\n                    role=\"assistant\",\n                    content=json.dumps(validated_output.dict()),\n                    structured_data=validated_output.dict()\n                )\n            except (json.JSONDecodeError, ValidationError) as e:\n                # Fallback to unstructured response\n                return Message(\n                    role=\"assistant\",\n                    content=response.content,\n                    metadata={\"validation_warning\": str(e)}\n                )\n\n        return Message(role=\"assistant\", content=response.content)\n</code></pre>"},{"location":"concepts/custom-agents/#monitoring-and-metrics","title":"Monitoring and Metrics","text":"<pre><code>class MonitoredAgent(BaseAgent):\n    \"\"\"Agent with built-in monitoring.\"\"\"\n\n    def __init__(self, model, **kwargs):\n        super().__init__(model, **kwargs)\n        self.metrics = {\n            \"total_requests\": 0,\n            \"total_tokens\": 0,\n            \"average_latency\": 0.0,\n            \"error_rate\": 0.0,\n            \"success_rate\": 0.0\n        }\n\n    async def _run(self, prompt, context, **kwargs):\n        \"\"\"Execute with metrics tracking.\"\"\"\n\n        start_time = time.time()\n\n        try:\n            # Execute\n            messages = self._prepare_messages(prompt)\n            response = await self.model.run(messages)\n\n            # Update success metrics (in post-processing)\n            latency = time.time() - start_time\n\n            return Message(\n                role=\"assistant\",\n                content=response.content,\n                metadata={\n                    \"latency\": latency,\n                    \"token_count\": self._estimate_tokens(response.content)\n                }\n            )\n\n        except Exception as e:\n            # Track error (in post-processing)\n            return Message(\n                role=\"error\",\n                content=str(e),\n                metadata={\"error_type\": type(e).__name__}\n            )\n\n    def update_metrics(self, metadata):\n        \"\"\"Update metrics based on execution metadata.\"\"\"\n        # This happens OUTSIDE _run() method\n        self.metrics[\"total_requests\"] += 1\n\n        if \"latency\" in metadata:\n            # Update average latency\n            prev_avg = self.metrics[\"average_latency\"]\n            n = self.metrics[\"total_requests\"]\n            self.metrics[\"average_latency\"] = (\n                (prev_avg * (n - 1) + metadata[\"latency\"]) / n\n            )\n\n        if \"token_count\" in metadata:\n            self.metrics[\"total_tokens\"] += metadata[\"token_count\"]\n</code></pre>"},{"location":"concepts/custom-agents/#best-practices","title":"\ud83d\udccb Best Practices","text":""},{"location":"concepts/custom-agents/#1-keep-_run-pure","title":"1. Keep _run() Pure","text":"<pre><code># \u2705 GOOD - Pure function, no side effects\nasync def _run(self, prompt, context, **kwargs):\n    messages = self._prepare_messages(prompt)\n    response = await self.model.run(messages)\n    return Message(role=\"assistant\", content=response.content)\n\n# \u274c BAD - Side effects in _run()\nasync def _run(self, prompt, context, **kwargs):\n    self.state = \"processing\"  # NO! State change\n    self.memory.add(...)  # NO! Memory manipulation\n    await self.log(...)  # NO! External I/O\n    return response\n</code></pre>"},{"location":"concepts/custom-agents/#2-use-composition-over-inheritance","title":"2. Use Composition Over Inheritance","text":"<pre><code># \u2705 GOOD - Composition\nclass ResearchAgent(BaseAgent):\n    def __init__(self, model, **kwargs):\n        super().__init__(model, **kwargs)\n        self.web_searcher = WebSearcher()\n        self.summarizer = Summarizer()\n\n# \u274c BAD - Deep inheritance\nclass AdvancedResearchAgent(ResearchAgent):\n    class SuperAdvancedResearchAgent(AdvancedResearchAgent):\n        # Too deep!\n</code></pre>"},{"location":"concepts/custom-agents/#3-proper-error-handling","title":"3. Proper Error Handling","text":"<pre><code># \u2705 GOOD - Graceful error handling\nasync def _run(self, prompt, context, **kwargs):\n    try:\n        result = await self.process(prompt)\n        return Message(role=\"assistant\", content=result)\n    except SpecificError as e:\n        return Message(\n            role=\"error\",\n            content=f\"Processing failed: {e}\",\n            metadata={\"recoverable\": True}\n        )\n\n# \u274c BAD - Swallowing errors\nasync def _run(self, prompt, context, **kwargs):\n    try:\n        return await self.process(prompt)\n    except:\n        return \"Error occurred\"  # Lost error details!\n</code></pre>"},{"location":"concepts/custom-agents/#4-document-capabilities","title":"4. Document Capabilities","text":"<pre><code># \u2705 GOOD - Clear documentation\nclass DataAnalyst(BaseAgent):\n    \"\"\"\n    Specialized agent for data analysis.\n\n    Capabilities:\n    - Statistical analysis\n    - Data visualization recommendations\n    - Trend detection\n    - Anomaly identification\n\n    Limitations:\n    - Requires structured data\n    - Maximum 10MB datasets\n    \"\"\"\n</code></pre>"},{"location":"concepts/custom-agents/#testing-custom-agents","title":"\ud83c\udfaf Testing Custom Agents","text":""},{"location":"concepts/custom-agents/#unit-testing","title":"Unit Testing","text":"<pre><code>import pytest\nfrom unittest.mock import Mock, AsyncMock\n\n@pytest.mark.asyncio\nasync def test_custom_agent():\n    # Create mock model\n    mock_model = Mock()\n    mock_model.run = AsyncMock(return_value=Mock(\n        content=\"Test response\"\n    ))\n\n    # Create custom agent\n    agent = CustomAgent(\n        model=mock_model,\n        specialized_knowledge={\"domain\": \"test\"}\n    )\n\n    # Test execution\n    response = await agent._run(\n        \"Test prompt\",\n        {\"test\": \"context\"}\n    )\n\n    # Assertions\n    assert response.role == \"assistant\"\n    assert \"Test response\" in response.content\n    mock_model.run.assert_called_once()\n</code></pre>"},{"location":"concepts/custom-agents/#integration-testing","title":"Integration Testing","text":"<pre><code>@pytest.mark.asyncio\nasync def test_agent_in_workflow():\n    # Create custom agent\n    agent = CustomAgent(\n        model_config=test_config,\n        agent_name=\"CustomTest\"\n    )\n\n    # Define test topology\n    topology = {\n        \"agents\": [\"CustomTest\"],\n        \"flows\": []\n    }\n\n    # Run in Orchestra\n    result = await Orchestra.run(\n        task=\"Test task\",\n        topology=topology\n    )\n\n    # Validate result\n    assert result.success\n    assert \"CustomTest\" in result.metadata\n</code></pre>"},{"location":"concepts/custom-agents/#next-steps","title":"\ud83d\udea6 Next Steps","text":"<ul> <li> <p> Agents</p> <p>Core agent concepts</p> </li> <li> <p> Memory Patterns</p> <p>Advanced memory strategies</p> </li> <li> <p> Learning Agents</p> <p>Agents that improve over time</p> </li> <li> <p> Agent API</p> <p>Complete API reference</p> </li> </ul> <p>Custom Agents Ready!</p> <p>You now understand how to create custom agents in MARSYS. Build specialized agents that extend the framework with domain-specific capabilities while maintaining pure execution principles.</p>"},{"location":"concepts/error-handling/","title":"Error Handling","text":"<p>MARSYS provides a comprehensive error handling system that ensures robust operation, graceful degradation, and intelligent recovery in multi-agent workflows.</p>"},{"location":"concepts/error-handling/#overview","title":"\ud83c\udfaf Overview","text":"<p>The error handling system provides:</p> <ul> <li>Hierarchical Exceptions: Granular error categorization with rich context</li> <li>Intelligent Recovery: Automatic retry strategies and fallback mechanisms</li> <li>Error Routing: Route errors to User nodes for human intervention</li> <li>Provider-Specific Handling: Tailored strategies for different AI providers</li> <li>Comprehensive Logging: Detailed error tracking and monitoring</li> </ul>"},{"location":"concepts/error-handling/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<pre><code>graph TB\n    subgraph \"Error Classification\"\n        CE[Critical Errors&lt;br/&gt;System Failures]\n        RE[Recoverable Errors&lt;br/&gt;Transient Issues]\n        VE[Validation Errors&lt;br/&gt;Input Problems]\n        PE[Permission Errors&lt;br/&gt;Access Denied]\n    end\n\n    subgraph \"Recovery Strategies\"\n        AR[Auto Retry&lt;br/&gt;Exponential Backoff]\n        FB[Fallback&lt;br/&gt;Alternative Paths]\n        UR[User Recovery&lt;br/&gt;Human Intervention]\n        CB[Circuit Breaker&lt;br/&gt;Failure Prevention]\n    end\n\n    subgraph \"Error Flow\"\n        Error[Error Occurs] --&gt; EC[Error Classifier]\n        EC --&gt; Strategy[Select Strategy]\n        Strategy --&gt; Execute[Execute Recovery]\n        Execute --&gt; Result[Success/Failure]\n    end\n\n    CE --&gt; UR\n    RE --&gt; AR\n    VE --&gt; FB\n    PE --&gt; UR\n\n    style CE fill:#ff6b6b\n    style RE fill:#ffd93d\n    style VE fill:#6bcf7f</code></pre>"},{"location":"concepts/error-handling/#exception-hierarchy","title":"\ud83d\udce6 Exception Hierarchy","text":""},{"location":"concepts/error-handling/#base-exception","title":"Base Exception","text":"<p>All MARSYS exceptions inherit from <code>AgentFrameworkError</code>:</p> <pre><code>from marsys.agents.exceptions import AgentFrameworkError, AgentError\n\nclass AgentFrameworkError(Exception):\n    \"\"\"Base exception for all MARSYS framework errors.\"\"\"\n    pass\n\nclass AgentError(AgentFrameworkError):\n    \"\"\"Exception for agent-specific errors.\"\"\"\n    pass\n\n# The actual exception classes are simpler than previously documented.\n# Complex error metadata is handled at the coordination layer, not in exceptions.\n</code></pre>"},{"location":"concepts/error-handling/#error-categories","title":"Error Categories","text":"<p>The framework uses specific exception types for different error scenarios:</p> <pre><code>from marsys.agents.exceptions import (\n    AgentFrameworkError,\n    AgentError,\n    ToolExecutionError,\n    ToolCallError,\n    ModelError\n)\n\n# Agent-specific errors\nclass AgentError(AgentFrameworkError):\n    \"\"\"Agent execution and initialization errors.\"\"\"\n    pass\n\n# Tool execution errors\nclass ToolExecutionError(AgentFrameworkError):\n    \"\"\"Tool function execution failures.\"\"\"\n    pass\n\nclass ToolCallError(AgentFrameworkError):\n    \"\"\"Tool call format errors (malformed arguments, missing required fields).\"\"\"\n    pass\n\nclass ActionValidationError(ValidationError):\n    \"\"\"Invalid agent actions.\"\"\"\n    pass\n\n# Configuration Errors\nclass ConfigurationError(MarsysError):\n    \"\"\"Configuration problems.\"\"\"\n    pass\n\nclass AgentConfigurationError(ConfigurationError):\n    \"\"\"Agent setup errors.\"\"\"\n    pass\n\nclass TopologyError(ConfigurationError):\n    \"\"\"Topology definition errors.\"\"\"\n    pass\n\n# Execution Errors\nclass ExecutionError(MarsysError):\n    \"\"\"Runtime execution failures.\"\"\"\n    pass\n\nclass AgentExecutionError(ExecutionError):\n    \"\"\"Agent execution failures.\"\"\"\n    pass\n\nclass TimeoutError(ExecutionError):\n    \"\"\"Operation timeout.\"\"\"\n    pass\n\n# Permission Errors\nclass PermissionError(MarsysError):\n    \"\"\"Access control violations.\"\"\"\n    pass\n\nclass AgentPermissionError(PermissionError):\n    \"\"\"Agent invocation denied.\"\"\"\n    pass\n\n# API Errors\nclass APIError(MarsysError):\n    \"\"\"External API failures.\"\"\"\n    pass\n\nclass RateLimitError(APIError):\n    \"\"\"API rate limit exceeded.\"\"\"\n    recoverable = True\n</code></pre>"},{"location":"concepts/error-handling/#error-handling-patterns","title":"\ud83c\udfaf Error Handling Patterns","text":""},{"location":"concepts/error-handling/#try-catch-with-context","title":"Try-Catch with Context","text":"<pre><code>async def execute_agent_task(agent, task, context):\n    \"\"\"Execute task with comprehensive error handling.\"\"\"\n    try:\n        result = await agent.run(task, context)\n        return result\n\n    except ValidationError as e:\n        # Handle validation errors\n        logger.warning(f\"Validation error: {e.message}\")\n        if e.suggestion:\n            logger.info(f\"Suggestion: {e.suggestion}\")\n        # Try with corrected input\n        corrected_task = correct_validation_issues(task, e)\n        return await agent.run(corrected_task, context)\n\n    except RateLimitError as e:\n        # Handle rate limits with backoff\n        wait_time = e.context.get(\"retry_after\", 60)\n        logger.info(f\"Rate limited. Waiting {wait_time}s...\")\n        await asyncio.sleep(wait_time)\n        return await execute_agent_task(agent, task, context)\n\n    except AgentPermissionError as e:\n        # Route to user for permission\n        if context.get(\"user_recovery\"):\n            return await route_to_user_for_permission(e, context)\n        raise\n\n    except TimeoutError as e:\n        # Handle timeout with retry or cancellation\n        if e.recoverable and context.get(\"retry_count\", 0) &lt; 3:\n            context[\"retry_count\"] = context.get(\"retry_count\", 0) + 1\n            return await execute_agent_task(agent, task, context)\n        raise\n\n    except ToolCallError as e:\n        # Tool call format errors - need steering, not blind retries\n        # The framework automatically sets error context for the agent\n        logger.warning(f\"Tool call format error: {e}\")\n        # Let the steering system guide the agent to fix the tool call\n        raise\n\n    except MarsysError as e:\n        # Log framework errors\n        logger.error(f\"Framework error: {e.to_dict()}\")\n        raise\n\n    except Exception as e:\n        # Wrap unexpected errors\n        wrapped = ExecutionError(\n            f\"Unexpected error: {str(e)}\",\n            context={\"original_error\": str(e), \"type\": type(e).__name__}\n        )\n        logger.error(f\"Unexpected error: {wrapped.to_dict()}\")\n        raise wrapped\n</code></pre>"},{"location":"concepts/error-handling/#agent-name-used-as-tool-call","title":"Agent Name Used as Tool Call","text":"<p>When an agent emits a <code>tool_calls</code> entry whose name matches a peer agent, MARSYS returns a targeted error instead of a generic \"tool not found\" message.</p> <p>Current behavior: - The executor checks next-hop peer agents from topology context. - If the name is a peer agent, the response explains that peer agents are not tools. - The response includes the correct JSON pattern for agent invocation.</p> <p>Use this form for peer-agent handoff:</p> <pre><code>{\n  \"thought\": \"Need specialized processing from another agent\",\n  \"next_action\": \"invoke_agent\",\n  \"action_input\": [\n    {\n      \"agent_name\": \"Analyzer\",\n      \"request\": \"Analyze the uploaded dataset and report anomalies\"\n    }\n  ]\n}\n</code></pre> <p>Do not place peer-agent names inside <code>tool_calls</code>.</p>"},{"location":"concepts/error-handling/#automatic-retry-in-api-adapters","title":"Automatic Retry in API Adapters","text":"<p>Built-in Retry Logic</p> <p>MARSYS automatically retries server-side API errors with exponential backoff at the adapter level. No manual retry logic needed for API calls!</p>"},{"location":"concepts/error-handling/#how-it-works","title":"How It Works","text":"<p>All API adapters (<code>APIProviderAdapter</code> and <code>AsyncBaseAPIAdapter</code>) automatically retry:</p> <p>Retryable Status Codes: - 500 - Internal Server Error - 502 - Bad Gateway - 503 - Service Unavailable - 504 - Gateway Timeout - 529 - Overloaded (Anthropic) - 408 - Request Timeout (OpenRouter) - 429 - Rate Limit (respects <code>retry-after</code> header)</p> <p>Configuration: - Max retries: 3 (total 4 attempts) - Base delay: 1 second - Exponential backoff: 1s \u2192 2s \u2192 4s</p> <p>Example Log Output: <pre><code>2025-11-05 00:58:46 - WARNING - Server error 503 from gpt-5.3-codex. Retry 1/3 after 1.0s\n2025-11-05 00:58:47 - WARNING - Server error 503 from gpt-5.3-codex. Retry 2/3 after 2.0s\n2025-11-05 00:58:49 - INFO - Request successful after 2 retries\n</code></pre></p>"},{"location":"concepts/error-handling/#provider-specific-behavior","title":"Provider-Specific Behavior","text":"OpenRouterOpenAIAnthropicGoogle Gemini <pre><code># Retryable errors\n- 408: Request Timeout \u2192 retry after 5s\n- 429: Rate Limit \u2192 respect X-RateLimit-Reset header\n- 502: Bad Gateway (provider error) \u2192 retry after 5s\n- 503: Service Unavailable \u2192 retry after 10s\n- 500+: Server errors \u2192 retry after 10s\n\n# Non-retryable errors (fail immediately)\n- 400: Bad Request (malformed request)\n- 401: Unauthorized (invalid API key)\n- 402: Insufficient Credits\n- 403: Forbidden (moderation flagged)\n</code></pre> <pre><code># Retryable errors\n- 429: Rate Limit \u2192 respect retry-after header\n- 500: Internal Server Error \u2192 retry\n- 502: Bad Gateway \u2192 retry\n- 503: Service Unavailable \u2192 retry\n\n# Non-retryable errors\n- 400: Bad Request\n- 401: Authentication Failed\n- 404: Invalid Model\n</code></pre> <pre><code># Retryable errors\n- 429: Rate Limit \u2192 respect retry-after header\n- 500: API Error (internal) \u2192 retry\n- 529: Overloaded \u2192 retry\n\n# Non-retryable errors\n- 400: Invalid Request\n- 401: Authentication Error\n- 403: Permission Error\n- 413: Request Too Large\n</code></pre> <pre><code># Retryable errors\n- 429: Resource Exhausted \u2192 retry\n- 500: INTERNAL \u2192 retry\n- 503: UNAVAILABLE \u2192 retry\n- 504: DEADLINE_EXCEEDED \u2192 retry\n\n# Non-retryable errors\n- 400: INVALID_ARGUMENT\n- 403: PERMISSION_DENIED\n- 404: NOT_FOUND\n</code></pre>"},{"location":"concepts/error-handling/#payload-too-large-recovery-request_too_large","title":"Payload Too Large Recovery (<code>REQUEST_TOO_LARGE</code>)","text":"<p>MARSYS has a dedicated recovery path for oversized request payloads (commonly image-heavy traces).</p> <p>Classification rules: - HTTP 413 is classified provider-agnostically as <code>request_too_large</code> - Message-text override also classifies <code>request_too_large</code> when payload hints appear, including:   - <code>\"request_too_large\"</code>   - <code>\"payload too large\"</code>   - <code>\"request exceeds the maximum\"</code>   - <code>\"request body is too large\"</code></p> <p>Execution flow: 1. Provider adapter / <code>BaseAPIModel</code> raises <code>ModelAPIError</code> with classification <code>request_too_large</code> 2. <code>Agent._run()</code> re-raises this specific error (instead of converting to an error <code>Message</code>) 3. <code>Agent.run_step()</code> catches it, triggers <code>memory.compact_for_payload_error(...)</code>, re-prepares messages, and retries 4. Retry is bounded to a hard cap of 2 attempts (<code>_MAX_PAYLOAD_RETRIES = 2</code>) 5. If compaction does not reduce payload enough (or retries are exhausted), the agent returns an error <code>Message</code> 6. Coordination treats <code>request_too_large</code> as terminal (<code>terminal_error</code>) to avoid endless retry loops</p> <p>Notes: - The payload compaction path is separate from adapter-level transient retries (5xx/429) - Recovery compaction success is measured by payload-byte reduction, not just token estimates</p>"},{"location":"concepts/error-handling/#when-to-use-manual-retry","title":"When to Use Manual Retry","text":"<p>The built-in adapter retry handles transient API errors. Use manual retry for:</p> <ol> <li>Application-level errors (business logic failures)</li> <li>Multi-step workflows (coordinating multiple agents)</li> <li>Custom retry policies (non-standard backoff)</li> </ol>"},{"location":"concepts/error-handling/#manual-retry-with-exponential-backoff","title":"Manual Retry with Exponential Backoff","text":"<p>For application-level retry needs:</p> <pre><code>class RetryHandler:\n    \"\"\"Intelligent retry with exponential backoff.\"\"\"\n\n    def __init__(\n        self,\n        max_retries: int = 3,\n        base_delay: float = 1.0,\n        max_delay: float = 60.0,\n        exponential_base: float = 2.0\n    ):\n        self.max_retries = max_retries\n        self.base_delay = base_delay\n        self.max_delay = max_delay\n        self.exponential_base = exponential_base\n\n    async def execute_with_retry(\n        self,\n        func: Callable,\n        *args,\n        **kwargs\n    ) -&gt; Any:\n        \"\"\"Execute function with retry logic.\"\"\"\n        last_exception = None\n\n        for attempt in range(self.max_retries):\n            try:\n                return await func(*args, **kwargs)\n\n            except RateLimitError as e:\n                # Use API-provided retry delay if available\n                delay = e.context.get(\"retry_after\", self._calculate_delay(attempt))\n                logger.info(f\"Rate limited. Retry {attempt + 1}/{self.max_retries} in {delay}s\")\n                await asyncio.sleep(delay)\n                last_exception = e\n\n            except TimeoutError as e:\n                if not e.recoverable:\n                    raise\n                delay = self._calculate_delay(attempt)\n                logger.warning(f\"Timeout. Retry {attempt + 1}/{self.max_retries} in {delay}s\")\n                await asyncio.sleep(delay)\n                last_exception = e\n\n            except APIError as e:\n                # Note: API adapters already retry server errors automatically\n                # This manual retry is for application-level API error handling\n                if e.context.get(\"status_code\") in [500, 502, 503, 504]:\n                    # Server error after adapter retries exhausted\n                    delay = self._calculate_delay(attempt)\n                    logger.warning(f\"Server error (after adapter retries). Retry {attempt + 1}/{self.max_retries} in {delay}s\")\n                    await asyncio.sleep(delay)\n                    last_exception = e\n                else:\n                    raise\n\n            except Exception as e:\n                # Don't retry unexpected errors\n                raise\n\n        # Max retries exceeded\n        raise ExecutionError(\n            f\"Max retries ({self.max_retries}) exceeded\",\n            context={\"last_error\": str(last_exception)},\n            suggestion=\"Consider increasing timeout or using a different approach\"\n        )\n\n    def _calculate_delay(self, attempt: int) -&gt; float:\n        \"\"\"Calculate exponential backoff delay.\"\"\"\n        delay = self.base_delay * (self.exponential_base ** attempt)\n        # Add jitter\n        delay = delay * (0.5 + random.random())\n        return min(delay, self.max_delay)\n</code></pre>"},{"location":"concepts/error-handling/#circuit-breaker-pattern","title":"Circuit Breaker Pattern","text":"<pre><code>class CircuitBreaker:\n    \"\"\"Prevent cascading failures with circuit breaker.\"\"\"\n\n    def __init__(\n        self,\n        failure_threshold: int = 5,\n        recovery_timeout: float = 60.0,\n        expected_exception: type = APIError\n    ):\n        self.failure_threshold = failure_threshold\n        self.recovery_timeout = recovery_timeout\n        self.expected_exception = expected_exception\n        self.failure_count = 0\n        self.last_failure_time = None\n        self.state = \"closed\"  # closed, open, half-open\n\n    async def call(self, func: Callable, *args, **kwargs) -&gt; Any:\n        \"\"\"Execute function with circuit breaker protection.\"\"\"\n\n        # Check circuit state\n        if self.state == \"open\":\n            if self._should_attempt_reset():\n                self.state = \"half-open\"\n            else:\n                raise ExecutionError(\n                    \"Circuit breaker is open\",\n                    context={\"failure_count\": self.failure_count},\n                    suggestion=f\"Wait {self.recovery_timeout}s for recovery\"\n                )\n\n        # Execute function\n        try:\n            result = await func(*args, **kwargs)\n\n            # Success - reset circuit\n            if self.state == \"half-open\":\n                self._reset()\n\n            return result\n\n        except self.expected_exception as e:\n            self._record_failure()\n\n            if self.failure_count &gt;= self.failure_threshold:\n                self._trip()\n\n            raise\n\n    def _should_attempt_reset(self) -&gt; bool:\n        \"\"\"Check if we should try to reset circuit.\"\"\"\n        return (\n            self.last_failure_time and\n            (datetime.now() - self.last_failure_time).total_seconds() &gt;= self.recovery_timeout\n        )\n\n    def _record_failure(self):\n        \"\"\"Record a failure.\"\"\"\n        self.failure_count += 1\n        self.last_failure_time = datetime.now()\n\n    def _reset(self):\n        \"\"\"Reset circuit to closed state.\"\"\"\n        self.failure_count = 0\n        self.last_failure_time = None\n        self.state = \"closed\"\n\n    def _trip(self):\n        \"\"\"Trip circuit to open state.\"\"\"\n        self.state = \"open\"\n        logger.warning(f\"Circuit breaker tripped after {self.failure_count} failures\")\n</code></pre>"},{"location":"concepts/error-handling/#error-configuration","title":"\ud83d\udd27 Error Configuration","text":""},{"location":"concepts/error-handling/#errorhandlingconfig","title":"ErrorHandlingConfig","text":"<pre><code>from marsys.coordination.config import ErrorHandlingConfig\n\nconfig = ErrorHandlingConfig(\n    # Classification\n    use_error_classification=True,\n    classify_as_critical=[\"PermissionError\", \"ConfigurationError\"],\n    classify_as_recoverable=[\"RateLimitError\", \"TimeoutError\"],\n\n    # Notifications\n    notify_on_critical_errors=True,\n    notification_channels=[\"terminal\", \"log\"],\n\n    # Recovery\n    enable_error_routing=True,  # Route to User node\n    error_recovery_timeout=300.0,\n\n    # Retry settings\n    auto_retry_on_rate_limits=True,\n    max_rate_limit_retries=3,\n    base_retry_delay=1.0,\n    max_retry_delay=60.0,\n\n    # Circuit breaker\n    enable_circuit_breaker=True,\n    circuit_breaker_threshold=5,\n    circuit_breaker_timeout=60.0,\n\n    # Provider-specific\n    provider_settings={\n        \"openai\": {\n            \"max_retries\": 3,\n            \"base_retry_delay\": 60,\n            \"rate_limit_strategy\": \"exponential_backoff\",\n            \"insufficient_quota_action\": \"fallback\"\n        },\n        \"anthropic\": {\n            \"max_retries\": 2,\n            \"base_retry_delay\": 30,\n            \"rate_limit_strategy\": \"fixed_delay\",\n            \"insufficient_quota_action\": \"raise\"\n        },\n        \"google\": {\n            \"max_retries\": 3,\n            \"base_retry_delay\": 45,\n            \"rate_limit_strategy\": \"exponential_backoff\",\n            \"insufficient_quota_action\": \"queue\"\n        }\n    }\n)\n</code></pre>"},{"location":"concepts/error-handling/#error-recovery-strategies","title":"\ud83c\udfaf Error Recovery Strategies","text":""},{"location":"concepts/error-handling/#user-driven-recovery","title":"User-Driven Recovery","text":"<p>Route errors to User node for human intervention:</p> <pre><code>class UserRecoveryHandler:\n    \"\"\"Handle error recovery through user interaction.\"\"\"\n\n    async def handle_error_with_user(\n        self,\n        error: MarsysError,\n        context: Dict[str, Any],\n        topology: Topology\n    ) -&gt; Optional[Any]:\n        \"\"\"Route error to User node for recovery.\"\"\"\n\n        if not topology.has_node(\"User\"):\n            return None\n\n        # Format error for user\n        error_message = self._format_error_for_user(error)\n\n        # Create recovery options\n        options = self._get_recovery_options(error)\n\n        # Ask user for decision\n        user_prompt = f\"\"\"\n{error_message}\n\nHow would you like to proceed?\n{self._format_options(options)}\n\"\"\"\n\n        # Get user response\n        response = await self._get_user_input(user_prompt, context)\n\n        # Execute recovery based on user choice\n        return await self._execute_recovery(response, error, context)\n\n    def _get_recovery_options(self, error: MarsysError) -&gt; List[str]:\n        \"\"\"Get recovery options based on error type.\"\"\"\n        options = [\"Abort execution\"]\n\n        if error.recoverable:\n            options.insert(0, \"Retry operation\")\n\n        if isinstance(error, ValidationError):\n            options.insert(0, \"Provide corrected input\")\n\n        if isinstance(error, PermissionError):\n            options.insert(0, \"Grant permission\")\n\n        if isinstance(error, RateLimitError):\n            options.insert(0, \"Wait and retry\")\n\n        return options\n</code></pre>"},{"location":"concepts/error-handling/#fallback-strategies","title":"Fallback Strategies","text":"<pre><code>class FallbackHandler:\n    \"\"\"Implement fallback strategies for errors.\"\"\"\n\n    def __init__(self, fallback_map: Dict[str, List[str]]):\n        self.fallback_map = fallback_map  # Primary -&gt; [fallbacks]\n\n    async def execute_with_fallback(\n        self,\n        primary_agent: str,\n        task: str,\n        context: Dict[str, Any]\n    ) -&gt; Any:\n        \"\"\"Execute with fallback agents on failure.\"\"\"\n\n        agents_to_try = [primary_agent] + self.fallback_map.get(primary_agent, [])\n\n        for agent_name in agents_to_try:\n            try:\n                agent = AgentRegistry.get(agent_name)\n                if not agent:\n                    continue\n\n                result = await agent.run(task, context)\n                if agent_name != primary_agent:\n                    logger.info(f\"Fallback to {agent_name} succeeded\")\n                return result\n\n            except MarsysError as e:\n                logger.warning(f\"Agent {agent_name} failed: {e.message}\")\n                if agent_name == agents_to_try[-1]:\n                    # No more fallbacks\n                    raise ExecutionError(\n                        f\"All agents failed: {', '.join(agents_to_try)}\",\n                        context={\"last_error\": str(e)},\n                        suggestion=\"Consider revising the task or adding more fallback agents\"\n                    )\n                continue\n</code></pre>"},{"location":"concepts/error-handling/#best-practices","title":"\ud83d\udccb Best Practices","text":""},{"location":"concepts/error-handling/#1-use-specific-exceptions","title":"1. Use Specific Exceptions","text":"<pre><code># \u2705 GOOD - Specific exception with context\nraise MessageFormatError(\n    \"Invalid JSON in model response\",\n    context={\n        \"response\": response[:200],\n        \"expected\": \"JSON object with 'next_action' field\"\n    },\n    suggestion=\"Ensure model is prompted to return valid JSON\",\n    recoverable=True\n)\n\n# \u274c BAD - Generic exception\nraise Exception(\"Invalid response\")\n</code></pre>"},{"location":"concepts/error-handling/#2-provide-recovery-information","title":"2. Provide Recovery Information","text":"<pre><code># \u2705 GOOD - Actionable error\nraise RateLimitError(\n    \"OpenAI API rate limit exceeded\",\n    context={\n        \"limit\": \"10000 tokens/min\",\n        \"used\": \"10500 tokens\",\n        \"retry_after\": 60\n    },\n    suggestion=\"Wait 60 seconds or use a different API key\",\n    recoverable=True\n)\n\n# \u274c BAD - No recovery info\nraise APIError(\"Rate limit hit\")\n</code></pre>"},{"location":"concepts/error-handling/#3-chain-exceptions","title":"3. Chain Exceptions","text":"<pre><code># \u2705 GOOD - Preserve original context\ntry:\n    result = await risky_operation()\nexcept ValueError as e:\n    raise ValidationError(\n        f\"Operation failed: {str(e)}\",\n        context={\"original_error\": str(e), \"traceback\": traceback.format_exc()}\n    ) from e\n\n# \u274c BAD - Lost context\ntry:\n    result = await risky_operation()\nexcept:\n    raise ValidationError(\"Operation failed\")\n</code></pre>"},{"location":"concepts/error-handling/#4-log-at-appropriate-levels","title":"4. Log at Appropriate Levels","text":"<pre><code># \u2705 GOOD - Appropriate logging\ntry:\n    result = await operation()\nexcept ValidationError as e:\n    logger.warning(f\"Validation failed: {e.message}\")  # Warning for recoverable\nexcept PermissionError as e:\n    logger.error(f\"Permission denied: {e.message}\")  # Error for critical\nexcept Exception as e:\n    logger.exception(f\"Unexpected error: {e}\")  # Full traceback for unexpected\n</code></pre>"},{"location":"concepts/error-handling/#next-steps","title":"\ud83d\udea6 Next Steps","text":"<ul> <li> <p> Validation</p> <p>Input and output validation</p> </li> <li> <p> Retry Strategies</p> <p>Advanced retry patterns</p> </li> <li> <p> User Recovery</p> <p>Human-in-the-loop error handling</p> </li> <li> <p> API Reference</p> <p>Complete exception API</p> </li> </ul> <p>Error Handling Ready!</p> <p>You now understand MARSYS error handling. Robust error management ensures your multi-agent workflows are resilient and maintainable.</p>"},{"location":"concepts/learning-agents/","title":"Learning Agents","text":"<p>Create agents that use local models with optional PEFT (Parameter-Efficient Fine-Tuning) capabilities.</p> <p>Development Status</p> <p>LearnableAgent is currently in active development. The API may change in future releases.</p> <p>We are working on integrating a comprehensive training module that will provide:</p> <ul> <li>Supervised Fine-Tuning (SFT) for instruction tuning</li> <li>Reinforcement Learning (RLHF/DPO) for preference alignment</li> <li>Workflow-Specific Adaptation for specialized agent behaviors</li> </ul> <p>Current capabilities are foundational, with full training integration planned for upcoming releases.</p>"},{"location":"concepts/learning-agents/#overview","title":"Overview","text":"<p>Learning agents in MARSYS are designed for:</p> <ul> <li>Local Model Execution: Run open-source models (Qwen, LLaMA, Mistral, etc.) locally</li> <li>PEFT Support: Attach learning heads like LoRA for fine-tuning</li> <li>Weight Access: Direct access to model weights and tokenizer for training</li> </ul> <p>Requirements</p> <p>LearnableAgent requires:</p> <ul> <li>Local GPU/compute resources</li> <li>The <code>marsys[local-models]</code> package</li> <li>HuggingFace backend only (vLLM does not support training)</li> </ul> <pre><code>pip install marsys[local-models]\n</code></pre>"},{"location":"concepts/learning-agents/#classes","title":"Classes","text":""},{"location":"concepts/learning-agents/#baselearnableagent","title":"BaseLearnableAgent","text":"<p>Abstract base class for agents with learnable components.</p> <pre><code>from marsys.agents import BaseLearnableAgent\nfrom marsys.models import ModelConfig\n\nclass BaseLearnableAgent(BaseAgent, ABC):\n    def __init__(\n        self,\n        model_config: ModelConfig,  # Must have type=\"local\"\n        goal: str,\n        instruction: str,\n        learning_head: Optional[str] = None,\n        learning_head_config: Optional[Dict[str, Any]] = None,\n        tools: Optional[Dict[str, Callable]] = None,\n        max_tokens: Optional[int] = None,\n        name: Optional[str] = None,\n        allowed_peers: Optional[List[str]] = None,\n        **kwargs\n    )\n</code></pre> <p>Parameters:</p> Parameter Type Description <code>model_config</code> <code>ModelConfig</code> Model configuration (must have <code>type=\"local\"</code> and <code>backend=\"huggingface\"</code>) <code>goal</code> <code>str</code> 1-2 sentence summary of what the agent accomplishes <code>instruction</code> <code>str</code> Detailed instructions on how the agent should behave <code>learning_head</code> <code>str</code> Type of learning head (currently only <code>\"peft\"</code>) <code>learning_head_config</code> <code>Dict</code> Configuration for the learning head <code>tools</code> <code>Dict</code> Dictionary of tool functions <code>max_tokens</code> <code>int</code> Maximum tokens for generation <code>name</code> <code>str</code> Name for registration <code>allowed_peers</code> <code>List[str]</code> Agents this agent can call <p>Local-Only Restriction</p> <p>LearnableAgent only supports local models (<code>type=\"local\"</code>) with the HuggingFace backend. Using <code>backend=\"vllm\"</code> will raise a <code>TypeError</code> since vLLM does not support training.</p>"},{"location":"concepts/learning-agents/#learnableagent","title":"LearnableAgent","text":"<p>Concrete implementation for local models with optional PEFT.</p> <pre><code>from marsys.agents import LearnableAgent\nfrom marsys.models import ModelConfig\n\n# Configure local model (HuggingFace only)\nmodel_config = ModelConfig(\n    type=\"local\",\n    model_class=\"llm\",\n    name=\"Qwen/Qwen3-4B-Instruct-2507\",\n    backend=\"huggingface\",  # Required for training\n    torch_dtype=\"bfloat16\",\n    device_map=\"auto\",\n    max_tokens=4096\n)\n\nagent = LearnableAgent(\n    model_config=model_config,\n    name=\"MyLearnableAgent\",\n    goal=\"A helpful assistant that answers questions\",\n    instruction=\"You are a helpful assistant. Provide clear and accurate responses to user queries.\",\n    tools={\"search\": search_function},\n    learning_head=\"peft\",\n    learning_head_config={\n        \"r\": 16,          # LoRA rank\n        \"lora_alpha\": 32,\n        \"target_modules\": [\"q_proj\", \"v_proj\"]\n    }\n)\n</code></pre> <p>Key Distinction: Unlike <code>Agent</code> which uses API-based models (OpenAI, Anthropic), <code>LearnableAgent</code> works with local models where you have direct weight access for training.</p>"},{"location":"concepts/learning-agents/#peft-configuration","title":"PEFT Configuration","text":"<p>When using <code>learning_head=\"peft\"</code>, provide configuration for the PEFT head:</p> <pre><code>from marsys.agents import LearnableAgent\nfrom marsys.models import ModelConfig\n\nlearning_head_config = {\n    \"r\": 16,                           # LoRA rank\n    \"lora_alpha\": 32,                  # LoRA alpha scaling\n    \"target_modules\": [\"q_proj\", \"v_proj\"],  # Modules to adapt\n    \"lora_dropout\": 0.1,               # Dropout rate\n    \"bias\": \"none\"                     # Bias training setting\n}\n\nmodel_config = ModelConfig(\n    type=\"local\",\n    model_class=\"llm\",\n    name=\"Qwen/Qwen3-4B-Instruct-2507\",\n    backend=\"huggingface\",\n    torch_dtype=\"bfloat16\",\n    device_map=\"auto\"\n)\n\nagent = LearnableAgent(\n    model_config=model_config,\n    name=\"ExpertCoder\",\n    goal=\"Expert coding assistant for development tasks\",\n    instruction=\"You are an expert coder. Help with code generation, debugging, and optimization.\",\n    learning_head=\"peft\",\n    learning_head_config=learning_head_config\n)\n</code></pre> <p>The model is wrapped in a <code>PeftHead</code> which handles the LoRA adaptation.</p>"},{"location":"concepts/learning-agents/#usage-example","title":"Usage Example","text":"<pre><code>from marsys.agents import LearnableAgent\nfrom marsys.models import ModelConfig\nfrom marsys.coordination import Orchestra\n\n# Configure local model\nmodel_config = ModelConfig(\n    type=\"local\",\n    model_class=\"llm\",\n    name=\"Qwen/Qwen3-4B-Instruct-2507\",\n    backend=\"huggingface\",\n    torch_dtype=\"bfloat16\",\n    device_map=\"auto\",\n    max_tokens=4096\n)\n\n# Create agent with PEFT\nagent = LearnableAgent(\n    model_config=model_config,\n    name=\"CodeReviewer\",\n    goal=\"Expert code reviewer for quality assurance\",\n    instruction=\"You are an expert code reviewer. Analyze code for bugs, security issues, and best practices.\",\n    learning_head=\"peft\",\n    learning_head_config={\n        \"r\": 8,\n        \"lora_alpha\": 16,\n        \"target_modules\": [\"q_proj\", \"v_proj\"]\n    }\n)\n\n# Use in a topology\ntopology = {\n    \"agents\": [\"CodeReviewer\"],\n    \"flows\": []\n}\n\nresult = await Orchestra.run(\n    task=\"Review this Python code for bugs\",\n    topology=topology\n)\n</code></pre>"},{"location":"concepts/learning-agents/#training-access","title":"Training Access","text":"<p>LearnableAgent provides access to the underlying PyTorch model and tokenizer for training:</p> <pre><code># Access model internals for training\npytorch_model = agent.model.trainable_model  # PEFT-wrapped model\ntokenizer = agent.model.tokenizer            # HuggingFace tokenizer\nbase_model = agent.model.base_model          # Original model (pre-PEFT)\n\n# Example: Use with trl for RLHF\nfrom trl import PPOTrainer, PPOConfig\n\nppo_config = PPOConfig(\n    learning_rate=1e-5,\n    batch_size=4\n)\n\ntrainer = PPOTrainer(\n    config=ppo_config,\n    model=agent.model.trainable_model,\n    tokenizer=agent.model.tokenizer,\n    # ... training data and reward model\n)\n</code></pre> <p>PeftHead Properties</p> <p>When <code>learning_head=\"peft\"</code> is used, the agent's model is wrapped in a <code>PeftHead</code> that provides:</p> <ul> <li><code>trainable_model</code>: The PEFT-wrapped model for training</li> <li><code>base_model</code>: The original HuggingFace model</li> <li><code>tokenizer</code>: The model's tokenizer</li> <li><code>save_pretrained(path)</code>: Save the PEFT adapter weights</li> </ul>"},{"location":"concepts/learning-agents/#when-to-use-learnableagent","title":"When to Use LearnableAgent","text":"<p>Use <code>LearnableAgent</code> when you need:</p> <ul> <li>Custom model behavior through training</li> <li>Local GPU/compute resources</li> <li>Open-source models (Qwen, LLaMA, Mistral, Phi, etc.)</li> <li>Full control over model architecture</li> <li>Fine-tuning for specific workflows</li> <li>Direct access to model weights and tokenizer</li> </ul> <p>Use <code>Agent</code> (with API models) when you need:</p> <ul> <li>Quick setup without GPU requirements</li> <li>Latest model capabilities (GPT-5.3 Codex, Claude Opus 4.6, Gemini 3 Flash/Pro Preview)</li> <li>Pay-per-use pricing</li> <li>No infrastructure management</li> </ul>"},{"location":"concepts/learning-agents/#limitations","title":"Limitations","text":"<p>The current implementation:</p> <ul> <li>Only supports <code>\"peft\"</code> as the learning head type</li> <li>Requires HuggingFace backend (<code>backend=\"huggingface\"</code>)</li> <li>vLLM backend is not supported (no training capabilities)</li> <li>Does not include feedback-based learning or experience tracking</li> <li>Training loop must be implemented separately</li> </ul>"},{"location":"concepts/learning-agents/#architecture","title":"Architecture","text":"<p>LearnableAgent uses the adapter pattern internally:</p> <pre><code>                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502     LearnableAgent      \u2502\n                    \u2502  (model_config: local)  \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n                    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                    \u2502   LocalAdapterFactory    \u2502\n                    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                                \u2502\n              \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n              \u25bc                 \u25bc                 \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 HuggingFaceLLM  \u2502 \u2502 HuggingFaceVLM  \u2502  \u2502 vLLM   \u2502\n    \u2502    Adapter      \u2502 \u2502    Adapter      \u2502  \u2502Adapter \u2502\n    \u2502 \u2705 Training     \u2502 \u2502 \u2705 Training     \u2502  \u2502 \u274c     \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n             \u2502                   \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502             PeftHead                 \u2502\n    \u2502  (LoRA adaptation wrapper)          \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"concepts/learning-agents/#next-steps","title":"Next Steps","text":"<ul> <li> <p> Agents</p> <p>Standard agents with API models</p> </li> <li> <p> Models</p> <p>Model configuration and local model backends</p> </li> <li> <p> Agent API</p> <p>Complete API reference</p> </li> </ul> <p>Future Training Module</p> <p>We are actively developing a comprehensive training module that will integrate with LearnableAgent:</p> <ul> <li>SFT Trainer: Supervised fine-tuning on instruction datasets</li> <li>DPO/RLHF Trainer: Preference alignment training</li> <li>Workflow Trainer: Train agents on multi-agent conversation traces</li> <li>Auto-Eval: Automatic evaluation of trained agents</li> </ul> <p>Stay tuned for updates in upcoming releases!</p>"},{"location":"concepts/memory/","title":"Memory","text":"<p>Memory management enables agents to maintain context across multi-turn conversations.</p> <p>See Also</p> <p>For detailed API signatures, see Memory API Reference.</p>"},{"location":"concepts/memory/#overview","title":"Overview","text":"<p>MARSYS provides a memory system that:</p> <ul> <li>Maintains Context: Preserves conversation history</li> <li>Supports Multiple Types: ConversationMemory, ManagedConversationMemory, KGMemory</li> <li>Handles Token Limits: ManagedConversationMemory automatically manages context size</li> </ul>"},{"location":"concepts/memory/#core-components","title":"Core Components","text":""},{"location":"concepts/memory/#message-structure","title":"Message Structure","text":"<p>The fundamental unit of memory:</p> <pre><code>from marsys.agents.memory import Message\n\n@dataclass\nclass Message:\n    role: str  # user, assistant, system, tool\n    content: Optional[Union[str, Dict[str, Any], List[Dict[str, Any]]]] = None\n    message_id: str  # Auto-generated UUID\n    name: Optional[str] = None  # Tool name or model name\n    tool_calls: Optional[List[ToolCallMsg]] = None\n    agent_calls: Optional[List[AgentCallMsg]] = None\n    structured_data: Optional[Dict[str, Any]] = None\n    images: Optional[List[str]] = None  # For vision models\n    tool_call_id: Optional[str] = None  # For tool response messages\n    reasoning_details: Optional[List[Dict[str, Any]]] = None  # For model thinking/reasoning traces\n</code></pre> <p>Reasoning Details</p> <p>The <code>reasoning_details</code> field preserves model thinking/reasoning traces (e.g., Gemini 3 thought signatures). This is critical for multi-turn tool calling with models that use extended thinking, as the reasoning context must be preserved across turns.</p>"},{"location":"concepts/memory/#conversationmemory","title":"ConversationMemory","text":"<p>Standard memory implementation for storing conversation history:</p> <pre><code>from marsys.agents.memory import ConversationMemory\n\n# Create memory with optional system prompt\nmemory = ConversationMemory(description=\"You are a helpful assistant\")\n\n# Add a message\nmessage_id = memory.add(role=\"user\", content=\"Hello\")\n\n# Or add a Message object directly\nfrom marsys.agents.memory import Message\nmsg = Message(role=\"assistant\", content=\"Hi there!\")\nmemory.add(message=msg)\n\n# Retrieve messages (returns List[Dict])\nall_messages = memory.retrieve_all()\nrecent_messages = memory.retrieve_recent(n=5)\n\n# Get messages for LLM (same as retrieve_all for ConversationMemory)\nllm_messages = memory.get_messages()\n\n# Other operations\nmemory.retrieve_by_id(\"message-uuid-here\")\nmemory.retrieve_by_role(\"user\", n=3)\nmemory.remove_by_id(\"message-uuid-here\")\nmemory.reset_memory()  # Clears all except system message\n</code></pre> <p>Key Methods:</p> Method Description <code>add()</code> Add a message, returns message_id <code>update()</code> Update existing message by ID <code>retrieve_all()</code> Get all messages as dicts <code>retrieve_recent(n)</code> Get last n messages as dicts <code>get_messages()</code> Get messages for LLM consumption <code>retrieve_by_id()</code> Get message by ID <code>retrieve_by_role()</code> Filter by role <code>remove_by_id()</code> Delete message by ID <code>reset_memory()</code> Clear all messages (keeps system prompt)"},{"location":"concepts/memory/#managedconversationmemory","title":"ManagedConversationMemory","text":"<p>Advanced memory with automatic token management:</p> <pre><code>from marsys.agents.memory import ManagedConversationMemory, ManagedMemoryConfig\n\nconfig = ManagedMemoryConfig(\n    threshold_tokens=150000,  # When to trigger compaction\n    image_token_estimate=800\n)\n# Derived: compaction_target_tokens = threshold_tokens * (1 - min_reduction_ratio)\n\nmemory = ManagedConversationMemory(config=config)\n\n# Usage is identical to ConversationMemory\nmemory.add(role=\"user\", content=\"Hello\")\nmessages = memory.get_messages()  # Returns curated context within token budget\n</code></pre>"},{"location":"concepts/memory/#active-context-compaction-acm","title":"Active Context Compaction (ACM)","text":"<p>Managed memory uses an active-context policy (<code>active_context</code>) to decide how and when to reduce context:</p> <ul> <li><code>mode=\"compaction\"</code>: run processor pipeline and rewrite memory</li> <li><code>mode=\"sliding_window\"</code>: return recent context window without rewriting raw history</li> <li><code>processor_order</code> (default): <code>[\"tool_truncation\", \"summarization\", \"backward_packing\"]</code></li> <li><code>excluded_processors</code>: skip specific processors by name</li> <li><code>min_reduction_ratio</code>: minimum estimated savings ratio to run non-final processors</li> </ul> <pre><code>from marsys.agents.memory import (\n    ActiveContextPolicyConfig,\n    ManagedMemoryConfig,\n    SummarizationConfig,\n    ToolTruncationConfig,\n)\n\nmemory_config = ManagedMemoryConfig(\n    threshold_tokens=120_000,\n    active_context=ActiveContextPolicyConfig(\n        mode=\"compaction\",\n        processor_order=[\"tool_truncation\", \"summarization\", \"backward_packing\"],\n        excluded_processors=[],\n        min_reduction_ratio=0.4,\n        tool_truncation=ToolTruncationConfig(max_tool_message_tokens=1200),\n        summarization=SummarizationConfig(output_max_tokens=6000),\n    ),\n)\n</code></pre> <p>The compaction target is derived automatically: <code>compaction_target_tokens = threshold_tokens * (1 - min_reduction_ratio)</code>.</p>"},{"location":"concepts/memory/#optional-separate-compaction-model","title":"Optional Separate Compaction Model","text":"<p>You can keep your main model for task execution and use a cheaper/faster model for memory compaction:</p> <pre><code>from marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\nagent = Agent(\n    model_config=ModelConfig(type=\"api\", provider=\"openrouter\", name=\"anthropic/claude-opus-4.6\"),\n    compaction_model_config=ModelConfig(\n        type=\"api\",\n        provider=\"openrouter\",\n        name=\"anthropic/claude-haiku-4.5\",\n    ),\n    goal=\"Research and synthesis\",\n    instruction=\"You are a research agent.\",\n)\n</code></pre>"},{"location":"concepts/memory/#kgmemory","title":"KGMemory","text":"<p>Knowledge graph memory that extracts facts from text:</p> <pre><code>from marsys.agents.memory import KGMemory\n\n# Requires a model for fact extraction\nmemory = KGMemory(model=your_model, description=\"Initial context\")\n\n# Add facts directly\nmemory.add_fact(role=\"user\", subject=\"Paris\", predicate=\"is capital of\", obj=\"France\")\n\n# Or add text and extract facts automatically\nmemory.add(role=\"user\", content=\"The Eiffel Tower is in Paris.\")\n# Facts are extracted asynchronously using the model\n</code></pre>"},{"location":"concepts/memory/#memorymanager","title":"MemoryManager","text":"<p>Factory class that creates the appropriate memory type:</p> <pre><code>from marsys.agents.memory import MemoryManager\n\n# Create ConversationMemory\nmanager = MemoryManager(\n    memory_type=\"conversation_history\",\n    description=\"System prompt\"\n)\n\n# Create ManagedConversationMemory\nmanager = MemoryManager(\n    memory_type=\"managed_conversation\",\n    description=\"System prompt\",\n    memory_config=ManagedMemoryConfig(...)\n)\n\n# Create KGMemory\nmanager = MemoryManager(\n    memory_type=\"kg\",\n    description=\"System prompt\",\n    model=your_model  # Required for KG\n)\n\n# Use like the underlying memory type\nmanager.add(role=\"user\", content=\"Hello\")\nmessages = manager.get_messages()\n\n# Save/load for persistence (can include additional state)\nmanager.save_to_file(\"memory.json\", additional_state={\"planning\": {...}})\nadditional_state = manager.load_from_file(\"memory.json\")\n</code></pre>"},{"location":"concepts/memory/#memory-events","title":"Memory Events","text":"<p>When memory is cleared via <code>reset_memory()</code>, MARSYS emits <code>MemoryResetEvent</code>. Managed compaction can also emit <code>CompactionEvent</code> (<code>started</code>, <code>completed</code>, <code>failed</code>) for status channels.</p> <pre><code>from marsys.coordination.event_bus import EventBus\n\nbus = EventBus()\nmanager.set_event_context(agent_name=\"Researcher\", event_bus=bus, session_id=\"run_123\")\n</code></pre> <p>When agents run through <code>Orchestra</code>/<code>auto_run()</code>, this context is wired automatically.</p>"},{"location":"concepts/memory/#message-addition-examples","title":"Message Addition Examples","text":"<pre><code>from marsys.agents.memory import ConversationMemory\n\nmemory = ConversationMemory()\n\n# User input\nmemory.add(role=\"user\", content=\"Analyze the quarterly sales data\")\n\n# Agent response\nmemory.add(role=\"assistant\", content=\"I'll analyze the data for you.\")\n\n# Tool call (assistant requesting a tool)\nmemory.add(\n    role=\"assistant\",\n    content=None,\n    tool_calls=[{\n        \"id\": \"call_123\",\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"analyze_sales\",\n            \"arguments\": '{\"quarter\": \"Q4\"}'\n        }\n    }]\n)\n\n# Tool result\nmemory.add(\n    role=\"tool\",\n    content='{\"total_sales\": 1500000, \"growth\": \"15%\"}',\n    tool_call_id=\"call_123\",\n    name=\"analyze_sales\"\n)\n</code></pre>"},{"location":"concepts/memory/#best-practices","title":"Best Practices","text":""},{"location":"concepts/memory/#1-use-correct-methods","title":"1. Use Correct Methods","text":"<pre><code># CORRECT\nmemory.add(role=\"user\", content=\"Hello\")\nmessages = memory.retrieve_all()\nmemory.reset_memory()\n\n# WRONG - these methods don't exist\n# memory.add_message(...)\n# memory.get_recent(...)\n# memory.clear()\n</code></pre>"},{"location":"concepts/memory/#2-handle-tool-results-properly","title":"2. Handle Tool Results Properly","text":"<pre><code># CORRECT - Link tool result to tool call\nmemory.add(\n    role=\"tool\",\n    content=result,\n    tool_call_id=\"call_123\",\n    name=\"tool_name\"\n)\n\n# WRONG - No association\nmemory.add(role=\"tool\", content=result)\n</code></pre>"},{"location":"concepts/memory/#3-use-managedconversationmemory-for-long-conversations","title":"3. Use ManagedConversationMemory for Long Conversations","text":"<p>For conversations that may exceed token limits:</p> <pre><code>from marsys.agents.memory import MemoryManager, ManagedMemoryConfig\n\nmanager = MemoryManager(\n    memory_type=\"managed_conversation\",\n    memory_config=ManagedMemoryConfig(\n        threshold_tokens=100000\n    )\n)\n</code></pre>"},{"location":"concepts/memory/#next-steps","title":"Next Steps","text":"<ul> <li> <p> Messages</p> <p>Understand message types and formats</p> </li> <li> <p> Agents</p> <p>How agents use memory systems</p> </li> <li> <p> Tools</p> <p>Tool results in memory</p> </li> </ul> <p>Memory System</p> <p>MARSYS provides ConversationMemory for basic needs, ManagedConversationMemory for automatic token management, and KGMemory for knowledge graphs.</p>"},{"location":"concepts/messages/","title":"Messages","text":"<p>Messages are the fundamental communication units that enable agents, models, and tools to exchange information in a structured format.</p>"},{"location":"concepts/messages/#overview","title":"\ud83c\udfaf Overview","text":"<p>Messages in MARSYS:</p> <ul> <li>Follow OpenAI Format: Compatible with standard LLM APIs</li> <li>Support Multi-Agent: Extended for agent-to-agent communication</li> <li>Handle Tools: Built-in support for function calling</li> <li>Track Context: Maintain conversation history and metadata</li> <li>Enable Traceability: Unique IDs for debugging and tracking</li> </ul>"},{"location":"concepts/messages/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<pre><code>graph TB\n    subgraph \"Message Types\"\n        SM[System Messages&lt;br/&gt;Instructions]\n        UM[User Messages&lt;br/&gt;Human Input]\n        AM[Assistant Messages&lt;br/&gt;AI Responses]\n        TM[Tool Messages&lt;br/&gt;Function Results]\n        ACM[Agent Call Messages&lt;br/&gt;Inter-agent]\n        ARM[Agent Response&lt;br/&gt;Agent Results]\n        EM[Error Messages&lt;br/&gt;Failures]\n    end\n\n    subgraph \"Message Flow\"\n        User[User] --&gt; Agent1[Agent]\n        Agent1 --&gt; Model[LLM/VLM]\n        Model --&gt; Tools[Tools]\n        Tools --&gt; Model\n        Agent1 --&gt; Agent2[Other Agent]\n        Agent2 --&gt; Agent1\n    end\n\n    subgraph \"Message Components\"\n        Role[Role]\n        Content[Content]\n        ID[Message ID]\n        Meta[Metadata]\n        TC[Tool Calls]\n        Images[Images]\n    end\n\n    style SM fill:#e1f5fe\n    style UM fill:#4fc3f7\n    style AM fill:#29b6f6</code></pre>"},{"location":"concepts/messages/#message-structure","title":"\ud83d\udce6 Message Structure","text":""},{"location":"concepts/messages/#core-message-class","title":"Core Message Class","text":"<pre><code>from dataclasses import dataclass, field\nfrom typing import Optional, Union, Dict, List, Any\nfrom datetime import datetime\nimport uuid\n\n@dataclass\nclass Message:\n    # Core fields\n    role: str                                      # Message role/type\n    content: Optional[Union[str, Dict, List]]      # Main content\n    message_id: str = field(default_factory=lambda: str(uuid.uuid4()))\n\n    # Extended fields\n    name: Optional[str] = None                     # Tool/agent name\n    tool_calls: Optional[List[ToolCallMsg]] = None # Tool invocations\n    tool_call_id: Optional[str] = None            # For tool responses\n    agent_calls: Optional[List[AgentCallMsg]] = None  # Agent invocations\n\n    # Additional data\n    structured_data: Optional[Dict] = None         # Structured responses\n    images: Optional[List[str]] = None            # For vision models\n    reasoning_details: Optional[List[Dict]] = None # Model thinking/reasoning traces\n\n    # Methods\n    def to_llm_dict(self) -&gt; Dict[str, Any]\n</code></pre>"},{"location":"concepts/messages/#message-roles","title":"Message Roles","text":"Role Description Usage <code>system</code> System instructions Initial agent configuration <code>user</code> User input Human queries, requests <code>assistant</code> AI response Model/agent responses <code>tool</code> Tool result Function execution results <code>agent_call</code> Agent invocation One agent calling another <code>agent_response</code> Agent reply Response from invoked agent <code>error</code> Error message Failures and exceptions"},{"location":"concepts/messages/#creating-messages","title":"\ud83c\udfaf Creating Messages","text":""},{"location":"concepts/messages/#basic-messages","title":"Basic Messages","text":"<pre><code>from marsys.agents.memory import Message\n\n# User message\nuser_msg = Message(\n    role=\"user\",\n    content=\"Analyze the quarterly sales data\"\n)\n\n# System message\nsystem_msg = Message(\n    role=\"system\",\n    content=\"You are a data analyst specializing in sales trends.\"\n)\n\n# Assistant response\nassistant_msg = Message(\n    role=\"assistant\",\n    content=\"I'll analyze the quarterly sales data for you.\",\n    name=\"DataAnalyst\"\n)\n\n# Error message\nerror_msg = Message(\n    role=\"error\",\n    content=\"Failed to connect to database\",\n    structured_data={\n        \"error_type\": \"ConnectionError\",\n        \"retry_count\": 3\n    }\n)\n</code></pre>"},{"location":"concepts/messages/#tool-messages","title":"Tool Messages","text":"<pre><code># Tool call message\ntool_call_msg = Message(\n    role=\"assistant\",\n    content=\"\",  # Can be empty when calling tools\n    tool_calls=[\n        ToolCallMsg(\n            id=\"call_abc123\",\n            call_id=\"call_abc123\",\n            type=\"function\",\n            name=\"analyze_data\",\n            arguments='{\"dataset\": \"sales_q4\", \"metrics\": [\"revenue\", \"growth\"]}'\n        )\n    ]\n)\n\n# Tool response\ntool_response = Message(\n    role=\"tool\",\n    content='{\"revenue\": 1500000, \"growth\": \"15%\", \"trend\": \"positive\"}',\n    name=\"analyze_data\",\n    tool_call_id=\"call_abc123\"\n)\n</code></pre>"},{"location":"concepts/messages/#multi-agent-messages","title":"Multi-Agent Messages","text":"<pre><code># Agent A calling Agent B\nagent_call = Message(\n    role=\"agent_call\",\n    content=\"Research the latest AI trends for 2025\",\n    name=\"Researcher\",\n    agent_calls=[\n        AgentCallMsg(\n            agent_name=\"Researcher\",\n            request=\"Research the latest AI trends for 2025\"\n        )\n    ]\n)\n\n# Agent B's response\nagent_response = Message(\n    role=\"agent_response\",\n    content=\"Here are the top AI trends for 2025:\\n1. Multimodal AI...\",\n    name=\"Researcher\",\n    structured_data={\n        \"trends\": [\n            {\"name\": \"Multimodal AI\", \"impact\": \"high\"},\n            {\"name\": \"Edge AI\", \"impact\": \"medium\"}\n        ],\n        \"sources\": [\"arxiv.org\", \"nature.com\"]\n    }\n)\n</code></pre>"},{"location":"concepts/messages/#multimodal-messages","title":"Multimodal Messages","text":"<p>MARSYS supports multimodal messages with images for vision models like GPT-4V, Gemini, and Claude.</p>"},{"location":"concepts/messages/#user-messages-with-images","title":"User Messages with Images","text":"<pre><code># Message with images (for vision models)\nvision_msg = Message(\n    role=\"user\",\n    content=\"What objects are in these images?\",\n    images=[\n        \"base64_encoded_image_1\",\n        \"https://example.com/image.jpg\",\n        \"/path/to/local/image.png\"\n    ]\n)\n\n# Mixed content message\nmixed_msg = Message(\n    role=\"user\",\n    content=[\n        {\"type\": \"text\", \"text\": \"Analyze this chart:\"},\n        {\"type\": \"image_url\", \"image_url\": {\"url\": \"data:image/png;base64,...\"}}\n    ]\n)\n</code></pre>"},{"location":"concepts/messages/#tool-results-with-images","title":"Tool Results with Images","text":"<p>Tools can return images alongside text results. The framework automatically handles image injection into agent memory:</p> <pre><code># Tool that extracts images from a PDF\ndef extract_pdf_content(pdf_path: str) -&gt; Dict[str, Any]:\n    \"\"\"\n    Extract text and images from a PDF file.\n\n    Returns:\n        Dictionary with 'result' (text) and 'images' (list of paths)\n    \"\"\"\n    text = extract_text(pdf_path)\n    image_paths = extract_images_to_temp(pdf_path)\n\n    return {\n        \"result\": f\"Extracted {len(image_paths)} pages from PDF\",\n        \"images\": image_paths  # List of file paths\n    }\n\n# The tool result message created automatically:\ntool_result_msg = Message(\n    role=\"tool\",\n    content=\"Extracted 3 pages from PDF\",\n    name=\"extract_pdf_content\",\n    tool_call_id=\"call_123\",\n    images=[\n        \"./outputs/pdf_page_1.png\",\n        \"./outputs/pdf_page_2.png\",\n        \"./outputs/pdf_page_3.png\"\n    ]\n)\n</code></pre> <p>Use virtual paths from the run filesystem (e.g., <code>./outputs</code>, <code>./downloads</code>, <code>./screenshots</code>) so other agents can access the same files. See Run Filesystem.</p>"},{"location":"concepts/messages/#task-descriptions-with-images","title":"Task Descriptions with Images","text":"<p>You can include images directly in task descriptions:</p> <pre><code># Task with images\ntask = {\n    \"content\": \"What is shown in these screenshots? Provide a detailed analysis.\",\n    \"images\": [\n        \"/path/to/screenshot1.png\",\n        \"/path/to/screenshot2.png\"\n    ]\n}\n\n# Images are automatically added to the first agent's memory\nresult = await Orchestra.run(task=task, topology=topology)\n</code></pre>"},{"location":"concepts/messages/#message-conversion","title":"\ud83d\udd04 Message Conversion","text":""},{"location":"concepts/messages/#to-llm-format","title":"To LLM Format","text":"<pre><code># Convert for OpenAI-compatible APIs\nmessage = Message(\n    role=\"assistant\",\n    content=\"I found the information you requested.\",\n    tool_calls=[...]\n)\n\nllm_dict = message.to_llm_dict()\n# Result:\n{\n    \"role\": \"assistant\",\n    \"content\": \"I found the information you requested.\",\n    \"tool_calls\": [...]\n}\n\n# Special conversions\nagent_call_msg = Message(role=\"agent_call\", content=\"Task\", name=\"Agent2\")\nllm_dict = agent_call_msg.to_llm_dict()\n# Converts to user message for LLM:\n{\n    \"role\": \"user\",\n    \"content\": \"[Request from Agent1]: Task\"\n}\n</code></pre>"},{"location":"concepts/messages/#from-llm-response","title":"From LLM Response","text":"<pre><code># Parse LLM response into Message\nllm_response = {\n    \"role\": \"assistant\",\n    \"content\": \"Here's the analysis:\",\n    \"tool_calls\": [{\n        \"id\": \"call_123\",\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"create_chart\",\n            \"arguments\": '{\"data\": [1,2,3]}'\n        }\n    }]\n}\n\nmessage = Message.from_llm_response(llm_response)\n# Automatically parses tool calls, content, etc.\n</code></pre>"},{"location":"concepts/messages/#message-patterns","title":"\ud83c\udfaf Message Patterns","text":""},{"location":"concepts/messages/#conversation-pattern","title":"Conversation Pattern","text":"<pre><code># Standard conversation flow\nconversation = [\n    Message(role=\"system\", content=\"You are a helpful assistant.\"),\n    Message(role=\"user\", content=\"What's the capital of France?\"),\n    Message(role=\"assistant\", content=\"The capital of France is Paris.\"),\n    Message(role=\"user\", content=\"What about Germany?\"),\n    Message(role=\"assistant\", content=\"The capital of Germany is Berlin.\")\n]\n\n# Convert for LLM\nllm_messages = [msg.to_llm_dict() for msg in conversation]\n</code></pre>"},{"location":"concepts/messages/#tool-usage-pattern","title":"Tool Usage Pattern","text":"<pre><code># Complete tool usage flow\ntool_flow = [\n    # 1. User request\n    Message(role=\"user\", content=\"What's the weather in Tokyo?\"),\n\n    # 2. Assistant decides to use tool\n    Message(\n        role=\"assistant\",\n        content=\"I'll check the weather in Tokyo for you.\",\n        tool_calls=[ToolCallMsg(\n            id=\"call_weather_1\",\n            call_id=\"call_weather_1\",\n            type=\"function\",\n            name=\"get_weather\",\n            arguments='{\"city\": \"Tokyo\", \"units\": \"celsius\"}'\n        )]\n    ),\n\n    # 3. Tool returns result\n    Message(\n        role=\"tool\",\n        content='{\"temp\": 22, \"conditions\": \"sunny\", \"humidity\": 65}',\n        name=\"get_weather\",\n        tool_call_id=\"call_weather_1\"\n    ),\n\n    # 4. Assistant incorporates result\n    Message(\n        role=\"assistant\",\n        content=\"The weather in Tokyo is currently 22\u00b0C and sunny with 65% humidity.\"\n    )\n]\n</code></pre>"},{"location":"concepts/messages/#error-handling-pattern","title":"Error Handling Pattern","text":"<pre><code>def handle_with_error_message(func):\n    \"\"\"Decorator to convert exceptions to Messages.\"\"\"\n    async def wrapper(*args, **kwargs):\n        try:\n            return await func(*args, **kwargs)\n        except Exception as e:\n            return Message(\n                role=\"error\",\n                content=str(e),\n                metadata={\n                    \"error_type\": type(e).__name__,\n                    \"traceback\": traceback.format_exc(),\n                    \"function\": func.__name__,\n                    \"timestamp\": datetime.now().isoformat()\n                }\n            )\n    return wrapper\n\n@handle_with_error_message\nasync def risky_operation():\n    # Operation that might fail\n    pass\n</code></pre>"},{"location":"concepts/messages/#multi-agent-communication-pattern","title":"Multi-Agent Communication Pattern","text":"<pre><code># Agent coordination flow\ncoordination_flow = [\n    # 1. Coordinator assigns task\n    Message(\n        role=\"agent_call\",\n        content=\"Analyze market data for Q4\",\n        name=\"DataAnalyst\",\n        agent_calls=[AgentCallMsg(\n            agent_name=\"DataAnalyst\",\n            request=\"Analyze market data for Q4\",\n            context={\"priority\": \"high\"}\n        )]\n    ),\n\n    # 2. DataAnalyst processes\n    Message(\n        role=\"agent_response\",\n        content=\"Analysis complete. Key findings:\",\n        name=\"DataAnalyst\",\n        structured_data={\n            \"revenue\": 2500000,\n            \"growth\": \"18%\",\n            \"top_products\": [\"A\", \"B\", \"C\"]\n        }\n    ),\n\n    # 3. Coordinator requests visualization\n    Message(\n        role=\"agent_call\",\n        content=\"Create charts for this data\",\n        name=\"Visualizer\",\n        structured_data={\"data\": {...}}\n    ),\n\n    # 4. Visualizer responds\n    Message(\n        role=\"agent_response\",\n        content=\"Charts created successfully\",\n        name=\"Visualizer\",\n        images=[\"chart1.png\", \"chart2.png\"]\n    )\n]\n</code></pre>"},{"location":"concepts/messages/#best-practices","title":"\ud83d\udccb Best Practices","text":""},{"location":"concepts/messages/#1-preserve-message-ids","title":"1. Preserve Message IDs","text":"<pre><code># \u2705 GOOD - Maintain IDs for tracking\noriginal_msg = Message(role=\"user\", content=\"Hello\")\nprint(f\"Tracking ID: {original_msg.message_id}\")\n\n# When forwarding or referencing\nresponse = Message(\n    role=\"assistant\",\n    content=\"Hello! How can I help?\",\n    metadata={\"in_reply_to\": original_msg.message_id}\n)\n\n# \u274c BAD - Creating new ID for same message\nforwarded = Message(\n    role=original_msg.role,\n    content=original_msg.content\n    # Lost original message_id!\n)\n</code></pre>"},{"location":"concepts/messages/#2-use-appropriate-roles","title":"2. Use Appropriate Roles","text":"<pre><code># \u2705 GOOD - Correct role usage\ntool_result = Message(\n    role=\"tool\",  # Correct role for tool results\n    content=json.dumps(result),\n    name=\"calculator\",\n    tool_call_id=\"call_123\"\n)\n\n# \u274c BAD - Wrong role\ntool_result = Message(\n    role=\"assistant\",  # Wrong! Tools aren't assistants\n    content=str(result)\n)\n</code></pre>"},{"location":"concepts/messages/#3-structure-tool-responses","title":"3. Structure Tool Responses","text":"<pre><code># \u2705 GOOD - Structured tool response\ntool_response = Message(\n    role=\"tool\",\n    content=json.dumps({\n        \"success\": True,\n        \"result\": calculation_result,\n        \"metadata\": {\"precision\": \"high\", \"method\": \"numpy\"}\n    }),\n    name=\"advanced_calculator\",\n    tool_call_id=call_id\n)\n\n# \u274c BAD - Unstructured response\ntool_response = Message(\n    role=\"tool\",\n    content=f\"The answer is {result}\"  # Not JSON!\n)\n</code></pre>"},{"location":"concepts/messages/#4-handle-errors-gracefully","title":"4. Handle Errors Gracefully","text":"<pre><code># \u2705 GOOD - Error as message\ntry:\n    result = await process_data()\nexcept DataError as e:\n    return Message(\n        role=\"error\",\n        content=f\"Data processing failed: {e}\",\n        metadata={\n            \"error_code\": \"DATA_001\",\n            \"recoverable\": True,\n            \"suggestion\": \"Check data format\"\n        }\n    )\n\n# \u274c BAD - Raw exception\ntry:\n    result = await process_data()\nexcept DataError as e:\n    raise  # Don't propagate raw exceptions\n</code></pre>"},{"location":"concepts/messages/#advanced-patterns","title":"\ud83c\udfaf Advanced Patterns","text":""},{"location":"concepts/messages/#message-validation","title":"Message Validation","text":"<pre><code>from typing import Set\nfrom pydantic import BaseModel, validator\n\nclass ValidatedMessage(BaseModel):\n    role: str\n    content: Optional[str] = None\n    tool_calls: Optional[List[Dict]] = None\n\n    @validator('role')\n    def validate_role(cls, v):\n        valid_roles = {'system', 'user', 'assistant', 'tool', 'error'}\n        if v not in valid_roles:\n            raise ValueError(f\"Invalid role: {v}\")\n        return v\n\n    @validator('tool_calls')\n    def validate_tool_calls(cls, v):\n        if v:\n            for call in v:\n                if 'id' not in call or 'function' not in call:\n                    raise ValueError(\"Invalid tool call format\")\n        return v\n</code></pre>"},{"location":"concepts/messages/#message-filtering","title":"Message Filtering","text":"<pre><code>class MessageFilter:\n    @staticmethod\n    def by_role(messages: List[Message], role: str) -&gt; List[Message]:\n        \"\"\"Filter messages by role.\"\"\"\n        return [m for m in messages if m.role == role]\n\n    @staticmethod\n    def by_agent(messages: List[Message], agent_name: str) -&gt; List[Message]:\n        \"\"\"Filter messages by agent name.\"\"\"\n        return [m for m in messages if m.name == agent_name]\n\n    @staticmethod\n    def recent(messages: List[Message], minutes: int = 5) -&gt; List[Message]:\n        \"\"\"Get messages from last N minutes.\"\"\"\n        cutoff = datetime.now() - timedelta(minutes=minutes)\n        return [m for m in messages if m.timestamp &gt; cutoff]\n\n    @staticmethod\n    def with_tools(messages: List[Message]) -&gt; List[Message]:\n        \"\"\"Get messages with tool calls.\"\"\"\n        return [m for m in messages if m.tool_calls]\n</code></pre>"},{"location":"concepts/messages/#message-chaining","title":"Message Chaining","text":"<pre><code>class MessageChain:\n    \"\"\"Track related messages in a conversation chain.\"\"\"\n\n    def __init__(self, initial: Message):\n        self.chain_id = str(uuid.uuid4())\n        self.messages: List[Message] = [initial]\n        initial.metadata[\"chain_id\"] = self.chain_id\n\n    def add(self, message: Message) -&gt; None:\n        \"\"\"Add message to chain.\"\"\"\n        message.metadata[\"chain_id\"] = self.chain_id\n        message.metadata[\"chain_position\"] = len(self.messages)\n        self.messages.append(message)\n\n    def get_context(self, max_messages: int = 10) -&gt; List[Message]:\n        \"\"\"Get recent context from chain.\"\"\"\n        return self.messages[-max_messages:]\n\n    def summarize(self) -&gt; Dict[str, Any]:\n        \"\"\"Get chain summary.\"\"\"\n        return {\n            \"chain_id\": self.chain_id,\n            \"message_count\": len(self.messages),\n            \"roles\": list(set(m.role for m in self.messages)),\n            \"has_errors\": any(m.role == \"error\" for m in self.messages),\n            \"tool_calls\": sum(1 for m in self.messages if m.tool_calls)\n        }\n</code></pre>"},{"location":"concepts/messages/#next-steps","title":"\ud83d\udea6 Next Steps","text":"<ul> <li> <p> Memory</p> <p>How messages are stored and managed</p> </li> <li> <p> Agents</p> <p>How agents create and process messages</p> </li> <li> <p> Communication</p> <p>Multi-agent message patterns</p> </li> <li> <p> Message API Reference</p> <p>Complete API documentation</p> </li> </ul> <p>Message System Ready!</p> <p>You now understand the message system in MARSYS. Messages are the lingua franca that enables all components to communicate effectively.</p>"},{"location":"concepts/models/","title":"Models","text":"<p>Models are the AI backends that power agent intelligence, providing a unified interface for different providers and model types.</p> <p>See Also</p> <p>For ModelConfig class definition and provider-specific parameters, see Models API Reference.</p>"},{"location":"concepts/models/#overview","title":"\ud83c\udfaf Overview","text":"<p>MARSYS provides a flexible model abstraction layer that:</p> <ul> <li>Unifies Providers: Single interface for OpenAI, Anthropic, Google, and more</li> <li>Supports Multiple Types: LLMs, VLMs, custom APIs, and local models</li> <li>Handles Complexity: Automatic retry, error handling, and response formatting</li> <li>Enables Tool Calling: OpenAI-compatible function calling across providers</li> <li>Manages Configuration: Centralized settings with environment variable support</li> </ul>"},{"location":"concepts/models/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<pre><code>graph TB\n    subgraph \"Model Types\"\n        LLM[Language Models&lt;br/&gt;Text Generation]\n        VLM[Vision-Language&lt;br/&gt;Multimodal]\n        API[API Models&lt;br/&gt;Custom Endpoints]\n        LOCAL[Local Models&lt;br/&gt;Self-hosted]\n    end\n\n    subgraph \"Providers\"\n        OAI[OpenAI&lt;br/&gt;GPT-4, GPT-3.5]\n        ANT[Anthropic&lt;br/&gt;Claude 3]\n        GOO[Google&lt;br/&gt;Gemini]\n        XAI[xAI&lt;br/&gt;Grok Models]\n        LOC[Local&lt;br/&gt;Llama, Mistral]\n    end\n\n    subgraph \"Features\"\n        TC[Tool Calling&lt;br/&gt;Function Execution]\n        JM[JSON Mode&lt;br/&gt;Structured Output]\n        RT[Auto Retry&lt;br/&gt;Error Recovery]\n        CV[Context&lt;br/&gt;Management]\n    end\n\n    Agent[Agent] --&gt; MA[Model Abstraction]\n    MA --&gt; LLM\n    MA --&gt; VLM\n    MA --&gt; API\n\n    LLM --&gt; OAI\n    LLM --&gt; ANT\n    LLM --&gt; GOO\n    VLM --&gt; OAI\n    API --&gt; Custom[Custom APIs]\n\n    style MA fill:#4fc3f7\n    style LLM fill:#29b6f6\n    style VLM fill:#29b6f6</code></pre>"},{"location":"concepts/models/#model-configuration","title":"\ud83d\udce6 Model Configuration","text":""},{"location":"concepts/models/#modelconfig","title":"ModelConfig","text":"<p>Central configuration for all models:</p> <pre><code>from marsys.models import ModelConfig\nfrom typing import Literal, Optional, Dict, Any\n\nclass ModelConfig(BaseModel):\n    # Core settings\n    type: Literal[\"api\", \"local\"]           # Model type\n    name: str                               # Model identifier\n    provider: Optional[str] = None          # openai, anthropic, google, xai, openrouter, openai-oauth, anthropic-oauth\n\n    # API settings\n    api_key: Optional[str] = None           # Auto-loaded from env if None\n    base_url: Optional[str] = None          # Custom endpoint\n    oauth_profile: Optional[str] = None     # Optional OAuth profile for openai-oauth / anthropic-oauth\n\n    # Generation parameters\n    max_tokens: int = 8192                  # Maximum output tokens\n    temperature: float = 0.7                # Sampling temperature (0.0-2.0)\n    thinking_budget: Optional[int] = 1024   # Token budget for thinking (Gemini, Claude, Qwen)\n    reasoning_effort: Optional[str] = \"low\" # Reasoning level for OpenAI/Grok (minimal, low, medium, high)\n\n    # Local model settings\n    model_class: Optional[Literal[\"llm\", \"vlm\"]] = None\n    torch_dtype: Optional[str] = \"auto\"     # PyTorch dtype (bfloat16, float16, auto)\n    device_map: Optional[str] = \"auto\"      # Device map (auto, cuda:0)\n    quantization_config: Optional[Dict] = None\n</code></pre>"},{"location":"concepts/models/#provider-configurations","title":"Provider Configurations","text":"<pre><code># OpenRouter (Recommended - unified access to all models)\nopenrouter_config = ModelConfig(\n    type=\"api\",\n    provider=\"openrouter\",\n    name=\"anthropic/claude-opus-4.6\",\n    temperature=0.7,\n    max_tokens=12000,\n    # api_key loaded from OPENROUTER_API_KEY env var\n)\n\n# OpenAI GPT-5 Codex\ngpt5_config = ModelConfig(\n    type=\"api\",\n    provider=\"openrouter\",\n    name=\"openai/gpt-5-codex\",\n    temperature=0.7,\n    max_tokens=12000,\n    # api_key loaded from OPENROUTER_API_KEY env var\n)\n\n# Anthropic Claude Opus 4.6\nclaude_opus_config = ModelConfig(\n    type=\"api\",\n    provider=\"openrouter\",\n    name=\"anthropic/claude-opus-4.6\",\n    temperature=0.5,\n    max_tokens=12000,\n    # api_key loaded from OPENROUTER_API_KEY env var\n)\n\n# Google Gemini 3 Pro Preview\ngemini_config = ModelConfig(\n    type=\"api\",\n    provider=\"openrouter\",\n    name=\"google/gemini-3-pro-preview\",\n    temperature=0.8,\n    max_tokens=12000,\n    # api_key loaded from OPENROUTER_API_KEY env var\n)\n\n# Local Model - HuggingFace Backend (Development/Research)\nlocal_hf_config = ModelConfig(\n    type=\"local\",\n    model_class=\"llm\",\n    name=\"Qwen/Qwen3-4B-Instruct-2507\",\n    backend=\"huggingface\",  # Default backend (can be omitted)\n    torch_dtype=\"bfloat16\",\n    device_map=\"auto\",\n    max_tokens=4096\n)\n\n# Local Model - vLLM Backend (Production/High-Throughput)\nlocal_vllm_config = ModelConfig(\n    type=\"local\",\n    model_class=\"vlm\",\n    name=\"Qwen/Qwen3-VL-8B-Instruct\",\n    backend=\"vllm\",  # High-throughput production backend\n    tensor_parallel_size=2,  # Multi-GPU inference\n    gpu_memory_utilization=0.9,\n    quantization=\"fp8\",  # Optional: awq, gptq, fp8\n    max_tokens=4096\n)\n</code></pre>"},{"location":"concepts/models/#oauth-providers-no-api-keys","title":"OAuth Providers (No API Keys)","text":"<p>MARSYS also supports OAuth-backed providers that use CLI logins instead of API keys:</p> <ul> <li><code>openai-oauth</code>: ChatGPT subscription via Codex CLI (<code>codex login</code>)</li> <li><code>anthropic-oauth</code>: Claude Max subscription via Claude CLI (<code>claude login</code>)</li> </ul> <p>Supported model families:</p> <ul> <li>OpenAI OAuth: <code>gpt-5.3-codex</code></li> <li>Anthropic OAuth: <code>claude-opus-4-6</code> (aliases like <code>opus</code> also work)</li> </ul> <p>Credentials are read from local CLI files and can be overridden with environment variables:</p> <ul> <li>OpenAI OAuth: <code>~/.codex/auth.json</code> (override with <code>CODEX_AUTH_PATH</code>)</li> <li>Anthropic OAuth: <code>~/.claude/.credentials.json</code> (override with <code>CLAUDE_AUTH_PATH</code>)</li> </ul> <p>Profile resolution order: 1. Explicit <code>credentials_path</code> 2. <code>oauth_profile</code> 3. Provider default profile (<code>marsys oauth set-default ...</code>)</p> <pre><code># OpenAI ChatGPT (OAuth via Codex CLI)\nopenai_oauth_config = ModelConfig(\n    type=\"api\",\n    provider=\"openai-oauth\",\n    name=\"gpt-5.3-codex\",\n    # Optional override:\n    # credentials_path=\"~/.codex/auth.json\"\n)\n\n# Anthropic Claude Max (OAuth via Claude CLI)\nanthropic_oauth_config = ModelConfig(\n    type=\"api\",\n    provider=\"anthropic-oauth\",\n    name=\"claude-opus-4-6\",\n    # Optional override:\n    # credentials_path=\"~/.claude/.credentials.json\"\n)\n</code></pre> <p>OAuth-Specific Behavior</p> <ul> <li>OAuth providers do not require API keys.</li> <li>Anthropic OAuth reserves certain tool names (e.g., <code>read</code>, <code>write</code>, <code>bash</code>). MARSYS transparently transforms these for compatibility.</li> </ul> <p>Use At Your Own Risk (Anthropic OAuth)</p> <p><code>anthropic-oauth</code> relies on a non-official integration path and may violate provider Terms of Service. Use at your own risk.</p> <p>OpenAI OAuth Compliance</p> <p>MARSYS does not make a legal determination about OpenAI ToS coverage for this OAuth path. Review OpenAI terms for your use case.</p>"},{"location":"concepts/models/#model-types","title":"\ud83c\udfaf Model Types","text":""},{"location":"concepts/models/#language-models-llm","title":"Language Models (LLM)","text":"<p>Standard text generation models:</p> <pre><code>from marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\n# Create agent with LLM\nagent = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        provider=\"openrouter\",\n        name=\"anthropic/claude-opus-4.6\",\n        temperature=0.7\n    ),\n    name=\"Assistant\",\n    goal=\"A helpful assistant\",\n    instruction=\"You are a helpful AI assistant that provides clear, accurate responses.\"\n)\n\n# Agent uses model internally\nresponse = await agent.run(\"Explain quantum computing\")\n</code></pre>"},{"location":"concepts/models/#vision-language-models-vlm","title":"Vision-Language Models (VLM)","text":"<p>Multimodal models that process text and images:</p> <pre><code># Configure vision model\nvlm_config = ModelConfig(\n    type=\"api\",\n    provider=\"openrouter\",\n    name=\"google/gemini-3-pro-preview\",\n    max_tokens=12000\n)\n\n# Create vision-capable agent\nvision_agent = Agent(\n    model_config=vlm_config,\n    name=\"ImageAnalyzer\",\n    goal=\"Analyze images and answer questions about visual content\",\n    instruction=\"You are an image analysis specialist. Describe and analyze visual content in detail.\"\n)\n\n# Process image\nfrom marsys.agents.memory import Message\n\nmessage = Message(\n    role=\"user\",\n    content=\"What's in this image?\",\n    images=[\"base64_encoded_image_data\"]  # Or URLs\n)\n\nresponse = await vision_agent.run(message)\n</code></pre>"},{"location":"concepts/models/#browseragent-vision-models","title":"BrowserAgent Vision Models","text":"<p>For browser automation with visual interaction, use separate models for the main agent (planning/decision-making) and vision analysis (screenshot understanding):</p> <pre><code>from marsys.agents import BrowserAgent\nfrom marsys.models import ModelConfig\n\n# Create BrowserAgent with vision capabilities\nbrowser_agent = await BrowserAgent.create_safe(\n    name=\"WebNavigator\",\n    # Main model: Any text-based model for planning and decision-making\n    model_config=ModelConfig(\n        type=\"api\",\n        provider=\"openrouter\",\n        name=\"anthropic/claude-opus-4.6\",\n        temperature=0.3\n    ),\n    mode=\"advanced\",\n    auto_screenshot=True,\n    # Vision model: Use Gemini for screenshot analysis\n    vision_model_config=ModelConfig(\n        type=\"api\",\n        provider=\"openrouter\",\n        name=\"google/gemini-3-flash-preview\",  # Recommended: fast and cost-effective\n        # For complex UI tasks, use: \"google/gemini-3-pro-preview\"\n        temperature=0,\n        thinking_budget=0  # Disable thinking for faster vision responses\n    ),\n    headless=True\n)\n</code></pre> <p>Vision Model Recommendations for BrowserAgent:</p> Task Complexity Recommended Model Characteristics Standard browsing <code>google/gemini-3-flash-preview</code> Fast, cost-effective, handles most UI detection tasks Complex UIs <code>google/gemini-3-pro-preview</code> Higher accuracy for complex layouts, anti-bot challenges <p>Note: While Claude Opus 4.6 and other models work well for the main BrowserAgent planning logic, Gemini models are specifically recommended for the vision component due to superior performance in browser control and UI element detection tasks.</p>"},{"location":"concepts/models/#local-models","title":"Local Models","text":"<p>MARSYS supports running models locally using two backends:</p>"},{"location":"concepts/models/#huggingface-backend-developmentresearch","title":"HuggingFace Backend (Development/Research)","text":"<p>The default backend using HuggingFace transformers. Ideal for development, debugging, and research:</p> <pre><code>from marsys.models import ModelConfig\n\n# Text-only LLM\nllm_config = ModelConfig(\n    type=\"local\",\n    model_class=\"llm\",\n    name=\"Qwen/Qwen3-4B-Instruct-2507\",\n    backend=\"huggingface\",  # Default, can be omitted\n    torch_dtype=\"bfloat16\",\n    device_map=\"auto\",\n    trust_remote_code=True,\n    max_tokens=4096\n)\n\n# Vision-Language Model\nvlm_config = ModelConfig(\n    type=\"local\",\n    model_class=\"vlm\",\n    name=\"Qwen/Qwen3-VL-8B-Instruct\",\n    backend=\"huggingface\",\n    torch_dtype=\"bfloat16\",\n    device_map=\"auto\",\n    thinking_budget=256,  # Token budget for thinking models\n    max_tokens=4096\n)\n</code></pre> <p>Installation: <pre><code>pip install marsys[local-models]\n# or\nuv pip install marsys[local-models]\n</code></pre></p>"},{"location":"concepts/models/#vllm-backend-productionhigh-throughput","title":"vLLM Backend (Production/High-Throughput)","text":"<p>For production deployments with high throughput requirements:</p> <pre><code>from marsys.models import ModelConfig\n\nvlm_config = ModelConfig(\n    type=\"local\",\n    model_class=\"vlm\",\n    name=\"Qwen/Qwen3-VL-8B-Instruct\",\n    backend=\"vllm\",\n    tensor_parallel_size=2,  # Multi-GPU inference\n    gpu_memory_utilization=0.9,\n    quantization=\"fp8\",  # Optional: awq, gptq, fp8\n    max_tokens=4096\n)\n</code></pre> <p>vLLM Features:</p> <ul> <li>Continuous batching for high throughput</li> <li>PagedAttention for memory efficiency</li> <li>FP8/AWQ/GPTQ quantization support</li> <li>Tensor parallelism for multi-GPU inference</li> </ul> <p>Installation: <pre><code>pip install marsys[production]\n# or\nuv pip install marsys[production]\n</code></pre></p>"},{"location":"concepts/models/#backend-comparison","title":"Backend Comparison","text":"Feature HuggingFace vLLM Use Case Development/Research Production Throughput Lower Higher (continuous batching) Memory Efficiency Standard Optimized (PagedAttention) Quantization BitsAndBytes FP8, AWQ, GPTQ Multi-GPU device_map=\"auto\" Tensor parallelism Training Support \u2705 Yes \u274c No Debugging Easier Harder <p>Choosing a Backend</p> <p>Use HuggingFace for development, debugging, and training integration. Use vLLM for production deployments requiring high throughput.</p>"},{"location":"concepts/models/#custom-api-models","title":"Custom API Models","text":"<p>For proprietary or specialized endpoints:</p> <pre><code>from marsys.models import BaseAPIModel\nfrom typing import List, Dict, Any, Optional\n\nclass CustomAPIModel(BaseAPIModel):\n    def __init__(self, api_key: str, endpoint: str):\n        super().__init__(api_key=api_key, base_url=endpoint)\n        self.endpoint = endpoint\n\n    def run(\n        self,\n        messages: List[Dict[str, str]],\n        json_mode: bool = False,\n        max_tokens: Optional[int] = None,\n        temperature: Optional[float] = None,\n        tools: Optional[List[Dict]] = None,\n        **kwargs\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Custom API implementation.\"\"\"\n\n        # Prepare request\n        payload = {\n            \"messages\": messages,\n            \"max_tokens\": max_tokens or 1024,\n            \"temperature\": temperature or 0.7,\n            \"response_format\": {\"type\": \"json\"} if json_mode else None\n        }\n\n        # Make API call\n        response = self._make_request(payload)\n\n        # Format response to standard format\n        return {\n            \"role\": \"assistant\",\n            \"content\": response.get(\"text\", \"\"),\n            \"tool_calls\": response.get(\"functions\", [])\n        }\n\n# Use custom model\ncustom_config = ModelConfig(\n    type=\"api\",\n    name=\"custom-model-v1\",\n    base_url=\"https://api.custom.ai/v1\"\n)\n</code></pre>"},{"location":"concepts/models/#model-features","title":"\ud83d\udd27 Model Features","text":""},{"location":"concepts/models/#tool-calling","title":"Tool Calling","text":"<p>Enable function execution across all providers:</p> <pre><code># Define tools\ndef search_web(query: str) -&gt; str:\n    \"\"\"Search the web for information.\"\"\"\n    return f\"Results for: {query}\"\n\ndef calculate(expression: str) -&gt; float:\n    \"\"\"Evaluate mathematical expression.\"\"\"\n    return eval(expression)  # Simplified example\n\n# Agent with tools\nagent = Agent(\n    model_config=gpt4_config,\n    name=\"ToolUser\",\n    goal=\"Use tools to search and calculate\",\n    instruction=\"You are an agent that uses tools to find information and perform calculations.\",\n    tools={\"search_web\": search_web, \"calculate\": calculate}\n)\n\n# Model automatically handles tool calls\nresponse = await agent.run(\n    \"Search for 'quantum computing' and calculate 2^10\"\n)\n# Agent will:\n# 1. Decide to call search_web(\"quantum computing\")\n# 2. Decide to call calculate(\"2**10\")\n# 3. Incorporate results in response\n</code></pre>"},{"location":"concepts/models/#json-mode","title":"JSON Mode","text":"<p>Use JSON mode when you need JSON output but not strict schema validation:</p> <pre><code>from marsys.models import BaseAPIModel\n\nmodel = BaseAPIModel(\n    provider=\"openrouter\",\n    model_name=\"anthropic/claude-opus-4.6\",\n)\n\nresponse = await model.run(\n    messages=[{\"role\": \"user\", \"content\": \"Return JSON with answer and confidence.\"}],\n    json_mode=True,\n)\n</code></pre>"},{"location":"concepts/models/#structured-output-response_schema","title":"Structured Output (<code>response_schema</code>)","text":"<p>Use <code>response_schema</code> for strict, reliable structured outputs:</p> <pre><code>schema = {\n    \"type\": \"object\",\n    \"properties\": {\n        \"answer\": {\"type\": \"string\"},\n        \"confidence\": {\"type\": \"number\"},\n    },\n    \"required\": [\"answer\", \"confidence\"],\n}\n\nresponse = await model.run(\n    messages=[{\"role\": \"user\", \"content\": \"What is 2+2?\"}],\n    response_schema=schema,\n)\n</code></pre> <p>Provider handling:</p> <ul> <li>OpenAI / OpenRouter / OpenAI OAuth: native JSON schema format</li> <li>Google: native <code>responseSchema</code></li> <li>Anthropic / Anthropic OAuth: native <code>output_config.format</code> JSON schema</li> <li>If both are provided, <code>response_schema</code> takes precedence over <code>json_mode</code></li> </ul> <p>Schema note:</p> <ul> <li>MARSYS enforces <code>additionalProperties: false</code> on object nodes for strict providers (without mutating your original schema object).</li> </ul>"},{"location":"concepts/models/#streaming-responses","title":"Streaming Responses","text":"<p>For real-time output (when supported):</p> <pre><code># Streaming configuration\nstream_config = ModelConfig(\n    type=\"api\",\n    provider=\"openrouter\",\n    name=\"anthropic/claude-opus-4.6\",\n    parameters={\"stream\": True}\n)\n\n# Note: Full streaming support coming soon\n# Currently, responses are collected and returned complete\n</code></pre>"},{"location":"concepts/models/#model-selection-guide","title":"\ud83d\udcca Model Selection Guide","text":""},{"location":"concepts/models/#by-use-case","title":"By Use Case","text":"Use Case Recommended Model Why General Chat Claude Opus 4.6 Strong overall understanding Code Generation GPT-5 Codex Strong coding ability Fast Responses Gemini 3 Flash Preview Low latency, cost-effective Long Context Gemini 3 Pro Preview Broad multimodal context handling Image Analysis Gemini 3 Pro Preview Strong multimodal capabilities Browser Vision Gemini 3 Flash Preview Fast screenshot analysis for BrowserAgent Complex Browser Vision Gemini 3 Pro Preview Advanced UI understanding for BrowserAgent Critical Reasoning GPT-5.3 Codex Advanced reasoning Writing &amp; Analysis Claude Opus 4.6, GPT-5.3 Codex High-quality content generation Local/Private Llama 2, Mistral Data privacy, no API costs"},{"location":"concepts/models/#by-requirements","title":"By Requirements","text":"<pre><code># High accuracy, cost not a concern\npremium_config = ModelConfig(\n    type=\"api\",\n    provider=\"openrouter\",\n    name=\"anthropic/claude-opus-4.6\",\n    temperature=0.3,\n    max_tokens=12000,\n    thinking_budget=4096  # Enable extended thinking for complex reasoning\n)\n\n# Balance of cost and performance\nbalanced_config = ModelConfig(\n    type=\"api\",\n    provider=\"openrouter\",\n    name=\"anthropic/claude-opus-4.6\",\n    temperature=0.5,\n    max_tokens=12000\n)\n\n# Maximum speed\nspeed_config = ModelConfig(\n    type=\"api\",\n    provider=\"openrouter\",\n    name=\"google/gemini-3-flash-preview\",\n    temperature=0.7,\n    max_tokens=12000\n)\n\n# Data privacy with local model\nprivate_config = ModelConfig(\n    type=\"local\",\n    model_class=\"llm\",\n    name=\"Qwen/Qwen3-4B-Instruct-2507\",\n    backend=\"huggingface\",\n    torch_dtype=\"bfloat16\",\n    device_map=\"auto\"\n)\n</code></pre>"},{"location":"concepts/models/#error-handling","title":"\ud83d\udee1\ufe0f Error Handling","text":"<p>Models include comprehensive error handling:</p> <pre><code>from marsys.coordination.config import ErrorHandlingConfig\n\nerror_config = ErrorHandlingConfig(\n    # Automatic retry on rate limits\n    auto_retry_on_rate_limits=True,\n    max_rate_limit_retries=3,\n\n    # Provider-specific settings\n    provider_settings={\n        \"openai\": {\n            \"max_retries\": 3,\n            \"base_retry_delay\": 60,\n            \"insufficient_quota_action\": \"fallback\"\n        },\n        \"anthropic\": {\n            \"max_retries\": 2,\n            \"base_retry_delay\": 30,\n            \"insufficient_quota_action\": \"raise\"\n        }\n    }\n)\n\n# Error types handled:\n# - RateLimitError: Automatic backoff and retry\n# - AuthenticationError: Clear error message\n# - InvalidRequestError: Validation feedback\n# - TimeoutError: Configurable timeout (default 180s)\n# - NetworkError: Connection retry logic\n</code></pre>"},{"location":"concepts/models/#best-practices","title":"\ud83d\udccb Best Practices","text":""},{"location":"concepts/models/#1-environment-variables","title":"1. Environment Variables","text":"<pre><code># \u2705 GOOD - Use environment variables\nimport os\n\nos.environ[\"OPENROUTER_API_KEY\"] = \"sk-or-...\"\nos.environ[\"OPENAI_API_KEY\"] = \"sk-...\"\nos.environ[\"ANTHROPIC_API_KEY\"] = \"sk-ant-...\"\n\nconfig = ModelConfig(\n    type=\"api\",\n    provider=\"openrouter\",\n    name=\"anthropic/claude-opus-4.6\"\n    # api_key automatically loaded\n)\n\n# \u274c BAD - Hardcoded keys\nconfig = ModelConfig(\n    type=\"api\",\n    provider=\"openrouter\",\n    name=\"anthropic/claude-opus-4.6\",\n    api_key=\"sk-or-...\"  # Don't hardcode!\n)\n</code></pre>"},{"location":"concepts/models/#2-temperature-settings","title":"2. Temperature Settings","text":"<pre><code># \u2705 GOOD - Match temperature to task\n# Creative tasks\ncreative_config = ModelConfig(\n    provider=\"openrouter\",\n    name=\"anthropic/claude-opus-4.6\",\n    temperature=0.8  # Higher for creativity\n)\n\n# Analytical tasks\nanalytical_config = ModelConfig(\n    provider=\"openrouter\",\n    name=\"anthropic/claude-opus-4.6\",\n    temperature=0.2  # Lower for consistency\n)\n\n# \u274c BAD - Same temperature for all tasks\nconfig = ModelConfig(\n    provider=\"openrouter\",\n    name=\"anthropic/claude-opus-4.6\",\n    temperature=1.5  # Too high for most tasks\n)\n</code></pre>"},{"location":"concepts/models/#3-token-management","title":"3. Token Management","text":"<pre><code># \u2705 GOOD - Appropriate token limits\nconfig = ModelConfig(\n    provider=\"openrouter\",\n    name=\"anthropic/claude-opus-4.6\",\n    max_tokens=12000\n)\n\n# Consider context window\n# GPT-5.3 Codex, Claude Opus 4.6, and Gemini 3 have different context limits.\n# Check provider docs for exact context windows before setting max_tokens.\n# Plan accordingly:\nshort_context = ModelConfig(\n    provider=\"openrouter\",\n    name=\"google/gemini-3-flash-preview\",\n    max_tokens=12000\n)\nlong_context = ModelConfig(\n    provider=\"openrouter\",\n    name=\"google/gemini-3-pro-preview\",\n    max_tokens=12000\n)\n</code></pre>"},{"location":"concepts/models/#4-fallback-models","title":"4. Fallback Models","text":"<pre><code>class ModelWithFallback:\n    def __init__(self):\n        self.primary = ModelConfig(\n            type=\"api\",\n            provider=\"openrouter\",\n            name=\"anthropic/claude-opus-4.6\"\n        )\n        self.fallback = ModelConfig(\n            type=\"api\",\n            provider=\"openrouter\",\n            name=\"openai/gpt-5-codex\"\n        )\n\n    async def run(self, prompt):\n        try:\n            return await self.run_with_model(self.primary, prompt)\n        except Exception as e:\n            print(f\"Primary failed: {e}, using fallback\")\n            return await self.run_with_model(self.fallback, prompt)\n</code></pre>"},{"location":"concepts/models/#advanced-patterns","title":"\ud83c\udfaf Advanced Patterns","text":""},{"location":"concepts/models/#model-pooling","title":"Model Pooling","text":"<pre><code>class ModelPool:\n    \"\"\"Load balance across multiple models.\"\"\"\n\n    def __init__(self, configs: List[ModelConfig]):\n        self.agents = [\n            Agent(\n                model_config=config,\n                name=f\"pool_{i}\",\n                goal=\"Handle pooled model requests\",\n                instruction=\"Process prompts and return concise results.\"\n            )\n            for i, config in enumerate(configs)\n        ]\n        self.current = 0\n\n    async def run(self, prompt: str) -&gt; str:\n        \"\"\"Round-robin execution.\"\"\"\n        agent = self.agents[self.current]\n        self.current = (self.current + 1) % len(self.agents)\n        return await agent.run(prompt)\n\n# Create pool\npool = ModelPool([\n    ModelConfig(provider=\"openrouter\", name=\"anthropic/claude-opus-4.6\", max_tokens=12000),\n    ModelConfig(provider=\"openrouter\", name=\"openai/gpt-5-codex\", max_tokens=12000),\n    ModelConfig(provider=\"openrouter\", name=\"google/gemini-3-flash-preview\", max_tokens=12000)\n])\n</code></pre>"},{"location":"concepts/models/#response-caching","title":"Response Caching","text":"<pre><code>import hashlib\nfrom functools import lru_cache\n\nclass CachedModel:\n    def __init__(self, model_config: ModelConfig, cache_size: int = 100):\n        self.agent = Agent(\n            model_config=model_config,\n            name=\"cached\",\n            goal=\"Serve cached model responses\",\n            instruction=\"Return accurate responses while leveraging cache hits.\"\n        )\n        self.cache = {}\n\n    def _cache_key(self, prompt: str) -&gt; str:\n        return hashlib.md5(prompt.encode()).hexdigest()\n\n    async def run(self, prompt: str) -&gt; str:\n        key = self._cache_key(prompt)\n\n        if key in self.cache:\n            return self.cache[key]\n\n        response = await self.agent.run(prompt)\n\n        if len(self.cache) &gt;= 100:  # Simple LRU\n            self.cache.pop(next(iter(self.cache)))\n\n        self.cache[key] = response\n        return response\n</code></pre>"},{"location":"concepts/models/#next-steps","title":"\ud83d\udea6 Next Steps","text":"<ul> <li> <p> Agents</p> <p>How agents use models</p> </li> <li> <p> Tools</p> <p>Extend model capabilities</p> </li> <li> <p> Model API Reference</p> <p>Complete API documentation</p> </li> <li> <p> Configuration</p> <p>Advanced configuration options</p> </li> </ul> <p>Model System Ready!</p> <p>You now understand how MARSYS abstracts different AI models. The unified interface makes it easy to switch providers and experiment with different models.</p>"},{"location":"concepts/overview/","title":"Core Concepts","text":"<p>Understand the fundamental architecture and components that power the MARSYS framework.</p>"},{"location":"concepts/overview/#overview","title":"\ud83c\udfaf Overview","text":"<p>MARSYS is built on a layered architecture where each component has a specific responsibility. Understanding these core concepts will help you build sophisticated multi-agent systems effectively.</p>"},{"location":"concepts/overview/#architecture-overview","title":"\ud83c\udfd7\ufe0f Architecture Overview","text":"<pre><code>graph TB\n    subgraph \"Orchestration Layer\"\n        O[Orchestra&lt;br/&gt;High-level API]\n        TC[Topology&lt;br/&gt;Controller]\n        EC[Execution&lt;br/&gt;Coordinator]\n    end\n\n    subgraph \"Execution Layer\"\n        BE[Branch&lt;br/&gt;Executor]\n        SE[Step&lt;br/&gt;Executor]\n        DBS[Branch&lt;br/&gt;Spawner]\n    end\n\n    subgraph \"Validation &amp; Routing\"\n        VP[Validation&lt;br/&gt;Processor]\n        R[Router]\n        RE[Rules&lt;br/&gt;Engine]\n    end\n\n    subgraph \"Agent Layer\"\n        AR[Agent&lt;br/&gt;Registry]\n        AP[Agent&lt;br/&gt;Pools]\n        A[Agents]\n    end\n\n    subgraph \"Infrastructure\"\n        CM[Communication&lt;br/&gt;Manager]\n        SM[State&lt;br/&gt;Manager]\n        MM[Memory&lt;br/&gt;Manager]\n    end\n\n    O --&gt; TC\n    O --&gt; EC\n    EC --&gt; BE\n    BE --&gt; SE\n    BE --&gt; DBS\n    SE --&gt; VP\n    VP --&gt; R\n    R --&gt; A\n    A --&gt; AR\n    A --&gt; AP\n    SE --&gt; CM\n    EC --&gt; SM\n    A --&gt; MM\n\n    style O fill:#4A90E2,stroke:#2E5C8A,stroke-width:3px,color:#fff\n    style EC fill:#7B68EE,stroke:#5A4FCF,stroke-width:2px,color:#fff\n    style A fill:#50C878,stroke:#3A9B5C,stroke-width:2px,color:#fff</code></pre>"},{"location":"concepts/overview/#concept-categories","title":"\ud83d\udcda Concept Categories","text":""},{"location":"concepts/overview/#core-components","title":"\ud83c\udfaf Core Components","text":"<p>These are the fundamental building blocks of every MARSYS application:</p> <ul> <li> <p> Agents</p> <p>The autonomous units that perform tasks and make decisions</p> </li> <li> <p> Memory</p> <p>How agents store and recall information across conversations</p> </li> <li> <p> Tools</p> <p>Functions and capabilities that extend agent abilities</p> </li> <li> <p> Models</p> <p>LLM configurations and provider integrations</p> </li> <li> <p> Registry</p> <p>Global agent discovery and management system</p> </li> <li> <p> Messages</p> <p>Standardized communication format between components</p> </li> <li> <p> Communication</p> <p>Inter-agent and user interaction patterns</p> </li> </ul>"},{"location":"concepts/overview/#advanced-topics","title":"\ud83d\ude80 Advanced Topics","text":"<p>Advanced concepts for building sophisticated systems:</p> <ul> <li> <p> Topology System</p> <p>Define complex agent interaction patterns and workflows</p> </li> <li> <p> Error Handling</p> <p>Comprehensive error recovery and retry strategies</p> </li> <li> <p> Browser Automation</p> <p>Web scraping and interaction capabilities</p> </li> <li> <p> Learning Agents</p> <p>Agents that adapt and improve through fine-tuning</p> </li> <li> <p> Memory Patterns</p> <p>Advanced strategies for knowledge retention</p> </li> <li> <p> Custom Agents</p> <p>Building specialized agent types for specific needs</p> </li> </ul>"},{"location":"concepts/overview/#learning-path","title":"\ud83c\udf93 Learning Path","text":""},{"location":"concepts/overview/#for-beginners","title":"For Beginners","text":"<ol> <li>Start with Agents to understand the basic building blocks</li> <li>Learn about Memory and how agents retain information</li> <li>Explore Tools to extend agent capabilities</li> <li>Understand Communication patterns</li> </ol>"},{"location":"concepts/overview/#for-intermediate-users","title":"For Intermediate Users","text":"<ol> <li>Master Topology System for complex workflows</li> <li>Implement Error Handling for production systems</li> <li>Explore Memory Patterns for advanced use cases</li> <li>Learn Custom Agents development</li> </ol>"},{"location":"concepts/overview/#for-advanced-users","title":"For Advanced Users","text":"<ol> <li>Build Learning Agents with adaptation</li> <li>Implement Browser Automation for web tasks</li> <li>Design complex topologies with dynamic branching</li> <li>Optimize performance with agent pools</li> </ol>"},{"location":"concepts/overview/#key-design-principles","title":"\ud83d\udd11 Key Design Principles","text":""},{"location":"concepts/overview/#1-pure-agent-logic","title":"1. Pure Agent Logic","text":"<p>Agents implement pure <code>_run()</code> methods without side effects:</p> <pre><code>async def _run(self, prompt, context, **kwargs):\n    # Pure logic - no memory manipulation\n    # No logging, no state changes\n    # Just process and return\n    messages = self._prepare_messages(prompt)\n    response = await self.model.run(messages)\n    return Message(role=\"assistant\", content=response.content)\n</code></pre>"},{"location":"concepts/overview/#2-centralized-validation","title":"2. Centralized Validation","text":"<p>All response processing happens in one place:</p> <pre><code># ValidationProcessor handles ALL parsing\n- JSON responses\n- Structured data\n- Tool calls\n- Agent invocations\n- Error classification\n</code></pre>"},{"location":"concepts/overview/#3-dynamic-branching","title":"3. Dynamic Branching","text":"<p>Branches created at runtime for parallel execution:</p> <pre><code># Agents decide parallelism dynamically\n{\n    \"next_action\": \"parallel_invoke\",\n    \"agents\": [\"A\", \"B\", \"C\"],  # Spawns 3 branches\n    \"agent_requests\": {...}\n}\n</code></pre>"},{"location":"concepts/overview/#4-branch-isolation","title":"4. Branch Isolation","text":"<p>Each branch maintains independent state:</p> <ul> <li>Separate memory contexts</li> <li>Individual execution traces</li> <li>Isolated metadata</li> <li>Independent status tracking</li> </ul>"},{"location":"concepts/overview/#5-topology-driven-routing","title":"5. Topology-Driven Routing","text":"<p>All routing decisions based on topology:</p> <pre><code>topology = {\n    \"agents\": [\"A\", \"B\", \"C\"],\n    \"flows\": [\"A -&gt; B\", \"B -&gt; C\"],  # Defines allowed paths\n    \"rules\": [...]  # Additional constraints\n}\n</code></pre>"},{"location":"concepts/overview/#core-execution-flow","title":"\ud83d\udca1 Core Execution Flow","text":"<p>Understanding the execution flow is crucial:</p>"},{"location":"concepts/overview/#1-task-submission","title":"1. Task Submission","text":"<pre><code>result = await Orchestra.run(task, topology)\n</code></pre>"},{"location":"concepts/overview/#2-topology-analysis","title":"2. Topology Analysis","text":"<ul> <li>Identify entry points</li> <li>Detect convergence nodes</li> <li>Validate agent permissions</li> <li>Apply rules</li> </ul>"},{"location":"concepts/overview/#3-branch-creation","title":"3. Branch Creation","text":"<ul> <li>Initial branches at entry points</li> <li>Dynamic spawning for parallel work</li> <li>Parent-child relationships</li> </ul>"},{"location":"concepts/overview/#4-step-execution","title":"4. Step Execution","text":"<pre><code>Validate \u2192 Route \u2192 Execute \u2192 Process \u2192 Continue\n</code></pre>"},{"location":"concepts/overview/#5-convergence","title":"5. Convergence","text":"<ul> <li>Wait for child branches</li> <li>Aggregate results</li> <li>Resume parent execution</li> </ul>"},{"location":"concepts/overview/#6-completion","title":"6. Completion","text":"<ul> <li>Extract final response</li> <li>Return OrchestraResult</li> </ul>"},{"location":"concepts/overview/#agent-communication-patterns","title":"\ud83d\udd04 Agent Communication Patterns","text":""},{"location":"concepts/overview/#sequential","title":"Sequential","text":"<pre><code>A \u2192 B \u2192 C \u2192 Final\n</code></pre>"},{"location":"concepts/overview/#parallel","title":"Parallel","text":"<pre><code>    \u250c\u2192 B \u2192\u2510\nA \u2192\u2500\u253c\u2192 C \u2192\u253c\u2192 E\n    \u2514\u2192 D \u2192\u2518\n</code></pre>"},{"location":"concepts/overview/#conversation","title":"Conversation","text":"<pre><code>A \u27f7 B (multiple rounds)\n</code></pre>"},{"location":"concepts/overview/#hierarchical","title":"Hierarchical","text":"<pre><code>     Manager\n    /        \\\n  Lead1      Lead2\n  /   \\      /   \\\nW1    W2    W3    W4\n</code></pre>"},{"location":"concepts/overview/#error-recovery-strategies","title":"\ud83d\udee1\ufe0f Error Recovery Strategies","text":"<p>MARSYS provides multiple levels of error handling:</p>"},{"location":"concepts/overview/#1-step-level-retry","title":"1. Step-Level Retry","text":"<p>Automatic retry with exponential backoff</p>"},{"location":"concepts/overview/#2-error-classification","title":"2. Error Classification","text":"<p>Different strategies for different error types: - Rate Limits: Wait and retry - Invalid Input: Route to user - API Errors: Fallback models - Timeouts: Cancel and recover</p>"},{"location":"concepts/overview/#3-user-recovery","title":"3. User Recovery","text":"<p>Route errors to User node for manual intervention</p>"},{"location":"concepts/overview/#4-graceful-degradation","title":"4. Graceful Degradation","text":"<p>Continue with partial results when possible</p>"},{"location":"concepts/overview/#performance-considerations","title":"\ud83d\udcca Performance Considerations","text":""},{"location":"concepts/overview/#agent-pools","title":"Agent Pools","text":"<p>Use pools for true parallelism: <pre><code>pool = AgentPool(agent_class=BrowserAgent, num_instances=3)\n</code></pre></p>"},{"location":"concepts/overview/#memory-management","title":"Memory Management","text":"<p>Choose appropriate retention: - <code>single_run</code>: Stateless, minimal memory - <code>session</code>: Balanced for most use cases - <code>persistent</code>: Long-term learning</p>"},{"location":"concepts/overview/#timeout-configuration","title":"Timeout Configuration","text":"<p>Set appropriate timeouts: - Step timeout: Individual operations - Branch timeout: Complete workflows - Convergence timeout: Parallel coordination</p>"},{"location":"concepts/overview/#status-verbosity","title":"Status Verbosity","text":"<p>Adjust output for performance: - <code>QUIET</code>: Production (minimal overhead) - <code>NORMAL</code>: Development - <code>VERBOSE</code>: Debugging</p>"},{"location":"concepts/overview/#next-steps","title":"\ud83d\udea6 Next Steps","text":"<p>Ready to dive deeper into specific concepts?</p> <ul> <li> <p> Learn About Agents</p> <p>Start with the fundamental building blocks</p> </li> <li> <p> Explore Topologies</p> <p>Design complex interaction patterns</p> </li> <li> <p> API Reference</p> <p>Detailed class and method documentation</p> </li> <li> <p> See Examples</p> <p>Learn from real-world implementations</p> </li> </ul> <p>Best Starting Point</p> <p>If you're new to MARSYS, start with the Agents documentation to understand the fundamental building blocks of the framework.</p>"},{"location":"concepts/planning/","title":"Task Planning","text":"<p>Task planning enables agents to create, track, and manage structured task lists during complex multi-step operations.</p> <p>See Also</p> <p>For the <code>plan_config</code> parameter details, see Agent API Reference.</p>"},{"location":"concepts/planning/#overview","title":"Overview","text":"<p>Planning helps agents:</p> <ul> <li>Track Progress: Know what's done and what remains</li> <li>Recover from Errors: Reorient after failures using plan context</li> <li>Provide Visibility: Users can see agent progress via CLI/web status</li> <li>Maintain Focus: Prevents task drift in long-running operations</li> </ul> <p>Planning is enabled by default for all agents but can be disabled when not needed.</p>"},{"location":"concepts/planning/#architecture","title":"Architecture","text":"<pre><code>graph TB\n    subgraph \"Agent\"\n        A[Agent._run]\n        PT[Planning Tools]\n        PS[PlanningState]\n    end\n\n    subgraph \"EventBus\"\n        EB[Event System]\n    end\n\n    subgraph \"Visualization\"\n        CLI[CLI Output]\n        WEB[Web Interface]\n    end\n\n    A --&gt;|calls| PT\n    PT --&gt;|modifies| PS\n    PS --&gt;|emits events| EB\n    EB --&gt;|notifies| CLI\n    EB --&gt;|notifies| WEB\n\n    style A fill:#4fc3f7\n    style PT fill:#81c784\n    style PS fill:#ffb74d</code></pre>"},{"location":"concepts/planning/#quick-start","title":"Quick Start","text":""},{"location":"concepts/planning/#basic-usage-default-enabled","title":"Basic Usage (Default: Enabled)","text":"<pre><code>from marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\n# Planning is enabled by default\nagent = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\",\n        max_tokens=12000\n    ),\n    name=\"Researcher\",\n    goal=\"Research and analyze topics\",\n    instruction=\"You are a thorough researcher...\"\n)\n\n# Agent has access to planning tools automatically\nresult = await agent.auto_run(\"Research AI trends and summarize findings\")\n</code></pre>"},{"location":"concepts/planning/#disabling-planning","title":"Disabling Planning","text":"<pre><code># Disable planning for simple, single-step agents\nsimple_agent = Agent(\n    model_config=config,\n    name=\"Calculator\",\n    goal=\"Perform calculations\",\n    instruction=\"...\",\n    plan_config=False  # Disable planning\n)\n</code></pre>"},{"location":"concepts/planning/#custom-configuration","title":"Custom Configuration","text":"<pre><code>from marsys.agents.planning import PlanningConfig, InjectionTrigger\n\ncustom_agent = Agent(\n    model_config=config,\n    name=\"Analyst\",\n    goal=\"Analyze complex datasets\",\n    instruction=\"...\",\n    plan_config=PlanningConfig(\n        min_plan_items=3,\n        max_plan_items=15,\n        compact_mode=True,\n        inject_triggers={\n            InjectionTrigger.SESSION_START,\n            InjectionTrigger.ERROR_RECOVERY,\n        }\n    )\n)\n</code></pre>"},{"location":"concepts/planning/#configuration","title":"Configuration","text":""},{"location":"concepts/planning/#planningconfig","title":"PlanningConfig","text":"Parameter Type Default Description <code>enabled</code> <code>bool</code> <code>True</code> Enable/disable planning <code>min_plan_items</code> <code>int</code> <code>2</code> Minimum items required for a valid plan <code>max_plan_items</code> <code>int</code> <code>20</code> Maximum allowed items <code>max_item_content_length</code> <code>int</code> <code>500</code> Max characters per item content <code>inject_after_step</code> <code>int</code> <code>0</code> Step number after which to start injecting plan context <code>inject_triggers</code> <code>Set[InjectionTrigger]</code> <code>{SESSION_START, STEP_START, ERROR_RECOVERY}</code> When to inject plan context <code>compact_mode</code> <code>bool</code> <code>True</code> Use compact display format <code>max_items_in_compact</code> <code>int</code> <code>3</code> Max items shown in compact view <code>custom_instruction</code> <code>Optional[str]</code> <code>None</code> Override default planning instruction"},{"location":"concepts/planning/#injection-triggers","title":"Injection Triggers","text":"Trigger When Activated Use Case <code>SESSION_START</code> First step of a fresh run Provide full plan reminder <code>STEP_START</code> After N steps (configurable) Compact reminder during work <code>ERROR_RECOVERY</code> During retry after an error Help agent reorient <pre><code>from marsys.agents.planning import InjectionTrigger\n\n# Only inject at session start and errors (skip step-by-step)\nconfig = PlanningConfig(\n    inject_triggers={\n        InjectionTrigger.SESSION_START,\n        InjectionTrigger.ERROR_RECOVERY,\n    }\n)\n</code></pre>"},{"location":"concepts/planning/#planning-tools","title":"Planning Tools","text":"<p>When planning is enabled, agents have access to these tools:</p> Tool Description <code>plan_create</code> Create a new plan with items and goal <code>plan_read</code> Read current plan state <code>plan_update</code> Update item status, title, or content <code>plan_add_item</code> Add item to existing plan <code>plan_remove_item</code> Remove item from plan <code>plan_clear</code> Clear the entire plan"},{"location":"concepts/planning/#tool-usage-examples","title":"Tool Usage Examples","text":""},{"location":"concepts/planning/#creating-a-plan","title":"Creating a Plan","text":"<p>The agent creates a plan when receiving a complex task:</p> <pre><code># Agent calls plan_create tool with:\n{\n    \"goal\": \"Build authentication system\",\n    \"items\": [\n        {\n            \"title\": \"Design user schema\",\n            \"content\": \"Create database tables for users and sessions\",\n            \"active_form\": \"Designing user schema\"\n        },\n        {\n            \"title\": \"Implement signup endpoint\",\n            \"content\": \"Create POST /auth/signup with validation\",\n            \"active_form\": \"Implementing signup endpoint\"\n        },\n        {\n            \"title\": \"Add authentication tests\",\n            \"content\": \"Write unit and integration tests\",\n            \"active_form\": \"Writing authentication tests\"\n        }\n    ]\n}\n</code></pre>"},{"location":"concepts/planning/#updating-progress","title":"Updating Progress","text":"<pre><code># Mark item as in progress\nplan_update(item_id=\"abc123\", status=\"in_progress\")\n\n# Mark as completed when done\nplan_update(item_id=\"abc123\", status=\"completed\")\n\n# Update content if scope changes\nplan_update(item_id=\"def456\", content=\"Updated scope: also add OAuth support\")\n</code></pre>"},{"location":"concepts/planning/#reading-plan-state","title":"Reading Plan State","text":"<pre><code># Agent calls plan_read to review current state\n# Returns structured plan with all items and their statuses\n</code></pre>"},{"location":"concepts/planning/#plan-item-states","title":"Plan Item States","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; pending\n    pending --&gt; in_progress: Start work\n    in_progress --&gt; completed: Finish successfully\n    in_progress --&gt; blocked: Cannot proceed\n    blocked --&gt; in_progress: Unblock\n    completed --&gt; [*]</code></pre> Status Description Rules <code>pending</code> Not yet started Default state for new items <code>in_progress</code> Currently working Only ONE item at a time <code>completed</code> Successfully finished Must complete current before starting next <code>blocked</code> Cannot proceed Should include reason <p>One In-Progress Rule</p> <p>Only one item can be <code>in_progress</code> at any time. Agents must complete the current item before starting the next one.</p>"},{"location":"concepts/planning/#status-visualization","title":"Status Visualization","text":"<p>Planning events are displayed in CLI and web interfaces:</p>"},{"location":"concepts/planning/#cli-output-examples","title":"CLI Output Examples","text":"<pre><code>\u250c\u2500 Plan Created \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2502 Goal: Research AI trends and create summary report\n\u2502 Items: 4\n\u2502   1. [pending] Search for recent AI papers\n\u2502   2. [pending] Analyze key findings\n\u2502   3. [pending] Synthesize insights\n\u2502   4. [pending] Write summary report\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\n[Researcher] \u25b8 Searching for recent AI papers...\n\n\u250c\u2500 Plan Updated \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n\u2502 \u2713 Search for recent AI papers \u2192 completed\n\u2502 \u25b8 Analyze key findings \u2192 in_progress\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n</code></pre>"},{"location":"concepts/planning/#verbosity-levels","title":"Verbosity Levels","text":"Level What's Shown QUIET (0) Nothing NORMAL (1) Status changes only VERBOSE (2) All updates including field changes"},{"location":"concepts/planning/#event-system-integration","title":"Event System Integration","text":"<p>Planning integrates with the EventBus for:</p> <ul> <li>Memory Reset Sync: Plans clear automatically when memory resets</li> <li>Status Updates: Events emit for CLI/web visualization</li> </ul>"},{"location":"concepts/planning/#web-delivery-statuswebchannel","title":"Web Delivery (StatusWebChannel)","text":"<p>To deliver planning events to web clients, attach <code>StatusWebChannel</code> to the <code>StatusManager</code> and use <code>WebChannel</code> polling or WebSocket push:</p> <pre><code>from marsys.coordination.communication.channels import WebChannel\nfrom marsys.coordination.status.channels import StatusWebChannel\n\nweb_channel = WebChannel()\nstatus_manager.add_channel(StatusWebChannel(web_channel))\n\n# Web clients can poll:\n# await web_channel.get_status_events()\n</code></pre>"},{"location":"concepts/planning/#events-emitted","title":"Events Emitted","text":"Event When Emitted <code>PlanCreatedEvent</code> New plan created <code>PlanUpdatedEvent</code> Item status or fields changed <code>PlanItemAddedEvent</code> Item added to plan <code>PlanItemRemovedEvent</code> Item removed from plan <code>PlanClearedEvent</code> Plan cleared"},{"location":"concepts/planning/#state-persistence","title":"State Persistence","text":"<p>Plans are saved alongside agent state:</p> <pre><code># Save agent state (includes plan)\nagent.save_state(\"/path/to/state.json\")\n\n# Load state later (plan is restored)\nnew_agent = Agent(\n    model_config=config,\n    name=\"Researcher\",\n    goal=\"...\",\n    instruction=\"...\",\n    plan_config=True  # Must enable planning\n)\nnew_agent.load_state(\"/path/to/state.json\")\n</code></pre>"},{"location":"concepts/planning/#best-practices","title":"Best Practices","text":""},{"location":"concepts/planning/#when-to-use-planning","title":"When to Use Planning","text":"<ul> <li>Tasks with 2+ distinct steps</li> <li>Operations requiring progress tracking</li> <li>Tasks needing recovery from errors</li> <li>Long-running autonomous workflows</li> </ul>"},{"location":"concepts/planning/#when-not-to-use-planning","title":"When NOT to Use Planning","text":"<ul> <li>Simple single-step operations</li> <li>Quick lookups or calculations</li> <li>Conversational interactions</li> <li>Agents that don't use <code>auto_run()</code></li> </ul>"},{"location":"concepts/planning/#effective-planning","title":"Effective Planning","text":"<ol> <li>Create plan BEFORE starting work - Plan first, then execute</li> <li>Mark items in_progress before working - Shows what's currently happening</li> <li>Mark items completed IMMEDIATELY after finishing - Don't batch completions</li> <li>Only ONE item in_progress at a time - Maintains focus</li> <li>Use blocked status with clear reason if stuck - Enables error recovery</li> </ol>"},{"location":"concepts/planning/#example-research-task-with-planning","title":"Example: Research Task with Planning","text":"<pre><code>from marsys.agents import Agent\nfrom marsys.agents.planning import PlanningConfig\nfrom marsys.models import ModelConfig\n\n# Create agent with planning\nresearcher = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\",\n        max_tokens=12000\n    ),\n    name=\"Researcher\",\n    goal=\"Research topics thoroughly and provide comprehensive summaries\",\n    instruction=\"\"\"You are a thorough researcher. When given a research task:\n\n    1. Create a plan with clear steps\n    2. Work through each step systematically\n    3. Mark items complete as you finish them\n    4. Provide a final summary when done\n\n    Use your planning tools to stay organized.\"\"\",\n    tools={\"search_web\": search_web, \"fetch_url\": fetch_url},\n    plan_config=PlanningConfig(\n        min_plan_items=2,\n        max_plan_items=10,\n        compact_mode=True\n    )\n)\n\n# Run the research task\nresult = await researcher.auto_run(\n    \"Research the latest developments in quantum computing and summarize the key breakthroughs\",\n    max_steps=10\n)\n</code></pre> <p>During execution, the agent: 1. Creates a plan with steps like \"Search for quantum computing news\", \"Read key articles\", \"Summarize findings\" 2. Marks each step in_progress as it works on it 3. Marks completed when done 4. Provides final response with research summary</p>"},{"location":"concepts/planning/#related-documentation","title":"Related Documentation","text":"<ul> <li>Agents - Agent architecture</li> <li>Memory - Memory management</li> <li>State Management - Persistence</li> <li>Agent API Reference - API details</li> </ul>"},{"location":"concepts/registry/","title":"Registry","text":"<p>The AgentRegistry is a central service discovery and lifecycle management system that enables dynamic agent registration, discovery, and communication in MARSYS workflows.</p>"},{"location":"concepts/registry/#overview","title":"\ud83c\udfaf Overview","text":"<p>The registry system provides:</p> <ul> <li>Service Discovery: Find agents by name, capability, or type</li> <li>Lifecycle Management: Automatic registration and cleanup</li> <li>Thread-Safe Operations: Concurrent access with locking</li> <li>Weak References: Automatic garbage collection</li> <li>Dynamic Communication: Runtime agent discovery</li> </ul>"},{"location":"concepts/registry/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<pre><code>graph TB\n    subgraph \"Registry System\"\n        AR[AgentRegistry&lt;br/&gt;Central Registry]\n        WR[WeakRefs&lt;br/&gt;Auto Cleanup]\n        TL[Thread Lock&lt;br/&gt;Concurrency]\n    end\n\n    subgraph \"Agent Lifecycle\"\n        Create[Agent Creation] --&gt; Register[Auto Register]\n        Register --&gt; Active[Active in Registry]\n        Active --&gt; GC[Garbage Collection]\n        GC --&gt; Remove[Auto Remove]\n    end\n\n    subgraph \"Discovery\"\n        Name[By Name]\n        Type[By Type]\n        Cap[By Capability]\n        All[List All]\n    end\n\n    AR --&gt; WR\n    AR --&gt; TL\n    Register --&gt; AR\n    AR --&gt; Name\n    AR --&gt; Type\n    AR --&gt; Cap\n\n    style AR fill:#4fc3f7\n    style WR fill:#29b6f6\n    style TL fill:#e1f5fe</code></pre>"},{"location":"concepts/registry/#core-registry","title":"\ud83d\udce6 Core Registry","text":""},{"location":"concepts/registry/#agentregistry-class","title":"AgentRegistry Class","text":"<pre><code>from marsys.agents.registry import AgentRegistry\nfrom marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\n# The registry is a singleton - no instantiation needed\n# It's automatically used by all agents\n\n# Create agents - they auto-register\nagent1 = Agent(\n    name=\"data_processor\",\n    model_config=ModelConfig(\n        type=\"api\",\n        provider=\"openrouter\",\n        name=\"anthropic/claude-opus-4.6\",\n        max_tokens=12000\n    ),\n    goal=\"Processes and analyzes data\",\n    instruction=\"Analyze structured inputs and return concise findings.\"\n)\n\nagent2 = Agent(\n    name=\"report_writer\",\n    model_config=config,\n    goal=\"Creates detailed reports\",\n    instruction=\"Turn analyzed data into clear, actionable reports.\"\n)\n\n# Check registration\nprint(AgentRegistry.all())  # ['data_processor', 'report_writer']\n\n# Get specific agent\nprocessor = AgentRegistry.get(\"data_processor\")\nif processor:\n    result = await processor.run(\"Analyze this data: ...\")\n</code></pre>"},{"location":"concepts/registry/#automatic-registration","title":"Automatic Registration","text":"<pre><code>from marsys.agents import Agent\nfrom marsys.agents.registry import AgentRegistry\n\nagent = Agent(\n    model_config=config,\n    name=\"assistant\",\n    goal=\"Help users with general tasks\",\n    instruction=\"Respond clearly and safely.\"\n)\n\n# Auto-registration happens in BaseAgent.__init__\nassert AgentRegistry.get(\"assistant\") is agent\n</code></pre>"},{"location":"concepts/registry/#registry-operations","title":"Registry Operations","text":"<pre><code># Get agent by name\nagent = AgentRegistry.get(\"assistant\")\n\n# Check if agent exists\nif AgentRegistry.get(\"assistant\") is not None:\n    print(\"Agent is available\")\n\n# List all agents\nall_agents = AgentRegistry.all()\nprint(f\"Active agents: {all_agents}\")\n\n# List all agents including pools\nall_with_pools = AgentRegistry.all_with_pools()\nprint(f\"All registrations: {all_with_pools}\")\n\n# Check if name is a pool\nif AgentRegistry.is_pool(\"BrowserPool\"):\n    pool = AgentRegistry.get_pool(\"BrowserPool\")\n\n# Count active agents\ncount = len(AgentRegistry.all())\nprint(f\"Total agents: {count}\")\n\n# Unregister agent (identity-safe)\nAgentRegistry.unregister_if_same(\"assistant\", agent_instance)\n</code></pre>"},{"location":"concepts/registry/#identity-safe-unregistration","title":"Identity-Safe Unregistration","text":"<p>To prevent race conditions during concurrent execution, use identity-safe unregistration methods:</p> <pre><code>from marsys.agents.registry import AgentRegistry\n\n# Create agent\nagent = Agent(\n    name=\"worker\",\n    model_config=config,\n    goal=\"Process assigned tasks\",\n    instruction=\"Execute assigned work and return concise results.\"\n)\n\n# Later: cleanup and unregister (identity-safe)\nawait agent.cleanup()  # Close resources\nAgentRegistry.unregister_if_same(\"worker\", agent)  # Only unregister if same instance\n\n# Or using convenience method\nAgentRegistry.unregister_instance(agent)  # Uses agent.name attribute\n</code></pre> <p>Why Identity-Safe?</p> <p>In concurrent workflows, an agent's <code>__del__</code> destructor might fire after a new agent with the same name is registered. Identity-safe methods use Python's <code>is</code> operator to verify the registry entry points to the exact same instance before unregistering.</p> <pre><code># Problem scenario (solved by identity-safe unregistration):\n# 1. Task 1 creates Agent \"Coordinator\" (instance A)\n# 2. Task 1 completes, A is queued for garbage collection\n# 3. Task 2 creates Agent \"Coordinator\" (instance B, registers successfully)\n# 4. Task 1's instance A gets garbage collected, __del__ fires\n# 5. OLD: A.__del__ calls unregister(\"Coordinator\") \u2192 removes B! \u274c\n# 6. NEW: A.__del__ calls unregister_if_same(\"Coordinator\", A) \u2192 sees B, skips \u2705\n</code></pre> <p>Methods:</p> <ul> <li><code>unregister_if_same(name, instance)</code>: Unregister only if registry entry matches instance</li> <li><code>unregister_instance(instance)</code>: Convenience method using <code>instance.name</code></li> <li><code>unregister(name)</code>: Legacy method (not identity-safe, avoid in concurrent contexts)</li> </ul> <p>Framework Integration:</p> <p>Orchestra automatically uses identity-safe unregistration when <code>auto_cleanup_agents=True</code> (default), preventing race conditions in multi-task workflows.</p>"},{"location":"concepts/registry/#discovery-patterns","title":"\ud83c\udfaf Discovery Patterns","text":""},{"location":"concepts/registry/#service-discovery","title":"Service Discovery","text":"<pre><code>class CapabilityRegistry:\n    \"\"\"Extended registry with capability tracking.\"\"\"\n\n    _capabilities: Dict[str, Set[str]] = {}\n\n    @classmethod\n    def register_capability(cls, agent_name: str, capability: str):\n        \"\"\"Register agent capability.\"\"\"\n        if capability not in cls._capabilities:\n            cls._capabilities[capability] = set()\n        cls._capabilities[capability].add(agent_name)\n\n    @classmethod\n    def find_by_capability(cls, capability: str) -&gt; List[str]:\n        \"\"\"Find agents with specific capability.\"\"\"\n        return list(cls._capabilities.get(capability, []))\n\n    @classmethod\n    def find_best_match(cls, capabilities: List[str]) -&gt; Optional[str]:\n        \"\"\"Find agent with most matching capabilities.\"\"\"\n        scores = {}\n        for cap in capabilities:\n            for agent in cls._capabilities.get(cap, []):\n                scores[agent] = scores.get(agent, 0) + 1\n\n        if scores:\n            return max(scores, key=scores.get)\n        return None\n\n# Usage\nCapabilityRegistry.register_capability(\"translator_1\", \"translation\")\nCapabilityRegistry.register_capability(\"translator_1\", \"localization\")\nCapabilityRegistry.register_capability(\"writer_1\", \"content_creation\")\n\n# Find specialists\ntranslators = CapabilityRegistry.find_by_capability(\"translation\")\nbest_match = CapabilityRegistry.find_best_match([\"translation\", \"localization\"])\n</code></pre>"},{"location":"concepts/registry/#dynamic-agent-selection","title":"Dynamic Agent Selection","text":"<pre><code>class SmartCoordinator(Agent):\n    \"\"\"Coordinator that dynamically selects agents.\"\"\"\n\n    async def delegate_task(self, task: str, task_type: str, context):\n        \"\"\"Delegate task to appropriate agent.\"\"\"\n\n        # Find suitable agents\n        candidates = self._find_suitable_agents(task_type)\n\n        if not candidates:\n            return Message(\n                role=\"error\",\n                content=f\"No agents available for {task_type}\",\n                name=self.name\n            )\n\n        # Select best agent (could use various strategies)\n        selected = self._select_best_agent(candidates, task)\n\n        # Invoke selected agent\n        return await self.invoke_agent(selected, task)\n\n    def _find_suitable_agents(self, task_type: str) -&gt; List[str]:\n        \"\"\"Find agents suitable for task type.\"\"\"\n        type_mapping = {\n            \"analysis\": [\"data_analyst\", \"researcher\"],\n            \"writing\": [\"writer\", \"editor\", \"reporter\"],\n            \"browsing\": [\"browser_agent\", \"scraper\"]\n        }\n\n        agent_names = type_mapping.get(task_type, [])\n        return [\n            name for name in agent_names\n            if AgentRegistry.get(name) is not None\n        ]\n\n    def _select_best_agent(self, candidates: List[str], task: str) -&gt; str:\n        \"\"\"Select best agent from candidates.\"\"\"\n        # Could implement various strategies:\n        # - Round-robin\n        # - Load balancing\n        # - Capability matching\n        # - Performance history\n        return candidates[0]  # Simple: first available\n</code></pre>"},{"location":"concepts/registry/#advanced-registry","title":"\ud83d\udd27 Advanced Registry","text":""},{"location":"concepts/registry/#load-balancing","title":"Load Balancing","text":"<pre><code>class LoadBalancedRegistry:\n    \"\"\"Registry with load balancing capabilities.\"\"\"\n\n    _invocation_counts: Dict[str, int] = {}\n    _active_tasks: Dict[str, int] = {}\n\n    @classmethod\n    def get_least_loaded(cls, agent_type: str = None) -&gt; Optional[str]:\n        \"\"\"Get least loaded agent.\"\"\"\n        candidates = list(AgentRegistry.all().keys())\n\n        if agent_type:\n            # Filter by type\n            candidates = [\n                name for name in candidates\n                if name.startswith(agent_type)\n            ]\n\n        if not candidates:\n            return None\n\n        # Find least loaded\n        return min(\n            candidates,\n            key=lambda n: cls._active_tasks.get(n, 0)\n        )\n\n    @classmethod\n    def start_task(cls, agent_name: str):\n        \"\"\"Mark task start.\"\"\"\n        cls._active_tasks[agent_name] = cls._active_tasks.get(agent_name, 0) + 1\n        cls._invocation_counts[agent_name] = cls._invocation_counts.get(agent_name, 0) + 1\n\n    @classmethod\n    def end_task(cls, agent_name: str):\n        \"\"\"Mark task end.\"\"\"\n        if agent_name in cls._active_tasks:\n            cls._active_tasks[agent_name] = max(0, cls._active_tasks[agent_name] - 1)\n\n    @classmethod\n    def get_statistics(cls) -&gt; Dict[str, Any]:\n        \"\"\"Get load balancing statistics.\"\"\"\n        return {\n            \"total_invocations\": sum(cls._invocation_counts.values()),\n            \"active_tasks\": dict(cls._active_tasks),\n            \"invocation_counts\": dict(cls._invocation_counts)\n        }\n</code></pre>"},{"location":"concepts/registry/#health-monitoring","title":"Health Monitoring","text":"<pre><code>class HealthMonitor:\n    \"\"\"Monitor agent health and availability.\"\"\"\n\n    _health_status: Dict[str, Dict[str, Any]] = {}\n    _last_check: Dict[str, datetime] = {}\n\n    @classmethod\n    async def check_agent_health(cls, agent_name: str) -&gt; bool:\n        \"\"\"Check if agent is healthy.\"\"\"\n        agent = AgentRegistry.get(agent_name)\n        if not agent:\n            return False\n\n        try:\n            # Simple ping test\n            start = time.time()\n            response = await agent.run(\"ping\", timeout=5.0)\n            latency = time.time() - start\n\n            cls._health_status[agent_name] = {\n                \"healthy\": True,\n                \"latency\": latency,\n                \"last_check\": datetime.now()\n            }\n            return True\n\n        except Exception as e:\n            cls._health_status[agent_name] = {\n                \"healthy\": False,\n                \"error\": str(e),\n                \"last_check\": datetime.now()\n            }\n            return False\n\n    @classmethod\n    async def check_all_agents(cls) -&gt; Dict[str, bool]:\n        \"\"\"Health check all registered agents.\"\"\"\n        results = {}\n        for agent_name in list(AgentRegistry.all().keys()):\n            results[agent_name] = await cls.check_agent_health(agent_name)\n        return results\n\n    @classmethod\n    def get_healthy_agents(cls) -&gt; List[str]:\n        \"\"\"Get list of healthy agents.\"\"\"\n        return [\n            name for name, status in cls._health_status.items()\n            if status.get(\"healthy\", False)\n        ]\n</code></pre>"},{"location":"concepts/registry/#registry-persistence","title":"Registry Persistence","text":"<pre><code>class PersistentRegistry:\n    \"\"\"Registry with state persistence.\"\"\"\n\n    @classmethod\n    def save_state(cls, filepath: str):\n        \"\"\"Save registry state to file.\"\"\"\n        state = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"agents\": {}\n        }\n\n        for agent_name in list(AgentRegistry.all().keys()):\n            agent = AgentRegistry.get(agent_name)\n            if agent:\n                state[\"agents\"][agent_name] = {\n                    \"type\": type(agent).__name__,\n                    \"description\": getattr(agent, 'description', ''),\n                    \"model\": getattr(agent.model, 'name', 'unknown')\n                }\n\n        with open(filepath, 'w') as f:\n            json.dump(state, f, indent=2)\n\n    @classmethod\n    def load_state(cls, filepath: str) -&gt; Dict:\n        \"\"\"Load registry state from file.\"\"\"\n        with open(filepath, 'r') as f:\n            return json.load(f)\n\n    @classmethod\n    async def restore_agents(cls, state: Dict, model_configs: Dict[str, ModelConfig]):\n        \"\"\"Restore agents from saved state.\"\"\"\n        for agent_name, info in state.get(\"agents\", {}).items():\n            agent_type = info[\"type\"]\n            model_name = info.get(\"model\", \"anthropic/claude-opus-4.6\")\n\n            # Get appropriate config\n            config = model_configs.get(model_name)\n            if not config:\n                continue\n\n            # Recreate agent based on type\n            if agent_type == \"Agent\":\n                Agent(\n                    name=agent_name,\n                    model_config=config,\n                    goal=\"Restored agent goal\",\n                    instruction=\"Restored agent instruction.\"\n                )\n            elif agent_type == \"BrowserAgent\":\n                await BrowserAgent.create_safe(\n                    name=agent_name,\n                    model_config=config,\n                    headless=True\n                )\n            # Add other agent types as needed\n</code></pre>"},{"location":"concepts/registry/#best-practices","title":"\ud83d\udccb Best Practices","text":""},{"location":"concepts/registry/#1-unique-naming","title":"1. Unique Naming","text":"<pre><code># \u2705 GOOD - Descriptive, unique names\nagent1 = Agent(\n    name=\"financial_analyst_v2\",\n    model_config=config,\n    goal=\"Analyze financial performance\",\n    instruction=\"Review financial data and report key findings.\"\n)\nagent2 = Agent(\n    name=\"report_generator_q4_2024\",\n    model_config=config,\n    goal=\"Generate Q4 reports\",\n    instruction=\"Create clear and complete quarterly reports.\"\n)\n\n# \u274c BAD - Generic, collision-prone names\nagent1 = Agent(\n    name=\"agent\",\n    model_config=config,\n    goal=\"Generic goal\",\n    instruction=\"Generic instruction.\"\n)\nagent2 = Agent(\n    name=\"helper\",\n    model_config=config,\n    goal=\"Generic goal\",\n    instruction=\"Generic instruction.\"\n)\n</code></pre>"},{"location":"concepts/registry/#2-existence-checks","title":"2. Existence Checks","text":"<pre><code># \u2705 GOOD - Always check before invoking\nasync def safe_delegate(agent_name: str, task: str):\n    if AgentRegistry.get(agent_name) is None:\n        logger.warning(f\"Agent {agent_name} not found\")\n        # Fallback logic\n        return await use_fallback_agent(task)\n\n    agent = AgentRegistry.get(agent_name)\n    return await agent.run(task)\n\n# \u274c BAD - Assuming agent exists\nasync def unsafe_delegate(agent_name: str, task: str):\n    agent = AgentRegistry.get(agent_name)\n    return await agent.run(task)  # Will fail if agent is None\n</code></pre>"},{"location":"concepts/registry/#3-resource-management","title":"3. Resource Management","text":"<pre><code># \u2705 GOOD - Use auto-cleanup in Orchestra\nresult = await Orchestra.run(\n    task=\"Process batch\",\n    topology=topology,\n    execution_config=ExecutionConfig(\n        auto_cleanup_agents=True  # Default - cleans up after run\n    )\n)\n# All topology agents automatically cleaned up and unregistered\n\n# \u2705 GOOD - Manual cleanup for standalone agents\nasync def process_batch(items):\n    temp_agent = Agent(\n        name=f\"batch_processor_{uuid.uuid4().hex[:8]}\",\n        model_config=config,\n        goal=\"Process batch items\",\n        instruction=\"Process each item and return concise structured output.\"\n    )\n\n    results = []\n    for item in items:\n        result = await temp_agent.run(f\"Process: {item}\")\n        results.append(result)\n\n    # Manual cleanup\n    await temp_agent.cleanup()\n    AgentRegistry.unregister_instance(temp_agent)\n\n    return results\n\n# \u274c BAD - Creating agents without cleanup\nfor i in range(1000):\n    Agent(\n        name=f\"worker_{i}\",\n        model_config=config,\n        goal=\"Temporary worker\",\n        instruction=\"Handle temporary workload.\"\n    )\n    # Creates 1000 agents with open aiohttp sessions, registry entries!\n</code></pre>"},{"location":"concepts/registry/#4-monitoring","title":"4. Monitoring","text":"<pre><code># \u2705 GOOD - Monitor registry health\nasync def monitor_registry():\n    \"\"\"Regular registry monitoring.\"\"\"\n    while True:\n        agents = list(AgentRegistry.all().keys())\n        logger.info(f\"Active agents: {len(agents)}\")\n\n        if len(agents) &gt; 100:\n            logger.warning(\"High agent count - possible leak\")\n\n        # Health checks\n        for agent_name in agents[:10]:  # Sample check\n            healthy = await HealthMonitor.check_agent_health(agent_name)\n            if not healthy:\n                logger.error(f\"Agent {agent_name} unhealthy\")\n\n        await asyncio.sleep(60)  # Check every minute\n</code></pre>"},{"location":"concepts/registry/#next-steps","title":"\ud83d\udea6 Next Steps","text":"<ul> <li> <p> Agents</p> <p>Learn about agent creation</p> </li> <li> <p> Communication</p> <p>How agents communicate</p> </li> <li> <p> Topology</p> <p>Agent organization patterns</p> </li> <li> <p> API Reference</p> <p>Complete registry API</p> </li> </ul> <p>Registry System Ready!</p> <p>You now understand the AgentRegistry in MARSYS. The registry provides robust service discovery and lifecycle management for dynamic multi-agent systems.</p>"},{"location":"concepts/run-filesystem/","title":"Run Filesystem (RunFileSystem)","text":"<p>MARSYS uses a run-scoped virtual filesystem to keep file paths consistent across tools, agents, and handoffs. This avoids the \u201cbrowser downloads to one folder, file tools read from another\u201d problem.</p>"},{"location":"concepts/run-filesystem/#overview","title":"Overview","text":"<p><code>RunFileSystem</code> provides a virtual POSIX path space for each run:</p> <ul> <li>All agent-facing paths are virtual and POSIX-style.</li> <li><code>/</code> is always the run root (the working root for that run).</li> <li>Paths are resolved with traversal protection (no escaping the run root).</li> <li>Optional mounts let you expose extra host folders at virtual prefixes.</li> </ul> <p>This lets every agent speak the same path language, even if they operate in different host directories.</p>"},{"location":"concepts/run-filesystem/#virtual-paths","title":"Virtual Paths","text":"<p>Use virtual paths everywhere between tools and agents:</p> <ul> <li>Preferred (tool-returned): <code>./downloads/report.pdf</code></li> <li>Also accepted: <code>/downloads/report.pdf</code></li> <li>Relative paths like <code>./data/summary.txt</code> are resolved against <code>RunFileSystem.cwd</code></li> </ul> <p>Tools that write files return virtual paths so other agents can read them without guessing host paths.</p>"},{"location":"concepts/run-filesystem/#creating-a-run-filesystem","title":"Creating a Run Filesystem","text":"<pre><code>from pathlib import Path\nfrom marsys.environment.filesystem import RunFileSystem\n\nrun_root = Path(\"./runs/run-20260206\")\nfs = RunFileSystem.local(\n    run_root=run_root,\n    cwd=\"/\",\n    extra_mounts={\n        \"/datasets\": Path(\"/shared/datasets\"),\n    },\n)\n</code></pre> <p>Key options:</p> <ul> <li><code>run_root</code>: host directory mounted at <code>/</code></li> <li><code>cwd</code>: initial virtual working directory</li> <li><code>extra_mounts</code>: map additional host paths to virtual prefixes</li> <li><code>memory_root</code>: convenience mount for <code>/memory</code></li> <li><code>allow_symlink_escape</code>: allow symlinks outside roots (off by default)</li> </ul>"},{"location":"concepts/run-filesystem/#sharing-across-agents","title":"Sharing Across Agents","text":"<p>To share files across agents, use the same run root or the same RunFileSystem:</p> <pre><code>from marsys.agents import FileOperationAgent, CodeExecutionAgent, DataAnalysisAgent\nfrom marsys.models import ModelConfig\n\nfs = RunFileSystem.local(run_root=Path(\"./runs/run-20260206\"))\n\nfile_agent = FileOperationAgent(model_config=config, name=\"files\", filesystem=fs)\ncode_agent = CodeExecutionAgent(model_config=config, name=\"code\", filesystem=fs)\ndata_agent = DataAnalysisAgent(model_config=config, name=\"data\", filesystem=fs)\n</code></pre> <p>Browser automation also uses a run filesystem internally. If you set <code>tmp_dir</code> to the same run root, downloads and screenshots will land under the same virtual paths:</p> <pre><code>browser = await BrowserAgent.create_safe(\n    model_config=config,\n    name=\"browser\",\n    tmp_dir=\"./runs/run-20260206\"\n)\n# Downloads will appear under ./downloads, screenshots under ./screenshots\n</code></pre> <p>If you need custom mounts to be visible to the browser too, pass the same <code>RunFileSystem</code> to <code>BrowserTool</code> or <code>BrowserAgent</code> (advanced usage).</p>"},{"location":"concepts/run-filesystem/#default-virtual-directories","title":"Default Virtual Directories","text":"<p>By convention, tools use these virtual folders:</p> <ul> <li><code>./downloads</code> \u2014 browser downloads</li> <li><code>./screenshots</code> \u2014 browser screenshots</li> <li><code>./outputs</code> \u2014 code execution images/artifacts</li> </ul> <p>These are just virtual paths under the run root unless you mount them elsewhere.</p>"},{"location":"concepts/run-filesystem/#path-mapping-example","title":"Path Mapping Example","text":"<pre><code>resolved = fs.resolve(\"./downloads/report.pdf\")\nresolved.virtual_path  # \"/downloads/report.pdf\"\nresolved.host_path     # \"/abs/path/to/runs/run-20260206/downloads/report.pdf\"\n\nfs.to_virtual(resolved.host_path)  # \"./downloads/report.pdf\"\n</code></pre>"},{"location":"concepts/run-filesystem/#why-it-matters","title":"Why It Matters","text":"<p>With <code>RunFileSystem</code>:</p> <ul> <li>Agents can safely pass file paths to each other.</li> <li>Tool outputs are consistent across handoffs.</li> <li>You can swap local storage for sandboxed or cloud-backed storage later without changing agent contracts.</li> </ul> <p>Use virtual paths everywhere in tool calls and agent prompts to keep workflows stable and portable.</p>"},{"location":"concepts/specialized-agents/","title":"Specialized Agents","text":"<p>MARSYS provides specialized agents that extend the base <code>Agent</code> class with domain-specific tools and instructions. These agents are production-ready and optimized for common tasks.</p>"},{"location":"concepts/specialized-agents/#overview","title":"Overview","text":"<p>Specialized agents combine:</p> <ul> <li>Domain-specific tools: Curated toolsets for specific tasks</li> <li>Scenario-based instructions: Adaptive guidance rather than rigid workflows</li> <li>Configurable capabilities: Enable/disable features based on requirements</li> <li>Security features: Built-in validation and safety mechanisms</li> </ul>"},{"location":"concepts/specialized-agents/#available-specialized-agents","title":"Available Specialized Agents","text":""},{"location":"concepts/specialized-agents/#browseragent","title":"BrowserAgent","text":"<p>Autonomous browser automation with vision-based interaction and screenshot analysis.</p> <p>Best for: Web scraping, UI testing, form filling, web research, dynamic content extraction</p> <p>Key Features: - Vision-based element interaction (no selectors needed) - Multi-mode operation (primitive, advanced) - Screenshot analysis with multimodal models - JavaScript execution and console monitoring - Auto-screenshot management with sliding window - Session persistence: Save and load browser sessions (cookies, localStorage) for persistent authentication - Tab management: List, switch, and close browser tabs programmatically</p> <p>Tools: Browser navigation, interaction, JavaScript execution, screenshot analysis, session management, tab management</p> <pre><code>from marsys.agents import BrowserAgent\n\n# BrowserAgent requires async creation via create_safe()\nagent = await BrowserAgent.create_safe(\n    model_config=config,\n    name=\"WebAutomation\",\n    mode=\"advanced\",  # \"primitive\" or \"advanced\"\n    headless=True,\n    session_path=\"./sessions/my_session.json\"  # Optional: load existing session\n)\n</code></pre> <p>Read Full Documentation \u2192</p>"},{"location":"concepts/specialized-agents/#fileoperationagent","title":"FileOperationAgent","text":"<p>Intelligent file and directory operations with optional shell command execution.</p> <p>Best for: Code analysis, configuration management, log processing, documentation generation</p> <p>Key Features: - Type-aware file handling (Python, JSON, PDF, Markdown, images) - Unified diff editing with high success rate - Content and structure search (ripgrep-based) - Optional shell tools for complex operations - Security: Command validation, blocked dangerous patterns, timeouts</p> <p>Tools: 6 file operation tools + 10 optional shell tools</p> <pre><code>from marsys.agents import FileOperationAgent\n\nagent = FileOperationAgent(\n    model_config=config,\n    name=\"FileHelper\",\n    enable_shell=True,  # Enable shell commands\n    allowed_shell_commands=[\"grep\", \"find\", \"wc\"]  # Whitelist\n)\n</code></pre> <p>To share files across agents, pass a shared <code>RunFileSystem</code> via <code>filesystem=...</code>. See Run Filesystem.</p> <p>Read Full Documentation \u2192</p>"},{"location":"concepts/specialized-agents/#codeexecutionagent","title":"CodeExecutionAgent","text":"<p>Code-first specialist that combines file operations with safe Python and shell execution.</p> <p>Best for: Running tests, scripts, build/lint workflows, automation tasks, reproducible code-driven debugging.</p> <p>Key Features: - Unified file + execution toolset (<code>read_file</code>/<code>edit_file</code> + <code>python_execute</code>/<code>shell_execute</code>) - Shared <code>RunFileSystem</code> support for consistent virtual paths across agents - Configurable <code>CodeExecutionConfig</code> for resource and security limits - Explicit cleanup support for persistent execution resources</p> <p>Tools: file operation tools + <code>python_execute</code> + <code>shell_execute</code></p> <pre><code>from marsys.agents import CodeExecutionAgent\n\nagent = CodeExecutionAgent(\n    model_config=config,\n    name=\"CodeRunner\",\n)\n</code></pre>"},{"location":"concepts/specialized-agents/#dataanalysisagent","title":"DataAnalysisAgent","text":"<p>Data-science oriented agent with persistent Python session behavior (Jupyter-like workflow).</p> <p>Best for: Iterative analysis, data exploration, statistical modeling, plotting, and experiment-style workflows.</p> <p>Key Features: - Persistent <code>python_execute</code> session by default (<code>session_persistent_python=True</code>) - File operations + execution tools in one agent - Shared <code>RunFileSystem</code> support for multi-agent handoffs - Designed for incremental analysis loops instead of one-shot commands</p> <p>Tools: file operation tools + persistent <code>python_execute</code> + <code>shell_execute</code></p> <pre><code>from marsys.agents import DataAnalysisAgent\n\nagent = DataAnalysisAgent(\n    model_config=config,\n    name=\"DataScientist\",\n)\n</code></pre>"},{"location":"concepts/specialized-agents/#websearchagent","title":"WebSearchAgent","text":"<p>Multi-source information gathering across web and scholarly databases.</p> <p>Best for: Research, fact-checking, literature reviews, current events</p> <p>Key Features: - Multi-source search (DuckDuckGo, Google, arXiv, Semantic Scholar, PubMed) - Configurable search modes (web, scholarly, or all) - API key validation at initialization - Query formulation strategies - Iterative refinement guidance</p> <p>Tools: Up to 8 search sources (configurable)</p> <pre><code>from marsys.agents import WebSearchAgent\n\nagent = WebSearchAgent(\n    model_config=config,\n    name=\"Researcher\",\n    search_mode=\"all\",  # \"web\", \"scholarly\", or \"all\"\n    include_google=False  # Avoid Google API key requirement\n)\n</code></pre> <p>Read Full Documentation \u2192</p>"},{"location":"concepts/specialized-agents/#comparison","title":"Comparison","text":"Agent Primary Use Case Tools API Keys Required Security Features BrowserAgent Web automation Browser control None Timeout enforcement, mode-based restrictions FileOperationAgent File system operations 6-16 tools None Command validation, blocked patterns CodeExecutionAgent Code + automation tasks File ops + Python + shell None Resource limits, blocked patterns, optional network disable DataAnalysisAgent Iterative data science workflows Persistent Python + file ops + shell None Resource limits, blocked patterns, persistent session controls WebSearchAgent Information gathering 1-8 sources Google (optional for Google tools)None (DuckDuckGo/scholarly basics) API key validation"},{"location":"concepts/specialized-agents/#common-patterns","title":"Common Patterns","text":""},{"location":"concepts/specialized-agents/#pattern-1-multi-agent-workflow","title":"Pattern 1: Multi-Agent Workflow","text":"<p>Combine specialized agents in a topology:</p> <pre><code>from marsys.coordination import Orchestra\nfrom marsys.coordination.topology.patterns import PatternConfig\nfrom marsys.agents import BrowserAgent, FileOperationAgent, DataAnalysisAgent, WebSearchAgent\n\nbrowser_agent = await BrowserAgent.create_safe(\n    model_config=config,\n    name=\"BrowserAgent\",\n    mode=\"primitive\"\n)\nfile_agent = FileOperationAgent(model_config=config, name=\"FileHelper\", enable_shell=True)\nanalysis_agent = DataAnalysisAgent(model_config=config, name=\"Analyzer\")\nsearch_agent = WebSearchAgent(model_config=config, name=\"Researcher\", search_mode=\"scholarly\")\n\ntopology = PatternConfig.hub_and_spoke(\n    hub=\"Coordinator\",\n    spokes=[\"BrowserAgent\", \"FileHelper\", \"Researcher\"]\n)\n\nresult = await Orchestra.run(\n    task=\"Research topic, scrape related websites, and analyze findings\",\n    topology=topology\n)\n</code></pre>"},{"location":"concepts/specialized-agents/#pattern-2-sequential-pipeline","title":"Pattern 2: Sequential Pipeline","text":"<p>Chain specialized agents for complex tasks:</p> <pre><code>topology = PatternConfig.pipeline(\n    stages=[\n        {\"name\": \"search\", \"agents\": [\"Researcher\"]},\n        {\"name\": \"scrape\", \"agents\": [\"BrowserAgent\"]},\n        {\"name\": \"analyze\", \"agents\": [\"FileHelper\"]},\n        {\"name\": \"report\", \"agents\": [\"ReportWriter\"]}\n    ]\n)\n</code></pre>"},{"location":"concepts/specialized-agents/#pattern-3-parallel-data-gathering","title":"Pattern 3: Parallel Data Gathering","text":"<p>Use agent pools for concurrent operations:</p> <pre><code>from marsys.agents import create_browser_agent_pool\n\n# Create pool of 3 browser instances\npool = await create_browser_agent_pool(\n    num_instances=3,\n    model_config=config,\n    mode=\"primitive\",\n    headless=True\n)\n\n# Pool is registered by default (register=True)\n# and automatically manages concurrent requests\n</code></pre>"},{"location":"concepts/specialized-agents/#pattern-4-conditional-tool-enabling","title":"Pattern 4: Conditional Tool Enabling","text":"<p>Enable features based on environment:</p> <pre><code># Production: restricted shell commands\nfile_agent = FileOperationAgent(\n    model_config=config,\n    name=\"FileHelper\",\n    enable_shell=True,\n    allowed_shell_commands=[\"grep\", \"find\", \"wc\", \"ls\"]\n)\n\n# Development: more permissive\nfile_agent = FileOperationAgent(\n    model_config=config,\n    name=\"FileHelperDev\",\n    enable_shell=True  # Uses default blocked list only\n)\n</code></pre>"},{"location":"concepts/specialized-agents/#creating-custom-specialized-agents","title":"Creating Custom Specialized Agents","text":"<p>To create your own specialized agent:</p> <ol> <li> <p>Extend Agent class:    <pre><code>from marsys.agents import Agent\n\nclass MySpecializedAgent(Agent):\n    def __init__(self, model_config, **kwargs):\n        # Initialize tools\n        tools = self._build_tools()\n\n        # Build instruction\n        instruction = self._build_instruction()\n\n        super().__init__(\n            model_config=model_config,\n            goal=\"Your goal here\",\n            instruction=instruction,\n            tools=tools,\n            **kwargs\n        )\n</code></pre></p> </li> <li> <p>Create domain-specific tools: Use classes like <code>FileOperationTools</code> or <code>SearchTools</code> as templates</p> </li> <li> <p>Write scenario-based instructions: Guide the agent on how to choose rather than prescribing steps</p> </li> <li> <p>Add validation: Validate configuration at initialization (API keys, paths, etc.)</p> </li> </ol> <p>See Custom Agents Guide for detailed instructions.</p>"},{"location":"concepts/specialized-agents/#tool-integration","title":"Tool Integration","text":"<p>Specialized agents use tool classes that provide:</p> <ul> <li>Structured output: Consistent Dict/JSON responses</li> <li>Error handling: Comprehensive error classification</li> <li>Configuration: Environment variables or explicit parameters</li> <li>Security: Validation, timeouts, output size limits</li> </ul> <p>Available tool classes:</p> <ul> <li>BrowserAgent Tools: Browser automation and control</li> <li>FileOperationTools: File system operations</li> <li>ShellTools: Shell command execution</li> <li>SearchTools: Multi-source search</li> </ul>"},{"location":"concepts/specialized-agents/#best-practices","title":"Best Practices","text":""},{"location":"concepts/specialized-agents/#1-choose-the-right-agent","title":"1. Choose the Right Agent","text":"<p>Use BrowserAgent when: - Interacting with dynamic web content - Need to fill forms or click buttons - Scraping JavaScript-rendered pages - Visual verification of web elements</p> <p>Use FileOperationAgent when: - Working with files on the local file system - Need shell commands for system integration - Analyzing codebases or processing logs</p> <p>Use CodeExecutionAgent when: - You need to execute Python/shell while editing files in the same workflow - Build/test/lint/automation loops are central to the task - You want strict execution controls via <code>CodeExecutionConfig</code></p> <p>Use DataAnalysisAgent when: - You need notebook-like iterative analysis with persistent Python state - You are exploring datasets across multiple execution steps - You need plotting/analysis artifacts while keeping shared virtual paths</p> <p>Use WebSearchAgent when: - Gathering information from online sources - Conducting research or fact-checking - Need both current web content and academic papers</p>"},{"location":"concepts/specialized-agents/#2-configure-security-appropriately","title":"2. Configure Security Appropriately","text":"<pre><code># BrowserAgent: production mode\nagent = await BrowserAgent.create_safe(\n    model_config=config,\n    name=\"WebAutomation\",\n    mode=\"advanced\",\n    headless=True,\n    auto_screenshot=False,\n    timeout=8000\n)\n\n# FileOperationAgent: strict whitelist\nagent = FileOperationAgent(\n    model_config=config,\n    name=\"FileHelper\",\n    enable_shell=True,\n    allowed_shell_commands=[\"grep\", \"find\", \"wc\"]\n)\n</code></pre>"},{"location":"concepts/specialized-agents/#3-handle-missing-api-keys-gracefully","title":"3. Handle Missing API Keys Gracefully","text":"<pre><code>try:\n    search_agent = WebSearchAgent(\n        model_config=config,\n        name=\"Researcher\",\n        search_mode=\"web\",\n        include_google=True,\n        google_api_key=os.getenv(\"GOOGLE_SEARCH_API_KEY\"),\n        google_cse_id=os.getenv(\"GOOGLE_CSE_ID_GENERIC\"),\n    )\nexcept ValueError as e:\n    print(f\"Missing API key: {e}\")\n    # Fall back to scholarly-only mode\n    search_agent = WebSearchAgent(model_config=config, name=\"Researcher\", search_mode=\"scholarly\")\n</code></pre>"},{"location":"concepts/specialized-agents/#4-use-scenario-based-instructions","title":"4. Use Scenario-Based Instructions","text":"<p>Specialized agents use scenario-based instructions that adapt to context:</p> <pre><code>**When you don't have complete context**:\n- List directories to understand structure before assuming paths\n- Take screenshots to see page state before interacting\n- Read file headers or samples before processing large files\n\n**When operations don't work as expected**:\n- File not found: List the directory to see what actually exists\n- Element not found: Take screenshot to verify page loaded correctly\n- No search results: Try broader terms, different file types\n</code></pre> <p>This approach is more flexible than step-by-step workflows.</p>"},{"location":"concepts/specialized-agents/#agent-pools-for-parallel-execution","title":"Agent Pools for Parallel Execution","text":"<p>Some specialized agents support pooling for true parallel execution:</p> <pre><code>from marsys.agents import create_browser_agent_pool\n\n# Create pool\npool = await create_browser_agent_pool(\n    num_instances=3,\n    model_config=config,\n    mode=\"advanced\"\n)\n\n# Acquire instance for task\nasync with pool.acquire(branch_id=\"task_1\") as agent:\n    result = await agent.run(\"Navigate to example.com\")\n\n# Pool handles instance allocation and release\n</code></pre> <p>Benefits: - True parallelism (separate instances, no shared state) - Automatic instance management - Fair allocation with queuing - Resource cleanup</p>"},{"location":"concepts/specialized-agents/#related-documentation","title":"Related Documentation","text":"<ul> <li>Base Agent API</li> <li>Tool Development Guide</li> <li>Multi-Agent Coordination</li> <li>Custom Agent Development</li> <li>Browser Automation Concepts</li> </ul>"},{"location":"concepts/specialized-agents/#support","title":"Support","text":"<p>For issues or questions: - GitHub Issues: Report bugs or request features - Examples: Check <code>examples/agents/</code> for usage patterns - Tests: Check <code>tests/agents/</code> for integration examples</p>"},{"location":"concepts/state-management/","title":"State Management","text":"<p>State persistence and checkpointing for long-running workflows.</p>"},{"location":"concepts/state-management/#overview","title":"Overview","text":"<p>The state management system enables:</p> <ul> <li>Pause and Resume: Stop execution and continue later</li> <li>Checkpointing: Save snapshots at critical points</li> <li>Session Recovery: Recover from failures</li> <li>State Persistence: Long-term workflow storage</li> </ul>"},{"location":"concepts/state-management/#core-components","title":"Core Components","text":""},{"location":"concepts/state-management/#statemanager","title":"StateManager","text":"<p>The main interface for state management:</p> <pre><code>from marsys.coordination.state import StateManager, FileStorageBackend\nfrom pathlib import Path\n\n# Initialize with storage backend\nstorage = FileStorageBackend(Path(\"./state\"))\nstate_manager = StateManager(storage_backend=storage)\n</code></pre> <p>Constructor: <pre><code>StateManager(storage_backend: StorageBackend)\n</code></pre></p> <p>The StateManager only takes a single parameter: the storage backend to use for persistence.</p>"},{"location":"concepts/state-management/#storagebackend","title":"StorageBackend","text":"<p>Abstract base class for storage implementations:</p> <pre><code>class StorageBackend(ABC):\n    async def save(self, key: str, data: Dict[str, Any]) -&gt; None\n    async def load(self, key: str) -&gt; Optional[Dict[str, Any]]\n    async def delete(self, key: str) -&gt; None\n    async def list_keys(self, prefix: str = \"\") -&gt; List[str]\n    async def exists(self, key: str) -&gt; bool\n</code></pre>"},{"location":"concepts/state-management/#filestoragebackend","title":"FileStorageBackend","text":"<p>Local file system storage (the only backend currently implemented):</p> <pre><code>from marsys.coordination.state import FileStorageBackend\nfrom pathlib import Path\n\nstorage = FileStorageBackend(base_path=Path(\"./state\"))\n</code></pre> <p>The FileStorageBackend: - Creates subdirectories for <code>sessions</code> and <code>checkpoints</code> - Stores data as JSON files - Uses the <code>base_path</code> parameter only</p>"},{"location":"concepts/state-management/#statesnapshot","title":"StateSnapshot","text":"<p>Internal dataclass for execution state:</p> <pre><code>@dataclass\nclass StateSnapshot:\n    session_id: str\n    timestamp: float\n    branches: Dict[str, Dict[str, Any]]\n    active_branches: Set[str]\n    completed_branches: Set[str]\n    waiting_branches: Dict[str, Set[str]]\n    branch_results: Dict[str, Dict[str, Any]]\n    parent_child_map: Dict[str, List[str]]\n    child_parent_map: Dict[str, str]\n    metadata: Dict[str, Any]\n    checksum: Optional[str]\n</code></pre>"},{"location":"concepts/state-management/#basic-usage","title":"Basic Usage","text":""},{"location":"concepts/state-management/#enable-state-management","title":"Enable State Management","text":"<pre><code>from marsys.coordination import Orchestra\nfrom marsys.coordination.state import StateManager, FileStorageBackend\n\n# Create state manager\nstate_manager = StateManager(\n    storage_backend=FileStorageBackend(\"./state\")\n)\n\n# Run with state management\nresult = await Orchestra.run(\n    task=\"Long-running research task\",\n    topology=topology,\n    state_manager=state_manager,\n    context={\"session_id\": \"research_2024\"}\n)\n</code></pre>"},{"location":"concepts/state-management/#statemanager-methods","title":"StateManager Methods","text":"<pre><code># Save session state\nawait state_manager.save_session(session_id, state)\n\n# Load session state\nstate = await state_manager.load_session(session_id)\n\n# Create checkpoint\ncheckpoint_id = await state_manager.create_checkpoint(\n    session_id,\n    name=\"before_critical_section\"\n)\n\n# Restore from checkpoint\nstate = await state_manager.restore_checkpoint(checkpoint_id)\n\n# List sessions\nsessions = await state_manager.list_sessions()\n\n# List checkpoints\ncheckpoints = await state_manager.list_checkpoints(session_id)\n</code></pre>"},{"location":"concepts/state-management/#checkpointing","title":"Checkpointing","text":""},{"location":"concepts/state-management/#manual-checkpoints","title":"Manual Checkpoints","text":"<p>Create checkpoints at critical points:</p> <pre><code># Create checkpoint before risky operation\ncheckpoint_id = await state_manager.create_checkpoint(\n    session_id=\"session_123\",\n    name=\"before_data_processing\"\n)\n\ntry:\n    # Risky operation\n    result = await process_data()\nexcept Exception as e:\n    # Restore from checkpoint\n    state = await state_manager.restore_checkpoint(checkpoint_id)\n    # Try alternative approach\n    result = await process_data_alternative()\n</code></pre>"},{"location":"concepts/state-management/#checkpoint-naming","title":"Checkpoint Naming","text":"<p>Checkpoints are stored with keys like <code>checkpoint_{session_id}_{name}_{timestamp}</code>.</p>"},{"location":"concepts/state-management/#example-workflow","title":"Example Workflow","text":"<pre><code>from marsys.coordination import Orchestra\nfrom marsys.coordination.state import StateManager, FileStorageBackend\nfrom pathlib import Path\n\n# Setup\nstorage = FileStorageBackend(Path(\"./workflow_state\"))\nstate_manager = StateManager(storage_backend=storage)\n\n# Start workflow\nresult = await Orchestra.run(\n    task=\"Analyze large dataset\",\n    topology=topology,\n    state_manager=state_manager,\n    context={\"session_id\": \"analysis_123\"}\n)\n\n# Create checkpoint after first phase\ncheckpoint_id = await state_manager.create_checkpoint(\n    \"analysis_123\",\n    name=\"after_initial_analysis\"\n)\n\n# Continue with more processing\n# If something fails, restore from checkpoint\n</code></pre>"},{"location":"concepts/state-management/#best-practices","title":"Best Practices","text":""},{"location":"concepts/state-management/#1-use-meaningful-session-ids","title":"1. Use Meaningful Session IDs","text":"<pre><code># Good - descriptive and unique\ncontext = {\"session_id\": \"market_analysis_2024_q1\"}\n\n# Bad - generic\ncontext = {\"session_id\": \"session1\"}\n</code></pre>"},{"location":"concepts/state-management/#2-checkpoint-before-critical-operations","title":"2. Checkpoint Before Critical Operations","text":"<pre><code>checkpoint_id = await state_manager.create_checkpoint(\n    session_id,\n    name=\"before_external_api_call\"\n)\n</code></pre>"},{"location":"concepts/state-management/#3-clean-up-old-sessions","title":"3. Clean Up Old Sessions","text":"<pre><code># List and delete old sessions\nsessions = await state_manager.list_sessions()\nfor session in sessions:\n    if session.timestamp &lt; cutoff_time:\n        await state_manager.delete_session(session.session_id)\n</code></pre>"},{"location":"concepts/state-management/#limitations","title":"Limitations","text":"<p>The current implementation:</p> <ul> <li>Only supports <code>FileStorageBackend</code> (Redis and Database backends are not yet implemented)</li> <li>Does not have automatic checkpointing (must be done manually)</li> <li>Does not support compression or encryption (use at file system level if needed)</li> </ul>"},{"location":"concepts/state-management/#related-documentation","title":"Related Documentation","text":"<ul> <li>Orchestra API - Using state management with Orchestra</li> <li>Configuration - Execution configuration</li> </ul>"},{"location":"concepts/tools/","title":"Tools","text":"<p>Tools extend agent capabilities by providing access to external functions, APIs, and services, enabling agents to interact with the real world.</p> <p>See Also</p> <p>For tool schema structure and API details, see Tools API Reference. For built-in tools list, see Built-in Tools Guide.</p>"},{"location":"concepts/tools/#overview","title":"\ud83c\udfaf Overview","text":"<p>Tools in MARSYS are Python functions that agents can invoke to:</p> <ul> <li>Access External Services: Web search, APIs, databases</li> <li>Perform Calculations: Mathematical operations, data analysis</li> <li>Control Systems: Browser automation, file operations</li> <li>Process Data: Text extraction, format conversion</li> <li>Interact with Environment: System commands, hardware control</li> </ul> <p>The framework uses OpenAI-compatible function calling for seamless tool integration.</p>"},{"location":"concepts/tools/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<pre><code>graph TB\n    subgraph \"Tool System\"\n        TS[Tool Schema&lt;br/&gt;Auto-generated]\n        TE[Tool Executor&lt;br/&gt;Safe Execution]\n        TR[Tool Registry&lt;br/&gt;Global/Local]\n    end\n\n    subgraph \"Tool Types\"\n        BT[Built-in Tools&lt;br/&gt;Standard Library]\n        CT[Custom Tools&lt;br/&gt;User Defined]\n        AT[Async Tools&lt;br/&gt;Non-blocking]\n        ST[Stateful Tools&lt;br/&gt;Persistent State]\n    end\n\n    subgraph \"Flow\"\n        A[Agent] --&gt; LLM[Language Model]\n        LLM --&gt; TC[Tool Call Decision]\n        TC --&gt; TE\n        TE --&gt; T[Tool Function]\n        T --&gt; R[Result]\n        R --&gt; A\n    end\n\n    TS --&gt; LLM\n    TR --&gt; TE\n    BT --&gt; TR\n    CT --&gt; TR\n\n    style TS fill:#4fc3f7\n    style TE fill:#29b6f6\n    style TR fill:#e1f5fe</code></pre>"},{"location":"concepts/tools/#creating-tools","title":"\ud83d\udce6 Creating Tools","text":""},{"location":"concepts/tools/#basic-tool-definition","title":"Basic Tool Definition","text":"<p>Every tool needs: 1. Type hints on all parameters 2. Comprehensive docstring with Args and Returns 3. Return type annotation 4. Descriptive parameter names</p> <pre><code>def search_database(\n    query: str,\n    database: str = \"products\",\n    limit: int = 10,\n    filters: Optional[Dict[str, Any]] = None\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"\n    Search database for matching records.\n\n    Args:\n        query: Search query string\n        database: Database to search (products, users, orders)\n        limit: Maximum number of results to return\n        filters: Additional filters as key-value pairs\n\n    Returns:\n        List of matching records with all fields\n\n    Raises:\n        ConnectionError: If database is unavailable\n        ValueError: If query is invalid\n    \"\"\"\n    # Implementation\n    results = perform_search(query, database, limit, filters)\n    return results\n</code></pre>"},{"location":"concepts/tools/#automatic-schema-generation","title":"Automatic Schema Generation","text":"<p>The framework automatically generates OpenAI-compatible schemas:</p> <pre><code>from marsys.environment.utils import generate_openai_tool_schema\n\n# Automatic schema generation from function\nschema = generate_openai_tool_schema(search_database)\n\n# Generated schema:\n{\n    \"type\": \"function\",\n    \"function\": {\n        \"name\": \"search_database\",\n        \"description\": \"Search database for matching records.\",\n        \"parameters\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"query\": {\n                    \"type\": \"string\",\n                    \"description\": \"Search query string\"\n                },\n                \"database\": {\n                    \"type\": \"string\",\n                    \"description\": \"Database to search (products, users, orders)\",\n                    \"default\": \"products\"\n                },\n                \"limit\": {\n                    \"type\": \"integer\",\n                    \"description\": \"Maximum number of results to return\",\n                    \"default\": 10\n                },\n                \"filters\": {\n                    \"type\": \"object\",\n                    \"description\": \"Additional filters as key-value pairs\"\n                }\n            },\n            \"required\": [\"query\"]\n        }\n    }\n}\n</code></pre>"},{"location":"concepts/tools/#tool-registration","title":"\ud83d\udd27 Tool Registration","text":""},{"location":"concepts/tools/#agent-specific-tools","title":"Agent-Specific Tools","text":"<pre><code>from marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\nagent = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\",\n        max_tokens=12000\n    ),\n    name=\"DataAnalyst\",\n    goal=\"Expert data analyst with database access\",\n    instruction=\"You are a data analyst. Use your tools to search databases, analyze data, and export results.\",\n    tools={  # Dict mapping names to functions\n        \"db_search\": search_database,\n        \"analyze\": analyze_data,\n        \"export\": export_results\n    }\n)\n</code></pre>"},{"location":"concepts/tools/#global-tool-registry","title":"Global Tool Registry","text":"<pre><code>from marsys.environment.tools import AVAILABLE_TOOLS\n\n# Register globally\nAVAILABLE_TOOLS[\"search_database\"] = search_database\nAVAILABLE_TOOLS[\"analyze_data\"] = analyze_data\n\n# Discover tools by category\nWEB_TOOLS = {\n    \"search_web\": search_web_func,\n    \"fetch_url\": fetch_url_func,\n    \"scrape_page\": scrape_page_func\n}\n\nDATA_TOOLS = {\n    \"analyze_csv\": analyze_csv_func,\n    \"process_json\": process_json_func,\n    \"transform_data\": transform_data_func\n}\n\n# Combine categories\nAVAILABLE_TOOLS.update(WEB_TOOLS)\nAVAILABLE_TOOLS.update(DATA_TOOLS)\n</code></pre>"},{"location":"concepts/tools/#tool-patterns","title":"\ud83c\udfaf Tool Patterns","text":""},{"location":"concepts/tools/#async-tools","title":"Async Tools","text":"<p>For non-blocking operations:</p> <pre><code>import aiohttp\nimport asyncio\n\nasync def fetch_api_data(\n    endpoint: str,\n    params: Optional[Dict[str, str]] = None,\n    timeout: int = 30\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Fetch data from API endpoint asynchronously.\n\n    Args:\n        endpoint: API endpoint URL\n        params: Query parameters\n        timeout: Request timeout in seconds\n\n    Returns:\n        API response data\n    \"\"\"\n    try:\n        async with aiohttp.ClientSession() as session:\n            async with session.get(\n                endpoint,\n                params=params,\n                timeout=aiohttp.ClientTimeout(total=timeout)\n            ) as response:\n                data = await response.json()\n                return {\n                    \"status\": response.status,\n                    \"data\": data,\n                    \"headers\": dict(response.headers)\n                }\n    except asyncio.TimeoutError:\n        return {\"error\": \"Request timed out\", \"timeout\": timeout}\n    except Exception as e:\n        return {\"error\": str(e)}\n</code></pre>"},{"location":"concepts/tools/#stateful-tools","title":"Stateful Tools","text":"<p>Tools that maintain state across calls:</p> <pre><code>class DatabaseConnection:\n    def __init__(self, connection_string: str):\n        self.connection = self._connect(connection_string)\n        self.query_cache = {}\n\n    async def query(\n        self,\n        sql: str,\n        params: Optional[tuple] = None,\n        use_cache: bool = False\n    ) -&gt; List[Dict]:\n        \"\"\"\n        Execute SQL query with optional caching.\n\n        Args:\n            sql: SQL query string\n            params: Query parameters for prepared statement\n            use_cache: Whether to use cached results\n\n        Returns:\n            Query results as list of dictionaries\n        \"\"\"\n        cache_key = f\"{sql}:{params}\"\n\n        if use_cache and cache_key in self.query_cache:\n            return self.query_cache[cache_key]\n\n        try:\n            cursor = await self.connection.execute(sql, params or ())\n            results = await cursor.fetchall()\n\n            if use_cache:\n                self.query_cache[cache_key] = results\n\n            return results\n        except Exception as e:\n            return [{\"error\": str(e)}]\n\n# Create instance and extract tool\ndb = DatabaseConnection(\"postgresql://...\")\nquery_tool = db.query  # This method becomes the tool\n</code></pre>"},{"location":"concepts/tools/#composite-tools","title":"Composite Tools","text":"<p>Tools that combine multiple operations:</p> <pre><code>async def research_topic(\n    topic: str,\n    depth: Literal[\"shallow\", \"medium\", \"deep\"] = \"medium\",\n    include_sources: bool = True\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Comprehensive research on a topic from multiple sources.\n\n    Args:\n        topic: Topic to research\n        depth: Research depth level\n        include_sources: Whether to include source URLs\n\n    Returns:\n        Research summary with sources and key points\n    \"\"\"\n    # Determine number of sources based on depth\n    source_count = {\"shallow\": 3, \"medium\": 5, \"deep\": 10}[depth]\n\n    # Phase 1: Web search\n    search_results = await search_web(topic, max_results=source_count)\n\n    # Phase 2: Fetch and analyze content\n    contents = []\n    for result in search_results:\n        content = await fetch_url_content(result[\"url\"])\n        contents.append({\n            \"url\": result[\"url\"],\n            \"title\": result[\"title\"],\n            \"content\": content\n        })\n\n    # Phase 3: Synthesize information\n    key_points = extract_key_points(contents)\n    summary = create_summary(key_points)\n\n    response = {\n        \"topic\": topic,\n        \"summary\": summary,\n        \"key_points\": key_points,\n        \"source_count\": len(contents)\n    }\n\n    if include_sources:\n        response[\"sources\"] = [\n            {\"title\": c[\"title\"], \"url\": c[\"url\"]}\n            for c in contents\n        ]\n\n    return response\n</code></pre>"},{"location":"concepts/tools/#error-handling-tools","title":"Error-Handling Tools","text":"<p>Robust tools with proper error handling:</p> <pre><code>from functools import wraps\nfrom typing import Callable\n\ndef safe_tool(func: Callable) -&gt; Callable:\n    \"\"\"Decorator for safe tool execution.\"\"\"\n\n    @wraps(func)\n    async def async_wrapper(*args, **kwargs):\n        try:\n            result = await func(*args, **kwargs)\n            return {\"success\": True, \"result\": result}\n        except ValueError as e:\n            return {\"success\": False, \"error\": f\"Invalid input: {e}\"}\n        except TimeoutError as e:\n            return {\"success\": False, \"error\": f\"Operation timed out: {e}\"}\n        except Exception as e:\n            return {\"success\": False, \"error\": f\"Unexpected error: {e}\"}\n\n    @wraps(func)\n    def sync_wrapper(*args, **kwargs):\n        try:\n            result = func(*args, **kwargs)\n            return {\"success\": True, \"result\": result}\n        except Exception as e:\n            return {\"success\": False, \"error\": str(e)}\n\n    if asyncio.iscoroutinefunction(func):\n        return async_wrapper\n    else:\n        return sync_wrapper\n\n# Usage\n@safe_tool\nasync def risky_operation(param: str) -&gt; str:\n    \"\"\"Operation that might fail.\"\"\"\n    if not param:\n        raise ValueError(\"Parameter cannot be empty\")\n    # Risky operation here\n    return f\"Processed: {param}\"\n</code></pre>"},{"location":"concepts/tools/#built-in-tools","title":"\ud83d\ude80 Built-in Tools","text":"<p>MARSYS includes a comprehensive tool library:</p>"},{"location":"concepts/tools/#web-tools","title":"Web Tools","text":"<pre><code>async def search_web(\n    query: str,\n    max_results: int = 5,\n    search_engine: Literal[\"google\", \"bing\", \"duckduckgo\"] = \"google\"\n) -&gt; List[Dict[str, str]]:\n    \"\"\"Search the web for information.\"\"\"\n    # Returns: [{\"title\": \"...\", \"url\": \"...\", \"snippet\": \"...\"}]\n\nasync def fetch_url_content(\n    url: str,\n    format: Literal[\"text\", \"markdown\", \"html\"] = \"text\"\n) -&gt; str:\n    \"\"\"Fetch and extract content from URL.\"\"\"\n    # Returns formatted content\n\nasync def check_website_status(url: str) -&gt; Dict[str, Any]:\n    \"\"\"Check if website is accessible.\"\"\"\n    # Returns: {\"online\": bool, \"status_code\": int, \"response_time\": float}\n</code></pre>"},{"location":"concepts/tools/#data-processing-tools","title":"Data Processing Tools","text":"<pre><code>def analyze_data(\n    data: List[float],\n    operations: List[Literal[\"mean\", \"median\", \"std\", \"min\", \"max\"]]\n) -&gt; Dict[str, float]:\n    \"\"\"Perform statistical analysis on data.\"\"\"\n    # Returns: {\"mean\": 5.2, \"std\": 1.3, ...}\n\ndef transform_json(\n    json_data: Dict,\n    jq_filter: str\n) -&gt; Any:\n    \"\"\"Transform JSON using JQ-like syntax.\"\"\"\n    # Returns transformed data\n\ndef parse_csv(\n    csv_text: str,\n    delimiter: str = \",\",\n    has_headers: bool = True\n) -&gt; List[Dict[str, str]]:\n    \"\"\"Parse CSV text into records.\"\"\"\n    # Returns list of dictionaries\n</code></pre>"},{"location":"concepts/tools/#file-system-tools","title":"File System Tools","text":"<p>File tool paths are virtual POSIX paths resolved by the run filesystem. See Run Filesystem.</p> <pre><code>async def read_file(\n    path: str,\n    encoding: str = \"utf-8\",\n    lines: Optional[Tuple[int, int]] = None\n) -&gt; str:\n    \"\"\"Read file contents.\"\"\"\n    # Returns file content\n\nasync def write_file(\n    path: str,\n    content: str,\n    mode: Literal[\"write\", \"append\"] = \"write\"\n) -&gt; Dict[str, Any]:\n    \"\"\"Write content to file.\"\"\"\n    # Returns: {\"success\": bool, \"bytes_written\": int}\n\nasync def list_directory(\n    path: str = \".\",\n    pattern: Optional[str] = None\n) -&gt; List[Dict[str, Any]]:\n    \"\"\"List directory contents.\"\"\"\n    # Returns: [{\"name\": \"...\", \"type\": \"file|dir\", \"size\": int}]\n</code></pre>"},{"location":"concepts/tools/#pdf-tools-with-image-extraction","title":"PDF Tools with Image Extraction","text":"<p>MARSYS supports extracting embedded images from PDFs using PyMuPDF, returning content as ordered chunks that preserve reading order.</p>"},{"location":"concepts/tools/#basic-pdf-reading","title":"Basic PDF Reading","text":"<pre><code># Text-only extraction (default)\nasync def read_pdf_text(path: str) -&gt; ToolResponse:\n    from marsys.environment.file_operations import read_file_wrapper\n\n    result = await read_file_wrapper(\n        path=\"document.pdf\",\n        start_page=1,\n        end_page=5\n    )\n    return result\n\n# Returns: ToolResponse with text content only\n</code></pre>"},{"location":"concepts/tools/#pdf-with-image-extraction","title":"PDF with Image Extraction","text":"<pre><code># Extract text + images in reading order\nasync def read_pdf_with_images(path: str) -&gt; ToolResponse:\n    from marsys.environment.file_operations import read_file_wrapper\n\n    result = await read_file_wrapper(\n        path=\"paper.pdf\",\n        start_page=5,\n        end_page=10,\n        extract_images=True,  # Enable image extraction\n        max_images_per_page=10,\n        max_pixels=None  # Optional: downsample large images\n    )\n    return result\n\n# Returns: ToolResponse with ordered text/image content blocks\n</code></pre>"},{"location":"concepts/tools/#what-gets-extracted","title":"What Gets Extracted","text":"<p>When <code>extract_images=True</code>: - Text blocks: Paragraphs, headings, captions - Embedded images: Figures, photos, diagrams, charts - Reading order: Content sorted by Y-position (top-to-bottom) then X-position - Metadata: Page numbers, bounding boxes, token estimates</p> <p>What does NOT get extracted: - Background images or watermarks (usually) - Text rendered as images (use OCR separately) - Vector graphics (converted to raster if possible)</p>"},{"location":"concepts/tools/#ordered-chunks-format","title":"Ordered Chunks Format","text":"<p>The framework creates <code>FileContent</code> with:</p> <pre><code>FileContent(\n    content=\"Text with placeholders:\\n\\nChapter 1...\\n\\n[IMAGE 1: 800x600, ~170 tokens, page 5]\\n\\n...\",\n    images=[ImageData(...), ImageData(...), ...],  # Ordered list\n    metadata={\n        'ordered_chunks': [\n            {\"type\": \"text\", \"text\": \"Chapter 1...\", \"page\": 5, \"block_num\": 0},\n            {\"type\": \"image\", \"image_index\": 0, \"page\": 5, \"block_num\": 1,\n             \"dimensions\": \"800x600\", \"tokens\": 170},\n            {\"type\": \"text\", \"text\": \"Figure 1 shows...\", \"page\": 5, \"block_num\": 2},\n            ...\n        ],\n        'total_pages': 20,\n        'pages_read': \"5-10\",\n        'images_extracted': 3,\n        'total_image_tokens': 510\n    }\n)\n</code></pre>"},{"location":"concepts/tools/#conversion-to-toolresponse","title":"Conversion to ToolResponse","text":"<p><code>FileContent.to_tool_response()</code> automatically converts ordered chunks to multimodal format:</p> <pre><code>ToolResponse(\n    content=[\n        ToolResponseContent(type=\"text\", text=\"Chapter 1: Introduction\\n...\"),\n        ToolResponseContent(type=\"image\", image_data=\"data:image/png;base64,iVBORw...\"),\n        ToolResponseContent(type=\"text\", text=\"Figure 1: Architecture diagram\\n...\"),\n        ToolResponseContent(type=\"image\", image_data=\"data:image/jpeg;base64,/9j...\"),\n        ToolResponseContent(type=\"text\", text=\"The system consists of...\\n...\"),\n    ],\n    metadata={\n        \"path\": \"paper.pdf\",\n        \"partial\": True,\n        \"total_pages\": 20,\n        \"pages_shown\": \"5-10\",\n        \"has_images\": True,\n        \"image_count\": 2,\n        \"total_image_tokens\": 340\n    }\n)\n</code></pre>"},{"location":"concepts/tools/#token-cost-comparison","title":"Token Cost Comparison","text":"Extraction Method Text Tokens Vision Tokens Cost (GPT-4o) Text-only ~5,000 0 $0.05 Images as base64 strings ~255,000 0 $2.55 \u274c Images with ToolResponse ~5,000 ~425 $0.055 \u2705 <p>Savings: ~46x cheaper when using proper image extraction vs treating images as text!</p>"},{"location":"concepts/tools/#agent-tool-schema","title":"Agent Tool Schema","text":"<p>When you register <code>read_file_wrapper</code> as an agent tool, include <code>extract_images</code> parameter:</p> <pre><code>from marsys.environment.file_operations import FileOperationsManager\nfrom marsys.agents import Agent\n\n# Create file operations manager\nfile_ops = FileOperationsManager()\n\n# Get tool wrappers (automatically includes extract_images parameter)\ntools = file_ops.get_tool_wrappers()\n\nagent = Agent(\n    model_config=gpt4_vision_config,\n    name=\"DocumentAnalyzer\",\n    goal=\"Analyze document sections with text and figures\",\n    instruction=\"Use read_file to inspect requested pages and summarize findings.\",\n    tools={\"read_file\": tools[\"read_file\"]}  # Auto-generates schema with extract_images param\n)\n\n# Agent can now call:\n{\n    \"tool\": \"read_file\",\n    \"arguments\": {\n        \"path\": \"report.pdf\",\n        \"start_page\": 10,\n        \"end_page\": 15,\n        \"extract_images\": true\n    }\n}\n</code></pre>"},{"location":"concepts/tools/#requirements","title":"Requirements","text":"<p>Dependencies: <pre><code># Install with file operations support\npip install marsys[file-ops]\n\n# Or manually\npip install PyMuPDF&gt;=1.23.0\n</code></pre></p> <p>Graceful Degradation: - If PyMuPDF not installed: PDF support will be disabled - Warning logged: \"PyMuPDF not installed. PDF support will be disabled.\"</p>"},{"location":"concepts/tools/#best-practices","title":"Best Practices","text":"<p>\u2705 DO: <pre><code># Use extract_images for documents with figures/diagrams\nresult = await read_file_wrapper(\"paper.pdf\", extract_images=True)\n\n# Set max_images_per_page to avoid overwhelming the model\nresult = await read_file_wrapper(\"paper.pdf\", extract_images=True, max_images_per_page=5)\n\n# Use vision-capable models (GPT-4V, Claude 3, Gemini Pro Vision)\nagent = Agent(\n    model_config=gpt4_vision_config,\n    goal=\"Analyze multimodal document content\",\n    instruction=\"Use read_file_wrapper when extracting PDF sections and images.\",\n    tools={\"read_file_wrapper\": read_file_wrapper}\n)\n</code></pre></p> <p>\u274c DON'T: <pre><code># Don't extract images with non-vision models\nagent = Agent(model_config=gpt3_5_config, ...)  # No vision support!\nresult = await read_file_wrapper(\"paper.pdf\", extract_images=True)  # Wasted extraction\n\n# Don't extract too many pages at once (token limits)\nresult = await read_file_wrapper(\"book.pdf\", end_page=500, extract_images=True)  # Too much!\n</code></pre></p>"},{"location":"concepts/tools/#example-research-paper-analysis","title":"Example: Research Paper Analysis","text":"<pre><code>from marsys.agents import Agent\nfrom marsys.environment.file_operations import FileOperationsManager\n\n# Create file operations manager\nfile_ops = FileOperationsManager()\ntools = file_ops.get_tool_wrappers()\n\n# Create vision-capable agent\nanalyst = Agent(\n    model_config=gpt4_vision_config,\n    name=\"PaperAnalyst\",\n    goal=\"Analyze research papers including text, figures, and tables\",\n    instruction=\"Analyze research papers including figures and tables.\",\n    tools={\"read_file\": tools[\"read_file\"]}\n)\n\n# Agent prompt\ntask = \"\"\"\nRead pages 5-10 of 'quantum_computing.pdf' with images.\nSummarize the key findings and describe Figure 3.\n\"\"\"\n\n# Agent calls tool:\nresponse = await analyst.run(task)\n\n# Behind the scenes:\n# 1. Tool call: read_file(path=\"quantum_computing.pdf\", start_page=5, end_page=10, extract_images=True)\n# 2. Framework extracts 6 pages with 4 embedded images\n# 3. Returns ToolResponse with ordered text + image blocks\n# 4. LLM receives multimodal message with properly typed images\n# 5. LLM can \"see\" Figure 3 and describe it accurately\n</code></pre>"},{"location":"concepts/tools/#best-practices_1","title":"\ud83d\udccb Best Practices","text":""},{"location":"concepts/tools/#1-clear-documentation","title":"1. Clear Documentation","text":"<pre><code># \u2705 GOOD - Comprehensive documentation\ndef process_invoice(\n    invoice_data: Dict[str, Any],\n    validation_level: Literal[\"basic\", \"strict\"] = \"basic\",\n    currency: str = \"USD\"\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Process and validate invoice data.\n\n    Args:\n        invoice_data: Invoice information containing:\n            - invoice_number (str): Unique invoice identifier\n            - amount (float): Total amount\n            - items (list): Line items\n        validation_level: How strictly to validate\n        currency: Currency code for amount conversion\n\n    Returns:\n        Processed invoice with:\n            - status: \"valid\" or \"invalid\"\n            - processed_amount: Converted amount\n            - warnings: List of validation warnings\n\n    Raises:\n        ValueError: If invoice_data is malformed\n        KeyError: If required fields are missing\n    \"\"\"\n    # Implementation\n    pass\n\n# \u274c BAD - Poor documentation\ndef process(data, level=\"basic\"):\n    \"\"\"Process data.\"\"\"\n    pass\n</code></pre>"},{"location":"concepts/tools/#2-input-validation","title":"2. Input Validation","text":"<pre><code># \u2705 GOOD - Validates inputs\ndef send_email(\n    to: str,\n    subject: str,\n    body: str,\n    cc: Optional[List[str]] = None\n) -&gt; Dict[str, Any]:\n    \"\"\"Send email with validation.\"\"\"\n    # Validate email format\n    email_pattern = r'^[\\w\\.-]+@[\\w\\.-]+\\.\\w+$'\n    if not re.match(email_pattern, to):\n        raise ValueError(f\"Invalid email address: {to}\")\n\n    # Validate CC addresses\n    if cc:\n        for addr in cc:\n            if not re.match(email_pattern, addr):\n                raise ValueError(f\"Invalid CC address: {addr}\")\n\n    # Validate content\n    if not subject.strip():\n        raise ValueError(\"Subject cannot be empty\")\n\n    if len(body) &gt; 100000:\n        raise ValueError(\"Body too large (max 100KB)\")\n\n    # Send email\n    return {\"sent\": True, \"message_id\": \"...\"}\n</code></pre>"},{"location":"concepts/tools/#3-consistent-returns","title":"3. Consistent Returns","text":"<pre><code># \u2705 GOOD - Always returns same structure\ndef database_query(sql: str) -&gt; Dict[str, Any]:\n    \"\"\"Query database with consistent response.\"\"\"\n    try:\n        results = execute_query(sql)\n        return {\n            \"success\": True,\n            \"data\": results,\n            \"row_count\": len(results),\n            \"error\": None\n        }\n    except Exception as e:\n        return {\n            \"success\": False,\n            \"data\": [],\n            \"row_count\": 0,\n            \"error\": str(e)\n        }\n\n# \u274c BAD - Inconsistent returns\ndef bad_query(sql: str):\n    try:\n        return execute_query(sql)  # Returns list\n    except Exception as e:\n        return str(e)  # Returns string\n</code></pre>"},{"location":"concepts/tools/#4-resource-management","title":"4. Resource Management","text":"<pre><code># \u2705 GOOD - Proper resource cleanup\nasync def process_large_file(\n    file_path: str,\n    chunk_size: int = 8192\n) -&gt; Dict[str, Any]:\n    \"\"\"Process large file with proper resource management.\"\"\"\n    file_handle = None\n    try:\n        file_handle = await aiofiles.open(file_path, 'r')\n        total_lines = 0\n\n        async for chunk in file_handle:\n            # Process chunk\n            total_lines += chunk.count('\\n')\n\n        return {\"lines\": total_lines, \"status\": \"completed\"}\n\n    except Exception as e:\n        return {\"error\": str(e), \"status\": \"failed\"}\n\n    finally:\n        if file_handle:\n            await file_handle.close()\n</code></pre>"},{"location":"concepts/tools/#advanced-patterns","title":"\ud83c\udfaf Advanced Patterns","text":""},{"location":"concepts/tools/#complex-tool-returns-with-toolresponse","title":"Complex Tool Returns with ToolResponse","text":"<p>Important: Understanding Tool Return Types</p> <p>What happens when you DON'T use ToolResponse:</p> <ul> <li> <p>Dictionaries \u2192 Converted to JSON strings   The LLM sees: <code>'{\"key\": \"value\"}'</code> instead of structured data</p> </li> <li> <p>Images (paths/URLs) \u2192 Converted to strings   The LLM sees: <code>'data:image/png;base64,iVBOR...'</code> as TEXT (not as an image!)   This wastes thousands of tokens treating image data as text</p> </li> <li> <p>Lists \u2192 Converted to string representations   The LLM sees: <code>'[1, 2, 3]'</code> instead of structured data</p> </li> </ul> <p>Solution: Use <code>ToolResponse</code> for complex returns!</p>"},{"location":"concepts/tools/#when-to-use-toolresponse","title":"When to Use ToolResponse","text":"<p>Use <code>ToolResponse</code> when your tool needs to return:</p> <p>\u2705 Structured data (dicts, lists) that shouldn't be stringified \u2705 Images that the LLM should actually SEE (not read as text) \u2705 Multimodal content (text + images together) \u2705 Metadata separate from main content</p>"},{"location":"concepts/tools/#ordered-content-blocks-multimodal-responses","title":"Ordered Content Blocks (Multimodal Responses)","text":"<p>For multimodal responses that mix text and images in a specific sequence, use <code>List[ToolResponseContent]</code> as the content format.</p>"},{"location":"concepts/tools/#toolresponsecontent-structure","title":"ToolResponseContent Structure","text":"<pre><code>from marsys.environment import ToolResponseContent\n\n# Text content\ntext_block = ToolResponseContent(\n    type=\"text\",\n    text=\"Chapter 1: Introduction\"\n)\n\n# Image from base64 data\nimage_block = ToolResponseContent(\n    type=\"image\",\n    image_data=\"data:image/png;base64,iVBORw...\"\n)\n\n# Image from file path (auto-converted to base64)\nimage_from_file = ToolResponseContent(\n    type=\"image\",\n    image_path=\"./outputs/diagram.png\"\n)\n</code></pre> <p>Use virtual paths from the run filesystem (e.g., <code>./outputs</code>, <code>./downloads</code>, <code>./screenshots</code>) so other agents can access the same artifacts. See Run Filesystem.</p>"},{"location":"concepts/tools/#validation-rules","title":"Validation Rules","text":"<p><code>ToolResponseContent</code> enforces strict validation:</p> <ul> <li>Text blocks (<code>type=\"text\"</code>):</li> <li>\u2705 MUST have <code>text</code> field (str or dict)</li> <li> <p>\u274c CANNOT have <code>image_path</code> or <code>image_data</code></p> </li> <li> <p>Image blocks (<code>type=\"image\"</code>):</p> </li> <li>\u2705 MUST have EITHER <code>image_path</code> OR <code>image_data</code> (not both)</li> <li>\u274c CANNOT have <code>text</code> field</li> <li>If <code>image_path</code> provided: automatically converted to base64 on <code>.to_dict()</code></li> </ul>"},{"location":"concepts/tools/#creating-ordered-responses","title":"Creating Ordered Responses","text":"<pre><code>from marsys.environment import ToolResponse, ToolResponseContent\n\ndef analyze_document(path: str) -&gt; ToolResponse:\n    \"\"\"Analyze document with text + image sections.\"\"\"\n\n    content_blocks = [\n        ToolResponseContent(type=\"text\", text=\"Section 1: Overview\"),\n        ToolResponseContent(type=\"text\", text=\"The architecture consists of...\"),\n        ToolResponseContent(type=\"image\", image_path=\"./outputs/architecture.png\"),\n        ToolResponseContent(type=\"text\", text=\"Figure 1: System architecture\"),\n        ToolResponseContent(type=\"text\", text=\"Section 2: Implementation\"),\n        # ... more blocks\n    ]\n\n    return ToolResponse(\n        content=content_blocks,\n        metadata={\n            \"sections\": 2,\n            \"images\": 1,\n            \"analysis_complete\": True\n        }\n    )\n</code></pre>"},{"location":"concepts/tools/#how-it-works","title":"How It Works","text":"<p>When you return <code>ToolResponse</code> with <code>List[ToolResponseContent]</code>:</p> <ol> <li>Framework calls <code>.to_content_array()</code> on ToolResponse</li> <li>Each <code>ToolResponseContent</code> converts to typed message format:</li> <li>Text \u2192 <code>{\"type\": \"text\", \"text\": \"...\"}</code></li> <li>Image \u2192 <code>{\"type\": \"image_url\", \"image_url\": {\"url\": \"data:...\"}}</code></li> <li>LLM receives multimodal message with properly typed content</li> <li>Images processed as VISION tokens (not text!)</li> </ol>"},{"location":"concepts/tools/#token-efficiency","title":"Token Efficiency","text":"Content Type Without ToolResponseContent With ToolResponseContent Small dict ~25 tokens (stringified) ~25 tokens (structured) Image (50KB) ~75,000 text tokens \u274c ~85 vision tokens \u2705 PDF 5 pages ~250,000 text tokens \u274c ~425 vision tokens \u2705 <p>Savings: Up to 750x cheaper for images!</p>"},{"location":"concepts/tools/#basic-usage","title":"Basic Usage","text":"<pre><code>from marsys.environment import ToolResponse\n\ndef analyze_document(file_path: str) -&gt; ToolResponse:\n    \"\"\"\n    Analyze a document and return structured results with images.\n\n    Returns:\n        ToolResponse with analysis data and document images\n    \"\"\"\n    # Process the document\n    analysis = {\n        \"word_count\": 1523,\n        \"topics\": [\"AI\", \"Machine Learning\", \"Neural Networks\"],\n        \"sentiment\": \"positive\",\n        \"key_findings\": [...]\n    }\n\n    # Extract images (as base64 data URLs)\n    images = extract_images_as_base64(file_path)\n\n    return ToolResponse(\n        content=analysis,  # Dict stays as dict (NOT stringified!)\n        metadata=\"Successfully analyzed 5-page technical document\",\n        images=images  # LLM will SEE these images\n    )\n</code></pre>"},{"location":"concepts/tools/#how-toolresponse-works","title":"How ToolResponse Works","text":"<p>The framework automatically uses the appropriate message pattern based on your <code>ToolResponse</code>:</p> <p>Two-Message Pattern (used when): - You provide <code>metadata</code> (usage guidance/context), OR - Your <code>content</code> contains images (list of <code>ToolResponseContent</code>)</p> <p>Messages created: 1. Tool Message (<code>role=\"tool\"</code>):    - Contains the <code>metadata</code> string you provided (if any)    - If no metadata but has images: \"Tool execution completed successfully. Content in next message.\"    - This is where you put explanations, warnings, usage guidance    - Example: \"\u26a0\ufe0f PARTIAL CONTENT - Showing pages 1-5 of 20 total.\\n\ud83d\udcca To read more: read_file(path, start_page=6, end_page=10)\"</p> <ol> <li>User Message (<code>role=\"user\"</code>):</li> <li>Contains the actual <code>content</code></li> <li>Can be text, dict, or list of <code>ToolResponseContent</code> blocks</li> <li>For multimodal: Images appear as proper vision input (not text!)</li> </ol> <p>Single-Message Pattern (used when): - No <code>metadata</code> provided AND - No images in <code>content</code> (simple text or dict)</p> <p>Messages created: 1. Tool Message (<code>role=\"tool\"</code>):    - Contains the actual <code>content</code> directly</p> <p>Why two patterns? - Images must be in \"user\" messages for proper VLM handling - OpenAI API requires <code>role=\"tool\"</code> messages to contain string content only - The two-message pattern lets you provide both context (metadata) and structured/multimodal content - Keeps tool-specific logic in your tool, not in the framework</p> <p>Important for Tool Developers: - Build your metadata string in your tool (don't expect the framework to build it) - If returning images, they will automatically use two-message pattern even without metadata - step_executor is generic - it just passes your metadata string through - See file operations tools for examples of building helpful metadata strings</p>"},{"location":"concepts/tools/#toolresponse-parameters","title":"ToolResponse Parameters","text":"<pre><code>@dataclass\nclass ToolResponse:\n    content: Union[str, Dict, List[ToolResponseContent], Any]  # Your actual result\n    metadata: Optional[str] = None  # Explanation string for agents\n</code></pre> <p>Parameters:</p> <ul> <li><code>content</code> (required): The actual tool result</li> <li>Can be: string, dict, list of <code>ToolResponseContent</code> blocks, or any type</li> <li>NOT stringified - LLM sees the structure</li> <li> <p>For multimodal (text + images): Use <code>List[ToolResponseContent]</code></p> </li> <li> <p><code>metadata</code> (optional): Explanation/guidance string for agents</p> </li> <li>Must be a STRING - built by your tool, not by the framework</li> <li>Used in first message (role=\"tool\") to provide context/guidance</li> <li>Should include: status, warnings, usage instructions, constraints</li> <li>If None: Simple success message used (\"Tool execution completed successfully.\")</li> </ul> <p>Important: <code>metadata</code> should be a string that your tool builds. The framework (step_executor) is generic and does not contain tool-specific logic. Build your explanation/guidance in the tool itself.</p>"},{"location":"concepts/tools/#examples","title":"Examples","text":""},{"location":"concepts/tools/#example-1-dictionary-return","title":"Example 1: Dictionary Return","text":"<pre><code># \u274c WITHOUT ToolResponse\ndef get_weather(city: str) -&gt; Dict:\n    return {\"temp\": 72, \"condition\": \"sunny\", \"humidity\": 45}\n\n# LLM receives: '{\"temp\": 72, \"condition\": \"sunny\", \"humidity\": 45}'\n# Problem: It's a STRING, not structured data!\n\n# \u2705 WITH ToolResponse\ndef get_weather(city: str) -&gt; ToolResponse:\n    data = {\"temp\": 72, \"condition\": \"sunny\", \"humidity\": 45}\n    return ToolResponse(\n        content=data,\n        metadata=f\"Weather data for {city}\"\n    )\n\n# LLM receives:\n#   1. \"Tool execution completed. Metadata: Weather data for Boston\"\n#   2. {\"temp\": 72, \"condition\": \"sunny\", \"humidity\": 45}  \u2190 STRUCTURED!\n</code></pre>"},{"location":"concepts/tools/#example-2-images-critical","title":"Example 2: Images (Critical!)","text":"<pre><code># \u274c WITHOUT ToolResponse\ndef capture_screenshot() -&gt; str:\n    img_base64 = \"data:image/png;base64,iVBORw0KGgoAAAANS...\"  # 50KB\n    return img_base64\n\n# LLM receives: \"data:image/png;base64,iVBORw0KGgoAAAANS...\" as TEXT\n# Problem:\n#   - LLM processes ~75,000 characters as TEXT tokens\n#   - Costs ~$0.75 for a single image (at $0.01/1K tokens)\n#   - LLM can't actually SEE the image!\n\n# \u2705 WITH ToolResponse\ndef capture_screenshot() -&gt; ToolResponse:\n    img_base64 = \"data:image/png;base64,iVBORw0KGgoAAAANS...\"\n    return ToolResponse(\n        content=\"Screenshot captured successfully\",\n        metadata=\"Screen capture at 1920x1080\",\n        images=[img_base64]\n    )\n\n# LLM receives: Screenshot as VISION INPUT (proper image tokens)\n# Benefits:\n#   - Uses vision tokens (~85 tokens for 1920x1080 image)\n#   - Costs ~$0.001 vs $0.75 (750x cheaper!)\n#   - LLM can actually SEE and analyze the image\n</code></pre>"},{"location":"concepts/tools/#example-3-pdf-with-text-images","title":"Example 3: PDF with Text + Images","text":"<pre><code>from marsys.environment import ToolResponse\nimport base64\n\ndef read_pdf(file_path: str) -&gt; ToolResponse:\n    \"\"\"Read PDF and return text + page images.\"\"\"\n\n    # Extract text\n    extracted_text = extract_pdf_text(file_path)\n\n    # Extract pages as images\n    page_images = []\n    for page in extract_pdf_pages(file_path):\n        # Convert to base64 data URL\n        img_bytes = page.to_bytes()\n        img_base64 = base64.b64encode(img_bytes).decode('ascii')\n        data_url = f\"data:image/png;base64,{img_base64}\"\n        page_images.append(data_url)\n\n    return ToolResponse(\n        content={\n            \"text\": extracted_text,\n            \"pages\": len(page_images),\n            \"file_size\": os.path.getsize(file_path)\n        },\n        metadata={\n            \"path\": file_path,\n            \"total_pages\": len(page_images),\n            \"partial\": False\n        },\n        images=page_images\n    )\n</code></pre>"},{"location":"concepts/tools/#example-4-using-filecontentto_tool_response","title":"Example 4: Using FileContent.to_tool_response()","text":"<p>The built-in <code>FileContent</code> class has a helper method:</p> <pre><code>from marsys.environment.file_operations import read_file\n\ndef smart_read_file(path: str) -&gt; ToolResponse:\n    \"\"\"Read any file and return as ToolResponse.\"\"\"\n\n    # read_file returns FileContent with text, images, metadata\n    file_content = read_file(path)\n\n    # Automatically converts to ToolResponse\n    return file_content.to_tool_response()\n\n# For PDFs, this automatically includes:\n#   - content: {text, pages, encoding, etc.}\n#   - metadata: {path, total_pages, pages_shown}\n#   - images: [base64 page images]\n</code></pre>"},{"location":"concepts/tools/#migration-guide","title":"Migration Guide","text":""},{"location":"concepts/tools/#from-legacy-dict-format","title":"From Legacy Dict Format","text":"<pre><code># OLD (Legacy format - still works but deprecated)\ndef old_tool(path: str) -&gt; Dict:\n    return {\n        \"result\": \"Some text\",\n        \"images\": [\"path/to/image.png\"],  # File paths\n        \"metadata\": {\"key\": \"value\"}\n    }\n\n# NEW (Recommended)\ndef new_tool(path: str) -&gt; ToolResponse:\n    # Convert image to base64\n    with open(\"path/to/image.png\", \"rb\") as f:\n        img_bytes = f.read()\n    img_base64 = base64.b64encode(img_bytes).decode('ascii')\n    img_url = f\"data:image/png;base64,{img_base64}\"\n\n    return ToolResponse(\n        content=\"Some text\",\n        metadata={\"key\": \"value\"},\n        images=[img_url]  # Base64 data URLs\n    )\n</code></pre>"},{"location":"concepts/tools/#simple-string-returns-still-work","title":"Simple String Returns (Still Work!)","text":"<pre><code># Simple string returns don't need ToolResponse\ndef simple_tool(query: str) -&gt; str:\n    return \"Here is the answer\"  # \u2705 Works fine!\n\n# Only use ToolResponse for complex returns\n</code></pre>"},{"location":"concepts/tools/#best-practices_2","title":"Best Practices","text":"<p>\u2705 DO:</p> <pre><code># Use ToolResponse for structured data\ndef analyze_data(data: List) -&gt; ToolResponse:\n    result = {\"mean\": 5.2, \"std\": 1.3, \"count\": 100}\n    return ToolResponse(content=result, metadata=\"Analysis complete\")\n\n# Use ToolResponse for images\ndef take_photo() -&gt; ToolResponse:\n    img = capture_image_as_base64()\n    return ToolResponse(\n        content=\"Photo captured\",\n        images=[img]\n    )\n\n# Provide helpful metadata\ndef complex_operation() -&gt; ToolResponse:\n    return ToolResponse(\n        content={...},\n        metadata={\n            \"status\": \"success\",\n            \"execution_time\": 2.5,\n            \"items_processed\": 150\n        }\n    )\n</code></pre> <p>\u274c DON'T:</p> <pre><code># Don't return image URLs as strings\ndef bad_screenshot() -&gt; str:\n    return \"data:image/png;base64,...\"  # \u274c Wastes tokens!\n\n# Don't return dicts without ToolResponse\ndef bad_analysis() -&gt; Dict:\n    return {\"key\": \"value\"}  # \u274c Gets stringified!\n\n# Don't use file paths in images (use base64)\ndef bad_images() -&gt; ToolResponse:\n    return ToolResponse(\n        content=\"...\",\n        images=[\"./local/path.png\"]  # \u274c Won't work!\n    )\n</code></pre>"},{"location":"concepts/tools/#token-cost-comparison_1","title":"Token Cost Comparison","text":"Return Type Without ToolResponse With ToolResponse Savings Small dict (100 chars) ~25 tokens ~25 tokens None Large dict (5KB) ~1,250 tokens ~1,250 tokens None Single image (50KB base64) ~75,000 text tokens$0.75 ~85 vision tokens$0.001 750x cheaper PDF with 5 pages ~250,000 text tokens$2.50 ~425 vision tokens$0.005 500x cheaper <p>Critical: Image Token Cost</p> <p>Returning base64 images WITHOUT ToolResponse can cost hundreds of times more in API usage. Always use ToolResponse for images!</p>"},{"location":"concepts/tools/#technical-details","title":"Technical Details","text":"<p>What happens internally:</p> <ol> <li>Your tool returns <code>ToolResponse(content=data, metadata=meta, images=[img])</code></li> <li>Framework creates TWO messages:    <pre><code># Message 1 (role=\"tool\")\n{\n  \"role\": \"tool\",\n  \"content\": \"Tool execution completed. Metadata: {meta}\",\n  \"tool_call_id\": \"...\",\n  \"name\": \"your_tool\"\n}\n\n# Message 2 (role=\"user\")\n{\n  \"role\": \"user\",\n  \"content\": [\n    {\"type\": \"text\", \"text\": \"{data}\"},  # Your content\n    {\"type\": \"image_url\", \"image_url\": {\"url\": \"{img}\"}}  # Vision input\n  ]\n}\n</code></pre></li> <li>LLM receives confirmation + structured data + images as vision input</li> </ol> <p>Provider compatibility: - \u2705 OpenAI (GPT-4V, GPT-4o) - \u2705 Anthropic (Claude 3 Sonnet, Opus) - \u2705 Google (Gemini Pro Vision) - \u2705 OpenRouter (all vision models)</p>"},{"location":"concepts/tools/#rate-limited-tools","title":"Rate-Limited Tools","text":"<pre><code>from asyncio import Semaphore\nfrom collections import defaultdict\nimport time\n\nclass RateLimiter:\n    def __init__(self, calls: int, period: float):\n        self.calls = calls\n        self.period = period\n        self.semaphore = Semaphore(calls)\n        self.call_times = []\n\n    async def acquire(self):\n        async with self.semaphore:\n            now = time.time()\n            # Remove old calls outside the period\n            self.call_times = [t for t in self.call_times if now - t &lt; self.period]\n\n            if len(self.call_times) &gt;= self.calls:\n                sleep_time = self.period - (now - self.call_times[0])\n                await asyncio.sleep(sleep_time)\n\n            self.call_times.append(time.time())\n\n# Rate-limited API tool\nrate_limiter = RateLimiter(calls=10, period=60)  # 10 calls per minute\n\nasync def api_call(endpoint: str, params: Dict) -&gt; Dict:\n    \"\"\"Rate-limited API call.\"\"\"\n    await rate_limiter.acquire()\n    # Make actual API call\n    response = await make_request(endpoint, params)\n    return response\n</code></pre>"},{"location":"concepts/tools/#cached-tools","title":"Cached Tools","text":"<pre><code>from functools import lru_cache\nimport hashlib\nimport json\n\nclass CachedTool:\n    def __init__(self, ttl: int = 300):\n        self.cache = {}\n        self.ttl = ttl\n\n    def _cache_key(self, *args, **kwargs):\n        \"\"\"Generate cache key from arguments.\"\"\"\n        key_data = json.dumps({\"args\": args, \"kwargs\": kwargs}, sort_keys=True)\n        return hashlib.md5(key_data.encode()).hexdigest()\n\n    async def expensive_operation(\n        self,\n        param1: str,\n        param2: int,\n        use_cache: bool = True\n    ) -&gt; Dict:\n        \"\"\"Expensive operation with caching.\"\"\"\n\n        cache_key = self._cache_key(param1, param2)\n\n        # Check cache\n        if use_cache and cache_key in self.cache:\n            cached_time, cached_result = self.cache[cache_key]\n            if time.time() - cached_time &lt; self.ttl:\n                return {\"result\": cached_result, \"cached\": True}\n\n        # Perform expensive operation\n        result = await self._do_expensive_work(param1, param2)\n\n        # Cache result\n        self.cache[cache_key] = (time.time(), result)\n\n        return {\"result\": result, \"cached\": False}\n</code></pre>"},{"location":"concepts/tools/#next-steps","title":"\ud83d\udea6 Next Steps","text":"<ul> <li> <p> Agents</p> <p>How agents use tools</p> </li> <li> <p> Models</p> <p>Model configurations for tool calling</p> </li> <li> <p> Browser Automation</p> <p>Web interaction tools</p> </li> <li> <p> Tool API Reference</p> <p>Complete tool API documentation</p> </li> </ul> <p>Tool System Ready!</p> <p>You now understand how to create and use tools in MARSYS. Tools are the bridge between AI intelligence and real-world actions.</p>"},{"location":"concepts/advanced/topology/","title":"Topology System","text":"<p>Master the powerful topology system that defines how agents interact, communicate, and collaborate in complex workflows.</p>"},{"location":"concepts/advanced/topology/#overview","title":"\ud83c\udfaf Overview","text":"<p>The topology system is the heart of MARSYS's orchestration capabilities. It defines:</p> <ul> <li>Agent Relationships: Who can communicate with whom</li> <li>Execution Flow: Sequential, parallel, or mixed patterns</li> <li>Permission Management: Control agent invocation rights</li> <li>Convergence Points: Where parallel branches merge</li> <li>Rules and Constraints: Execution policies and limits</li> </ul>"},{"location":"concepts/advanced/topology/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<pre><code>graph TB\n    subgraph \"Topology Components\"\n        T[Topology]\n        N[Nodes]\n        E[Edges]\n        R[Rules]\n    end\n\n    subgraph \"Analysis\"\n        TA[Topology&lt;br/&gt;Analyzer]\n        TG[Topology&lt;br/&gt;Graph]\n        TV[Topology&lt;br/&gt;Validator]\n    end\n\n    subgraph \"Patterns\"\n        P1[Hub-Spoke]\n        P2[Pipeline]\n        P3[Mesh]\n        P4[Hierarchical]\n    end\n\n    T --&gt; N\n    T --&gt; E\n    T --&gt; R\n    T --&gt; TA\n    TA --&gt; TG\n    TA --&gt; TV\n    P1 --&gt; T\n    P2 --&gt; T\n    P3 --&gt; T\n    P4 --&gt; T\n\n    style T fill:#4A90E2,stroke:#2E5C8A,stroke-width:3px,color:#fff\n    style TA fill:#7B68EE,stroke:#5A4FCF,stroke-width:2px,color:#fff</code></pre>"},{"location":"concepts/advanced/topology/#four-ways-to-define-multi-agent-systems","title":"\ud83d\udcdd Four Ways to Define Multi-Agent Systems","text":"<p>MARSYS provides four different approaches to define how agents interact, from simple to sophisticated. We'll demonstrate each approach using the same example: a Researcher agent that gathers information and passes it to a Writer agent.</p>"},{"location":"concepts/advanced/topology/#1-peer-based-with-auto-run-simplest","title":"1\ufe0f\u20e3 Peer-Based with Auto-Run (Simplest)","text":"<p>Perfect for quick prototyping and simple agent interactions. The topology is automatically created from the <code>allowed_peers</code> configuration:</p> <pre><code>from marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\n# Configure the model\nmodel_config = ModelConfig(\n    type=\"api\",\n    name=\"anthropic/claude-opus-4.6\",\n    provider=\"openrouter\"\n)\n\n# Create agents with allowed_peers\nresearcher = Agent(\n    model_config=model_config,\n    name=\"Researcher\",\n    goal=\"Expert at finding and analyzing information\",\n    instruction=\"You are a research specialist. Find and analyze information thoroughly.\",\n    allowed_peers=[\"Writer\"]  # Can invoke Writer\n)\n\nwriter = Agent(\n    model_config=model_config,\n    name=\"Writer\",\n    goal=\"Skilled at creating clear, engaging content\",\n    instruction=\"You are a skilled writer. Create clear, engaging content based on research.\",\n    allowed_peers=[]  # Cannot invoke other agents\n)\n\n# Run with automatic topology creation\nresult = await researcher.auto_run(\n    task=\"Research AI trends and write a report\",\n    max_steps=20,\n    verbosity=1\n)\n</code></pre> <p>Key Features: - Topology is auto-generated from <code>allowed_peers</code> - No need to explicitly define nodes and edges - Great for simple workflows and testing - Supports user interaction when \"User\" is in <code>allowed_peers</code></p>"},{"location":"concepts/advanced/topology/#2-string-notation-topology-clear-visual","title":"2\ufe0f\u20e3 String Notation Topology (Clear &amp; Visual)","text":"<p>Define topology using simple string notation with Orchestra:</p> <pre><code>from marsys.coordination import Orchestra\nfrom marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\n# Create the same agents\nmodel_config = ModelConfig(type=\"api\", name=\"anthropic/claude-opus-4.6\", provider=\"openrouter\")\n\nresearcher = Agent(\n    model_config=model_config,\n    name=\"Researcher\",\n    goal=\"Expert at finding and analyzing information\",\n    instruction=\"You are a research specialist. Find and analyze information thoroughly.\"\n)\n\nwriter = Agent(\n    model_config=model_config,\n    name=\"Writer\",\n    goal=\"Skilled at creating clear, engaging content\",\n    instruction=\"You are a skilled writer. Create clear, engaging content based on research.\"\n)\n\n# Define topology with string notation\ntopology = {\n    \"agents\": [\"Researcher\", \"Writer\"],\n    \"flows\": [\"Researcher -&gt; Writer\"],  # Researcher can invoke Writer\n    \"rules\": [\"max_steps(20)\", \"timeout(300)\"]\n}\n\n# Run with Orchestra\nresult = await Orchestra.run(\n    task=\"Research AI trends and write a report\",\n    topology=topology\n)\n</code></pre> <p>Special Notation: - <code>-&gt;</code>: Unidirectional edge - <code>&lt;-&gt;</code>: Bidirectional edge (conversation) - <code>User</code>: Special node for human interaction</p>"},{"location":"concepts/advanced/topology/#3-canonical-object-based-type-safe","title":"3\ufe0f\u20e3 Canonical Object-Based (Type-Safe)","text":"<p>For production systems with full control and type safety:</p> <pre><code>from marsys.coordination import Orchestra\nfrom marsys.coordination.topology import Topology, Node, Edge, NodeType, EdgeType\nfrom marsys.coordination.rules import TimeoutRule, MaxStepsRule\nfrom marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\n# Create the same agents\nmodel_config = ModelConfig(type=\"api\", name=\"anthropic/claude-opus-4.6\", provider=\"openrouter\")\n\nresearcher = Agent(\n    model_config=model_config,\n    name=\"Researcher\",\n    goal=\"Expert at finding and analyzing information\",\n    instruction=\"You are a research specialist. Find and analyze information thoroughly.\"\n)\n\nwriter = Agent(\n    model_config=model_config,\n    name=\"Writer\",\n    goal=\"Skilled at creating clear, engaging content\",\n    instruction=\"You are a skilled writer. Create clear, engaging content based on research.\"\n)\n\n# Define nodes with full control\nnodes = [\n    Node(\n        name=\"Researcher\",\n        node_type=NodeType.AGENT,\n        metadata={\"role\": \"information_gatherer\"}\n    ),\n    Node(\n        name=\"Writer\",\n        node_type=NodeType.AGENT,\n        metadata={\"role\": \"content_creator\"}\n    )\n]\n\n# Define edges with specific types\nedges = [\n    Edge(\n        source=\"Researcher\",\n        target=\"Writer\",\n        edge_type=EdgeType.INVOKE,\n        metadata={\"pass_context\": True}\n    )\n]\n\n# Define rules\nrules = [\n    TimeoutRule(max_duration_seconds=300),\n    MaxStepsRule(max_steps=20)\n]\n\n# Create topology\ntopology = Topology(nodes=nodes, edges=edges, rules=rules)\n\n# Run with Orchestra\nresult = await Orchestra.run(\n    task=\"Research AI trends and write a report\",\n    topology=topology\n)\n</code></pre>"},{"location":"concepts/advanced/topology/#4-pattern-configuration-pre-defined","title":"4\ufe0f\u20e3 Pattern Configuration (Pre-defined)","text":"<p>Use battle-tested patterns for common multi-agent scenarios:</p> <pre><code>from marsys.coordination import Orchestra\nfrom marsys.coordination.topology.patterns import PatternConfig\nfrom marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\n# Create the same agents\nmodel_config = ModelConfig(type=\"api\", name=\"anthropic/claude-opus-4.6\", provider=\"openrouter\")\n\nresearcher = Agent(\n    model_config=model_config,\n    name=\"Researcher\",\n    goal=\"Expert at finding and analyzing information\",\n    instruction=\"You are a research specialist. Find and analyze information thoroughly.\"\n)\n\nwriter = Agent(\n    model_config=model_config,\n    name=\"Writer\",\n    goal=\"Skilled at creating clear, engaging content\",\n    instruction=\"You are a skilled writer. Create clear, engaging content based on research.\"\n)\n\n# Use Pipeline Pattern for our workflow\ntopology = PatternConfig.pipeline(\n    stages=[\n        {\"name\": \"research\", \"agents\": [\"Researcher\"]},\n        {\"name\": \"writing\", \"agents\": [\"Writer\"]}\n    ],\n    parallel_within_stage=False  # Sequential stage execution\n)\n\n# Run with Orchestra\nresult = await Orchestra.run(\n    task=\"Research AI trends and write a report\",\n    topology=topology\n)\n</code></pre> <p>Other Available Patterns: - Hub-and-Spoke: Central coordinator with spoke agents - Mesh: Fully connected network where all agents can communicate - Hierarchical: Tree-based delegation structure - Ring: Circular agent chain - Star: Similar to hub-and-spoke with bidirectional edges - Broadcast: One-to-many notification pattern</p>"},{"location":"concepts/advanced/topology/#comparison-which-approach-to-use","title":"\ud83d\udcca Comparison: Which Approach to Use?","text":"Method Best For Complexity Key Features Way 1: allowed_peers + auto_run Quick prototyping, simple flows \u2b50 Simplest Auto-topology, minimal setup, great for testing Way 2: String notation Clear visual flows, medium complexity \u2b50\u2b50 Moderate Easy to read, supports bidirectional edges Way 3: Object-based Type-safe production systems \u2b50\u2b50\u2b50 Complex Full control, metadata support, type checking Way 4: PatternConfig Common team structures \u2b50\u2b50 Moderate Pre-tested patterns, quick setup for standard workflows"},{"location":"concepts/advanced/topology/#decision-guide","title":"Decision Guide:","text":"<ul> <li>Start with Way 1 if you're:</li> <li>Prototyping or testing</li> <li>Building simple agent chains</li> <li> <p>Want minimal boilerplate</p> </li> <li> <p>Use Way 2 if you:</p> </li> <li>Need clear, readable topology definitions</li> <li>Have moderate complexity (5-10 agents)</li> <li> <p>Want to visualize agent relationships easily</p> </li> <li> <p>Choose Way 3 if you:</p> </li> <li>Building production systems</li> <li>Need type safety and validation</li> <li> <p>Want full control over metadata and edge properties</p> </li> <li> <p>Select Way 4 if you:</p> </li> <li>Have a standard pattern (hub-spoke, pipeline, etc.)</li> <li>Want battle-tested configurations</li> <li>Need to implement common team structures quickly</li> </ul>"},{"location":"concepts/advanced/topology/#available-patterns","title":"\ud83c\udfa8 Available Patterns","text":""},{"location":"concepts/advanced/topology/#hub-and-spoke","title":"Hub-and-Spoke","text":"<p>Central coordinator with satellite agents:</p> <pre><code>graph TB\n    H[Hub]\n    S1[Spoke1]\n    S2[Spoke2]\n    S3[Spoke3]\n\n    H &lt;--&gt; S1\n    H &lt;--&gt; S2\n    H &lt;--&gt; S3\n\n    style H fill:#4A90E2,color:#fff</code></pre> <p>Use Cases: Research teams, customer support, data aggregation</p>"},{"location":"concepts/advanced/topology/#pipeline","title":"Pipeline","text":"<p>Sequential stages with optional parallelism:</p> <pre><code>graph LR\n    S1[Stage 1] --&gt; S2[Stage 2] --&gt; S3[Stage 3] --&gt; S4[Stage 4]\n\n    style S1 fill:#50C878,color:#fff\n    style S4 fill:#FF6B6B,color:#fff</code></pre> <p>Use Cases: Data processing, content creation, ETL workflows</p>"},{"location":"concepts/advanced/topology/#mesh","title":"Mesh","text":"<p>Fully connected network:</p> <pre><code>graph TB\n    A1[Agent1]\n    A2[Agent2]\n    A3[Agent3]\n    A4[Agent4]\n\n    A1 &lt;--&gt; A2\n    A1 &lt;--&gt; A3\n    A1 &lt;--&gt; A4\n    A2 &lt;--&gt; A3\n    A2 &lt;--&gt; A4\n    A3 &lt;--&gt; A4</code></pre> <p>Use Cases: Collaborative problem solving, consensus building</p>"},{"location":"concepts/advanced/topology/#hierarchical","title":"Hierarchical","text":"<p>Tree-based delegation:</p> <pre><code>graph TB\n    M[Manager]\n    L1[Lead1]\n    L2[Lead2]\n    W1[Worker1]\n    W2[Worker2]\n    W3[Worker3]\n    W4[Worker4]\n\n    M --&gt; L1\n    M --&gt; L2\n    L1 --&gt; W1\n    L1 --&gt; W2\n    L2 --&gt; W3\n    L2 --&gt; W4\n\n    style M fill:#4A90E2,color:#fff</code></pre> <p>Use Cases: Organization simulation, cascading tasks</p>"},{"location":"concepts/advanced/topology/#advanced-features","title":"\ud83d\udd27 Advanced Features","text":""},{"location":"concepts/advanced/topology/#dynamic-topology-mutation","title":"Dynamic Topology Mutation","text":"<p>Modify topologies at runtime:</p> <pre><code># Start with basic topology\ntopology = Topology(\n    nodes=[\"Coordinator\", \"Worker1\"],\n    edges=[\"Coordinator -&gt; Worker1\"]\n)\n\n# Add nodes dynamically\ntopology.add_node(\"Worker2\")\ntopology.add_node(Node(\"Analyzer\", node_type=NodeType.AGENT))\n\n# Add edges\ntopology.add_edge(\"Coordinator\", \"Worker2\")\ntopology.add_edge(Edge(\"Worker2\", \"Analyzer\", bidirectional=True))\n\n# Add rules\ntopology.add_rule(TimeoutRule(300))\ntopology.add_rule(\"max_steps(100)\")\n\n# Remove components\ntopology.remove_node(\"Worker1\")\ntopology.remove_edge(\"Coordinator\", \"Worker1\")\n</code></pre>"},{"location":"concepts/advanced/topology/#convergence-points","title":"Convergence Points","text":"<p>Define where parallel branches merge:</p> <pre><code># Manual convergence point\ntopology = Topology(\n    nodes=[\n        Node(\"Splitter\", node_type=NodeType.AGENT),\n        Node(\"Worker1\", node_type=NodeType.AGENT),\n        Node(\"Worker2\", node_type=NodeType.AGENT),\n        Node(\"Worker3\", node_type=NodeType.AGENT),\n        Node(\"Aggregator\",\n             node_type=NodeType.AGENT,\n             is_convergence_point=True)  # Convergence point\n    ],\n    edges=[\n        \"Splitter -&gt; Worker1\",\n        \"Splitter -&gt; Worker2\",\n        \"Splitter -&gt; Worker3\",\n        \"Worker1 -&gt; Aggregator\",\n        \"Worker2 -&gt; Aggregator\",\n        \"Worker3 -&gt; Aggregator\"\n    ]\n)\n\n# Automatic detection\nconfig = ExecutionConfig(\n    auto_detect_convergence=True,  # Auto-detect from topology\n    dynamic_convergence_enabled=True,  # Runtime convergence\n    convergence_timeout=300.0  # Max wait time\n)\n</code></pre>"},{"location":"concepts/advanced/topology/#edge-patterns","title":"Edge Patterns","text":"<p>Special edge behaviors:</p> <pre><code>from marsys.coordination.topology import EdgePattern\n\n# Alternating conversation\nEdge(\n    source=\"Negotiator1\",\n    target=\"Negotiator2\",\n    bidirectional=True,\n    pattern=EdgePattern.ALTERNATING,  # Strict turn-taking\n    metadata={\"max_turns\": 5}\n)\n\n# Symmetric communication\nEdge(\n    source=\"Peer1\",\n    target=\"Peer2\",\n    bidirectional=True,\n    pattern=EdgePattern.SYMMETRIC,  # Equal communication rights\n)\n\n# Conditional edge\nEdge(\n    source=\"Checker\",\n    target=\"Escalator\",\n    metadata={\n        \"condition\": \"error_rate &gt; 0.1\",  # Only if condition met\n        \"priority\": \"high\"\n    }\n)\n</code></pre>"},{"location":"concepts/advanced/topology/#rules-system","title":"Rules System","text":"<p>Control execution behavior:</p> <pre><code>from marsys.coordination.rules import (\n    Rule, RuleType, RuleResult, RuleContext,\n    TimeoutRule, MaxAgentsRule, MaxStepsRule,\n    MemoryLimitRule, ConditionalRule\n)\n\n# Built-in rules\nrules = [\n    TimeoutRule(max_duration_seconds=600),\n    MaxAgentsRule(max_agents=20),\n    MaxStepsRule(max_steps=100),\n    MemoryLimitRule(max_memory_mb=2048),\n    ConditionalRule(\n        condition=lambda ctx: ctx.error_count &lt; 3,\n        action=\"continue\"\n    )\n]\n\n# Custom rule\nclass BusinessHoursRule(Rule):\n    def __init__(self):\n        super().__init__(\n            name=\"business_hours\",\n            rule_type=RuleType.PRE_EXECUTION,\n            priority=10\n        )\n\n    async def check(self, context: RuleContext) -&gt; RuleResult:\n        from datetime import datetime\n        hour = datetime.now().hour\n\n        if 9 &lt;= hour &lt; 17:  # Business hours\n            return RuleResult(\n                rule_name=self.name,\n                passed=True,\n                action=\"allow\"\n            )\n        else:\n            return RuleResult(\n                rule_name=self.name,\n                passed=False,\n                action=\"defer\",\n                reason=\"Outside business hours\",\n                metadata={\"retry_at\": \"09:00\"}\n            )\n\n# Use custom rule\ntopology.add_rule(BusinessHoursRule())\n</code></pre>"},{"location":"concepts/advanced/topology/#topology-analysis","title":"\ud83d\udcca Topology Analysis","text":"<p>The framework provides powerful analysis tools:</p> <pre><code>from marsys.coordination.topology import TopologyAnalyzer\n\nanalyzer = TopologyAnalyzer(topology)\n\n# Find entry points (nodes with no incoming edges)\nentry_points = analyzer.get_entry_points()\nprint(f\"Entry points: {entry_points}\")  # e.g., [\"User\", \"Scheduler\"]\n\n# Find convergence points\nconvergence_points = analyzer.get_convergence_points()\nprint(f\"Convergence: {convergence_points}\")  # e.g., [\"Aggregator\"]\n\n# Check if conversation pattern exists\nhas_conversation = analyzer.has_conversation_pattern()\nprint(f\"Has conversation: {has_conversation}\")\n\n# Get agent permissions\npermissions = analyzer.get_agent_permissions(\"Coordinator\")\nprint(f\"Coordinator can invoke: {permissions}\")  # e.g., [\"Worker1\", \"Worker2\"]\n\n# Validate topology\nis_valid, errors = analyzer.validate()\nif not is_valid:\n    print(f\"Topology errors: {errors}\")\n\n# Get execution order (topological sort)\norder = analyzer.get_execution_order()\nprint(f\"Execution order: {order}\")\n\n# Detect cycles\nhas_cycles = analyzer.has_cycles()\nprint(f\"Has cycles: {has_cycles}\")\n\n# Get shortest path\npath = analyzer.get_shortest_path(\"User\", \"Reporter\")\nprint(f\"Shortest path: {path}\")\n</code></pre>"},{"location":"concepts/advanced/topology/#best-practices","title":"\ud83c\udfaf Best Practices","text":""},{"location":"concepts/advanced/topology/#1-start-simple","title":"1. Start Simple","text":"<p>Begin with basic patterns and add complexity as needed: <pre><code># Start with this\ntopology = PatternConfig.hub_and_spoke(\"Coordinator\", [\"Worker1\", \"Worker2\"])\n\n# Evolve to this\ntopology.add_node(\"Analyzer\")\ntopology.add_edge(\"Worker1\", \"Analyzer\")\n</code></pre></p>"},{"location":"concepts/advanced/topology/#2-use-convergence-points","title":"2. Use Convergence Points","text":"<p>Always define clear convergence for parallel work: <pre><code>Node(\"Aggregator\", is_convergence_point=True)\n</code></pre></p>"},{"location":"concepts/advanced/topology/#3-set-appropriate-timeouts","title":"3. Set Appropriate Timeouts","text":"<p>Different timeouts for different scenarios: <pre><code>rules = [\n    TimeoutRule(60),    # Quick task\n    TimeoutRule(3600),  # Long research\n]\n</code></pre></p>"},{"location":"concepts/advanced/topology/#4-validate-before-execution","title":"4. Validate Before Execution","text":"<p>Always validate topology before running: <pre><code>analyzer = TopologyAnalyzer(topology)\nis_valid, errors = analyzer.validate()\nassert is_valid, f\"Invalid topology: {errors}\"\n</code></pre></p>"},{"location":"concepts/advanced/topology/#5-document-intent","title":"5. Document Intent","text":"<p>Use metadata to document topology purpose: <pre><code>topology = Topology(\n    nodes=[...],\n    edges=[...],\n    metadata={\n        \"purpose\": \"Customer support escalation\",\n        \"version\": \"2.0\",\n        \"author\": \"Team Lead\"\n    }\n)\n</code></pre></p>"},{"location":"concepts/advanced/topology/#common-patterns","title":"\ud83d\udea6 Common Patterns","text":""},{"location":"concepts/advanced/topology/#research-team","title":"Research Team","text":"<pre><code>topology = PatternConfig.hub_and_spoke(\n    hub=\"LeadResearcher\",\n    spokes=[\"DataCollector\", \"FactChecker\", \"Analyst\", \"Writer\"],\n    parallel_spokes=True\n)\n</code></pre>"},{"location":"concepts/advanced/topology/#customer-support","title":"Customer Support","text":"<pre><code>topology = PatternConfig.hierarchical(\n    tree={\n        \"Dispatcher\": [\"L1Support\"],\n        \"L1Support\": [\"L2Support\"],\n        \"L2Support\": [\"Engineering\", \"Management\"]\n    }\n)\n</code></pre>"},{"location":"concepts/advanced/topology/#data-pipeline","title":"Data Pipeline","text":"<pre><code>topology = PatternConfig.pipeline(\n    stages=[\n        {\"name\": \"extract\", \"agents\": [\"Scraper\"]},\n        {\"name\": \"transform\", \"agents\": [\"Parser\", \"Cleaner\"]},\n        {\"name\": \"load\", \"agents\": [\"Database\"]}\n    ],\n    parallel_within_stage=True\n)\n</code></pre>"},{"location":"concepts/advanced/topology/#consensus-building","title":"Consensus Building","text":"<pre><code>topology = PatternConfig.mesh(\n    agents=[\"Expert1\", \"Expert2\", \"Expert3\", \"Moderator\"],\n    fully_connected=True\n)\n</code></pre>"},{"location":"concepts/advanced/topology/#dynamic-behavior","title":"\ud83d\udd04 Dynamic Behavior","text":""},{"location":"concepts/advanced/topology/#runtime-parallel-invocation","title":"Runtime Parallel Invocation","text":"<p>Agents can spawn parallel branches dynamically:</p> <pre><code># In agent response\n{\n    \"next_action\": \"parallel_invoke\",\n    \"agents\": [\"Analyst1\", \"Analyst2\", \"Analyst3\"],\n    \"agent_requests\": {\n        \"Analyst1\": \"Analyze financial data\",\n        \"Analyst2\": \"Analyze market trends\",\n        \"Analyst3\": \"Analyze competition\"\n    }\n}\n</code></pre>"},{"location":"concepts/advanced/topology/#conditional-routing","title":"Conditional Routing","text":"<p>Route based on conditions:</p> <pre><code># In agent response\n{\n    \"next_action\": \"invoke_agent\",\n    \"action_input\": \"ErrorHandler\" if error else \"NextStep\"\n}\n</code></pre>"},{"location":"concepts/advanced/topology/#dynamic-agent-discovery","title":"Dynamic Agent Discovery","text":"<p>Agents can discover peers at runtime:</p> <pre><code># Through context\navailable_agents = context.get(\"available_agents\", [])\nspecialist = next((a for a in available_agents if \"expert\" in a.lower()), None)\n</code></pre>"},{"location":"concepts/advanced/topology/#next-steps","title":"\ud83d\udea6 Next Steps","text":"<p>Master topology patterns:</p> <ul> <li> <p> See Examples</p> <p>Real-world topology implementations</p> </li> <li> <p> API Reference</p> <p>Detailed topology API documentation</p> </li> <li> <p> Agent Development</p> <p>Build agents that work with topologies</p> </li> <li> <p> Configuration</p> <p>Configure execution behavior</p> </li> </ul> <p>Topology Mastered!</p> <p>You now understand the topology system! Use it to build complex multi-agent workflows with confidence.</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Join the MARSYS community and help build the future of multi-agent AI systems!</p>"},{"location":"contributing/#ways-to-contribute","title":"\ud83e\udd1d Ways to Contribute","text":"<ul> <li> <p> Report Issues</p> <p>Found a bug? Let us know!</p> <ul> <li>Bug reports</li> <li>Performance issues</li> <li>Documentation gaps</li> <li>Feature requests</li> </ul> <p>Report Issue \u2192</p> </li> <li> <p> Code Contributions</p> <p>Improve the framework</p> <ul> <li>Bug fixes</li> <li>New features</li> <li>Performance optimizations</li> <li>Refactoring</li> </ul> <p>View Guidelines \u2192</p> </li> <li> <p> Documentation</p> <p>Help others learn</p> <ul> <li>Fix typos and errors</li> <li>Improve explanations</li> <li>Add examples</li> <li>Write tutorials</li> </ul> <p>Documentation Guide \u2192</p> </li> <li> <p> Testing</p> <p>Ensure quality</p> <ul> <li>Write unit tests</li> <li>Add integration tests</li> <li>Test edge cases</li> <li>Report test failures</li> </ul> <p>Testing Guide \u2192</p> </li> </ul>"},{"location":"contributing/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"contributing/#1-fork-clone","title":"1. Fork &amp; Clone","text":"<pre><code># Fork on GitHub, then:\ngit clone https://github.com/yourusername/marsys.git\ncd marsys\n\n# Add upstream remote\ngit remote add upstream https://github.com/original/marsys.git\n</code></pre>"},{"location":"contributing/#2-set-up-development-environment","title":"2. Set Up Development Environment","text":"<pre><code># Create virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\\Scripts\\activate\n\n# Install in development mode\npip install -e \".[dev]\"\n\n# Install pre-commit hooks\npre-commit install\n</code></pre>"},{"location":"contributing/#3-create-feature-branch","title":"3. Create Feature Branch","text":"<pre><code># Sync with upstream\ngit fetch upstream\ngit checkout main\ngit merge upstream/main\n\n# Create feature branch\ngit checkout -b feature/your-feature-name\n</code></pre>"},{"location":"contributing/#4-make-changes","title":"4. Make Changes","text":"<pre><code># Make your changes\n# Add tests\n# Update documentation\n\n# Run tests\npytest tests/\n\n# Check code style\nblack src/ tests/\nisort src/ tests/\nflake8 src/ tests/\n\n# Commit changes\ngit add .\ngit commit -m \"feat: add amazing feature\"\n</code></pre>"},{"location":"contributing/#5-submit-pull-request","title":"5. Submit Pull Request","text":"<pre><code># Push to your fork\ngit push origin feature/your-feature-name\n\n# Open PR on GitHub\n# Link any related issues\n# Describe your changes\n</code></pre>"},{"location":"contributing/#code-contributions","title":"\ud83d\udcdd Code Contributions","text":""},{"location":"contributing/#code-style","title":"Code Style","text":"<p>We use: - Black for code formatting - isort for import sorting - flake8 for linting - mypy for type checking</p> <pre><code># Format code\nblack src/ tests/\n\n# Sort imports\nisort src/ tests/\n\n# Check linting\nflake8 src/ tests/\n\n# Type checking\nmypy src/\n</code></pre>"},{"location":"contributing/#commit-messages","title":"Commit Messages","text":"<p>Follow Conventional Commits:</p> <pre><code>feat: add parallel agent execution\nfix: resolve memory leak in agent pools\ndocs: update topology documentation\ntest: add tests for branch executor\nrefactor: simplify validation logic\nperf: optimize message passing\n</code></pre>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>\u2705 DO: - Keep PRs focused on a single feature/fix - Include tests for new functionality - Update documentation - Add type hints - Follow existing code patterns - Link related issues</p> <p>\u274c DON'T: - Mix unrelated changes - Break existing tests - Introduce unnecessary dependencies - Change code style arbitrarily - Submit incomplete work</p>"},{"location":"contributing/#documentation","title":"\ud83d\udcda Documentation","text":""},{"location":"contributing/#documentation-structure","title":"Documentation Structure","text":"<pre><code>docs/\n\u251c\u2500\u2500 getting-started/    # Beginner guides\n\u251c\u2500\u2500 concepts/          # Core concepts\n\u251c\u2500\u2500 tutorials/         # Step-by-step tutorials\n\u251c\u2500\u2500 api/              # API reference\n\u251c\u2500\u2500 use-cases/        # Real-world examples\n\u2514\u2500\u2500 contributing/     # This section\n</code></pre>"},{"location":"contributing/#writing-style","title":"Writing Style","text":"<ul> <li>Clear: Use simple, direct language</li> <li>Concise: Be brief but complete</li> <li>Practical: Include working examples</li> <li>Visual: Add diagrams where helpful</li> </ul>"},{"location":"contributing/#example-template","title":"Example Template","text":"<pre><code># Feature Name\n\nBrief description of what this feature does.\n\n## Overview\n\nExplain the purpose and use cases.\n\n## Example\n\n\\```python\n# Complete, working example\nfrom marsys import Feature\n\nfeature = Feature()\nresult = feature.do_something()\n\\```\n\n## API Reference\n\nDocument all public methods and parameters.\n\n## Best Practices\n\nTips for effective usage.\n</code></pre>"},{"location":"contributing/#testing","title":"\ud83e\uddea Testing","text":""},{"location":"contributing/#test-structure","title":"Test Structure","text":"<pre><code>tests/\n\u251c\u2500\u2500 unit/           # Unit tests\n\u251c\u2500\u2500 integration/    # Integration tests\n\u251c\u2500\u2500 e2e/           # End-to-end tests\n\u2514\u2500\u2500 fixtures/      # Test fixtures\n</code></pre>"},{"location":"contributing/#writing-tests","title":"Writing Tests","text":"<pre><code>import pytest\nfrom marsys.agents import Agent\n\n@pytest.mark.asyncio\nasync def test_agent_creation():\n    \"\"\"Test agent can be created with config.\"\"\"\n    agent = Agent(\n        model_config=test_config,\n        name=\"TestAgent\",\n        goal=\"Handle test tasks\",\n        instruction=\"Return deterministic outputs for tests.\"\n    )\n\n    assert agent.name == \"TestAgent\"\n    assert agent.model is not None\n\n@pytest.mark.asyncio\nasync def test_agent_execution():\n    \"\"\"Test agent can execute tasks.\"\"\"\n    agent = create_test_agent()\n    result = await agent.run(\"Test task\")\n\n    assert result.success\n    assert result.response is not None\n</code></pre>"},{"location":"contributing/#running-tests","title":"Running Tests","text":"<pre><code># Run all tests\npytest\n\n# Run with coverage\npytest --cov=src --cov-report=html\n\n# Run specific test file\npytest tests/unit/test_agent.py\n\n# Run with markers\npytest -m \"not slow\"\n</code></pre>"},{"location":"contributing/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":""},{"location":"contributing/#key-principles","title":"Key Principles","text":"<ol> <li>Pure Functions: Agents use pure <code>_run()</code> methods</li> <li>Centralized Validation: Single validation processor</li> <li>Dynamic Branching: Runtime parallel execution</li> <li>Topology-Driven: Graph-based routing</li> </ol>"},{"location":"contributing/#adding-new-features","title":"Adding New Features","text":"<ol> <li>Identify Component: Where does it belong?</li> <li>Design API: Keep it consistent</li> <li>Implement: Follow existing patterns</li> <li>Test: Comprehensive test coverage</li> <li>Document: Update relevant docs</li> </ol>"},{"location":"contributing/#release-process","title":"\ud83d\udd04 Release Process","text":""},{"location":"contributing/#version-numbering","title":"Version Numbering","text":"<p>We follow Semantic Versioning: - MAJOR: Breaking changes - MINOR: New features (backward compatible) - PATCH: Bug fixes</p>"},{"location":"contributing/#release-checklist","title":"Release Checklist","text":"<ul> <li> All tests passing</li> <li> Documentation updated</li> <li> CHANGELOG updated</li> <li> Version bumped</li> <li> Tagged release</li> <li> Published to PyPI</li> </ul>"},{"location":"contributing/#community","title":"\ud83d\udc65 Community","text":""},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>We follow the Contributor Covenant Code of Conduct.</p> <p>Be: - Respectful - Constructive - Inclusive - Professional</p> <p>Don't: - Harass or discriminate - Troll or spam - Use inappropriate language - Share private information</p>"},{"location":"contributing/#getting-help","title":"Getting Help","text":"<ul> <li>Discord: Join our server</li> <li>Discussions: GitHub Discussions</li> <li>Issues: GitHub Issues</li> <li>Email: support@marsys.ai</li> </ul>"},{"location":"contributing/#current-priorities","title":"\ud83c\udfaf Current Priorities","text":""},{"location":"contributing/#high-priority","title":"High Priority","text":"<ul> <li>Performance optimization</li> <li>Browser agent stability</li> <li>Documentation improvements</li> <li>Test coverage expansion</li> </ul>"},{"location":"contributing/#feature-requests","title":"Feature Requests","text":"<ul> <li>Streaming responses</li> <li>Distributed execution</li> <li>Advanced learning agents</li> <li>Custom storage backends</li> </ul>"},{"location":"contributing/#known-issues","title":"Known Issues","text":"<p>Check our issue tracker for current bugs and feature requests.</p>"},{"location":"contributing/#license","title":"\ud83d\udcdc License","text":"<p>By contributing, you agree that your contributions will be licensed under the same license as the project (Apache License 2.0).</p>"},{"location":"contributing/#recognition","title":"\ud83d\ude4f Recognition","text":""},{"location":"contributing/#contributors","title":"Contributors","text":"<p>Thanks to all our contributors!</p>"},{"location":"contributing/#special-thanks","title":"Special Thanks","text":"<ul> <li>OpenAI, Anthropic, Google for AI models</li> <li>The open-source community</li> <li>All our users and testers</li> </ul>"},{"location":"contributing/#next-steps","title":"\ud83d\udea6 Next Steps","text":"<ul> <li> <p> GitHub Repo</p> <p>Star and watch the repository</p> </li> <li> <p> Documentation</p> <p>Learn the framework</p> </li> <li> <p>:material-discord:{ .lg .middle } Join Discord</p> <p>Chat with the community</p> </li> <li> <p> Contact Us</p> <p>Get in touch</p> </li> </ul> <p>Thank You!</p> <p>Every contribution makes MARSYS better. Whether it's fixing a typo, adding a feature, or helping others - we appreciate your effort!</p> <p>First Time?</p> <p>If this is your first open-source contribution, check out First Contributions for a gentle introduction.</p>"},{"location":"getting-started/","title":"Getting Started with MARSYS","text":"<p>Welcome to MARSYS (Multi-Agent Reasoning Systems) - a beta framework for building collaborative AI agent systems. This guide will help you understand what MARSYS offers and how to get started.</p>"},{"location":"getting-started/#what-youll-build","title":"\ud83c\udfaf What You'll Build","text":"<p>With MARSYS, you can create sophisticated multi-agent systems where AI agents collaborate to solve complex problems. Here's what's possible:</p> <ul> <li> <p> Collaborative Teams</p> <p>Build teams of specialized agents that work together, like research teams, customer support systems, or development squads</p> </li> <li> <p> Complex Workflows</p> <p>Design intricate workflows with parallel execution, conditional routing, and automatic convergence</p> </li> <li> <p> Human-AI Collaboration</p> <p>Integrate human feedback seamlessly with User nodes for approval workflows and interactive systems</p> </li> <li> <p> Persistent Sessions</p> <p>Create long-running workflows that can be paused, resumed, and checkpointed for reliability</p> </li> </ul>"},{"location":"getting-started/#quick-overview","title":"\ud83d\ude80 Quick Overview","text":"<p>API Keys Required for API Models</p> <p>Set your API key by environment variable or directly in <code>ModelConfig(api_key=\"...\")</code>. For local models, no API keys needed.</p> <p>Quick setup - Set OpenRouter API key (recommended for unified access):</p> macOS/LinuxWindows <pre><code>export OPENROUTER_API_KEY=\"your-api-key-here\"\n</code></pre> <pre><code>set OPENROUTER_API_KEY=your-api-key-here\n</code></pre> <p>See Installation Guide - Configure API Keys for other providers and detailed setup.</p> <p>MARSYS provides multiple ways to orchestrate agents. Here's the simplest approach using <code>allowed_peers</code>:</p> <pre><code>from marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\n# Create agents with same configuration\nmodel_config = ModelConfig(\n    type=\"api\",\n    name=\"anthropic/claude-opus-4.6\",\n    provider=\"openrouter\"\n)\n\n# Define agents and their allowed interactions\nresearcher = Agent(\n    model_config=model_config,\n    name=\"Researcher\",\n    goal=\"Expert at finding and analyzing information\",\n    instruction=\"You are a research specialist. Find and analyze information thoroughly.\",\n    allowed_peers=[\"Writer\"]  # Can invoke the Writer agent\n)\n\nwriter = Agent(\n    model_config=model_config,\n    name=\"Writer\",\n    goal=\"Skilled at creating clear, engaging content\",\n    instruction=\"You are a skilled writer. Create clear, engaging content based on research.\",\n    allowed_peers=[]  # Cannot invoke other agents\n)\n\n# Run with automatic topology creation\nresult = await researcher.auto_run(\n    task=\"Research AI trends and write a report\",\n    max_steps=20,\n    verbosity=1  # Show progress\n)\n\nprint(result)\n</code></pre> <p>This is just one of four ways to define multi-agent systems in MARSYS. As your needs grow, you can use more structured approaches with explicit topologies and pre-defined patterns.</p>"},{"location":"getting-started/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>Python 3.12+ installed on your system</li> <li>pip or conda for package management</li> <li>API keys for your chosen AI providers (OpenAI, Anthropic, Google, etc.)</li> <li>Basic understanding of Python async/await (helpful but not required)</li> </ul>"},{"location":"getting-started/#learning-path","title":"\ud83d\uddfa\ufe0f Learning Path","text":"<p>Follow this recommended path to master MARSYS:</p>"},{"location":"getting-started/#1-installation-5-minutes","title":"1\ufe0f\u20e3 Installation (5 minutes)","text":"<p>Get MARSYS installed and configured on your system. \ud83d\udc49 Installation Guide</p>"},{"location":"getting-started/#2-quick-start-10-minutes","title":"2\ufe0f\u20e3 Quick Start (10 minutes)","text":"<p>Build your first multi-agent system with a simple example. \ud83d\udc49 Quick Start Tutorial</p>"},{"location":"getting-started/#3-your-first-agent-15-minutes","title":"3\ufe0f\u20e3 Your First Agent (15 minutes)","text":"<p>Create a custom agent with tools and memory management. \ud83d\udc49 First Agent Guide</p>"},{"location":"getting-started/#4-configuration-10-minutes","title":"4\ufe0f\u20e3 Configuration (10 minutes)","text":"<p>Learn about execution configs, timeouts, and status management. \ud83d\udc49 Configuration Reference</p>"},{"location":"getting-started/#5-core-concepts-30-minutes","title":"5\ufe0f\u20e3 Core Concepts (30 minutes)","text":"<p>Understand topologies, execution flow, and agent communication. \ud83d\udc49 Concepts Overview</p>"},{"location":"getting-started/#key-features-at-a-glance","title":"\u2728 Key Features at a Glance","text":""},{"location":"getting-started/#simple-yet-powerful","title":"Simple yet Powerful","text":"<pre><code># One-line execution for simple tasks\nresult = await Orchestra.run(\n    task=\"Analyze this data\",\n    topology={\"agents\": [\"Analyst\"], \"flows\": []}\n)\n</code></pre>"},{"location":"getting-started/#flexible-topologies","title":"Flexible Topologies","text":"<pre><code># Choose from 8 pre-defined patterns\ntopology = PatternConfig.pipeline(\n    stages=[\n        {\"name\": \"collect\", \"agents\": [\"Collector\"]},\n        {\"name\": \"process\", \"agents\": [\"Processor1\", \"Processor2\"]},\n        {\"name\": \"report\", \"agents\": [\"Reporter\"]}\n    ],\n    parallel_within_stage=True\n)\n</code></pre>"},{"location":"getting-started/#agent-pools-for-parallelism","title":"Agent Pools for Parallelism","text":"<pre><code># True parallel execution with isolated agents\npool = AgentPool(\n    agent_class=BrowserAgent,\n    num_instances=3,\n    name=\"BrowserPool\"\n)\n</code></pre>"},{"location":"getting-started/#state-persistence","title":"State Persistence","text":"<pre><code># Long-running workflows with checkpoints\nresult = await Orchestra.run(\n    task=\"Multi-day research project\",\n    topology=topology,\n    state_manager=StateManager(storage)\n)\n</code></pre>"},{"location":"getting-started/#framework-architecture","title":"\ud83c\udfd7\ufe0f Framework Architecture","text":"<p>MARSYS uses a layered architecture for maximum flexibility:</p> <pre><code>graph LR\n    A[User Task] --&gt; B[Orchestra]\n    B --&gt; C[Topology]\n    C --&gt; D[Execution&lt;br/&gt;Branches]\n    D --&gt; E[Agents]\n    E --&gt; F[Models/Tools]\n\n    style B fill:#4A90E2,color:#fff\n    style D fill:#7B68EE,color:#fff\n    style E fill:#50C878,color:#fff</code></pre> <p>Key Components:</p> <ul> <li>Orchestra: High-level coordination API</li> <li>Topology: Defines agent relationships and communication rules</li> <li>Branches: Parallel execution contexts with isolation</li> <li>Agents: Individual AI agents with specific capabilities</li> <li>Tools: Functions agents can call to interact with external systems</li> </ul>"},{"location":"getting-started/#common-use-cases","title":"\ud83d\udca1 Common Use Cases","text":""},{"location":"getting-started/#research-systems","title":"Research Systems","text":"<p>Build intelligent research assistants that gather, analyze, and synthesize information from multiple sources.</p>"},{"location":"getting-started/#customer-support","title":"Customer Support","text":"<p>Create multi-tier support systems with automatic escalation and specialized agents for different issues.</p>"},{"location":"getting-started/#content-creation","title":"Content Creation","text":"<p>Design content pipelines with agents for ideation, writing, editing, and formatting.</p>"},{"location":"getting-started/#data-processing","title":"Data Processing","text":"<p>Orchestrate complex data workflows with parallel processing and validation stages.</p>"},{"location":"getting-started/#example-simple-research-team","title":"\ud83c\udf93 Example: Simple Research Team","text":"<p>Here's a complete example to get you started:</p> <pre><code>import asyncio\nfrom marsys.coordination import Orchestra\nfrom marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\n# Create a single model configuration\nmodel_config = ModelConfig(\n    type=\"api\",\n    name=\"anthropic/claude-opus-4.6\",\n    provider=\"openrouter\"\n)\n\n# Create specialized agents\nresearcher = Agent(\n    model_config=model_config,\n    name=\"Researcher\",\n    goal=\"Expert at finding and analyzing information\",\n    instruction=\"You are a research specialist. Find and analyze information thoroughly.\"\n)\n\nwriter = Agent(\n    model_config=model_config,\n    name=\"Writer\",\n    goal=\"Skilled at creating clear, engaging content\",\n    instruction=\"You are a skilled writer. Create clear, engaging content based on research.\"\n)\n\n# Define workflow\ntopology = {\n    \"agents\": [\"Researcher\", \"Writer\"],\n    \"flows\": [\"Researcher -&gt; Writer\"]\n}\n\n# Run the system\nasync def main():\n    result = await Orchestra.run(\n        task=\"Research quantum computing and write a beginner's guide\",\n        topology=topology\n    )\n    print(result.final_response)\n\nasyncio.run(main())\n</code></pre>"},{"location":"getting-started/#next-steps","title":"\ud83d\udea6 Next Steps","text":"<p>Ready to build your first multi-agent system? Here's what to do:</p> <ul> <li> <p> Install MARSYS</p> <p>Get the framework installed and set up your environment</p> </li> <li> <p> Quick Start Tutorial</p> <p>Build a working multi-agent system in 10 minutes</p> </li> <li> <p> Read the Concepts</p> <p>Understand the core ideas behind MARSYS</p> </li> <li> <p> Explore Examples</p> <p>See real-world implementations and patterns</p> </li> </ul>"},{"location":"getting-started/#getting-help","title":"\ud83c\udd98 Getting Help","text":"<p>If you run into issues:</p> <ul> <li>Check the FAQ for common questions</li> <li>Browse GitHub Issues for similar problems</li> <li>Join our Discord Community for real-time help</li> <li>Review the API Reference for detailed documentation</li> </ul> <p>Ready to Start?</p> <p>Jump into the Installation Guide to get MARSYS up and running on your system!</p>"},{"location":"getting-started/configuration/","title":"Configuration","text":"<p>Master MARSYS configuration to fine-tune execution behavior, timeouts, status management, and more.</p>"},{"location":"getting-started/configuration/#overview","title":"\ud83c\udfaf Overview","text":"<p>MARSYS provides comprehensive configuration at multiple levels:</p> <ul> <li>Model Configuration: Provider settings, API keys, parameters</li> <li>Agent Configuration: Tools, memory, response formats</li> <li>Execution Configuration: Timeouts, retries, convergence behavior</li> <li>Status Configuration: Verbosity, output formatting, channels</li> <li>Communication Configuration: User interaction, rich formatting</li> </ul>"},{"location":"getting-started/configuration/#environment-variables","title":"\ud83d\udd11 Environment Variables","text":""},{"location":"getting-started/configuration/#basic-setup","title":"Basic Setup","text":"<p>Create a <code>.env</code> file in your project root:</p> <pre><code># .env\n\n# API Keys (at least one required)\nOPENAI_API_KEY=\"sk-...\"\nANTHROPIC_API_KEY=\"sk-ant-...\"\nGOOGLE_API_KEY=\"AIza...\"\nGROQ_API_KEY=\"gsk_...\"\n\n# Optional Configuration\nHEADLESS=true              # Browser automation mode\nLOG_LEVEL=INFO            # Logging verbosity\nMAX_RETRIES=3             # API retry attempts\nTIMEOUT=300               # Default timeout in seconds\n</code></pre>"},{"location":"getting-started/configuration/#advanced-environment-variables","title":"Advanced Environment Variables","text":"<pre><code># Model-specific settings\nOPENAI_ORG_ID=\"org-...\"\nOPENAI_BASE_URL=\"https://api.openai.com/v1\"\nANTHROPIC_VERSION=\"2023-06-01\"\n\n# Browser automation\nPLAYWRIGHT_BROWSERS_PATH=\"/path/to/browsers\"\nPLAYWRIGHT_TIMEOUT=30000\n\n# System resources\nMAX_WORKERS=4\nMEMORY_LIMIT_MB=2048\nDISK_CACHE_PATH=\"/tmp/marsys_cache\"\n\n# Monitoring\nENABLE_TELEMETRY=false\nMETRICS_PORT=9090\nTRACE_LEVEL=ERROR\n</code></pre>"},{"location":"getting-started/configuration/#model-configuration","title":"\ud83e\udd16 Model Configuration","text":""},{"location":"getting-started/configuration/#modelconfig-class","title":"ModelConfig Class","text":"<p>The core configuration class for all models:</p> <pre><code>from marsys.models import ModelConfig\n\nconfig = ModelConfig(\n    type=\"api\",                    # \"api\" or \"local\"\n    provider=\"openrouter\",         # Provider name\n    name=\"anthropic/claude-opus-4.6\",  # Model name\n    api_key=None,                  # Auto-loads from env\n    base_url=None,                 # Custom endpoint\n    temperature=0.7,               # Sampling temperature\n    max_tokens=2000                # Maximum output tokens\n)\n</code></pre>"},{"location":"getting-started/configuration/#provider-specific-configurations","title":"Provider-Specific Configurations","text":"<p>Common provider examples:</p> <pre><code># OpenRouter (recommended - access to all models)\nconfig = ModelConfig(\n    type=\"api\",\n    provider=\"openrouter\",\n    name=\"anthropic/claude-opus-4.6\",  # or openai/gpt-5-codex, google/gemini-3-flash-preview, etc.\n    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n    temperature=0.7,\n    max_tokens=12000\n)\n\n# Local Ollama\nconfig = ModelConfig(\n    type=\"local\",\n    provider=\"ollama\",\n    name=\"llama2:13b\",\n    base_url=\"http://localhost:11434\"\n)\n</code></pre>"},{"location":"getting-started/configuration/#oauth-providers-no-api-keys","title":"OAuth Providers (No API Keys)","text":"<p>You can also use subscription-based OAuth providers that rely on CLI logins and <code>marsys oauth</code> profile management:</p> <pre><code># OpenAI ChatGPT OAuth (Codex CLI)\nconfig = ModelConfig(\n    type=\"api\",\n    provider=\"openai-oauth\",\n    name=\"gpt-5.3-codex\",\n    oauth_profile=\"personal-openai\",  # Optional: explicit profile\n)\n\n# Anthropic Claude OAuth (Claude CLI)\nconfig = ModelConfig(\n    type=\"api\",\n    provider=\"anthropic-oauth\",\n    name=\"claude-opus-4-6\",\n    oauth_profile=\"work-claude\",  # Optional: explicit profile\n)\n</code></pre> <p>These providers load credentials from:</p> <ul> <li><code>~/.codex/auth.json</code> (override with <code>CODEX_AUTH_PATH</code>)</li> <li><code>~/.claude/.credentials.json</code> (override with <code>CLAUDE_AUTH_PATH</code>)</li> </ul> <p>Profile resolution order: 1. <code>credentials_path</code> in <code>ModelConfig</code> (if provided) 2. <code>oauth_profile</code> in <code>ModelConfig</code> (if provided) 3. Default profile for that provider (<code>marsys oauth set-default ...</code>)</p> <p>Useful OAuth CLI commands:</p> <pre><code>marsys oauth add &lt;name&gt; --provider openai-oauth\nmarsys oauth add &lt;name&gt; --provider anthropic-oauth\nmarsys oauth list\nmarsys oauth set-default &lt;provider&gt; &lt;name&gt;\nmarsys oauth refresh &lt;name&gt; [--force]\n</code></pre> <p>Use At Your Own Risk (Anthropic OAuth)</p> <p><code>anthropic-oauth</code> relies on a non-official integration path and may violate provider Terms of Service. Use at your own risk.</p> <p>OpenAI OAuth Compliance</p> <p>MARSYS does not make a legal determination about OpenAI ToS coverage for this OAuth path. Review OpenAI terms for your use case.</p> <p>Provider-Specific Parameters</p> <p>Each provider supports unique parameters (reasoning_effort, thinking_budget, safety_settings, etc.). See Models API Reference for complete provider-specific documentation.</p>"},{"location":"getting-started/configuration/#execution-configuration","title":"\u2699\ufe0f Execution Configuration","text":""},{"location":"getting-started/configuration/#executionconfig","title":"ExecutionConfig","text":"<p>Fine-tune how Orchestra executes workflows:</p> <pre><code>from marsys.coordination.config import ExecutionConfig, StatusConfig, VerbosityLevel\n\nconfig = ExecutionConfig(\n    # Timeout settings (seconds)\n    convergence_timeout=300.0,         # Max wait for parallel branches\n    branch_timeout=600.0,              # Max time per branch\n    agent_acquisition_timeout=240.0,   # Max wait to acquire from pool\n    step_timeout=300.0,                # Max time per step\n    tool_execution_timeout=120.0,      # Max time for tool calls\n    user_interaction_timeout=300.0,    # Max wait for user input\n\n    # Convergence behavior\n    dynamic_convergence_enabled=True,  # Auto-detect convergence points\n    parent_completes_on_spawn=True,    # Parent waits for children\n    auto_detect_convergence=True,      # Automatic convergence detection\n\n    # Steering mode for retry guidance\n    steering_mode=\"error\",             # \"auto\", \"always\", \"error\"\n\n    # Status and output\n    status=StatusConfig.from_verbosity(VerbosityLevel.NORMAL),\n\n    # User interaction\n    user_interaction=\"terminal\",       # \"terminal\", \"none\", \"async\"\n    user_first=False,                  # Show initial message to user\n    initial_user_msg=None,            # Custom initial message\n)\n</code></pre>"},{"location":"getting-started/configuration/#timeout-configuration","title":"Timeout Configuration","text":"<p>Different timeout levels for different scenarios:</p> <pre><code># Quick tasks - tight timeouts\nquick_config = ExecutionConfig(\n    step_timeout=30.0,\n    convergence_timeout=60.0,\n    branch_timeout=120.0\n)\n\n# Long-running research - relaxed timeouts\nresearch_config = ExecutionConfig(\n    step_timeout=300.0,\n    convergence_timeout=600.0,\n    branch_timeout=1800.0,\n    user_interaction_timeout=600.0\n)\n\n# Real-time systems - strict timeouts\nrealtime_config = ExecutionConfig(\n    step_timeout=10.0,\n    convergence_timeout=30.0,\n    branch_timeout=60.0,\n    steering_mode=\"error\"  # Minimal steering for speed\n)\n</code></pre>"},{"location":"getting-started/configuration/#status-configuration","title":"\ud83d\udcca Status Configuration","text":""},{"location":"getting-started/configuration/#statusconfig","title":"StatusConfig","text":"<p>Control output verbosity and formatting:</p> <pre><code>from marsys.coordination.config import StatusConfig, VerbosityLevel\n\n# Quick setup with verbosity levels\nstatus = StatusConfig.from_verbosity(VerbosityLevel.QUIET)    # Minimal output\nstatus = StatusConfig.from_verbosity(VerbosityLevel.NORMAL)   # Standard output\nstatus = StatusConfig.from_verbosity(VerbosityLevel.VERBOSE)  # Detailed output\n\n# Detailed configuration\nstatus = StatusConfig(\n    enabled=True,\n    verbosity=VerbosityLevel.NORMAL,\n\n    # Output control\n    cli_output=True,                  # Show CLI output\n    cli_colors=True,                  # Use colors\n    show_thoughts=False,              # Show agent thoughts\n    show_tool_calls=True,             # Show tool invocations\n    show_timings=True,                # Show execution times\n\n    # Aggregation\n    aggregation_window_ms=500,        # Group updates within window\n    aggregate_parallel=True,          # Aggregate parallel branches\n\n    # Display formatting\n    show_agent_prefixes=True,         # Show agent names\n    prefix_width=20,                  # Width for agent names\n    prefix_alignment=\"left\",          # \"left\", \"right\", \"center\"\n\n    # Output channels\n    channels=[\"cli\"],                 # Output destinations\n\n    # Follow-up timeout\n    follow_up_timeout=30.0            # Timeout for follow-up questions\n)\n</code></pre>"},{"location":"getting-started/configuration/#verbosity-levels-explained","title":"Verbosity Levels Explained","text":"Level Description Use Case <code>QUIET</code> (0) Minimal output, errors only Production, CI/CD <code>NORMAL</code> (1) Standard output with key events Development <code>VERBOSE</code> (2) Detailed output with all events Debugging"},{"location":"getting-started/configuration/#communication-configuration","title":"\ud83d\udcac Communication Configuration","text":""},{"location":"getting-started/configuration/#communicationconfig","title":"CommunicationConfig","text":"<p>Configure user interaction and formatting:</p> <pre><code>from marsys.coordination.config import CommunicationConfig\n\ncomm_config = CommunicationConfig(\n    # Rich formatting\n    use_rich_formatting=True,          # Use rich terminal features\n    theme_name=\"modern\",               # \"modern\", \"classic\", \"minimal\"\n\n    # Display settings\n    prefix_width=20,                  # Agent name column width\n    show_timestamps=True,             # Show message timestamps\n    timestamp_format=\"%H:%M:%S\",      # Time format\n\n    # History\n    enable_history=True,              # Keep conversation history\n    history_size=1000,                # Max history entries\n\n    # Interactive features\n    enable_tab_completion=True,       # Tab completion for commands\n    use_colors=True,                  # Terminal colors\n    color_depth=\"truecolor\",          # \"truecolor\", \"256\", \"16\", \"none\"\n\n    # Input handling\n    input_timeout=None,               # No timeout by default\n    multiline_input=True,             # Support multi-line input\n\n    # Terminal enhancement\n    use_enhanced_terminal=True,       # Use enhanced terminal features\n    fallback_on_error=True,          # Fallback to basic on error\n)\n</code></pre>"},{"location":"getting-started/configuration/#error-handling-configuration","title":"\ud83d\udd27 Error Handling Configuration","text":""},{"location":"getting-started/configuration/#errorhandlingconfig","title":"ErrorHandlingConfig","text":"<p>Configure error recovery strategies:</p> <pre><code>from marsys.coordination.config import ErrorHandlingConfig\n\nerror_config = ErrorHandlingConfig(\n    # Classification and routing\n    use_error_classification=True,    # Classify error types\n    enable_error_routing=True,        # Route errors to User node\n    preserve_error_context=True,      # Keep error context\n\n    # Notifications\n    notify_on_critical_errors=True,   # Alert on critical errors\n\n    # Retry behavior\n    auto_retry_on_rate_limits=True,   # Auto-retry rate limits\n    max_rate_limit_retries=3,\n\n    # Pool-specific\n    pool_retry_attempts=2,            # Retries for pool acquisition\n    pool_retry_delay=5.0,             # Delay between pool retries\n\n    # Timeout handling\n    timeout_seconds=300.0,            # Global timeout\n    timeout_retry_enabled=False,      # Retry on timeout\n\n    # Provider-specific settings\n    provider_settings={\n        \"openai\": {\n            \"max_retries\": 3,\n            \"base_retry_delay\": 60,\n            \"insufficient_quota_action\": \"raise\",  # or \"fallback\"\n            \"fallback_model\": \"gpt-5.3-codex\"\n        },\n        \"anthropic\": {\n            \"max_retries\": 2,\n            \"base_retry_delay\": 30,\n            \"insufficient_quota_action\": \"fallback\",\n            \"fallback_model\": \"anthropic/claude-opus-4.6\"\n        },\n        \"google\": {\n            \"max_retries\": 3,\n            \"base_retry_delay\": 45,\n            \"insufficient_quota_action\": \"raise\"\n        }\n    }\n)\n</code></pre>"},{"location":"getting-started/configuration/#complete-configuration-example","title":"\ud83c\udf9b\ufe0f Complete Configuration Example","text":"<p>Here's a comprehensive configuration for a production system:</p> <pre><code>import os\nfrom marsys.coordination import Orchestra\nfrom marsys.coordination.config import (\n    ExecutionConfig,\n    StatusConfig,\n    CommunicationConfig,\n    ErrorHandlingConfig,\n    VerbosityLevel\n)\nfrom marsys.coordination.state import StateManager, FileStorageBackend\nfrom pathlib import Path\n\n# Create comprehensive configuration\ndef create_production_config():\n    \"\"\"Create production-ready configuration.\"\"\"\n\n    # Execution configuration\n    exec_config = ExecutionConfig(\n        # Balanced timeouts\n        convergence_timeout=300.0,\n        branch_timeout=600.0,\n        step_timeout=120.0,\n        tool_execution_timeout=30.0,\n        user_interaction_timeout=300.0,\n\n        # Enable smart features\n        dynamic_convergence_enabled=True,\n        auto_detect_convergence=True,\n        steering_mode=\"auto\",\n\n        # Agent lifecycle\n        auto_cleanup_agents=True,\n\n        # Status for production\n        status=StatusConfig(\n            enabled=True,\n            verbosity=VerbosityLevel.NORMAL,\n            cli_output=True,\n            cli_colors=True,\n            show_timings=True,\n            show_tool_calls=False,  # Reduce noise\n            show_thoughts=False,    # Reduce noise\n            aggregate_parallel=True,\n            channels=[\"cli\", \"file\"],\n            file_path=\"logs/execution.log\"\n        ),\n\n        # User interaction\n        user_interaction=\"terminal\",\n        user_first=False\n    )\n\n    # Communication configuration\n    comm_config = CommunicationConfig(\n        use_rich_formatting=True,\n        theme_name=\"modern\",\n        show_timestamps=True,\n        enable_history=True,\n        history_size=1000,\n        use_enhanced_terminal=True,\n        fallback_on_error=True\n    )\n\n    # Error handling\n    error_config = ErrorHandlingConfig(\n        use_error_classification=True,\n        enable_error_routing=True,\n        notify_on_critical_errors=True,\n        auto_retry_on_rate_limits=True,\n        max_rate_limit_retries=5,\n        rate_limit_backoff=60,\n        provider_settings={\n            \"openai\": {\n                \"max_retries\": 3,\n                \"base_retry_delay\": 60,\n                \"insufficient_quota_action\": \"fallback\",\n                \"fallback_model\": \"gpt-5.3-codex\"\n            }\n        }\n    )\n\n    return exec_config, comm_config, error_config\n\n# Use configuration\nasync def run_with_config():\n    exec_config, comm_config, error_config = create_production_config()\n\n    # State persistence\n    storage = FileStorageBackend(Path(\"./state\"))\n    state_manager = StateManager(storage)\n\n    # Run with full configuration\n    # Note: communication and error handling settings are part of ExecutionConfig\n    result = await Orchestra.run(\n        task=\"Complex multi-agent task\",\n        topology=topology,\n        execution_config=exec_config,\n        state_manager=state_manager,\n        max_steps=50\n    )\n\n    return result\n</code></pre>"},{"location":"getting-started/configuration/#configuration-patterns","title":"\ud83c\udfaf Configuration Patterns","text":""},{"location":"getting-started/configuration/#pattern-1-development-configuration","title":"Pattern 1: Development Configuration","text":"<pre><code># Maximum visibility for debugging\ndev_config = ExecutionConfig(\n    status=StatusConfig.from_verbosity(VerbosityLevel.VERBOSE),\n    steering_mode=\"always\",  # Always retry\n    user_interaction=\"terminal\"\n)\n</code></pre>"},{"location":"getting-started/configuration/#pattern-2-production-configuration","title":"Pattern 2: Production Configuration","text":"<pre><code># Balanced for reliability\nprod_config = ExecutionConfig(\n    status=StatusConfig.from_verbosity(VerbosityLevel.QUIET),\n    steering_mode=\"auto\",\n    max_retries=5,\n    exponential_backoff=True\n)\n</code></pre>"},{"location":"getting-started/configuration/#pattern-3-real-time-configuration","title":"Pattern 3: Real-time Configuration","text":"<pre><code># Optimized for speed\nrealtime_config = ExecutionConfig(\n    step_timeout=10.0,\n    convergence_timeout=30.0,\n    steering_mode=\"error\",  # Minimal retries (only on errors)\n    status=StatusConfig(enabled=False)  # No output overhead\n)\n</code></pre>"},{"location":"getting-started/configuration/#pattern-4-long-running-configuration","title":"Pattern 4: Long-running Configuration","text":"<pre><code># For multi-hour workflows\nlong_config = ExecutionConfig(\n    branch_timeout=3600.0,  # 1 hour\n    convergence_timeout=1800.0,  # 30 minutes\n    user_interaction_timeout=900.0,  # 15 minutes\n    dynamic_convergence_enabled=True\n)\n</code></pre> <p>Advanced Configuration Topics</p> <p>For production deployment, monitoring, security, and advanced features, see:</p> <ul> <li>Configuration API Reference - Complete parameter documentation</li> <li>Guides - Production deployment patterns</li> </ul>"},{"location":"getting-started/configuration/#next-steps","title":"\ud83d\udea6 Next Steps","text":"<p>With configuration mastered:</p> <ul> <li> <p> Learn Topologies</p> <p>Design agent interaction patterns</p> </li> <li> <p> Understand Concepts</p> <p>Explore framework architecture</p> </li> <li> <p> See Examples</p> <p>Learn from real implementations</p> </li> <li> <p> API Reference</p> <p>Detailed API documentation</p> </li> </ul> <p>Configuration Complete!</p> <p>You now understand MARSYS configuration! Explore Core Concepts to understand the framework architecture.</p>"},{"location":"getting-started/first-agent/","title":"Your First Agent","text":"<p>Learn how to create custom agents with specialized capabilities, tools, and memory management.</p>"},{"location":"getting-started/first-agent/#what-youll-learn","title":"\ud83c\udfaf What You'll Learn","text":"<p>In this guide, you'll learn how to: - Create basic agents with different models - Add tools to extend agent capabilities - Implement memory patterns - Create custom agent classes - Build specialized agents (browser, learnable, etc.)</p>"},{"location":"getting-started/first-agent/#basic-agent-creation","title":"\ud83e\udd16 Basic Agent Creation","text":""},{"location":"getting-started/first-agent/#simple-agent","title":"Simple Agent","text":"<p>The simplest way to create an agent:</p> <pre><code>import asyncio\nfrom marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\nasync def main():\n    # Create an agent with Claude Opus 4.6\n    agent = Agent(\n        model_config=ModelConfig(\n            type=\"api\",\n            name=\"anthropic/claude-opus-4.6\",\n            provider=\"openrouter\"\n        ),\n        name=\"Assistant\",\n        goal=\"Provide helpful assistance to users\",\n        instruction=\"A helpful AI assistant that responds thoughtfully to user queries\"\n    )\n\n    # Use with Orchestra\n    from marsys.coordination import Orchestra\n\n    result = await Orchestra.run(\n        task=\"Explain quantum computing in simple terms\",\n        topology={\"agents\": [\"Assistant\"], \"flows\": []}\n    )\n\n    print(result.final_response)\n\nasyncio.run(main())\n</code></pre>"},{"location":"getting-started/first-agent/#agent-with-system-prompt","title":"Agent with System Prompt","text":"<p>Customize agent behavior with detailed system prompts:</p> <pre><code>agent = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\"\n    ),\n    name=\"TechnicalWriter\",\n    goal=\"Write clear, professional technical documentation\",\n    instruction=\"\"\"You are an expert technical writer who:\n    - Writes clear, concise documentation\n    - Uses examples to illustrate concepts\n    - Follows best practices for technical writing\n    - Organizes content logically with headers\n    - Includes code examples when relevant\n\n    Always structure your responses with proper markdown formatting.\"\"\"\n)\n</code></pre>"},{"location":"getting-started/first-agent/#agent-with-different-providers","title":"Agent with Different Providers","text":"<p>MARSYS supports multiple AI providers:</p> OpenAIAnthropicGoogleLocal (Ollama) <pre><code>agent = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"openai/gpt-5-codex\",\n        provider=\"openrouter\",\n        api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n        temperature=0.7,\n        max_tokens=12000\n    ),\n    name=\"GPTAgent\",\n    goal=\"Assist with general AI tasks using GPT-5 Codex\",\n    instruction=\"An intelligent GPT-5 Codex agent for versatile assistance\"\n)\n</code></pre> <pre><code>agent = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\",\n        api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n        temperature=0.5,\n        max_tokens=12000\n    ),\n    name=\"ClaudeAgent\",\n    goal=\"Provide thoughtful assistance using Claude's capabilities\",\n    instruction=\"An Anthropic Claude agent with strong reasoning abilities\"\n)\n</code></pre> <pre><code>agent = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"gemini-3-flash-preview\",\n        provider=\"google\",\n        api_key=os.getenv(\"GOOGLE_API_KEY\"),\n        temperature=0.9,\n        top_p=0.95\n    ),\n    name=\"GeminiAgent\",\n    goal=\"Leverage Google's Gemini model for AI assistance\",\n    instruction=\"A Google Gemini agent for advanced language understanding\"\n)\n</code></pre> <pre><code>agent = Agent(\n    model_config=ModelConfig(\n        type=\"local\",\n        name=\"llama2\",\n        provider=\"ollama\",\n        base_url=\"http://localhost:11434\",\n        temperature=0.8\n    ),\n    name=\"LocalAgent\",\n    goal=\"Provide local AI assistance without external API dependencies\",\n    instruction=\"A locally-running Llama 2 agent for privacy-conscious applications\"\n)\n</code></pre>"},{"location":"getting-started/first-agent/#agents-with-tools","title":"\ud83d\udee0\ufe0f Agents with Tools","text":""},{"location":"getting-started/first-agent/#adding-built-in-tools","title":"Adding Built-in Tools","text":"<p>Give your agents access to pre-built tools:</p> <pre><code>from marsys.environment.tools import AVAILABLE_TOOLS\n\n# Agent with multiple tools\nagent = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\"\n    ),\n    name=\"ToolMaster\",\n    goal=\"Execute various tools to assist with complex tasks\",\n    instruction=\"Agent with various tool capabilities for calculations, time, and web search\",\n    tools={\n        \"calculate\": AVAILABLE_TOOLS[\"calculate\"],\n        \"get_time\": AVAILABLE_TOOLS[\"get_time\"],\n        \"search_web\": AVAILABLE_TOOLS[\"search_web\"]\n    }\n)\n</code></pre>"},{"location":"getting-started/first-agent/#creating-custom-tools","title":"Creating Custom Tools","text":"<p>Define your own tools with automatic schema generation:</p> <pre><code>def fetch_stock_price(symbol: str, date: str = \"latest\") -&gt; dict:\n    \"\"\"\n    Fetch stock price for a given symbol.\n\n    Args:\n        symbol: Stock ticker symbol (e.g., 'AAPL')\n        date: Date for historical price or 'latest'\n\n    Returns:\n        Dictionary with price information\n    \"\"\"\n    # Implementation here\n    return {\n        \"symbol\": symbol,\n        \"price\": 150.25,\n        \"date\": date,\n        \"currency\": \"USD\"\n    }\n\ndef analyze_sentiment(text: str, language: str = \"en\") -&gt; dict:\n    \"\"\"\n    Analyze sentiment of provided text.\n\n    Args:\n        text: Text to analyze\n        language: Language code (default: 'en')\n\n    Returns:\n        Sentiment analysis results\n    \"\"\"\n    # Implementation here\n    return {\n        \"sentiment\": \"positive\",\n        \"confidence\": 0.85,\n        \"emotions\": [\"joy\", \"excitement\"]\n    }\n\n# Create agent with custom tools\nagent = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"openai/gpt-5-codex\",\n        provider=\"openrouter\"\n    ),\n    name=\"FinancialAnalyst\",\n    goal=\"Analyze financial data and provide investment insights\",\n    instruction=\"Financial analysis expert with stock price and sentiment analysis capabilities\",\n    tools={\"fetch_stock_price\": fetch_stock_price, \"analyze_sentiment\": analyze_sentiment}\n)\n</code></pre> <p>Tool Schema Generation</p> <p>MARSYS automatically generates OpenAI-compatible tool schemas from your function signatures and docstrings. Use clear type hints and Google-style docstrings for best results.</p>"},{"location":"getting-started/first-agent/#complex-tool-example","title":"Complex Tool Example","text":"<p>Here's a more sophisticated tool with error handling:</p> <pre><code>import aiohttp\nimport json\nfrom typing import Optional, List, Dict\n\nasync def fetch_news(\n    query: str,\n    sources: Optional[List[str]] = None,\n    limit: int = 5,\n    sort_by: str = \"relevance\"\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Fetch news articles based on search query.\n\n    Args:\n        query: Search query for news\n        sources: List of news sources to search (optional)\n        limit: Maximum number of articles to return\n        sort_by: Sort order ('relevance', 'date', 'popularity')\n\n    Returns:\n        Dictionary containing news articles and metadata\n\n    Raises:\n        ValueError: If invalid parameters provided\n        ConnectionError: If API is unreachable\n    \"\"\"\n    if limit &gt; 100:\n        raise ValueError(\"Limit cannot exceed 100\")\n\n    if sort_by not in [\"relevance\", \"date\", \"popularity\"]:\n        raise ValueError(f\"Invalid sort_by: {sort_by}\")\n\n    # API call implementation\n    async with aiohttp.ClientSession() as session:\n        try:\n            # Make API call\n            response = await session.get(\n                \"https://api.example.com/news\",\n                params={\n                    \"q\": query,\n                    \"limit\": limit,\n                    \"sort\": sort_by\n                }\n            )\n            data = await response.json()\n\n            return {\n                \"articles\": data[\"articles\"],\n                \"total\": data[\"total\"],\n                \"query\": query\n            }\n        except Exception as e:\n            raise ConnectionError(f\"Failed to fetch news: {str(e)}\")\n\n# Agent with async tool\nagent = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\",\n        max_tokens=12000\n    ),\n    name=\"NewsAnalyst\",\n    goal=\"Analyze and summarize news articles for key insights\",\n    instruction=\"News analysis and summarization expert with real-time news fetching capabilities\",\n    tools={\"fetch_news\": fetch_news}\n)\n</code></pre>"},{"location":"getting-started/first-agent/#memory-management","title":"\ud83d\udcbe Memory Management","text":""},{"location":"getting-started/first-agent/#memory-retention-policies","title":"Memory Retention Policies","text":"<p>Control how agents remember conversations:</p> <pre><code># Session memory (default) - remembers within session\nagent = Agent(\n    model_config=config,\n    name=\"SessionAgent\",\n    goal=\"Maintain conversation context within a session\",\n    instruction=\"Agent with session memory that remembers previous interactions\",\n    memory_retention=\"session\"  # Default\n)\n\n# Single-run memory - forgets after each task\nagent = Agent(\n    model_config=config,\n    name=\"StatelessAgent\",\n    goal=\"Process each request independently without context\",\n    instruction=\"Stateless agent that treats each interaction as completely new\",\n    memory_retention=\"single_run\"\n)\n\n# Persistent memory - saves to disk\nagent = Agent(\n    model_config=config,\n    name=\"PersistentAgent\",\n    goal=\"Maintain long-term memory across sessions\",\n    instruction=\"Agent with persistent memory that saves conversation history to disk\",\n    memory_retention=\"persistent\"\n)\n</code></pre>"},{"location":"getting-started/first-agent/#working-with-memory","title":"Working with Memory","text":"<p>Access and manipulate agent memory:</p> <pre><code># Access conversation history\nmessages = agent.memory.get_messages()\nfor msg in messages:\n    print(f\"{msg.role}: {msg.content}\")\n\n# Add custom message to memory\nfrom marsys.agents.memory import Message\n\nagent.memory.add_message(Message(\n    role=\"system\",\n    content=\"Remember to be concise in responses\"\n))\n\n# Clear memory\nagent.memory.clear()\n\n# Save/load memory\nagent.memory.save_to_file(\"conversation.json\")\nagent.memory.load_from_file(\"conversation.json\")\n</code></pre>"},{"location":"getting-started/first-agent/#custom-agent-classes","title":"\ud83c\udfa8 Custom Agent Classes","text":""},{"location":"getting-started/first-agent/#creating-a-specialized-agent","title":"Creating a Specialized Agent","text":"<p>Extend the base agent for custom behavior:</p> <pre><code>from marsys.agents import BaseAgent\nfrom marsys.agents.memory import Message\nfrom typing import Dict, Any\n\nclass CodeReviewAgent(BaseAgent):\n    \"\"\"Specialized agent for code review.\"\"\"\n\n    def __init__(self, model_config, **kwargs):\n        super().__init__(\n            model=self._create_model(model_config),\n            goal=\"Review code for style, quality, and security issues\",\n            instruction=\"Expert code reviewer focusing on best practices and security\",\n            **kwargs\n        )\n        self.review_standards = {\n            \"style\": [\"PEP 8\", \"naming conventions\"],\n            \"quality\": [\"DRY\", \"SOLID principles\"],\n            \"security\": [\"input validation\", \"SQL injection\"]\n        }\n\n    async def _run(self, prompt: Any, context: Dict[str, Any], **kwargs) -&gt; Message:\n        \"\"\"Pure execution logic for code review.\"\"\"\n\n        # Enhance prompt with review standards\n        enhanced_prompt = f\"\"\"\n        Review the following code considering:\n        - Style: {', '.join(self.review_standards['style'])}\n        - Quality: {', '.join(self.review_standards['quality'])}\n        - Security: {', '.join(self.review_standards['security'])}\n\n        Original request: {prompt}\n        \"\"\"\n\n        # Prepare messages\n        messages = self._prepare_messages(enhanced_prompt)\n\n        # Call model\n        response = await self.model.run(messages)\n\n        # Return pure Message\n        return Message(\n            role=\"assistant\",\n            content=response.content,\n            metadata={\"review_type\": \"comprehensive\"}\n        )\n\n    def add_review_standard(self, category: str, standard: str):\n        \"\"\"Add custom review standard.\"\"\"\n        if category in self.review_standards:\n            self.review_standards[category].append(standard)\n</code></pre> <p>Advanced Custom Agents</p> <p>For more complex patterns like stateful agents, see Custom Agents Guide.</p>"},{"location":"getting-started/first-agent/#specialized-agent-types","title":"\ud83c\udf10 Specialized Agent Types","text":""},{"location":"getting-started/first-agent/#browser-agent","title":"Browser Agent","text":"<p>For web automation and scraping:</p> <pre><code>from marsys.agents import BrowserAgent\n\nbrowser_agent = await BrowserAgent.create_safe(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"google/gemini-3-flash-preview\",\n        provider=\"openrouter\",\n        max_tokens=12000\n    ),\n    name=\"WebNavigator\",\n    goal=\"Navigate and extract information from websites\",\n    instruction=\"Web automation specialist capable of browser control and content extraction\",\n    mode=\"advanced\",\n    headless=False,\n    viewport_width=1280,\n    viewport_height=720,\n    timeout=30000\n)\n\n# Use in a topology\ntopology = {\n    \"agents\": [\"WebNavigator\"],\n    \"flows\": []\n}\n\nresult = await Orchestra.run(\n    task=\"Go to github.com and find the trending Python repositories\",\n    topology=topology\n)\n</code></pre>"},{"location":"getting-started/first-agent/#learnable-agent","title":"Learnable Agent","text":"<p>Agents that can be fine-tuned:</p> <pre><code>from marsys.agents import LearnableAgent\n\nlearnable_agent = LearnableAgent(\n    model_config=ModelConfig(\n        type=\"local\",\n        name=\"llama2-7b\",\n        provider=\"huggingface\"\n    ),\n    name=\"AdaptiveAgent\",\n    goal=\"Learn and adapt from user interactions to improve over time\",\n    instruction=\"Agent that learns from interactions and can be fine-tuned with examples\",\n    learning_config={\n        \"method\": \"lora\",  # LoRA fine-tuning\n        \"learning_rate\": 1e-4,\n        \"batch_size\": 4\n    }\n)\n\n# Train on examples\nawait learnable_agent.train(\n    examples=[\n        {\"input\": \"What is AI?\", \"output\": \"AI is...\"},\n        {\"input\": \"Explain ML\", \"output\": \"ML is...\"}\n    ]\n)\n</code></pre>"},{"location":"getting-started/first-agent/#agent-communication","title":"\ud83d\udd04 Agent Communication","text":""},{"location":"getting-started/first-agent/#allowing-peer-communication","title":"Allowing Peer Communication","text":"<p>Enable agents to invoke each other:</p> <pre><code># Create researcher\nresearcher = Agent(\n    model_config=config,\n    name=\"Researcher\",\n    goal=\"Conduct thorough research on various topics\",\n    instruction=\"Research specialist with expertise in information gathering and analysis\"\n)\n\n# Create writer that can call researcher\nwriter = Agent(\n    model_config=config,\n    name=\"Writer\",\n    goal=\"Content writer\",\n    instruction=\"Draft clear content using verified research from peer agents.\",\n    allowed_peers=[\"Researcher\"]  # Can invoke Researcher\n)\n\n# Create editor that can call both\neditor = Agent(\n    model_config=config,\n    name=\"Editor\",\n    goal=\"Content editor\",\n    instruction=\"Review and refine drafts for clarity, correctness, and style.\",\n    allowed_peers=[\"Researcher\", \"Writer\"]  # Can invoke both\n)\n</code></pre>"},{"location":"getting-started/first-agent/#agent-response-formats","title":"Agent Response Formats","text":"<p>Agents should return responses in standard formats:</p> <pre><code># For invoking another agent\nresponse = {\n    \"thought\": \"I need more information about this topic\",\n    \"next_action\": \"invoke_agent\",\n    \"action_input\": \"Researcher\"\n}\n\n# For parallel invocation\nresponse = {\n    \"thought\": \"I'll gather data from multiple sources\",\n    \"next_action\": \"parallel_invoke\",\n    \"agents\": [\"DataSource1\", \"DataSource2\"],\n    \"agent_requests\": {\n        \"DataSource1\": \"Get sales data\",\n        \"DataSource2\": \"Get marketing data\"\n    }\n}\n\n# For final response\nresponse = {\n    \"next_action\": \"final_response\",\n    \"content\": \"Here is my analysis...\"\n}\n</code></pre>"},{"location":"getting-started/first-agent/#inputoutput-schemas","title":"\ud83d\udcdd Input/Output Schemas","text":""},{"location":"getting-started/first-agent/#defining-schemas","title":"Defining Schemas","text":"<p>Use Pydantic models for type safety:</p> <pre><code>from pydantic import BaseModel, Field\nfrom typing import List, Optional\n\nclass ResearchRequest(BaseModel):\n    \"\"\"Schema for research requests.\"\"\"\n    topic: str = Field(..., description=\"Research topic\")\n    depth: str = Field(\"medium\", description=\"Research depth: shallow/medium/deep\")\n    sources: Optional[List[str]] = Field(None, description=\"Preferred sources\")\n    max_results: int = Field(10, ge=1, le=100, description=\"Maximum results\")\n\nclass ResearchResponse(BaseModel):\n    \"\"\"Schema for research responses.\"\"\"\n    summary: str = Field(..., description=\"Executive summary\")\n    findings: List[str] = Field(..., description=\"Key findings\")\n    sources: List[str] = Field(..., description=\"Sources used\")\n    confidence: float = Field(..., ge=0, le=1, description=\"Confidence score\")\n\n# Agent with schemas\nagent = Agent(\n    model_config=config,\n    name=\"StructuredResearcher\",\n    goal=\"Researcher with structured I/O\",\n    instruction=\"Return outputs that strictly match the configured schemas.\",\n    input_schema=ResearchRequest,\n    output_schema=ResearchResponse\n)\n</code></pre>"},{"location":"getting-started/first-agent/#advanced-configuration","title":"\u2699\ufe0f Advanced Configuration","text":""},{"location":"getting-started/first-agent/#fine-tuning-agent-behavior","title":"Fine-tuning Agent Behavior","text":"<pre><code>agent = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\",\n        temperature=0.3,\n        max_tokens=12000\n    ),\n    name=\"PrecisionAgent\",\n    goal=\"High-precision analytical agent\",\n    instruction=\"You are a precision analyst. Provide accurate, detailed analysis with clear reasoning.\",\n    max_tokens=12000\n)\n</code></pre>"},{"location":"getting-started/first-agent/#best-practices","title":"\ud83c\udfaf Best Practices","text":""},{"location":"getting-started/first-agent/#1-clear-descriptions","title":"1. Clear Descriptions","text":"<p>Always provide clear, specific descriptions: <pre><code># Good\ngoal=\"Technical documentation writer specializing in API documentation\"\n\n# Bad\ngoal=\"Writer\"\n</code></pre></p>"},{"location":"getting-started/first-agent/#2-appropriate-models","title":"2. Appropriate Models","text":"<p>Choose models based on task requirements: - Claude Opus 4.6 (<code>anthropic/claude-opus-4.6</code>): Strong orchestration, planning, writing - GPT-5 Codex (<code>openai/gpt-5-codex</code>): Advanced coding and analytical tasks via OpenRouter - GPT-5.3 Codex (<code>gpt-5.3-codex</code>): Latest OpenAI OAuth model via <code>provider=\"openai-oauth\"</code> - Gemini 3 Flash Preview (<code>google/gemini-3-flash-preview</code>): Browser vision (fast, cost-effective), general vision tasks - Gemini 3 Pro Preview (<code>google/gemini-3-pro-preview</code>): Complex vision tasks, advanced UI detection - Local: Privacy-sensitive data</p>"},{"location":"getting-started/first-agent/#3-tool-design","title":"3. Tool Design","text":"<p>Keep tools focused and composable: <pre><code># Good - Single responsibility\ndef calculate_tax(amount: float, rate: float) -&gt; float:\n    return amount * rate\n\n# Bad - Multiple responsibilities\ndef process_order_and_calculate_tax_and_send_email(...):\n    # Too many things!\n</code></pre></p>"},{"location":"getting-started/first-agent/#4-memory-management","title":"4. Memory Management","text":"<p>Choose appropriate retention: - single_run: Stateless operations - session: Most workflows - persistent: Long-term learning</p>"},{"location":"getting-started/first-agent/#5-error-handling","title":"5. Error Handling","text":"<p>Always handle potential failures: <pre><code>try:\n    result = await agent.run(prompt)\nexcept Exception as e:\n    logger.error(f\"Agent failed: {e}\")\n    # Fallback logic\n</code></pre></p>"},{"location":"getting-started/first-agent/#next-steps","title":"\ud83d\udea6 Next Steps","text":"<p>Now that you can create custom agents:</p> <ul> <li> <p> Multimodal Agents</p> <p>Build agents that process images and visual content</p> </li> <li> <p> Configure Execution</p> <p>Learn about timeouts, retries, and status management</p> </li> <li> <p> Design Topologies</p> <p>Create complex agent interaction patterns</p> </li> <li> <p> Explore Concepts</p> <p>Understand the framework architecture</p> </li> <li> <p> See Examples</p> <p>Learn from real-world implementations</p> </li> </ul> <p>Ready to Orchestrate?</p> <p>You've learned to create custom agents! Next, explore Configuration to fine-tune execution behavior.</p>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>Get MARSYS up and running on your system in just a few minutes.</p>"},{"location":"getting-started/installation/#prerequisites","title":"\ud83d\udccb Prerequisites","text":"<ul> <li>Python 3.12+ (required)</li> <li>pip package manager</li> <li>Git for cloning the repository (optional)</li> <li>API Keys from at least one provider (OpenAI, Anthropic, Google)</li> </ul>"},{"location":"getting-started/installation/#quick-install","title":"\ud83d\ude80 Quick Install","text":""},{"location":"getting-started/installation/#recommended-setup-with-uv-10-100x-faster-than-pip","title":"Recommended Setup with uv (10-100x faster than pip)","text":"<p>uv is the recommended package manager for MARSYS. It's significantly faster than pip and handles dependency resolution more reliably.</p> <p>Step 1: Install uv</p> Unix/macOSWindows (PowerShell) <pre><code>curl -LsSf https://astral.sh/uv/install.sh | sh\n</code></pre> <pre><code>powershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"\n</code></pre> <p>Step 2: Create virtual environment</p> <pre><code># Create virtual environment\nuv venv\n\n# Activate (Unix/macOS)\nsource .venv/bin/activate\n\n# Activate (Windows)\n.venv\\Scripts\\activate\n\n# Alternative: Use uv run without explicit activation\nuv run python your_script.py\n</code></pre> <p>Step 3: Install MARSYS</p> Basic (Recommended)With Local ModelsProductionDevelopment <p>Everything you need for most use cases: <pre><code>uv pip install marsys\n</code></pre></p> <p>Includes: API models, browser automation, UI, tools, logging</p> <p>Add PyTorch and Transformers for local LLM/VLM support: <pre><code>uv pip install marsys[local-models]\n</code></pre></p> <p>Includes: Everything in Basic + PyTorch, Transformers, TRL, Datasets</p> <p>High-performance inference with vLLM: <pre><code>uv pip install marsys[production]\n</code></pre></p> <p>Includes: vLLM, Flash Attention, Triton, Ninja</p> <p>Complete setup for contributors: <pre><code>uv pip install marsys[dev]\n</code></pre></p> <p>Includes: Everything + testing, linting, documentation tools</p>"},{"location":"getting-started/installation/#alternative-installation-methods","title":"Alternative Installation Methods","text":"Using pipFrom Source <p>Standard Python package manager: <pre><code># Create virtual environment\npython -m venv .venv\nsource .venv/bin/activate  # Unix/macOS\n# .venv\\Scripts\\activate  # Windows\n\n# Install MARSYS\npip install marsys\n</code></pre></p> <p>For development or latest changes: <pre><code>git clone https://github.com/rezaho/MARSYS.git\ncd MARSYS\npip install -e .[dev]\n</code></pre></p>"},{"location":"getting-started/installation/#detailed-installation","title":"\ud83d\udd27 Detailed Installation","text":""},{"location":"getting-started/installation/#1-set-up-virtual-environment-recommended-uv","title":"1. Set Up Virtual Environment (Recommended: uv)","text":"<p>Best Practice</p> <p>Always use a virtual environment to avoid dependency conflicts. We recommend uv for faster installation.</p> uv (Recommended)venv (Standard)conda <pre><code># Create virtual environment\nuv venv\n\n# Activate (Unix/macOS)\nsource .venv/bin/activate\n\n# Activate (Windows)\n.venv\\Scripts\\activate\n\n# Or skip activation and use uv run\nuv run python your_script.py\n</code></pre> <pre><code>python -m venv .venv\nsource .venv/bin/activate  # Unix/macOS\n# .venv\\Scripts\\activate  # Windows\n</code></pre> <pre><code>conda create -n marsys python=3.12\nconda activate marsys\n</code></pre>"},{"location":"getting-started/installation/#2-choose-your-installation","title":"2. Choose Your Installation","text":"Installation Size Time Use Case <code>marsys</code> ~200 MB 1-2 min API models + browser + tools \u2728 <code>marsys[local-models]</code> ~2-3 GB 5-10 min + Local LLMs/VLMs <code>marsys[production]</code> ~1 GB 3-5 min + High-performance inference <code>marsys[dev]</code> ~3+ GB 10-15 min + Testing &amp; docs tools <p>Install with uv (recommended): <pre><code>uv pip install marsys  # or marsys[local-models], etc.\n</code></pre></p> <p>Or with pip: <pre><code>pip install marsys  # or marsys[local-models], etc.\n</code></pre></p>"},{"location":"getting-started/installation/#3-configure-api-keys-required","title":"3. Configure API Keys (Required)","text":"<p>Required Step</p> <p>You must configure authentication before running any examples. MARSYS needs at least one API provider configured, either via API keys or OAuth.</p> <p>Method 1: <code>.env</code> file (Recommended for development)</p> <p>Create a <code>.env</code> file in your project root:</p> <pre><code># .env\n# Required: At least one API key\nOPENAI_API_KEY=\"sk-...\"           # OpenAI GPT models\nANTHROPIC_API_KEY=\"sk-ant-...\"    # Claude models\nGOOGLE_API_KEY=\"AIza...\"          # Gemini models\nOPENROUTER_API_KEY=\"sk-or-...\"    # OpenRouter (access to many models)\n\n# Optional: Additional configurations\nHEADLESS=true                      # Browser automation mode\nLOG_LEVEL=INFO                     # Logging verbosity\n</code></pre> <p>MARSYS automatically loads <code>.env</code> files using <code>python-dotenv</code>.</p> <p>Method 2: Environment variables (Recommended for production)</p> Unix/macOS/LinuxWindows (Command Prompt)Windows (PowerShell) <pre><code>export OPENAI_API_KEY=\"your-key-here\"\nexport ANTHROPIC_API_KEY=\"your-key-here\"\nexport GOOGLE_API_KEY=\"your-key-here\"\nexport OPENROUTER_API_KEY=\"your-key-here\"\n</code></pre> <pre><code>set OPENAI_API_KEY=your-key-here\nset ANTHROPIC_API_KEY=your-key-here\nset GOOGLE_API_KEY=your-key-here\n</code></pre> <pre><code>$env:OPENAI_API_KEY=\"your-key-here\"\n$env:ANTHROPIC_API_KEY=\"your-key-here\"\n$env:GOOGLE_API_KEY=\"your-key-here\"\n</code></pre> <p>Security</p> <p>Never commit <code>.env</code> files to version control. Add <code>.env</code> to your <code>.gitignore</code> file.</p>"},{"location":"getting-started/installation/#oauth-option-no-api-keys","title":"OAuth Option (No API Keys)","text":"<p>If you want to use subscription-based OAuth providers instead of API keys, log in with the corresponding CLI:</p> <ul> <li>OpenAI ChatGPT (OAuth): <code>codex login</code>   Credentials are stored in <code>~/.codex/auth.json</code> (override with <code>CODEX_AUTH_PATH</code>)</li> <li>Anthropic Claude Max (OAuth): <code>claude login</code>   Credentials are stored in <code>~/.claude/.credentials.json</code> (override with <code>CLAUDE_AUTH_PATH</code>)</li> </ul> <p>You can then set <code>provider=\"openai-oauth\"</code> or <code>provider=\"anthropic-oauth\"</code> in <code>ModelConfig</code> (optionally with <code>oauth_profile=\"your-profile\"</code>).</p> <p>Use At Your Own Risk (Anthropic OAuth)</p> <p><code>anthropic-oauth</code> relies on a non-official integration path and may violate provider Terms of Service. Use at your own risk.</p> <p>OpenAI OAuth Compliance</p> <p>MARSYS does not make a legal determination about OpenAI ToS coverage for this OAuth path. Review OpenAI terms for your use case.</p>"},{"location":"getting-started/installation/#4-install-browser-automation-optional","title":"4. Install Browser Automation (Optional)","text":"<p>Only for BrowserAgent</p> <p>This step is optional and only required if you plan to use <code>BrowserAgent</code> for web automation and scraping.</p> <p>Important: After installing the <code>playwright</code> package (included in basic installation), you must separately install browser binaries:</p> <pre><code># Install Chromium (recommended - smallest download)\nplaywright install chromium\n\n# Or install all browsers (Chrome, Firefox, WebKit)\nplaywright install\n\n# On Linux: Install system dependencies\nplaywright install --with-deps chromium\n</code></pre> <p>If you skip this step, BrowserAgent will fail with an error about missing browser binaries. All other MARSYS features will work normally.</p>"},{"location":"getting-started/installation/#verify-installation","title":"\u2705 Verify Installation","text":"<p>Run this quick test to verify everything is working:</p> <pre><code># test_installation.py\nimport asyncio\nfrom marsys import Orchestra, Agent\nfrom marsys.models import ModelConfig\n\nasync def test():\n    # Create a simple agent\n    agent = Agent(\n        model_config=ModelConfig(\n            type=\"api\",\n            name=\"anthropic/claude-opus-4.6\",\n            provider=\"openrouter\"\n        ),\n        name=\"TestAgent\",\n        goal=\"Test agent for verification\",\n        instruction=\"You are a test agent. Respond to requests clearly and concisely.\"\n    )\n\n    # Run a simple task\n    result = await Orchestra.run(\n        task=\"Say 'Hello, MARSYS is working!'\",\n        topology={\"agents\": [\"TestAgent\"], \"flows\": []}\n    )\n\n    print(\"\u2705 Installation successful!\")\n    print(f\"Response: {result.final_response}\")\n\nif __name__ == \"__main__\":\n    asyncio.run(test())\n</code></pre> <p>Run the test: <pre><code>python test_installation.py\n</code></pre></p>"},{"location":"getting-started/installation/#docker-installation","title":"\ud83d\udc33 Docker Installation","text":"<p>For containerized deployments:</p>"},{"location":"getting-started/installation/#using-docker-compose","title":"Using Docker Compose","text":"<pre><code># docker-compose.yml\nversion: '3.8'\n\nservices:\n  marsys:\n    image: marsys:latest\n    build: .\n    environment:\n      - OPENAI_API_KEY=${OPENAI_API_KEY}\n      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}\n      - GOOGLE_API_KEY=${GOOGLE_API_KEY}\n    volumes:\n      - ./workspace:/app/workspace\n      - ./logs:/app/logs\n    ports:\n      - \"8000:8000\"  # If running web interface\n</code></pre> <p>Build and run: <pre><code># Build the image\ndocker-compose build\n\n# Run the container\ndocker-compose up\n</code></pre></p>"},{"location":"getting-started/installation/#using-docker-cli","title":"Using Docker CLI","text":"<pre><code># Build image\ndocker build -t marsys .\n\n# Run container\ndocker run -it \\\n  -e OPENAI_API_KEY=$OPENAI_API_KEY \\\n  -v $(pwd)/workspace:/app/workspace \\\n  marsys\n</code></pre>"},{"location":"getting-started/installation/#package-structure","title":"\ud83d\udce6 Package Structure","text":"<p>After installation, you'll have access to:</p> <pre><code>marsys/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 coordination/     # Orchestra and topology system\n\u2502   \u251c\u2500\u2500 agents/           # Agent implementations\n\u2502   \u251c\u2500\u2500 models/           # Model configurations\n\u2502   \u251c\u2500\u2500 environment/      # Browser and OS tools\n\u2502   \u2514\u2500\u2500 utils/            # Utility functions\n\u251c\u2500\u2500 examples/             # Example implementations\n\u251c\u2500\u2500 tests/                # Test suite\n\u2514\u2500\u2500 docs/                 # Documentation\n</code></pre>"},{"location":"getting-started/installation/#configuration-options","title":"\ud83d\udd27 Configuration Options","text":""},{"location":"getting-started/installation/#environment-variables","title":"Environment Variables","text":"Variable Description Default <code>OPENAI_API_KEY</code> OpenAI API key Required* <code>ANTHROPIC_API_KEY</code> Anthropic API key Required* <code>GOOGLE_API_KEY</code> Google AI API key Required* <code>HEADLESS</code> Run browsers headlessly <code>true</code> <code>LOG_LEVEL</code> Logging level <code>INFO</code> <code>MAX_RETRIES</code> API retry attempts <code>3</code> <code>TIMEOUT</code> Default timeout (seconds) <code>300</code> <p>*At least one API key is required</p>"},{"location":"getting-started/installation/#model-providers-setup","title":"Model Providers Setup","text":"OpenRouter (Recommended)OpenAIAnthropicGoogleLocal (Ollama) <pre><code>ModelConfig(\n    type=\"api\",\n    name=\"anthropic/claude-opus-4.6\",\n    provider=\"openrouter\",\n    api_key=os.getenv(\"OPENROUTER_API_KEY\")\n)\n</code></pre> <pre><code>ModelConfig(\n    type=\"api\",\n    name=\"openai/gpt-5-codex\",\n    provider=\"openrouter\",\n    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n    max_tokens=12000\n)\n</code></pre> <pre><code>ModelConfig(\n    type=\"api\",\n    name=\"anthropic/claude-opus-4.6\",\n    provider=\"openrouter\",\n    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n    max_tokens=12000\n)\n</code></pre> <pre><code>ModelConfig(\n    type=\"api\",\n    name=\"gemini-3-flash-preview\",\n    provider=\"google\",\n    api_key=os.getenv(\"GOOGLE_API_KEY\")\n)\n</code></pre> <pre><code>ModelConfig(\n    type=\"local\",\n    name=\"llama2\",\n    provider=\"ollama\",\n    base_url=\"http://localhost:11434\"\n)\n</code></pre>"},{"location":"getting-started/installation/#troubleshooting","title":"\ud83d\udd0d Troubleshooting","text":""},{"location":"getting-started/installation/#common-issues-and-solutions","title":"Common Issues and Solutions","text":"ImportError: No module named 'src' <p>Solution: Ensure you're in the project root and have installed MARSYS: <pre><code>cd MARSYS\npip install -e .\n</code></pre></p> API Key not found <p>Solution: Check your <code>.env</code> file is in the project root: <pre><code># Verify .env exists\nls -la .env\n\n# Check environment variable\necho $OPENAI_API_KEY\n</code></pre></p> Playwright browser not found <p>Solution: Install browser binaries: <pre><code>playwright install chromium\n# For all browsers\nplaywright install\n</code></pre></p> Async syntax error <p>Solution: MARSYS requires Python 3.12+ for async support: <pre><code>python --version  # Should be 3.12 or higher\n</code></pre></p>"},{"location":"getting-started/installation/#platform-specific-issues","title":"Platform-Specific Issues","text":"macOSWindowsLinux <ul> <li>For M1/M2 Macs, use Python 3.10+ for best compatibility</li> <li>Install Rosetta 2 if needed: <code>softwareupdate --install-rosetta</code></li> </ul> <ul> <li>Use PowerShell or WSL2 for best experience</li> <li>Ensure long path support is enabled in Windows</li> </ul> <ul> <li>Install system dependencies for Playwright:   <pre><code>playwright install-deps\n</code></pre></li> <li>On Ubuntu/Debian, you may need: <code>sudo apt-get install python3-dev</code></li> </ul>"},{"location":"getting-started/installation/#next-steps","title":"\ud83d\udea6 Next Steps","text":"<p>Installation complete! Now you're ready to:</p> <ul> <li> <p> Quick Start</p> <p>Build your first multi-agent system in 10 minutes</p> </li> <li> <p> Create Your First Agent</p> <p>Learn how to create custom agents with tools</p> </li> <li> <p> Configuration Guide</p> <p>Explore advanced configuration options</p> </li> </ul>"},{"location":"getting-started/installation/#need-help","title":"\ud83c\udd98 Need Help?","text":"<ul> <li>\ud83d\udcd6 Check the FAQ</li> <li>\ud83d\udc1b Report issues on GitHub</li> <li>\ud83d\udcac Join our Discord Community</li> <li>\ud83d\udce7 Email support: support@marsys.ai</li> </ul> <p>Ready to build?</p> <p>Head to the Quick Start Guide to create your first multi-agent system!</p>"},{"location":"getting-started/quick-start/","title":"Quick Start","text":"<p>Build your first multi-agent system in just 10 minutes! This guide will get you up and running with MARSYS quickly.</p>"},{"location":"getting-started/quick-start/#what-well-build","title":"\ud83c\udfaf What We'll Build","text":"<p>In this quickstart, you'll create: 1. A simple single agent 2. A multi-agent research team 3. A system with parallel execution 4. An interactive system with user input</p>"},{"location":"getting-started/quick-start/#prerequisites","title":"\u26a1 Prerequisites","text":"<p>Before starting, complete these setup steps:</p>"},{"location":"getting-started/quick-start/#1-set-up-virtual-environment","title":"1. Set Up Virtual Environment","text":"<p>Recommended: Use uv for faster installation</p> <pre><code># Install uv (if not already installed)\ncurl -LsSf https://astral.sh/uv/install.sh | sh  # Unix/macOS\n# powershell -c \"irm https://astral.sh/uv/install.ps1 | iex\"  # Windows\n\n# Create and activate virtual environment\nuv venv\nsource .venv/bin/activate  # Unix/macOS\n# .venv\\Scripts\\activate  # Windows\n</code></pre> <p>Alternative: Use standard Python venv</p> <pre><code>python -m venv .venv\nsource .venv/bin/activate  # Unix/macOS\n# .venv\\Scripts\\activate  # Windows\n</code></pre>"},{"location":"getting-started/quick-start/#2-install-marsys","title":"2. Install MARSYS","text":"<pre><code># With uv (recommended)\nuv pip install marsys\n\n# Or with pip\npip install marsys\n</code></pre>"},{"location":"getting-started/quick-start/#3-configure-api-keys-required-for-api-models","title":"3. Configure API Keys (Required for API Models)","text":"<p>\u26a0\ufe0f This is required if you are using API models to run the agents!</p> <p>Create a <code>.env</code> file in your project directory:</p> <pre><code># .env\nOPENAI_API_KEY=\"your-key-here\"\nANTHROPIC_API_KEY=\"your-key-here\"\nGOOGLE_API_KEY=\"your-key-here\"\n</code></pre> <p>Or set environment variables:</p> <pre><code># Unix/macOS/Linux\nexport OPENAI_API_KEY=\"your-key-here\"\n\n# Windows (PowerShell)\n$env:OPENAI_API_KEY=\"your-key-here\"\n</code></pre>"},{"location":"getting-started/quick-start/#4-install-playwright-browsers-optional","title":"4. Install Playwright Browsers (Optional)","text":"<p>Only needed if using BrowserAgent examples</p> <p>After installing MARSYS, run:</p> <pre><code>playwright install chromium\n</code></pre> <p>Skip this if you're not using BrowserAgent - all other features work without it.</p> <p>\u2705 Ready! You now have Python 3.12+, MARSYS installed, and API keys configured.</p>"},{"location":"getting-started/quick-start/#example-1-your-first-agent","title":"\ud83d\ude80 Example 1: Your First Agent","text":"<p>Let's start with the simplest possible example:</p> <pre><code>import asyncio\nfrom marsys.coordination import Orchestra\nfrom marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\nasync def main():\n    # Create the agent first\n    poet = Agent(\n        model_config=ModelConfig(\n            type=\"api\",\n            name=\"anthropic/claude-opus-4.6\",\n            provider=\"openrouter\"\n        ),\n        name=\"Poet\",\n        goal=\"Creative poet\",\n        instruction=\"You are a talented poet who writes beautiful, evocative poetry.\"\n    )\n\n    # One-line execution\n    result = await Orchestra.run(\n        task=\"Write a haiku about artificial intelligence\",\n        topology={\"agents\": [\"Poet\"], \"flows\": []}\n    )\n\n    print(result.final_response)\n\nasyncio.run(main())\n</code></pre> <p>Output: <pre><code>Silicon mind thinks,\nAlgorithms dance in code,\nFuture awakening.\n</code></pre></p>"},{"location":"getting-started/quick-start/#example-2-two-agent-collaboration","title":"\ud83e\udd1d Example 2: Two-Agent Collaboration","text":"<p>Now let's have two agents work together using the simplest approach - <code>allowed_peers</code>:</p> <pre><code>import asyncio\nfrom marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\nasync def main():\n    # Create a single model configuration\n    model_config = ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\"\n    )\n\n    # Create specialized agents with allowed_peers\n    researcher = Agent(\n        model_config=model_config,\n        name=\"Researcher\",\n        goal=\"Expert at finding and analyzing information\",\n        instruction=\"You are a research specialist. Find and analyze information thoroughly.\",\n        allowed_peers=[\"Writer\"]  # Can invoke Writer\n    )\n\n    writer = Agent(\n        model_config=model_config,\n        name=\"Writer\",\n        goal=\"Skilled at creating clear, engaging content\",\n        instruction=\"You are a skilled writer. Create clear, engaging content based on research.\",\n        allowed_peers=[]  # Cannot invoke other agents\n    )\n\n    # Run with automatic topology creation from allowed_peers\n    result = await researcher.auto_run(\n        task=\"Research the latest AI breakthroughs and write a summary\",\n        max_steps=20,\n        verbosity=1  # Show progress\n    )\n\n    print(result)\n\nasyncio.run(main())\n</code></pre> <p>Four Ways to Define Multi-Agent Systems</p> <p>This example uses the simplest approach (Way 1: <code>allowed_peers</code> + <code>auto_run</code>). MARSYS offers four different ways to define agent interactions, from simple peer-based to sophisticated pattern configurations.</p>"},{"location":"getting-started/quick-start/#example-3-simple-three-agent-workflow","title":"\ud83e\udd1d Example 3: Simple Three-Agent Workflow","text":"<p>Let's create a workflow with three agents working in sequence:</p> <pre><code>import asyncio\nfrom marsys.coordination import Orchestra\nfrom marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\nasync def main():\n    # Use a single model configuration\n    model_config = ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\"\n    )\n\n    # Create three specialized agents\n    data_collector = Agent(\n        model_config=model_config,\n        name=\"DataCollector\",\n        goal=\"Collects and gathers relevant data\",\n        instruction=\"You are a data collection specialist. Gather relevant information systematically.\"\n    )\n\n    analyzer = Agent(\n        model_config=model_config,\n        name=\"Analyzer\",\n        goal=\"Analyzes collected data and finds patterns\",\n        instruction=\"You are a data analyst. Analyze data thoroughly and identify key patterns.\"\n    )\n\n    reporter = Agent(\n        model_config=model_config,\n        name=\"Reporter\",\n        goal=\"Creates comprehensive reports from analysis\",\n        instruction=\"You are a report writer. Create clear, comprehensive reports from analysis results.\"\n    )\n\n    # Define sequential workflow\n    topology = {\n        \"agents\": [\"DataCollector\", \"Analyzer\", \"Reporter\"],\n        \"flows\": [\n            \"DataCollector -&gt; Analyzer\",\n            \"Analyzer -&gt; Reporter\"\n        ]\n    }\n\n    # Run the workflow\n    result = await Orchestra.run(\n        task=\"Analyze market trends in the technology sector\",\n        topology=topology\n    )\n\n    print(result.final_response)\n\nasyncio.run(main())\n</code></pre> <p>\u2705 Congratulations! You've completed the Quick Start and learned the core MARSYS patterns:</p> <ol> <li>\u2713 Single agent execution</li> <li>\u2713 Multi-agent collaboration</li> <li>\u2713 Sequential workflows</li> </ol>"},{"location":"getting-started/quick-start/#whats-next","title":"\ud83d\ude80 What's Next?","text":"<p>Ready to build more advanced systems? Explore these topics:</p> <ul> <li> <p> Agent Tools</p> <p>Give agents superpowers with custom tools</p> </li> <li> <p> User Interaction</p> <p>Build human-in-the-loop workflows</p> </li> <li> <p> Browser Automation</p> <p>Automate web tasks with BrowserAgent</p> </li> <li> <p>:material-pipeline:{ .lg .middle } Advanced Patterns</p> <p>Pipeline, mesh, and hierarchical topologies</p> </li> </ul>"},{"location":"getting-started/quick-start/#key-concepts-to-remember","title":"\ud83c\udfaf Key Concepts to Remember","text":""},{"location":"getting-started/quick-start/#1-everything-is-async","title":"1. Everything is Async","text":"<p>All MARSYS operations are asynchronous. Always use <code>async/await</code>: <pre><code>async def main():\n    result = await Orchestra.run(...)\n\nasyncio.run(main())\n</code></pre></p>"},{"location":"getting-started/quick-start/#2-topology-defines-flow","title":"2. Topology Defines Flow","text":"<p>The topology determines how agents communicate: <pre><code>topology = {\n    \"agents\": [\"A\", \"B\", \"C\"],\n    \"flows\": [\"A -&gt; B\", \"B -&gt; C\"]  # A calls B, B calls C\n}\n</code></pre></p>"},{"location":"getting-started/quick-start/#3-agents-auto-register","title":"3. Agents Auto-Register","text":"<p>Creating an agent automatically registers it: <pre><code>agent = Agent(name=\"MyAgent\", ...)  # Auto-registered\n</code></pre></p>"},{"location":"getting-started/quick-start/#4-patterns-simplify-complex-workflows","title":"4. Patterns Simplify Complex Workflows","text":"<p>Use pre-defined patterns instead of manual topology: <pre><code>topology = PatternConfig.hub_and_spoke(...)  # Easier than manual\n</code></pre></p>"},{"location":"getting-started/quick-start/#5-configuration-controls-behavior","title":"5. Configuration Controls Behavior","text":"<p>Fine-tune execution with configs: <pre><code>config = ExecutionConfig(\n    convergence_timeout=300,  # Max wait for parallel branches\n    status=StatusConfig.from_verbosity(2)  # Detailed output\n)\n</code></pre></p>"},{"location":"getting-started/quick-start/#performance-tips","title":"\ud83d\udcc8 Performance Tips","text":"<ol> <li>Use Parallel Execution: Set <code>parallel_spokes=True</code> for independent tasks</li> <li>Configure Timeouts: Prevent hanging with appropriate timeouts</li> <li>Use Agent Pools: For true parallelism with stateful agents</li> <li>Cache Results: Agents remember conversations within a session</li> <li>Minimize Steps: Set reasonable <code>max_steps</code> to avoid unnecessary iterations</li> </ol>"},{"location":"getting-started/quick-start/#next-steps","title":"\ud83d\udea6 Next Steps","text":"<p>Now that you've built your first multi-agent systems:</p> <ul> <li> <p> Create Custom Agents</p> <p>Learn to build specialized agents with custom logic</p> </li> <li> <p> Master Configuration</p> <p>Fine-tune timeouts, retries, and execution behavior</p> </li> <li> <p> Understand Topologies</p> <p>Design complex agent interaction patterns</p> </li> <li> <p> Explore Examples</p> <p>See real-world implementations</p> </li> </ul>"},{"location":"getting-started/quick-start/#troubleshooting","title":"\ud83c\udd98 Troubleshooting","text":"Why is my agent not responding? <p>Check that: - The agent name in topology matches the created agent - API keys are correctly configured - The model name is valid for your provider</p> How do I debug agent interactions? <p>Use verbose output: <pre><code>config = ExecutionConfig(\n    status=StatusConfig.from_verbosity(2)\n)\n</code></pre></p> Can agents work in parallel? <p>Yes! Use <code>parallel_spokes=True</code> in hub-and-spoke pattern or create parallel branches in your topology.</p> <p>Ready for More?</p> <p>You've mastered the basics! Now explore Your First Agent to create custom agents with specialized capabilities.</p>"},{"location":"guides/built-in-tools/","title":"Built-in Tools Reference","text":"<p>Complete guide to MARSYS built-in tools with prerequisites, setup instructions, and usage examples.</p>"},{"location":"guides/built-in-tools/#overview","title":"\ud83c\udfaf Overview","text":"<p>MARSYS includes several built-in tools for common operations. Each tool has specific prerequisites that must be met before use.</p>"},{"location":"guides/built-in-tools/#web-search-tools","title":"\ud83d\udd0d Web Search Tools","text":"<p>Production Recommendation</p> <p>For production deployments, use Google Custom Search API (<code>tool_google_search_api</code> or <code>web_search</code> with API key configured). DuckDuckGo has aggressive bot detection and will block automated requests. DuckDuckGo should only be used for:</p> <ul> <li>Development/testing</li> <li>Low-volume use cases (&lt; 10 searches/hour)</li> <li>Fallback when Google quota is exhausted</li> <li>Privacy-sensitive queries where API usage must be avoided</li> </ul>"},{"location":"guides/built-in-tools/#tool_google_search_api","title":"tool_google_search_api","text":"<p>Google Custom Search API integration for high-quality web search results.</p> <p>Prerequisites: - Google Cloud Platform account - Custom Search API enabled - Two environment variables required</p> <p>Setup Steps:</p> <ol> <li>Create a Google Cloud Project:</li> <li>Go to Google Cloud Console</li> <li>Create a new project (or select existing)</li> <li> <p>Give it a descriptive name</p> </li> <li> <p>Enable Custom Search API:</p> </li> <li>In the Cloud Console, navigate to \"APIs &amp; Services\"</li> <li>Click \"Enable APIs and Services\"</li> <li>Search for \"Custom Search API\"</li> <li> <p>Click on it and press \"Enable\"</p> </li> <li> <p>Create API Key:</p> </li> <li>Go to \"APIs &amp; Services\" \u2192 \"Credentials\"</li> <li>Click \"CREATE CREDENTIALS\" \u2192 \"API key\"</li> <li>Copy the API key immediately (you won't see it again)</li> <li> <p>Recommended: Click \"Edit API key\" to restrict access by IP address or HTTP referrer</p> </li> <li> <p>Create Programmable Search Engine:</p> </li> <li>Visit Programmable Search Engine</li> <li>Click \"Get started\" or \"Add\"</li> <li>Configure your search engine:<ul> <li>Name: Give it a descriptive name</li> <li>What to search: Choose \"Search the entire web\" or specify sites</li> </ul> </li> <li>Click \"Create\"</li> <li>In the Overview page \u2192 Basic section, find your Search engine ID (cx parameter)</li> <li> <p>Copy this ID</p> </li> <li> <p>Set Environment Variables: <pre><code># Unix/macOS/Linux\nexport GOOGLE_SEARCH_API_KEY=\"your-api-key-here\"\nexport GOOGLE_CSE_ID_GENERIC=\"your-search-engine-id-here\"\n\n# Windows (Command Prompt)\nset GOOGLE_SEARCH_API_KEY=your-api-key-here\nset GOOGLE_CSE_ID_GENERIC=your-search-engine-id-here\n\n# Windows (PowerShell)\n$env:GOOGLE_SEARCH_API_KEY=\"your-api-key-here\"\n$env:GOOGLE_CSE_ID_GENERIC=\"your-search-engine-id-here\"\n\n# Or add to .env file\nGOOGLE_SEARCH_API_KEY=your-api-key-here\nGOOGLE_CSE_ID_GENERIC=your-search-engine-id-here\n</code></pre></p> </li> </ol> <p>Usage: <pre><code>from marsys.environment.tools import tool_google_search_api\n\n# Perform search\nresults = tool_google_search_api(\n    query=\"Python machine learning\",\n    num_results=5,\n    lang=\"en\"\n)\n</code></pre></p> <p>API Limits &amp; Pricing: - Free tier: 100 queries/day - Paid tier: $5 per 1,000 additional queries (up to 10,000 queries/day max) - Maximum 10 results per query</p>"},{"location":"guides/built-in-tools/#tool_google_search_community","title":"tool_google_search_community","text":"<p>Alternative Google search using web scraping (no API key required).</p> <p>Prerequisites: - <code>googlesearch-python</code> package (installed by default with MARSYS) - No API keys required</p> <p>Setup: <pre><code># Already included in MARSYS dependencies\n# If needed separately:\npip install googlesearch-python\n</code></pre></p> <p>Usage: <pre><code>from marsys.environment.tools import tool_google_search_community\n\n# Perform search without API\nresults = tool_google_search_community(\n    query=\"Python tutorials\",\n    num_results=5,\n    lang=\"en\"\n)\n</code></pre></p> <p>Limitations: - Slower than API version (1 second delay between requests) - Rate-limited by Google (uses sleep intervals) - May be blocked with excessive use - Less reliable for production - No cost but less stable</p> <p>When to Use: - Development and testing - Personal projects - When API quota exhausted - No API key available</p>"},{"location":"guides/built-in-tools/#web_search","title":"web_search","text":"<p>Unified web search interface with automatic fallback.</p> <p>Prerequisites: - Optional: Google Search API credentials (for API mode) - Falls back to community scraper if no API key</p> <p>Usage: <pre><code>from marsys.environment.tools import web_search\n\n# Automatically tries API first, falls back to scraper\nresults = await web_search(\n    query=\"AI trends 2025\",\n    max_results=5,\n    search_engine=\"google\"  # Currently only google supported\n)\n</code></pre></p> <p>Returns: <pre><code>[\n    {\n        \"title\": \"Article Title\",\n        \"url\": \"https://example.com\",\n        \"snippet\": \"Description of the article...\",\n        \"source\": \"Google Search API\"  # or \"Google Search (Community Library)\"\n    },\n    # ... more results\n]\n</code></pre></p> <p>Behavior: 1. Checks for <code>GOOGLE_SEARCH_API_KEY</code> environment variable 2. If found, uses <code>tool_google_search_api</code> (fast, reliable) 3. If not found or fails, falls back to <code>tool_google_search_community</code> (slower, free)</p>"},{"location":"guides/built-in-tools/#fetch_url_content","title":"fetch_url_content","text":"<p>Fetch and extract clean content from any URL.</p> <p>Prerequisites: - <code>aiohttp</code>, <code>beautifulsoup4</code>, <code>markdownify</code> (included in MARSYS)</p> <p>Usage: <pre><code>from marsys.environment.tools import fetch_url_content\n\n# Fetch webpage content\ncontent = await fetch_url_content(\n    url=\"https://example.com/article\",\n    timeout=30,\n    include_metadata=True\n)\n</code></pre></p> <p>Returns: <pre><code>{\n    \"url\": \"https://example.com/article\",\n    \"title\": \"Article Title\",\n    \"content\": \"Clean extracted text content...\",\n    \"markdown\": \"# Article Title\\n\\nContent in markdown...\",\n    \"links\": [\"https://...\", ...],\n    \"images\": [\"https://...\", ...],\n    \"metadata\": {\n        \"description\": \"Meta description\",\n        \"author\": \"Author name\",\n        \"published_date\": \"2025-01-01\"\n    }\n}\n</code></pre></p>"},{"location":"guides/built-in-tools/#data-processing-tools","title":"\ud83d\udcca Data Processing Tools","text":""},{"location":"guides/built-in-tools/#calculate_math","title":"calculate_math","text":"<p>Evaluate mathematical expressions safely.</p> <p>Prerequisites: - None (pure Python)</p> <p>Usage: <pre><code>from marsys.environment.tools import calculate_math\n\n# Calculate expression\nresult = calculate_math(\n    expression=\"(2 + 3) * 4 / 2\",\n    precision=2\n)\n</code></pre></p> <p>Returns: <pre><code>{\n    \"result\": 10.0,\n    \"expression\": \"(2 + 3) * 4 / 2\",\n    \"precision\": 2\n}\n</code></pre></p> <p>Safety: - Uses <code>ast.literal_eval</code> for safe evaluation - Prevents code execution - Supports: <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>**</code>, <code>()</code>, numbers</p>"},{"location":"guides/built-in-tools/#data_transform","title":"data_transform","text":"<p>Transform and process structured data.</p> <p>Prerequisites: - None (pure Python)</p> <p>Usage: <pre><code>from marsys.environment.tools import data_transform\n\n# Transform data\nresult = data_transform(\n    data={\"values\": [1, 2, 3, 4, 5]},\n    operation=\"statistics\",  # or \"filter\", \"map\", \"reduce\"\n    params={\"fields\": [\"mean\", \"median\", \"std\"]}\n)\n</code></pre></p> <p>Operations: - <code>statistics</code>: Calculate statistical measures - <code>filter</code>: Filter data by conditions - <code>map</code>: Transform each element - <code>reduce</code>: Aggregate data</p>"},{"location":"guides/built-in-tools/#file-operations","title":"\ud83d\udcc1 File Operations","text":""},{"location":"guides/built-in-tools/#file_operations","title":"file_operations","text":"<p>Unified interface for file system operations.</p> <p>Prerequisites: - File system access permissions</p> <p>Note: This tool uses a simple sandboxed workspace path. For shared, virtual paths across agents, use FileOperationTools and the Run Filesystem.</p> <p>Usage: <pre><code>from marsys.environment.tools import file_operations\n\n# Read file\ncontent = await file_operations(\n    operation=\"read\",\n    path=\"/path/to/file.txt\",\n    encoding=\"utf-8\"\n)\n\n# Write file\nresult = await file_operations(\n    operation=\"write\",\n    path=\"/path/to/output.txt\",\n    content=\"Hello, World!\",\n    mode=\"write\"  # or \"append\"\n)\n\n# List directory\nfiles = await file_operations(\n    operation=\"list\",\n    path=\"/path/to/directory\",\n    pattern=\"*.py\"  # optional glob pattern\n)\n</code></pre></p> <p>Supported Operations: - <code>read</code>: Read file contents - <code>write</code>: Write to file - <code>append</code>: Append to file - <code>list</code>: List directory contents - <code>exists</code>: Check if path exists - <code>delete</code>: Remove file (use with caution)</p>"},{"location":"guides/built-in-tools/#web-content-tools","title":"\ud83c\udf10 Web Content Tools","text":""},{"location":"guides/built-in-tools/#read_file-from-web_tools","title":"read_file (from web_tools)","text":"<p>Read and parse various file formats.</p> <p>Prerequisites: - <code>pypdf</code> for PDF files (included in MARSYS)</p> <p>Usage: <pre><code>from marsys.environment.web_tools import read_file\n\n# Read text file\ncontent = await read_file(\"/path/to/document.txt\")\n\n# Read PDF\ncontent = await read_file(\"/path/to/document.pdf\")\n</code></pre></p> <p>Supported Formats: - Plain text (<code>.txt</code>, <code>.md</code>, <code>.py</code>, etc.) - PDF files (<code>.pdf</code>) - Automatic format detection</p>"},{"location":"guides/built-in-tools/#extract_text_from_pdf","title":"extract_text_from_pdf","text":"<p>Extract text content from PDF files.</p> <p>Prerequisites: - <code>pdfminer.six</code> (included in MARSYS)</p> <p>Usage: <pre><code>from marsys.environment.web_tools import extract_text_from_pdf\n\n# Extract PDF text\ntext = extract_text_from_pdf(\"/path/to/document.pdf\")\n</code></pre></p>"},{"location":"guides/built-in-tools/#clean_and_extract_html","title":"clean_and_extract_html","text":"<p>Clean HTML and extract structured content.</p> <p>Prerequisites: - <code>beautifulsoup4</code>, <code>markdownify</code> (included in MARSYS)</p> <p>Usage: <pre><code>from marsys.environment.web_tools import clean_and_extract_html\n\n# Extract from HTML\nresult = await clean_and_extract_html(\n    html_content=\"&lt;html&gt;...&lt;/html&gt;\",\n    base_url=\"https://example.com\",\n    output_format=\"markdown\"  # or \"text\"\n)\n</code></pre></p> <p>Returns: <pre><code>{\n    \"title\": \"Page Title\",\n    \"content\": \"Clean content...\",\n    \"markdown\": \"# Title\\n\\nContent...\",\n    \"links\": [...],\n    \"images\": [...],\n    \"metadata\": {...}\n}\n</code></pre></p>"},{"location":"guides/built-in-tools/#tool-registration","title":"\ud83d\udd27 Tool Registration","text":""},{"location":"guides/built-in-tools/#using-tools-with-agents","title":"Using Tools with Agents","text":"<pre><code>from marsys import Agent, ModelConfig\nfrom marsys.environment.tools import (\n    web_search,\n    fetch_url_content,\n    calculate_math\n)\n\nagent = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\",\n        max_tokens=12000\n    ),\n    name=\"ResearchAgent\",\n    goal=\"Research agent with web search capabilities\",\n    instruction=\"You are a research agent with access to web search, URL fetching, and calculation tools.\",\n    tools={\"web_search\": web_search, \"fetch_url_content\": fetch_url_content, \"calculate_math\": calculate_math}\n)\n</code></pre>"},{"location":"guides/built-in-tools/#list-available-tools","title":"List Available Tools","text":"<pre><code>from marsys.environment.tools import list_tools\n\n# Get list of all built-in tools\ntools = list_tools()\nprint(tools)\n# Output: ['tool_google_search_api', 'tool_google_search_community', 'web_search', ...]\n</code></pre>"},{"location":"guides/built-in-tools/#get-tool-by-name","title":"Get Tool by Name","text":"<pre><code>from marsys.environment.tools import get_tool\n\n# Dynamically get tool function\nsearch_tool = get_tool(\"web_search\")\nif search_tool:\n    results = await search_tool(\"Python tutorials\")\n</code></pre>"},{"location":"guides/built-in-tools/#common-issues","title":"\ud83d\udea8 Common Issues","text":""},{"location":"guides/built-in-tools/#issue-google-search-api-key-not-configured","title":"Issue: \"Google Search API key not configured\"","text":"<p>Solution: <pre><code># Set the required environment variables\nexport GOOGLE_SEARCH_API_KEY=\"your-api-key\"\nexport GOOGLE_CSE_ID_GENERIC=\"your-cse-id\"\n</code></pre></p> <p>Or use the community search instead: <pre><code>from marsys.environment.tools import tool_google_search_community\n# No API key required\n</code></pre></p>"},{"location":"guides/built-in-tools/#issue-googlesearch-library-not-installed","title":"Issue: \"googlesearch library not installed\"","text":"<p>Solution: <pre><code>pip install googlesearch-python\n</code></pre></p>"},{"location":"guides/built-in-tools/#issue-pdf-extraction-fails","title":"Issue: PDF extraction fails","text":"<p>Solution: <pre><code># Ensure PDF dependencies are installed\npip install pypdf pdfminer.six\n</code></pre></p>"},{"location":"guides/built-in-tools/#issue-rate-limiting-on-web-scraping","title":"Issue: Rate limiting on web scraping","text":"<p>Solution: - Use the API version instead of community scraper - Add delays between requests - Implement caching to reduce repeated requests - Use <code>web_search</code> which has automatic fallback</p>"},{"location":"guides/built-in-tools/#best-practices","title":"\ud83d\udccb Best Practices","text":""},{"location":"guides/built-in-tools/#1-use-google-api-for-production-search","title":"1. Use Google API for Production Search","text":"<pre><code># \u2705 BEST - Google Custom Search API (recommended for production)\nfrom marsys.environment.tools import tool_google_search_api\n# Requires GOOGLE_SEARCH_API_KEY and GOOGLE_CSE_ID_GENERIC\n\n# \u2705 GOOD - Automatic fallback (API if available, scraper otherwise)\nfrom marsys.environment.tools import web_search\n\n# \u26a0\ufe0f  DEVELOPMENT ONLY - DuckDuckGo (will be blocked in production)\nfrom marsys.environment.search_tools import SearchTools\nsearch_tools = SearchTools()\n# Only for testing/development, &lt; 10 searches/hour\n\n# \u274c AVOID - Community scraper for production\nfrom marsys.environment.tools import tool_google_search_community\n</code></pre>"},{"location":"guides/built-in-tools/#2-always-set-timeouts","title":"2. Always Set Timeouts","text":"<pre><code># \u2705 GOOD - Prevents hanging\ncontent = await fetch_url_content(url, timeout=30)\n\n# \u274c BAD - No timeout\ncontent = await fetch_url_content(url)  # Uses default, but be explicit\n</code></pre>"},{"location":"guides/built-in-tools/#3-handle-errors-gracefully","title":"3. Handle Errors Gracefully","text":"<pre><code># \u2705 GOOD - Error handling\ntry:\n    results = await web_search(query)\n    if results and \"error\" not in results[0]:\n        process_results(results)\nexcept Exception as e:\n    logger.error(f\"Search failed: {e}\")\n    # Use fallback or notify user\n</code></pre>"},{"location":"guides/built-in-tools/#4-cache-expensive-operations","title":"4. Cache Expensive Operations","text":"<pre><code># \u2705 GOOD - Cache search results\nfrom functools import lru_cache\n\n@lru_cache(maxsize=100)\ndef cached_search(query: str):\n    return web_search(query)\n</code></pre>"},{"location":"guides/built-in-tools/#5-secure-your-api-keys","title":"5. Secure Your API Keys","text":"<pre><code># \u2705 GOOD - Use environment variables\nimport os\napi_key = os.getenv(\"GOOGLE_SEARCH_API_KEY\")\n\n# \u274c NEVER - Hardcode credentials\napi_key = \"AIzaSyABC123...\"  # DON'T DO THIS\n</code></pre>"},{"location":"guides/built-in-tools/#next-steps","title":"\ud83c\udfaf Next Steps","text":"<ul> <li>Tool API Reference - Complete API documentation</li> <li>Custom Tools - Create your own tools</li> <li>Agent Development - Integrate tools with agents</li> <li>Browser Automation - Advanced web interaction</li> </ul> <p>Environment Variables</p> <p>Always store API keys in environment variables or <code>.env</code> files. Never hardcode credentials in your code.</p> <p>Rate Limits</p> <p>Be aware of API rate limits and implement appropriate caching and retry strategies for production use.</p> <p>API Key Security</p> <p>In the Google Cloud Console, restrict your API key by IP address or HTTP referrer to prevent unauthorized use.</p>"},{"location":"guides/file-operations/","title":"File Operations Toolkit","text":"<p>Advanced file management system with intelligent reading strategies, hierarchical content extraction, and secure editing capabilities for MARSYS agents.</p>"},{"location":"guides/file-operations/#overview","title":"\ud83c\udfaf Overview","text":"<p>The File Operations Toolkit provides type-aware file handling with advanced features designed for AI agents:</p> <ul> <li>Intelligent Reading Strategies: Optimize token usage with AUTO, FULL, PARTIAL, OVERVIEW, and PROGRESSIVE strategies</li> <li>Character-Based Token Management: Uses character count (not file size) as proxy for text tokens</li> <li>Image Token Estimation: Provider-specific token estimation for images (OpenAI, Anthropic, Google, xAI)</li> <li>Hierarchical Structure Extraction: AST-based parsing for code, font-analysis for PDFs</li> <li>Image Support: Extract and process images from PDFs and read image files directly</li> <li>Unified Diff Editing: High-success-rate patching with multiple fallback strategies</li> <li>Security Framework: Virtual filesystem boundaries, pattern-based permissions, approval workflows</li> <li>Search Capabilities: Content search (grep), filename search (glob), and structure search</li> <li>Type-Specific Handlers: Specialized handlers for images, PDFs, JSON, YAML, Markdown, and code files</li> </ul> <p>This toolkit was designed to address the limitations of simple file reading tools, particularly for handling complex documents like PDFs and source code files, with intelligent token management for vision-language models.</p>"},{"location":"guides/file-operations/#prerequisites","title":"\ud83d\udce6 Prerequisites","text":"<p>Core Dependencies:</p> <p>PDF support and image support are included in the core marsys installation: <pre><code>pip install marsys  # Includes PyMuPDF and Pillow\n</code></pre></p> <p>For advanced code parsing (future feature): <pre><code>pip install tree-sitter\n</code></pre></p> <p>Core Dependencies</p> <ul> <li>PDF support is provided by <code>PyMuPDF</code> (included in core installation).</li> <li>Image support is provided by <code>Pillow</code> (PIL) (included in core installation).</li> <li>Both are automatically installed with marsys for full functionality with vision-language models.</li> </ul>"},{"location":"guides/file-operations/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"guides/file-operations/#basic-usage","title":"Basic Usage","text":"<pre><code>import os\nfrom pathlib import Path\nfrom marsys import Agent\nfrom marsys.models import ModelConfig\nfrom marsys.environment import FileOperationConfig, create_file_operation_tools\nfrom marsys.environment.filesystem import RunFileSystem\n\n# Create model configuration (example using OpenRouter)\n# Note: API key is only required if you use API-based models\nmodel_config = ModelConfig(\n    type=\"api\",\n    name=\"anthropic/claude-opus-4.6\",\n    provider=\"openrouter\",\n    api_key=os.getenv(\"OPENROUTER_API_KEY\")  # Set if using OpenRouter\n)\n\n# Create file operation tools\n# Shared run filesystem for all agents\nfs = RunFileSystem.local(run_root=Path(\"./runs/run-20260206\"))\nfile_config = FileOperationConfig(run_filesystem=fs)\nfile_tools = create_file_operation_tools(file_config)\n\n# Create agent with file capabilities\nfile_agent = Agent(\n    model_config=model_config,\n    goal=\"Manage and analyze files efficiently\",\n    instruction=\"\"\"You are a file management assistant. Use your file operation tools to:\n    - Read files intelligently based on size and type\n    - Extract structured information from documents\n    - Edit files using unified diff format for reliability\n    - Search for content across multiple files\n    - Maintain security by respecting run filesystem boundaries\n\n    Always use the most appropriate reading strategy to optimize token usage.\n    When editing, prefer unified diff format for complex changes.\"\"\",\n    name=\"FileAssistant\",\n    tools=file_tools\n)\n\n# Use the agent\nresult = await file_agent.run(\n    prompt=\"Read the README.md file and summarize its contents\"\n)\n</code></pre> <p>API Keys</p> <p>If you're using API-based models (like OpenRouter, OpenAI, etc.), ensure the appropriate API key environment variable is set (e.g., <code>OPENROUTER_API_KEY</code>, <code>OPENAI_API_KEY</code>).</p>"},{"location":"guides/file-operations/#virtual-paths-runfilesystem","title":"\ud83d\uddc2\ufe0f Virtual Paths &amp; RunFileSystem","text":"<p>File operations use virtual POSIX paths. Tool-returned paths are typically <code>./...</code>, while the run filesystem also accepts absolute virtual form (<code>/...</code>):</p> <ul> <li><code>/</code> is the run root</li> <li>Use <code>./downloads</code>, <code>./screenshots</code>, <code>./outputs</code> for common artifacts</li> <li>Relative paths like <code>./data.csv</code> resolve against the run filesystem working directory</li> </ul> <p>To share files between agents, create a <code>RunFileSystem</code> once and pass it to tools/agents:</p> <pre><code>from pathlib import Path\nfrom marsys.environment.filesystem import RunFileSystem\nfrom marsys.environment import FileOperationConfig, create_file_operation_tools\n\nfs = RunFileSystem.local(run_root=Path(\"./runs/run-20260206\"))\n\nconfig = FileOperationConfig(run_filesystem=fs)\nfile_tools = create_file_operation_tools(config)\n</code></pre> <p>See Run Filesystem for details and mount examples.</p>"},{"location":"guides/file-operations/#configuration","title":"\ud83d\udd27 Configuration","text":""},{"location":"guides/file-operations/#default-configuration","title":"Default Configuration","text":"<pre><code>from pathlib import Path\nfrom marsys.environment import create_file_operation_tools, FileOperationConfig\n\n# Use defaults (permissive mode)\nfile_tools = create_file_operation_tools()\n</code></pre>"},{"location":"guides/file-operations/#custom-configuration","title":"Custom Configuration","text":"<pre><code>from pathlib import Path\nfrom marsys.environment import FileOperationConfig, create_file_operation_tools\nfrom marsys.environment.filesystem import RunFileSystem\n\n# Create custom configuration (virtual filesystem + security)\nfs = RunFileSystem.local(\n    run_root=Path(\"/home/user/projects\"),\n    extra_mounts={\"/datasets\": Path(\"/shared/datasets\")}\n)\n\nconfig = FileOperationConfig(\n    base_directory=Path(\"/home/user/projects\"),\n    run_filesystem=fs,\n\n    # File size limits (hard limit for safety)\n    max_file_size_bytes=100 * 1024 * 1024,  # 100 MB absolute limit\n\n    # Character-based reading thresholds (token proxy for text)\n    small_file_threshold=10000,      # &lt; 10k chars (~2.5k tokens): FULL read\n    medium_file_threshold=100000,    # 10-100k chars (~25k tokens): PARTIAL read\n    large_file_threshold=500000,     # &gt; 500k chars (~125k tokens): OVERVIEW first\n\n    # File type-specific limits\n    max_json_content_chars=40000,     # JSON truncation threshold (~10k tokens)\n    max_lines_per_read=250,           # Max lines for text files\n    max_pages_per_read=5,             # Max pages for PDF files\n\n    # Absolute safety limit (applies to ALL file types)\n    max_characters_absolute=120000,   # Hard limit: 120K chars (~30k tokens)\n\n    # Image token limits (for vision models)\n    max_image_pixels=1024 * 1024,    # 1 megapixel (1024x1024)\n    max_images_per_read=4,           # Maximum images per operation\n\n    # Security patterns (glob-style)\n    blocked_patterns=[\n        \"*.key\", \"*.pem\", \"*.p12\",  # Private keys\n        \".env\", \".env.*\",             # Environment files\n        \"*.sqlite\", \"*.db\",           # Databases\n        \".git/**\",                    # Git internals\n    ],\n\n    # Auto-approve patterns (no user confirmation needed)\n    auto_approve_patterns=[\n        \"*.md\", \"*.txt\",              # Documentation\n        \"*.py\", \"*.js\", \"*.java\",     # Source code\n        \"*.json\", \"*.yaml\", \"*.yml\",  # Configuration\n    ],\n\n    # Require approval patterns\n    require_approval_patterns=[\n        \"*.sh\", \"*.bash\",             # Shell scripts\n        \"Makefile\", \"Dockerfile\",     # Build files\n        \"*.sql\",                      # SQL files\n    ],\n\n    # Feature flags\n    enable_delete=False,\n    enable_tree_sitter=True,\n    enable_semantic_search=False,\n    enable_caching=True,\n    cache_ttl_seconds=300,\n\n    # Search\n    max_search_results=100,\n\n    # Audit logging\n    enable_audit_logging=True,\n    log_file_path=Path(\"./file_operations_audit.log\"),\n)\n\n# Create tools with custom config\nfile_tools = create_file_operation_tools(config)\n</code></pre>"},{"location":"guides/file-operations/#character-limit-configuration","title":"Character Limit Configuration","text":"<p>The toolkit uses different character limits for different purposes:</p>"},{"location":"guides/file-operations/#1-file-type-specific-limits","title":"1. File Type-Specific Limits","text":"<p>These limits control how different file types are read and processed:</p> <ul> <li><code>max_json_content_chars</code> (default: 40,000 characters):</li> <li>Applies to: JSON files only</li> <li>Behavior: Triggers truncation/overview when JSON exceeds this limit</li> <li>What happens: Dictionary values truncated to 200 chars, arrays show first 20 items</li> <li> <p>Use case: Prevent huge JSON files from consuming entire context window</p> </li> <li> <p><code>max_lines_per_read</code> (default: 250 lines):</p> </li> <li>Applies to: Text files (.txt, .py, .md, .yaml, etc.)</li> <li>Behavior: Controls line-based partial reading</li> <li>What happens: Used with <code>start_line</code>/<code>end_line</code> parameters</li> <li> <p>Use case: Read specific sections of code or text files</p> </li> <li> <p><code>max_pages_per_read</code> (default: 5 pages):</p> </li> <li>Applies to: PDF files</li> <li>Behavior: Controls page-based partial reading</li> <li>What happens: Used with <code>start_page</code>/<code>end_page</code> parameters</li> <li>Use case: Read specific sections of PDFs incrementally</li> </ul>"},{"location":"guides/file-operations/#2-absolute-safety-limit","title":"2. Absolute Safety Limit","text":"<ul> <li><code>max_characters_absolute</code> (default: 120,000 characters):</li> <li>Applies to: ALL file types (text, PDF, JSON, code)</li> <li>Behavior: Hard limit that raises an error when exceeded</li> <li>What happens: Returns detailed error telling agent to request fewer lines/pages</li> <li>Use case: Prevent context window overflow from excessively large reads</li> <li>\u26a0\ufe0f WARNING: Setting this too high (&gt;120K) can cause:<ul> <li>Context window overflow (most models: 128K-200K tokens total)</li> <li>Out of memory errors</li> <li>API timeout failures</li> <li>Workflow crashes</li> </ul> </li> </ul> <p>Recommended values: <pre><code>config = FileOperationConfig(\n    # JSON-specific truncation\n    max_json_content_chars=40000,      # ~10K tokens for JSON\n\n    # Text file line-based limiting\n    max_lines_per_read=250,            # ~10-20K chars typically\n\n    # PDF page-based limiting\n    max_pages_per_read=5,              # ~2.5K chars/page typical\n\n    # Hard safety limit for ALL files\n    max_characters_absolute=120000,    # ~30K tokens maximum\n)\n</code></pre></p> <p>Context Window Management</p> <p>The absolute character limit (120K) leaves room for: - System prompts (~2-5K tokens) - Agent memory/history (~10-20K tokens) - Images (if any) (~500-2000 tokens per image) - Response generation (~2-10K tokens)</p> <p>Total context budget: ~128K-200K tokens for most modern models</p>"},{"location":"guides/file-operations/#preset-configurations","title":"Preset Configurations","text":"<pre><code>from marsys.environment import FileOperationConfig, create_file_operation_tools\n\n# Permissive mode (default)\npermissive_config = FileOperationConfig.create_permissive()\npermissive_tools = create_file_operation_tools(permissive_config)\n\n# Restrictive mode (tighter security)\nrestrictive_config = FileOperationConfig.create_restrictive(\n    base_directory=Path(\"/workspace\")\n)\nrestrictive_tools = create_file_operation_tools(restrictive_config)\n</code></pre>"},{"location":"guides/file-operations/#reading-strategies","title":"\ud83d\udcd6 Reading Strategies","text":"<p>The toolkit provides five intelligent reading strategies to optimize token usage:</p>"},{"location":"guides/file-operations/#auto-strategy-default","title":"AUTO Strategy (Default)","text":"<p>Automatically selects the best strategy based on file size:</p> <pre><code># Agent automatically uses AUTO strategy\nresult = await file_agent.run(\n    prompt=\"Read data.json\",\n    context={}\n)\n</code></pre> <p>Selection Logic (based on character count for text files): - &lt; 10k characters (~2.5k tokens): FULL read (complete content) - 10-100k characters (~2.5-25k tokens): PARTIAL read (sections with overview) - 100-500k characters (~25-125k tokens): PROGRESSIVE (structure first, drill down) - &gt; 500k characters (~125k+ tokens): OVERVIEW (structure + summary only)</p>"},{"location":"guides/file-operations/#full-strategy","title":"FULL Strategy","text":"<p>Read complete file contents:</p> <pre><code>from marsys.environment.file_operations import ReadStrategy\n\nresult = await file_agent.run(\n    prompt=\"Read config.yaml using FULL strategy\",\n    context={\"read_strategy\": ReadStrategy.FULL}\n)\n</code></pre> <p>Best For: - Small configuration files - Complete data processing needed - Files under 10 KB</p>"},{"location":"guides/file-operations/#partial-strategy","title":"PARTIAL Strategy","text":"<p>Read with structure overview + selected sections:</p> <pre><code>result = await file_agent.run(\n    prompt=\"Read the 'Installation' section from README.md using PARTIAL strategy\",\n    context={\"read_strategy\": ReadStrategy.PARTIAL}\n)\n</code></pre> <p>Best For: - Medium-sized documents - When specific sections needed - Files 10-100 KB</p>"},{"location":"guides/file-operations/#overview-strategy","title":"OVERVIEW Strategy","text":"<p>Extract structure and summary only:</p> <pre><code>result = await file_agent.run(\n    prompt=\"Get overview of large_report.pdf\",\n    context={\"read_strategy\": ReadStrategy.OVERVIEW}\n)\n</code></pre> <p>Best For: - Large documents - Initial exploration - Files &gt; 100 KB</p> <p>Returns: - Table of contents - Section headings - Document summary - Metadata</p>"},{"location":"guides/file-operations/#progressive-strategy","title":"PROGRESSIVE Strategy","text":"<p>Load sections incrementally on demand:</p> <pre><code># First: Get structure\nresult1 = await file_agent.run(\n    prompt=\"Get structure of codebase/main.py\",\n    context={\"read_strategy\": ReadStrategy.PROGRESSIVE}\n)\n\n# Then: Load specific sections\nresult2 = await file_agent.run(\n    prompt=\"Read section 'class:DatabaseManager' from main.py\",\n    context={\"section_id\": \"class:DatabaseManager\"}\n)\n</code></pre> <p>Best For: - Very large files - Code exploration - Files &gt; 500 KB</p>"},{"location":"guides/file-operations/#incremental-reading","title":"\ud83d\udcd1 Incremental Reading","text":"<p>For large documents, the toolkit provides incremental reading capabilities that allow agents to request specific page or line ranges.</p>"},{"location":"guides/file-operations/#reading-specific-pdf-pages","title":"Reading Specific PDF Pages","text":"<pre><code># Read pages 5-10 of a PDF\nresult = await file_agent.run(\n    prompt=\"Read pages 5 to 10 from research_paper.pdf\",\n    context={\n        \"start_page\": 5,\n        \"end_page\": 10\n    }\n)\n</code></pre> <p>Features: - Automatic limit enforcement (prevents requesting too many pages at once) - Clean response without usage guides (agent already knows what was requested) - Returns pure content from requested range</p> <p>Response Format: When you explicitly specify a page range, you get just the content:</p> <pre><code>JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 5\n[Content from pages 5-10]\nJOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 10\n</code></pre> <p>Note: Usage guides are only shown when the system automatically returns partial content (file too large, no range specified). When you explicitly request pages 5-10, the system knows you're aware of what you're requesting.</p>"},{"location":"guides/file-operations/#reading-specific-text-lines","title":"Reading Specific Text Lines","text":"<pre><code># Read lines 100-200 from a code file\nresult = await file_agent.run(\n    prompt=\"Read lines 100 to 200 from main.py\",\n    context={\n        \"start_line\": 100,\n        \"end_line\": 200\n    }\n)\n</code></pre> <p>Features: - Character-based limit enforcement (prevents requesting too many lines) - Maximum characters enforced by <code>max_characters_absolute</code> (120K default) - Line-range reads are streamed from disk (no full-file load for large files) - Clean response without usage guides (explicit request)</p> <p>Response Format: <pre><code>Line 100\nLine 101\nLine 102\n...\nLine 200\n</code></pre></p> <p>Pure content from the requested line range, no headers or footers.</p>"},{"location":"guides/file-operations/#automatic-overflow-handling","title":"Automatic Overflow Handling","text":"<p>When a file exceeds <code>max_characters_absolute</code> (120K default) and no explicit range is specified, the system raises an error telling the agent to request specific page/line ranges instead.</p> <p>For PDFs: Returns first N pages (default: 5, configurable via <code>max_pages_per_read</code>) with:</p> <pre><code>=== PARTIAL CONTENT ===\nDocument: 18 pages total\nShowing: Pages 1-5\nMaximum pages per request: 7\nTo read more: use read_file(path, start_page=X, end_page=Y) or search_files(query)\n==================================================\n\n[PDF content from pages 1-5]\n\n==================================================\nEND OF PAGES 1-5 (of 18 total)\nTo continue: read_file(path, start_page=6, end_page=...)\n==================================================\n</code></pre> <p>For Text Files: 1. Truncates content at character limit 2. Prepends usage guide showing total lines 3. Provides guidance on reading more with line ranges</p> <p>Important: Usage guides are only shown for automatic overflow, not for explicit range requests.</p>"},{"location":"guides/file-operations/#request-validation","title":"Request Validation","text":"<p>The toolkit validates all page/line range requests:</p> <pre><code># Request too many pages (e.g., 200 pages when limit is 100)\nresult = await file_agent.run(\n    prompt=\"Read pages 1 to 200 from large_manual.pdf\",\n    context={\"start_page\": 1, \"end_page\": 200}\n)\n\n# Returns error response:\n# {\n#   \"error\": true,\n#   \"message\": \"Request exceeds maximum pages per read\",\n#   \"details\": {\n#     \"requested_pages\": 200,\n#     \"maximum_pages\": 100,\n#     \"suggestion\": \"Request fewer pages (e.g., start_page=1, end_page=100)\"\n#   }\n# }\n</code></pre> <p>Limits enforced: - PDF pages: <code>max_pages_per_read</code> (default: 5 pages) - Text lines: <code>max_lines_per_read</code> (default: 250 lines) - All file types: <code>max_characters_absolute</code> (default: 120K characters)</p>"},{"location":"guides/file-operations/#search-within-large-documents","title":"Search Within Large Documents","text":"<p>For finding specific information in large files:</p> <pre><code># Search for keywords in PDF with page numbers\nresult = await file_agent.run(\n    prompt=\"Search for 'machine learning' in research_paper.pdf\",\n    context={\n        \"search_type\": \"content\",\n        \"pattern\": \"machine learning\",\n        \"include_context\": True\n    }\n)\n\n# Result includes page numbers and line numbers:\n# {\n#   \"matches\": [\n#     {\n#       \"match\": \"Machine learning algorithms...\",\n#       \"location\": \"page 3, line 45\",\n#       \"page\": 3,\n#       \"line\": 45,\n#       \"context_before\": [...],\n#       \"context_after\": [...]\n#     }\n#   ]\n# }\n</code></pre> <p>Benefits: - Quickly locate information without reading entire document - Page-level navigation for PDFs - Context lines show surrounding content</p>"},{"location":"guides/file-operations/#structure-extraction","title":"\ud83c\udfd7\ufe0f Structure Extraction","text":"<p>The toolkit extracts hierarchical structure from various file types:</p>"},{"location":"guides/file-operations/#pdf-structure","title":"PDF Structure","text":"<p>Uses font-size analysis to detect headings:</p> <pre><code>result = await file_agent.run(\n    prompt=\"Extract structure from research_paper.pdf\",\n    context={}\n)\n\n# Returns DocumentStructure with sections like:\n# Section(id=\"1\", title=\"Introduction\", level=1, ...)\n#   \u251c\u2500\u2500 Section(id=\"1.1\", title=\"Background\", level=2, ...)\n#   \u2514\u2500\u2500 Section(id=\"1.2\", title=\"Motivation\", level=2, ...)\n</code></pre>"},{"location":"guides/file-operations/#code-structure-future","title":"Code Structure (Future)","text":"<p>AST-based parsing with tree-sitter:</p> <pre><code>result = await file_agent.run(\n    prompt=\"Show me the class structure of models.py\",\n    context={}\n)\n\n# Returns hierarchy like:\n# Section(id=\"module\", title=\"models.py\", ...)\n#   \u251c\u2500\u2500 Section(id=\"class:User\", title=\"class User\", ...)\n#   \u2502   \u251c\u2500\u2500 Section(id=\"method:__init__\", ...)\n#   \u2502   \u2514\u2500\u2500 Section(id=\"method:validate\", ...)\n#   \u2514\u2500\u2500 Section(id=\"class:Database\", ...)\n</code></pre>"},{"location":"guides/file-operations/#accessing-sections","title":"Accessing Sections","text":"<pre><code># Read specific section by ID\nresult = await file_agent.run(\n    prompt=\"Read section '1.2' from research_paper.pdf\",\n    context={\"section_id\": \"1.2\"}\n)\n</code></pre>"},{"location":"guides/file-operations/#editing-files","title":"\u270f\ufe0f Editing Files","text":""},{"location":"guides/file-operations/#unified-diff-format-recommended","title":"Unified Diff Format (Recommended)","text":"<p>High-success-rate editing using unified diff format:</p> <pre><code>result = await file_agent.run(\n    prompt=\"\"\"Edit config.py using unified diff format:\n\n    --- config.py\n    +++ config.py\n    @@ -10,3 +10,3 @@\n     DEBUG = True\n    -MAX_WORKERS = 4\n    +MAX_WORKERS = 8\n     LOG_LEVEL = \"INFO\"\n    \"\"\",\n    context={}\n)\n</code></pre> <p>Features: - Multiple fallback strategies (exact match \u2192 whitespace normalization \u2192 fuzzy matching) - Dry-run preview before applying - Detailed change reports - ~98% success rate (targeting Aider-like performance)</p>"},{"location":"guides/file-operations/#search-and-replace","title":"Search and Replace","text":"<p>Simple text replacement:</p> <pre><code>result = await file_agent.run(\n    prompt=\"\"\"Replace 'old_function()' with 'new_function()' in utils.py\"\"\",\n    context={}\n)\n</code></pre>"},{"location":"guides/file-operations/#dry-run-preview","title":"Dry Run Preview","text":"<p>Preview changes before applying:</p> <pre><code>result = await file_agent.run(\n    prompt=\"\"\"Show me what would change if I apply this diff (dry run):\n\n    --- app.py\n    +++ app.py\n    @@ -5,1 +5,1 @@\n    -version = \"1.0.0\"\n    +version = \"1.1.0\"\n    \"\"\",\n    context={\"dry_run\": True}\n)\n</code></pre>"},{"location":"guides/file-operations/#image-support-token-estimation","title":"\ud83d\uddbc\ufe0f Image Support &amp; Token Estimation","text":"<p>The toolkit provides comprehensive image support with provider-specific token estimation for vision-language models.</p>"},{"location":"guides/file-operations/#reading-images-directly","title":"Reading Images Directly","text":"<pre><code># Read an image file with token estimation\nresult = await file_agent.run(\n    prompt=\"Read the diagram.png image\",\n    context={\n        \"provider\": \"anthropic\",  # Options: openai, anthropic, google, xai, generic\n        \"detail\": \"high\",          # Options: high, low (affects some providers)\n        \"max_pixels\": 1024 * 1024  # Downsample if exceeds this limit\n    }\n)\n\n# Result includes:\n# - Image dimensions and format\n# - Estimated token count for the provider\n# - Base64-encoded image data (for sending to VLM)\n# - Metadata (DPI, color mode, etc.)\n</code></pre>"},{"location":"guides/file-operations/#token-estimation-by-provider","title":"Token Estimation by Provider","text":"<p>Different vision-language model providers use different tokenization strategies:</p> <p>OpenAI (GPT-4V, GPT-4o): - Divides images into 512x512 pixel tiles - Formula: <code>85 + (170 * num_tiles)</code> - Example: 1024x1024 image = 85 + (170 \u00d7 4) = 765 tokens</p> <p>Anthropic (Claude): - Formula: <code>(width * height) / 750</code> - Scales down images &gt; 1568px on long edge - Example: 1024x1024 image = (1024 \u00d7 1024) / 750 = 1398 tokens</p> <p>Google (Gemini): - Small images (\u2264384px both dimensions): 258 tokens - Larger images: 768x768 pixel tiles, 258 tokens/tile - Example: 1024x1024 image = 2 \u00d7 2 tiles = 1032 tokens</p> <p>xAI (Grok): - Divides into 448x448 pixel tiles - Formula: <code>(num_tiles + 1) * 256</code> - Example: 1024x1024 image = (6 + 1) \u00d7 256 = 1792 tokens</p>"},{"location":"guides/file-operations/#image-configuration","title":"Image Configuration","text":"<pre><code>config = FileOperationConfig(\n    # Image pixel limits\n    max_image_pixels=1024 * 1024,  # 1 megapixel max per image\n    max_images_per_read=4,          # Max images in single operation\n\n    # Auto-downsample if needed\n    # Images exceeding max_pixels will be resized maintaining aspect ratio\n)\n</code></pre>"},{"location":"guides/file-operations/#supported-image-formats","title":"Supported Image Formats","text":"<ul> <li>JPEG (.jpg, .jpeg)</li> <li>PNG (.png)</li> <li>GIF (.gif)</li> <li>WebP (.webp)</li> <li>BMP (.bmp)</li> <li>TIFF (.tiff, .tif)</li> <li>ICO (.ico)</li> <li>SVG (.svg)</li> </ul>"},{"location":"guides/file-operations/#image-extraction-from-pdfs","title":"Image Extraction from PDFs","text":"<p>When reading PDFs, the toolkit can extract embedded images:</p> <pre><code># Read PDF with images (future feature)\nresult = await file_agent.run(\n    prompt=\"Read report.pdf and include any charts or diagrams\",\n    context={\n        \"extract_images\": True,\n        \"provider\": \"openai\",  # For token estimation\n        \"max_images\": 4        # Limit images per PDF\n    }\n)\n\n# Result includes both text and ImageData objects\nprint(f\"Text tokens: {result.estimated_tokens}\")\nprint(f\"Image tokens: {result.total_estimated_image_tokens}\")\nprint(f\"Total tokens: {result.get_total_estimated_tokens()}\")\n</code></pre>"},{"location":"guides/file-operations/#token-budget-management","title":"Token Budget Management","text":"<pre><code>from marsys.environment.file_operations.token_estimation import (\n    estimate_total_tokens,\n    should_downsample_image\n)\n\n# Estimate total tokens before reading\nestimation = estimate_total_tokens(\n    text_content=\"Sample text...\",\n    images=[(1920, 1080), (1024, 768)],  # Image dimensions\n    provider=\"anthropic\"\n)\nprint(f\"Total estimated tokens: {estimation['total_tokens']}\")\nprint(f\"  Text: {estimation['text_tokens']} tokens\")\nprint(f\"  Images: {estimation['image_tokens']} tokens\")\n\n# Check if image needs downsampling\nneeds_downsample, target_dims = should_downsample_image(\n    width=2048,\n    height=2048,\n    max_pixels=1024 * 1024,\n    max_tokens=1000,\n    provider=\"openai\"\n)\nif needs_downsample:\n    print(f\"Downsample to: {target_dims}\")\n</code></pre>"},{"location":"guides/file-operations/#search-capabilities","title":"\ud83d\udd0d Search Capabilities","text":""},{"location":"guides/file-operations/#content-search-grep","title":"Content Search (Grep)","text":"<p>Search file contents with regex patterns:</p> <pre><code>result = await file_agent.run(\n    prompt=\"Search for 'TODO' comments in all Python files\",\n    context={\n        \"search_type\": \"content\",\n        \"pattern\": r\"#\\s*TODO:\",\n        \"file_pattern\": \"*.py\"\n    }\n)\n</code></pre> <p>Options: - Case-sensitive/insensitive search - Regex patterns - Context lines (before/after matches) - File type filtering - Pagination for large results</p>"},{"location":"guides/file-operations/#pdf-content-search-with-page-numbers","title":"PDF Content Search with Page Numbers","text":"<p>Search within PDF files with page-level location tracking:</p> <pre><code>result = await file_agent.run(\n    prompt=\"Search for 'neural network' in all PDF files\",\n    context={\n        \"search_type\": \"content\",\n        \"pattern\": \"neural network\",\n        \"file_pattern\": \"*.pdf\",\n        \"include_context\": True,\n        \"context_lines\": 2\n    }\n)\n\n# Returns matches with page numbers:\n# {\n#   \"matches\": [\n#     {\n#       \"file\": \"paper.pdf\",\n#       \"match\": \"Neural networks have revolutionized...\",\n#       \"location\": \"page 5, line 23\",\n#       \"page\": 5,\n#       \"line\": 23,\n#       \"context_before\": [\"...\", \"...\"],\n#       \"context_after\": [\"...\", \"...\"]\n#     }\n#   ]\n# }\n</code></pre> <p>Features: - Automatic page number tracking - Line numbers within each page - Context lines around matches - Location string for easy reference (\"page X, line Y\")</p>"},{"location":"guides/file-operations/#filename-search-glob","title":"Filename Search (Glob)","text":"<p>Find files by name patterns:</p> <pre><code>result = await file_agent.run(\n    prompt=\"Find all test files\",\n    context={\n        \"search_type\": \"filename\",\n        \"pattern\": \"**/test_*.py\"\n    }\n)\n</code></pre> <p>Supports: - Glob patterns (<code>*.py</code>, <code>**/*.md</code>, <code>test_*</code>) - Recursive search - File metadata (size, modified time, etc.)</p>"},{"location":"guides/file-operations/#structure-search","title":"Structure Search","text":"<p>Search within document structures:</p> <pre><code>result = await file_agent.run(\n    prompt=\"Find all class definitions in the codebase\",\n    context={\n        \"search_type\": \"structure\",\n        \"query\": \"class:*\"\n    }\n)\n</code></pre>"},{"location":"guides/file-operations/#security-features","title":"\ud83d\udd12 Security Features","text":""},{"location":"guides/file-operations/#run-filesystem-root-mounts","title":"Run Filesystem Root &amp; Mounts","text":"<p>Restrict operations to a run root and optionally add mounts:</p> <pre><code>from pathlib import Path\nfrom marsys.environment import FileOperationConfig, create_file_operation_tools\n\nconfig = FileOperationConfig(\n    base_directory=Path(\"/home/user/safe_workspace\"),\n    extra_mounts={\"/datasets\": Path(\"/shared/datasets\")}\n)\n\nfile_tools = create_file_operation_tools(config)\n\n# Attempts to escape the run root are blocked\n# Virtual paths like /datasets/* map to the mounted host directory\n</code></pre>"},{"location":"guides/file-operations/#pattern-based-permissions","title":"Pattern-Based Permissions","text":"<p>Control access with glob patterns:</p> <pre><code>config = FileOperationConfig(\n    # Block these patterns entirely\n    blocked_patterns=[\n        \"*.key\", \"*.pem\",  # Private keys\n        \".env*\",           # Environment files\n        \".git/**\",         # Git internals\n    ],\n\n    # Auto-approve these patterns (no confirmation)\n    auto_approve_patterns=[\n        \"*.md\", \"*.txt\",   # Safe documents\n        \"*.json\",          # Configuration\n    ],\n\n    # Require user approval for these\n    require_approval_patterns=[\n        \"*.sh\",            # Shell scripts\n        \"*.sql\",           # Database queries\n    ]\n)\n</code></pre> <p>Default behavior note: - <code>*.json</code> and <code>*.xml</code> are not in default require-approval patterns. - Sensitive config and execution-related files still require approval by default.</p>"},{"location":"guides/file-operations/#file-size-limits","title":"File Size Limits","text":"<p>Prevent memory issues:</p> <pre><code>config = FileOperationConfig(\n    max_file_size_bytes=10 * 1024 * 1024,  # 10 MB limit\n    max_characters_absolute=80000,          # Absolute read limit (chars)\n    max_lines_per_read=200                  # Line-based partial reads\n)\n</code></pre> <p>Error message safety: - File-operation errors are sanitized to avoid leaking host filesystem paths. - Agents see virtual paths in error messages (for example, <code>./data/file.txt</code>) instead of host-absolute paths.</p>"},{"location":"guides/file-operations/#audit-logging","title":"Audit Logging","text":"<p>Track all file operations:</p> <pre><code>config = FileOperationConfig(\n    enable_audit_logging=True,\n    log_file_path=Path(\"./file_ops_audit.log\")\n)\n\n# All operations logged with:\n# - Timestamp\n# - Operation type\n# - File path\n# - Success/failure\n# - Agent name\n</code></pre>"},{"location":"guides/file-operations/#available-tools","title":"\ud83d\udcda Available Tools","text":"<p>When you call <code>create_file_operation_tools()</code>, you get these tools:</p> Tool Description Parameters Example Usage <code>read_file</code> Read file with intelligent strategy <code>path</code>, <code>strategy</code>, <code>start_page</code>, <code>end_page</code>, <code>start_line</code>, <code>end_line</code> \"Read pages 5-10 from paper.pdf\" <code>write_file</code> Write content to file <code>path</code>, <code>content</code> \"Write results to output.txt\" <code>edit_file</code> Edit using unified diff or search/replace <code>path</code>, <code>changes</code>, <code>edit_format</code>, <code>dry_run</code> \"Change version to 2.0.0 in setup.py\" <code>search_files</code> Search content, filenames, or structure <code>query</code>, <code>search_type</code>, <code>path</code>, <code>include_context</code>, <code>context_lines</code> \"Search for 'TODO' in all .py files\" <code>get_file_structure</code> Extract hierarchical structure <code>path</code> \"Show structure of report.pdf\" <code>read_file_section</code> Read specific section by ID <code>path</code>, <code>section_id</code> \"Read section 3.2 from report.pdf\" <code>list_files</code> List directory contents <code>path</code>, <code>pattern</code> \"List all Python files in src/\" <code>create_directory</code> Create directories <code>path</code> \"Create directory for logs\" <code>delete_file</code> Delete files (with approval) <code>path</code> \"Delete temp files\""},{"location":"guides/file-operations/#read_file-parameters","title":"read_file Parameters","text":"<ul> <li>path (required): File path to read</li> <li>strategy (optional): Reading strategy (<code>auto</code>, <code>full</code>, <code>partial</code>, <code>overview</code>, <code>progressive</code>)</li> <li>start_page (optional): First page to read (PDFs only)</li> <li>end_page (optional): Last page to read (PDFs only)</li> <li>start_line (optional): First line to read (text files)</li> <li>end_line (optional): Last line to read (text files)</li> </ul> <p>Validation: - Page range requests validated against <code>max_pages_per_read</code> limit - Line range requests validated against <code>max_lines_per_read</code> limit - All requests validated against <code>max_characters_absolute</code> (120K) hard limit - Returns error with suggestion if request exceeds limits</p>"},{"location":"guides/file-operations/#search_files-parameters","title":"search_files Parameters","text":"<ul> <li>query (required): Search pattern or query</li> <li>search_type (optional): <code>content</code> (default), <code>filename</code>, or <code>structure</code></li> <li>path (optional): Specific file or directory to search</li> <li>include_context (optional): Include surrounding lines (default: false)</li> <li>context_lines (optional): Number of context lines (default: 2)</li> </ul> <p>PDF Search Features: - Automatically tracks page numbers - Returns location as \"page X, line Y\" - Includes context lines from the same page</p>"},{"location":"guides/file-operations/#use-cases","title":"\ud83d\udca1 Use Cases","text":""},{"location":"guides/file-operations/#use-case-1-analyzing-large-documents-with-incremental-reading","title":"Use Case 1: Analyzing Large Documents with Incremental Reading","text":"<pre><code># Agent extracts key information from large PDF using incremental reading\nresult = await file_agent.run(\n    prompt=\"\"\"Analyze research_paper.pdf (18 pages):\n    1. First, read the file without specifying pages to get overview\n    2. The system will return first 5 pages with guidance\n    3. Search for 'methodology' to find the relevant section\n    4. Read specific pages containing methodology\n    5. Summarize key findings\n    \"\"\",\n    context={}\n)\n\n# Example of what happens:\n# Step 1: Agent calls read_file(\"paper.pdf\")\n# System returns: Pages 1-5 WITH usage guide header/footer\n#   Content starts with: \"=== PARTIAL CONTENT ===\\nDocument: 18 pages total...\"\n#\n# Step 2: Agent calls search_files(\"methodology\", path=\"paper.pdf\")\n# System returns: \"Found at page 8, line 15\"\n#\n# Step 3: Agent calls read_file(\"paper.pdf\", start_page=7, end_page=10)\n# System returns: Pages 7-10 WITHOUT usage guide (clean content only)\n#   Content starts with: \"JOURNALOFLATEXCLASSFILES,VOL.14,NO.8,AUGUST2021 7...\"\n</code></pre>"},{"location":"guides/file-operations/#use-case-2-code-refactoring","title":"Use Case 2: Code Refactoring","text":"<pre><code># Agent performs safe code changes\nresult = await file_agent.run(\n    prompt=\"\"\"Refactor database.py:\n    1. Search for all deprecated function calls\n    2. Preview changes with dry-run\n    3. Apply unified diff to update functions\n    4. Verify changes were successful\n    \"\"\",\n    context={\"dry_run\": True}\n)\n</code></pre>"},{"location":"guides/file-operations/#use-case-3-multi-file-search-and-update","title":"Use Case 3: Multi-File Search and Update","text":"<pre><code># Agent searches and updates across codebase\nresult = await file_agent.run(\n    prompt=\"\"\"Update version numbers:\n    1. Search for 'version = ' in all Python files\n    2. Update to version 2.0.0\n    3. List all modified files\n    \"\"\",\n    context={}\n)\n</code></pre>"},{"location":"guides/file-operations/#use-case-4-secure-file-management","title":"Use Case 4: Secure File Management","text":"<pre><code># Agent with restricted permissions\nfrom pathlib import Path\nfrom marsys.environment import FileOperationConfig, create_file_operation_tools\n\nconfig = FileOperationConfig.create_restrictive(\n    base_directory=Path(\"/workspace/project\")\n)\n\nsecure_tools = create_file_operation_tools(config)\n\nsecure_agent = Agent(\n    model_config=model_config,\n    name=\"SecureFileAgent\",\n    goal=\"Manage project files securely\",\n    instruction=\"Only access files within /workspace/project. Never access system files.\",\n    tools=secure_tools\n)\n</code></pre>"},{"location":"guides/file-operations/#use-case-5-image-analysis-with-token-management","title":"Use Case 5: Image Analysis with Token Management","text":"<pre><code># Agent analyzes images with token budget awareness\nresult = await file_agent.run(\n    prompt=\"\"\"Analyze the architecture diagram:\n    1. Read architecture_diagram.png\n    2. Identify main components\n    3. Estimate token cost\n    4. If needed, downsample to fit budget\n    \"\"\",\n    context={\n        \"provider\": \"anthropic\",      # Claude for analysis\n        \"max_pixels\": 1024 * 1024,    # 1MP budget\n        \"detail\": \"high\"               # High detail analysis\n    }\n)\n\n# Result includes token estimation\nprint(f\"Image tokens used: {result.total_estimated_image_tokens}\")\n</code></pre>"},{"location":"guides/file-operations/#use-case-6-multi-modal-document-processing","title":"Use Case 6: Multi-Modal Document Processing","text":"<pre><code># Agent processes documents with text and images\nresult = await file_agent.run(\n    prompt=\"\"\"Process the quarterly report:\n    1. Extract text content\n    2. Find all embedded charts/graphs\n    3. Analyze each chart\n    4. Generate executive summary combining text and visual insights\n    \"\"\",\n    context={\n        \"extract_images\": True,\n        \"provider\": \"openai\",  # GPT-4V for vision\n        \"max_images\": 4,       # Limit to key visuals\n        \"max_pixels\": 512 * 512  # Reasonable size per image\n    }\n)\n</code></pre>"},{"location":"guides/file-operations/#common-issues","title":"\ud83d\udea8 Common Issues","text":""},{"location":"guides/file-operations/#issue-pymupdf-not-available","title":"Issue: \"PyMuPDF not available\"","text":"<p>Solution: <pre><code>pip install --upgrade marsys  # PyMuPDF is included in core\n# Or install directly:\npip install PyMuPDF\n</code></pre></p> <p>PyMuPDF is included in core marsys installation for PDF text/image extraction and layout analysis.</p>"},{"location":"guides/file-operations/#issue-pillow-pil-not-available","title":"Issue: \"Pillow (PIL) not available\"","text":"<p>Solution: <pre><code>pip install --upgrade marsys  # Pillow is included in core\n# Or install directly:\npip install Pillow\n</code></pre></p> <p>Pillow is included in core marsys installation for: - Direct image file reading (.jpg, .png, .webp, etc.) - Image extraction from PDFs - Image token estimation and processing</p>"},{"location":"guides/file-operations/#issue-path-outside-run-filesystem","title":"Issue: \"Path outside run filesystem\"","text":"<p>Solution: <pre><code># Either expand the run root\nconfig = FileOperationConfig(\n    base_directory=Path(\"/broader/path\")\n)\n\n# Or mount the external folder into the virtual filesystem\nconfig = FileOperationConfig(\n    base_directory=Path(\"/workspace\"),\n    extra_mounts={\"/datasets\": Path(\"/shared/datasets\")}\n)\n</code></pre></p>"},{"location":"guides/file-operations/#issue-file-too-large-to-read","title":"Issue: \"File too large to read\"","text":"<p>Solution: <pre><code># Use OVERVIEW or PROGRESSIVE strategy\nresult = await file_agent.run(\n    prompt=\"Get overview of large_file.pdf\",\n    context={\"read_strategy\": ReadStrategy.OVERVIEW}\n)\n\n# Or increase limits (use cautiously)\nconfig = FileOperationConfig(\n    max_file_size_bytes=100 * 1024 * 1024,  # 100 MB hard limit\n    max_characters_absolute=150000,          # Increase absolute limit (use cautiously!)\n    max_pages_per_read=10,                   # More pages per request\n    max_lines_per_read=500,                  # More lines per request\n    large_file_threshold=1000000             # 1M chars threshold\n)\n</code></pre></p>"},{"location":"guides/file-operations/#issue-request-exceeds-maximum-pages-per-read","title":"Issue: \"Request exceeds maximum pages per read\"","text":"<p>When an agent requests too many pages at once:</p> <p>Error: <pre><code>{\n  \"error\": true,\n  \"message\": \"Request exceeds maximum pages per read\",\n  \"details\": {\n    \"requested_pages\": 50,\n    \"maximum_pages\": 7,\n    \"suggestion\": \"Request fewer pages (e.g., start_page=1, end_page=7)\"\n  }\n}\n</code></pre></p> <p>Solutions: <pre><code># Option 1: Request fewer pages (recommended)\nresult = await file_agent.run(\n    prompt=\"Read pages 1-7 instead of 1-50\",\n    context={\"start_page\": 1, \"end_page\": 7}\n)\n\n# Option 2: Increase page limit via config\nconfig = FileOperationConfig(\n    max_pages_per_read=10,  # Increase pages per request\n    max_characters_absolute=150000,  # May also need to increase absolute limit\n)\n\n# Option 3: Read in batches\nfor start in range(1, 50, 7):\n    result = await file_agent.run(\n        prompt=f\"Read pages {start} to {start+6}\",\n        context={\"start_page\": start, \"end_page\": min(start+6, 50)}\n    )\n</code></pre></p>"},{"location":"guides/file-operations/#issue-request-exceeds-maximum-lines-per-read","title":"Issue: \"Request exceeds maximum lines per read\"","text":"<p>Similar to pages, but for text files:</p> <p>Error: <pre><code>{\n  \"error\": true,\n  \"message\": \"Request exceeds maximum lines per read\",\n  \"details\": {\n    \"requested_lines\": 1000,\n    \"maximum_lines\": 625,\n    \"suggestion\": \"Request fewer lines (e.g., start_line=1, end_line=625)\"\n  }\n}\n</code></pre></p> <p>Solution: Read in batches or increase <code>max_lines_per_read</code> and <code>max_characters_absolute</code> configuration (use cautiously).</p>"},{"location":"guides/file-operations/#issue-image-exceeds-token-budget","title":"Issue: \"Image exceeds token budget\"","text":"<p>Solution: <pre><code># Images are automatically downsampled if they exceed max_pixels\nconfig = FileOperationConfig(\n    max_image_pixels=2 * 1024 * 1024,  # 2 megapixels\n    max_images_per_read=6               # More images allowed\n)\n\n# Or specify max_pixels per operation\nresult = await file_agent.run(\n    prompt=\"Read large_image.png\",\n    context={\"max_pixels\": 2 * 1024 * 1024}  # Will downsample if needed\n)\n</code></pre></p>"},{"location":"guides/file-operations/#issue-edit-failed-to-apply","title":"Issue: \"Edit failed to apply\"","text":"<p>Solution: <pre><code># Use dry-run to preview\nresult = await file_agent.run(\n    prompt=\"Apply diff with dry-run first\",\n    context={\"dry_run\": True}\n)\n\n# Check the preview before applying\n# If still fails, use search-replace format instead\n</code></pre></p>"},{"location":"guides/file-operations/#best-practices","title":"\ud83d\udccb Best Practices","text":""},{"location":"guides/file-operations/#1-use-appropriate-reading-strategies","title":"1. Use Appropriate Reading Strategies","text":"<pre><code># \u2705 GOOD - Let AUTO choose for you\nresult = await file_agent.run(\"Read document.pdf\", context={})\n\n# \u2705 GOOD - Use incremental reading for large files\nresult = await file_agent.run(\n    \"Read pages 10-15 from large_report.pdf\",\n    context={\"start_page\": 10, \"end_page\": 15}\n)\n\n# \u2705 GOOD - Use search to find relevant sections first\nresult = await file_agent.run(\n    \"Search for 'conclusions' in report.pdf, then read those pages\",\n    context={}\n)\n\n# \u274c AVOID - Requesting entire large file at once\nresult = await file_agent.run(\n    \"Read all 100 pages of manual.pdf\",  # Will hit limits or return partial\n    context={}\n)\n</code></pre>"},{"location":"guides/file-operations/#2-leverage-search-for-large-documents","title":"2. Leverage Search for Large Documents","text":"<pre><code># \u2705 GOOD - Search before reading\nresult = await file_agent.run(\n    prompt=\"\"\"Find sections about 'machine learning' in research.pdf,\n    then read the relevant pages in detail\"\"\",\n    context={}\n)\n\n# \u274c LESS EFFICIENT - Reading everything hoping to find it\nresult = await file_agent.run(\n    prompt=\"Read entire 200-page thesis and find ML sections\",\n    context={}\n)\n</code></pre>"},{"location":"guides/file-operations/#3-always-use-dry-run-for-critical-edits","title":"3. Always Use Dry Run for Critical Edits","text":"<pre><code># \u2705 GOOD - Preview before applying\nresult = await file_agent.run(\n    \"Update production config (dry run first)\",\n    context={\"dry_run\": True}\n)\n\n# \u274c RISKY - Direct edit without preview\nresult = await file_agent.run(\n    \"Update production config\",  # No preview\n    context={}\n)\n</code></pre>"},{"location":"guides/file-operations/#4-restrict-run-root-for-security","title":"4. Restrict Run Root for Security","text":"<pre><code># \u2705 GOOD - Limit the run root\nconfig = FileOperationConfig(\n    base_directory=Path(\"/workspace\")\n)\n\n# \u274c RISKY - Overly broad root\nconfig = FileOperationConfig(\n    base_directory=Path(\"/\")  # Agent can access the entire host filesystem\n)\n</code></pre>"},{"location":"guides/file-operations/#5-use-pattern-based-permissions","title":"5. Use Pattern-Based Permissions","text":"<pre><code># \u2705 GOOD - Block sensitive files\nconfig = FileOperationConfig(\n    blocked_patterns=[\"*.key\", \"*.pem\", \".env*\"]\n)\n\n# \u274c MISSING - No protection for secrets\nconfig = FileOperationConfig(\n    blocked_patterns=[]  # No restrictions\n)\n</code></pre>"},{"location":"guides/file-operations/#6-enable-audit-logging-for-production","title":"6. Enable Audit Logging for Production","text":"<pre><code># \u2705 GOOD - Track all operations\nconfig = FileOperationConfig(\n    enable_audit_logging=True,\n    log_file_path=Path(\"./audit.log\")\n)\n\n# \u274c MISSING - No audit trail\nconfig = FileOperationConfig(\n    enable_audit_logging=False\n)\n</code></pre>"},{"location":"guides/file-operations/#7-handle-errors-gracefully","title":"7. Handle Errors Gracefully","text":"<pre><code># \u2705 GOOD - Provide fallback instructions\nfile_agent = Agent(\n    model_config=model_config,\n    name=\"FileAssistant\",\n    goal=\"Manage files\",\n    instruction=\"\"\"Handle errors gracefully:\n    - If file not found, suggest similar filenames\n    - If access denied, explain permissions needed\n    - If edit fails, try search-replace format\n    - Always report errors clearly to user\n    \"\"\",\n    tools=file_tools\n)\n</code></pre>"},{"location":"guides/file-operations/#advanced-examples","title":"\ud83c\udfaf Advanced Examples","text":""},{"location":"guides/file-operations/#multi-agent-file-processing-pipeline","title":"Multi-Agent File Processing Pipeline","text":"<pre><code>from marsys import Agent\nfrom marsys.models import ModelConfig\nfrom pathlib import Path\nfrom marsys.environment import FileOperationConfig, create_file_operation_tools\nfrom marsys.environment.filesystem import RunFileSystem\nfrom marsys.coordination import Orchestra\nfrom marsys.coordination.topology.patterns import PatternConfig\nimport os\n\n# Model configuration (adjust based on your provider)\nmodel_config = ModelConfig(\n    type=\"api\",\n    name=\"anthropic/claude-opus-4.6\",\n    provider=\"openrouter\",\n    api_key=os.getenv(\"OPENROUTER_API_KEY\")\n)\n\n# Shared run filesystem for all agents\nfs = RunFileSystem.local(run_root=Path(\"./runs/run-20260206\"))\nfile_config = FileOperationConfig(run_filesystem=fs)\nfile_tools = create_file_operation_tools(file_config)\n\n# Agent 1: File Scanner\nscanner = Agent(\n    model_config=model_config,\n    name=\"Scanner\",\n    goal=\"Scan directories and identify files for processing\",\n    instruction=\"Use list_files and search_files to find target files\",\n    tools=file_tools\n)\n\n# Agent 2: Content Analyzer\nanalyzer = Agent(\n    model_config=model_config,\n    name=\"Analyzer\",\n    goal=\"Analyze file contents and extract insights\",\n    instruction=\"Read files intelligently using appropriate strategies\",\n    tools=file_tools\n)\n\n# Agent 3: Report Generator\nreporter = Agent(\n    model_config=model_config,\n    name=\"Reporter\",\n    goal=\"Generate summary reports from analysis\",\n    instruction=\"Create structured reports and write to output files\",\n    tools=file_tools\n)\n\n# Create pipeline topology\ntopology = PatternConfig.pipeline(\n    stages=[\n        {\"name\": \"scan\", \"agents\": [\"Scanner\"]},\n        {\"name\": \"analyze\", \"agents\": [\"Analyzer\"]},\n        {\"name\": \"report\", \"agents\": [\"Reporter\"]}\n    ],\n    parallel_within_stage=False\n)\n\n# Execute pipeline\nresult = await Orchestra.run(\n    task=\"Analyze all Python files in src/ and generate report\",\n    topology=topology\n)\n</code></pre>"},{"location":"guides/file-operations/#progressive-document-reading","title":"Progressive Document Reading","text":"<pre><code># Agent uses progressive strategy for large documents\nresult = await file_agent.run(\n    prompt=\"\"\"Read technical_manual.pdf progressively:\n    1. Get document structure first\n    2. Identify the 'Installation' section\n    3. Read only the Installation section in detail\n    4. Summarize installation steps\n    \"\"\",\n    context={\"read_strategy\": ReadStrategy.PROGRESSIVE}\n)\n</code></pre>"},{"location":"guides/file-operations/#next-steps","title":"\ud83c\udfaf Next Steps","text":"<ul> <li>Tool API Reference - Complete API documentation</li> <li>Custom Tools - Create your own file handlers</li> <li>Agent Development - Build agents with file capabilities</li> <li>Security Best Practices - Secure file operations</li> </ul> <p>Security</p> <p>Always configure <code>blocked_patterns</code> to prevent access to sensitive files like private keys, environment variables, and credentials.</p> <p>Core Dependencies</p> <ul> <li>PDF support: Provided by <code>PyMuPDF</code> (included in core marsys installation) for PDF structure extraction, text reading, and image extraction</li> <li>Image support: Provided by <code>Pillow</code> (included in core marsys installation) for image reading and processing</li> <li>Both are automatically included for full VLM capabilities</li> </ul> <p>Token Management</p> <ul> <li>The toolkit uses character count (not file size) as a proxy for text tokens</li> <li>Image tokens are estimated using provider-specific formulas (OpenAI, Anthropic, Google, xAI)</li> <li>AUTO strategy intelligently selects reading approach based on character count</li> <li>Images are automatically downsampled if they exceed pixel/token budgets</li> </ul> <p>Incremental Reading (New in v0.2)</p> <p>Efficient Large Document Handling: - PDF pages: Use <code>start_page</code>/<code>end_page</code> parameters to read specific page ranges - Text lines: Use <code>start_line</code>/<code>end_line</code> parameters for line-based reading - Clean responses: Explicit range requests return pure content without usage guides - Automatic limits: System enforces limits and returns helpful error messages - PDF search: Returns page numbers with each match (\"page 5, line 23\") - Validation: All requests validated against:   - <code>max_pages_per_read</code> (default: 5 pages)   - <code>max_lines_per_read</code> (default: 250 lines)   - <code>max_characters_absolute</code> (default: 120K characters)</p> <p>Response Types: - Explicit range (<code>start_page=5, end_page=10</code>): Pure content only - File too large (exceeds 120K chars): Error with suggestion to use ranges - Excessive range (exceeds limit): Error with suggestion to request fewer lines/pages</p> <p>Recommended workflow for large documents: 1. Try reading the file (if &gt; 120K chars, error will suggest using ranges) 2. Use search to find relevant sections (returns page numbers) 3. Request specific page/line ranges based on search results 4. Continue reading in batches if needed</p>"},{"location":"guides/multimodal-agents/","title":"Multimodal Agents Guide","text":"<p>A comprehensive guide to building agents that can process and reason about visual content alongside text.</p>"},{"location":"guides/multimodal-agents/#overview","title":"\ud83c\udfaf Overview","text":"<p>MARSYS supports multimodal AI agents that can:</p> <ul> <li>Process Images: Analyze screenshots, photos, diagrams, charts</li> <li>Read Documents: Extract text and images from PDFs</li> <li>Visual Reasoning: Answer questions about visual content</li> <li>Mixed Input: Handle tasks with both text and images</li> </ul> <p>This guide covers: 1. Quick start 2. Creating multimodal tasks 3. Building multimodal tools 4. Real-world examples</p>"},{"location":"guides/multimodal-agents/#quick-start","title":"\ud83d\ude80 Quick Start","text":""},{"location":"guides/multimodal-agents/#basic-multimodal-task","title":"Basic Multimodal Task","text":"<pre><code>from marsys.coordination import Orchestra\nfrom marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\n# Create vision-enabled agent\nvision_agent = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\",\n        api_key=os.getenv(\"OPENROUTER_API_KEY\")\n    ),\n    name=\"VisionAnalyst\",\n    goal=\"Expert at analyzing visual content\",\n    instruction=\"You are an expert at analyzing images and providing detailed insights.\"\n)\n\n# Run with images\nresult = await Orchestra.run(\n    task={\n        \"content\": \"What is shown in this image? Provide a detailed analysis.\",\n        \"images\": [\"/path/to/screenshot.png\"]\n    },\n    topology={\"agents\": [\"VisionAnalyst\"], \"flows\": []}\n)\n\nprint(result.final_response)\n</code></pre>"},{"location":"guides/multimodal-agents/#model-configuration","title":"Model Configuration","text":"<pre><code>from marsys.models import ModelConfig\n\n# OpenRouter with Claude Opus 4.6 for vision\nclaude_config = ModelConfig(\n    type=\"api\",\n    name=\"anthropic/claude-opus-4.6\",\n    provider=\"openrouter\",\n    api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n    temperature=0.7,\n    max_tokens=2000\n)\n\n# Anthropic model with vision (Claude Opus 4.6)\nanthropic_config = ModelConfig(\n    type=\"api\",\n    name=\"claude-opus-4-6\",\n    provider=\"anthropic\",\n    api_key=os.getenv(\"ANTHROPIC_API_KEY\")\n)\n\n# Google model with vision (Gemini 3 Pro Preview)\ngoogle_config = ModelConfig(\n    type=\"api\",\n    name=\"gemini-3-pro-preview\",\n    provider=\"google\",\n    api_key=os.getenv(\"GOOGLE_API_KEY\")\n)\n</code></pre>"},{"location":"guides/multimodal-agents/#multimodal-tasks","title":"\ud83d\udccb Multimodal Tasks","text":""},{"location":"guides/multimodal-agents/#task-format","title":"Task Format","text":"<p>Tasks with images use this format:</p> <pre><code>task = {\n    \"content\": \"Text description of what you want\",\n    \"images\": [\"path/to/image1.png\", \"path/to/image2.jpg\"]\n}\n</code></pre>"},{"location":"guides/multimodal-agents/#image-sources","title":"Image Sources","text":"<p>The <code>images</code> field accepts multiple formats:</p> <pre><code># Local file paths\ntask = {\n    \"content\": \"Analyze these screenshots\",\n    \"images\": [\n        \"/home/user/screenshot1.png\",\n        \"./downloads/image.jpg\"\n    ]\n}\n\n# URLs (if supported by model)\ntask = {\n    \"content\": \"What's in this image?\",\n    \"images\": [\"https://example.com/photo.jpg\"]\n}\n\n# Mixed sources\ntask = {\n    \"content\": \"Compare these images\",\n    \"images\": [\n        \"/local/path/image1.png\",\n        \"https://example.com/image2.jpg\"\n    ]\n}\n</code></pre> <p>When images come from tools (browser downloads, code execution, etc.), prefer the virtual paths they return (e.g., <code>./downloads/...</code>, <code>./outputs/...</code>, <code>./screenshots/...</code>) so other agents can access them consistently. See Run Filesystem.</p>"},{"location":"guides/multimodal-agents/#how-it-works","title":"How It Works","text":"<p>When you provide images in a task:</p> <ol> <li>Extraction: Orchestra extracts the <code>images</code> field</li> <li>Memory Injection: Images are added to the first agent's memory</li> <li>Base64 Encoding: Framework automatically encodes local images</li> <li>API Format: Message formatted per provider requirements</li> <li>Vision Model: Model receives multimodal input</li> </ol> <pre><code>graph LR\n    A[Task with Images] --&gt; B[Orchestra.run]\n    B --&gt; C[Extract images field]\n    C --&gt; D[Add to agent memory]\n    D --&gt; E[Base64 encode]\n    E --&gt; F[Format for API]\n    F --&gt; G[Vision Model]\n    G --&gt; H[Response]</code></pre>"},{"location":"guides/multimodal-agents/#multimodal-tools","title":"\ud83d\udee0\ufe0f Multimodal Tools","text":""},{"location":"guides/multimodal-agents/#toolresponse-the-proper-way-to-return-multimodal-content","title":"ToolResponse: The Proper Way to Return Multimodal Content","text":"<p>Tools should return <code>ToolResponse</code> objects for multimodal content. This enables ordered sequences of text and images that map directly to LLM message content arrays.</p> <pre><code>from marsys.environment.tool_response import ToolResponse, ToolResponseContent\n\ndef tool_read_pdf(pdf_path: str) -&gt; ToolResponse:\n    \"\"\"\n    Read PDF and return text + page images for vision analysis.\n\n    Args:\n        pdf_path: Path to PDF file\n\n    Returns:\n        ToolResponse with ordered text and image content blocks\n    \"\"\"\n    # Extract text\n    text = extract_text_from_pdf(pdf_path)\n\n    # Convert pages to images\n    page_images = convert_pdf_pages_to_images(pdf_path)\n\n    # Build ordered content blocks\n    content_blocks = [\n        ToolResponseContent(text=f\"Extracted {len(page_images)} pages from PDF.\")\n    ]\n\n    # Add each page image with its text\n    for i, (page_text, page_image) in enumerate(zip(text.split(\"---\"), page_images), 1):\n        content_blocks.append(ToolResponseContent(text=f\"--- Page {i} ---\"))\n        content_blocks.append(ToolResponseContent(image_path=page_image))\n        content_blocks.append(ToolResponseContent(text=page_text.strip()))\n\n    return ToolResponse(\n        content=content_blocks,\n        metadata={\"pages\": len(page_images), \"file\": pdf_path}\n    )\n</code></pre>"},{"location":"guides/multimodal-agents/#toolresponsecontent-options","title":"ToolResponseContent Options","text":"<p><code>ToolResponseContent</code> supports three content types:</p> <pre><code>from marsys.environment.tool_response import ToolResponseContent\n\n# 1. Text content (string)\nToolResponseContent(text=\"Hello world\")\n\n# 2. Text content (dict - will be JSON stringified)\nToolResponseContent(text={\"key\": \"value\", \"count\": 42})\n\n# 3. Image with local file path (auto-converted to base64)\nToolResponseContent(image_path=\"/path/to/image.png\")\n\n# 4. Image with base64 data URL (already encoded)\nToolResponseContent(image_data=\"data:image/png;base64,iVBORw0KGgo...\")\n</code></pre> <p>Mutually Exclusive</p> <p>Each <code>ToolResponseContent</code> must have exactly ONE of: <code>text</code>, <code>image_path</code>, or <code>image_data</code>. You cannot combine them in the same content block.</p>"},{"location":"guides/multimodal-agents/#toolresponse-content-formats","title":"ToolResponse Content Formats","text":"<p><code>ToolResponse</code> supports three content formats:</p> <pre><code>from marsys.environment.tool_response import ToolResponse, ToolResponseContent\n\n# 1. Simple string (for text-only results)\nToolResponse(content=\"File read successfully\")\n\n# 2. Dictionary (for structured data)\nToolResponse(content={\"status\": \"success\", \"count\": 42})\n\n# 3. List of ToolResponseContent (for ordered multimodal content)\nToolResponse(\n    content=[\n        ToolResponseContent(text=\"Chapter 1\"),\n        ToolResponseContent(image_data=\"data:image/png;base64,...\"),\n        ToolResponseContent(text=\"Figure 1.1: System Architecture\")\n    ],\n    metadata={\"pages\": \"1-5\", \"images\": 3}\n)\n</code></pre>"},{"location":"guides/multimodal-agents/#tool-result-flow","title":"Tool Result Flow","text":"<p>The framework automatically handles <code>ToolResponse</code> processing:</p> <pre><code># 1. Agent calls tool\nagent: \"I need to read this PDF\"\ntool_call: tool_read_pdf(\"/path/to/document.pdf\")\n\n# 2. Tool returns ToolResponse with multimodal content\ntool_result = ToolResponse(\n    content=[\n        ToolResponseContent(text=\"Extracted 3 pages.\"),\n        ToolResponseContent(image_path=\"./outputs/page1.png\"),\n        ToolResponseContent(text=\"Page 1: Annual Report...\"),\n        ToolResponseContent(image_path=\"./outputs/page2.png\"),\n        ToolResponseContent(text=\"Page 2: Financial Data...\")\n    ]\n)\n\n# 3. Framework processes ToolResponse (tool_executor.py)\n# - Detects ToolResponse object\n# - Calls to_content_array() for proper LLM message format\n\n# 4. Framework creates two-message pattern (step_executor.py)\n# - role=\"tool\": Metadata message about the tool execution\n# - role=\"user\": Actual multimodal content array\n\n# 5. Agent receives properly formatted multimodal context\n# Vision model sees ordered text + images with correct structure\n</code></pre>"},{"location":"guides/multimodal-agents/#complete-tool-example-with-toolresponse","title":"Complete Tool Example with ToolResponse","text":"<pre><code>import PyPDF2\nfrom pdf2image import convert_from_path\nfrom pathlib import Path\nimport tempfile\nfrom marsys.environment.tool_response import ToolResponse, ToolResponseContent\n\ndef tool_analyze_document(\n    file_path: str,\n    extract_images: bool = True\n) -&gt; ToolResponse:\n    \"\"\"\n    Analyze a document file (PDF, image, text).\n\n    Args:\n        file_path: Path to document\n        extract_images: Whether to extract visual content\n\n    Returns:\n        ToolResponse with document content and optional images\n    \"\"\"\n    file_path = Path(file_path)\n\n    if not file_path.exists():\n        return ToolResponse(\n            content=f\"Error: File not found: {file_path}\",\n            metadata={\"error\": \"file_not_found\"}\n        )\n\n    # Handle PDFs\n    if file_path.suffix.lower() == '.pdf':\n        content_blocks = []\n\n        # Extract text\n        text_parts = []\n        with open(file_path, 'rb') as f:\n            reader = PyPDF2.PdfReader(f)\n            for i, page in enumerate(reader.pages, 1):\n                page_text = page.extract_text()\n                if page_text.strip():\n                    text_parts.append((i, page_text.strip()))\n\n        # Optionally convert pages to images\n        image_paths = []\n        if extract_images:\n            temp_dir = Path(tempfile.mkdtemp(prefix=\"pdf_analysis_\"))\n            pdf_images = convert_from_path(str(file_path), dpi=200)\n\n            for i, img in enumerate(pdf_images, 1):\n                img_path = temp_dir / f\"page_{i}.png\"\n                img.save(str(img_path), 'PNG')\n                image_paths.append(str(img_path))\n\n        # Build ordered content: text, then image for each page\n        content_blocks.append(\n            ToolResponseContent(text=f\"Document: {file_path.name} ({len(text_parts)} pages)\")\n        )\n\n        for i, (page_num, page_text) in enumerate(text_parts):\n            content_blocks.append(\n                ToolResponseContent(text=f\"--- Page {page_num} ---\\n{page_text}\")\n            )\n            if i &lt; len(image_paths):\n                content_blocks.append(\n                    ToolResponseContent(image_path=image_paths[i])\n                )\n\n        return ToolResponse(\n            content=content_blocks,\n            metadata={\n                \"pages\": len(text_parts),\n                \"file_type\": \"pdf\",\n                \"visual_pages\": len(image_paths)\n            }\n        )\n\n    # Handle image files\n    elif file_path.suffix.lower() in ['.png', '.jpg', '.jpeg', '.gif', '.bmp']:\n        return ToolResponse(\n            content=[\n                ToolResponseContent(text=f\"Image file: {file_path.name}\"),\n                ToolResponseContent(image_path=str(file_path))\n            ],\n            metadata={\"file_type\": \"image\"}\n        )\n\n    # Handle text files\n    else:\n        try:\n            with open(file_path, 'r', encoding='utf-8') as f:\n                content = f.read()\n            return ToolResponse(\n                content=content,\n                metadata={\"file_type\": \"text\", \"chars\": len(content)}\n            )\n        except Exception as e:\n            return ToolResponse(\n                content=f\"Error reading file: {e}\",\n                metadata={\"error\": \"read_failed\"}\n            )\n</code></pre>"},{"location":"guides/multimodal-agents/#real-world-examples","title":"\ud83d\udca1 Real-World Examples","text":""},{"location":"guides/multimodal-agents/#example-1-screenshot-analysis","title":"Example 1: Screenshot Analysis","text":"<pre><code>from marsys.coordination import Orchestra\nfrom marsys.agents import Agent\nfrom marsys.models import ModelConfig\n\n# Create agent\nui_analyst = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\",\n        api_key=os.getenv(\"OPENROUTER_API_KEY\")\n    ),\n    name=\"UIAnalyst\",\n    goal=\"Expert at analyzing user interfaces\",\n    instruction=\"\"\"You are a UI/UX expert. When analyzing screenshots:\n    1. Identify all UI elements\n    2. Assess usability and accessibility\n    3. Note any design issues\n    4. Suggest improvements\"\"\"\n)\n\n# Analyze screenshots\nresult = await Orchestra.run(\n    task={\n        \"content\": \"Analyze these app screenshots and identify UI/UX issues\",\n        \"images\": [\n            \"./screenshots/login_screen.png\",\n            \"./screenshots/dashboard.png\",\n            \"./screenshots/settings.png\"\n        ]\n    },\n    topology={\"agents\": [\"UIAnalyst\"], \"flows\": []}\n)\n\nprint(result.final_response)\n</code></pre>"},{"location":"guides/multimodal-agents/#example-2-document-processing-with-tools","title":"Example 2: Document Processing with Tools","text":"<pre><code>from marsys.coordination import Orchestra\nfrom marsys.coordination.topology.patterns import PatternConfig\n\n# Define tools\ndef tool_read_file(file_path: str) -&gt; Dict[str, Any]:\n    \"\"\"Read file and extract images if applicable.\"\"\"\n    # Implementation from above\n    return tool_analyze_document(file_path, extract_images=True)\n\n# Create agents\ncoordinator = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\",\n        api_key=os.getenv(\"OPENROUTER_API_KEY\")\n    ),\n    name=\"Coordinator\",\n    goal=\"Coordinates document analysis\",\n    instruction=\"You coordinate document analysis tasks between agents.\",\n    tools={\"read_file\": tool_read_file}\n)\n\nanalyst = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\",\n        api_key=os.getenv(\"OPENROUTER_API_KEY\")\n    ),\n    name=\"DocumentAnalyst\",\n    goal=\"Analyzes document content\",\n    instruction=\"You are an expert at analyzing documents and extracting key information.\"\n)\n\n# Define workflow\ntopology = PatternConfig.hub_and_spoke(\n    hub=\"Coordinator\",\n    spokes=[\"DocumentAnalyst\"]\n)\n\n# Execute\nresult = await Orchestra.run(\n    task=\"Read the file report.pdf and extract all key metrics and charts\",\n    topology=topology\n)\n</code></pre>"},{"location":"guides/multimodal-agents/#example-3-gaia-benchmark-task","title":"Example 3: GAIA Benchmark Task","text":"<pre><code># GAIA benchmark question with file attachment\ngaia_question = {\n    \"question\": \"Based on the chart in the attached file, what was the growth rate in Q3?\",\n    \"file_path\": \"./gaia_dataset/files/chart_q3.pdf\",\n    \"answer\": \"15.2%\"\n}\n\n# Setup GAIA tool\ndef tool_read_gaia_file(file_path: str) -&gt; Dict[str, Any]:\n    \"\"\"Read GAIA question attachment.\"\"\"\n    return tool_analyze_document(file_path, extract_images=True)\n\n# Create research agent with file reading capability\nresearcher = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\",\n        api_key=os.getenv(\"OPENROUTER_API_KEY\"),\n        temperature=0.0  # Deterministic for benchmarks\n    ),\n    name=\"GaiaResearcher\",\n    goal=\"Answers GAIA benchmark questions\",\n    instruction=\"\"\"You are a helpful assistant that answers questions precisely.\n    When files are provided, read them using the read_file tool.\n    Extract information carefully and answer concisely.\"\"\",\n    tools={\"read_gaia_file\": tool_read_gaia_file, \"google_search\": tool_google_search}\n)\n\n# Run GAIA task\nresult = await Orchestra.run(\n    task=f\"File: {gaia_question['file_path']}\\nQuestion: {gaia_question['question']}\",\n    topology={\"agents\": [\"GaiaResearcher\"], \"flows\": []}\n)\n\n# Compare answer\npredicted = result.final_response\nexpected = gaia_question[\"answer\"]\ncorrect = normalize_answer(predicted) == normalize_answer(expected)\n</code></pre>"},{"location":"guides/multimodal-agents/#example-4-multi-agent-vision-pipeline","title":"Example 4: Multi-Agent Vision Pipeline","text":"<pre><code>from marsys.coordination.topology.patterns import PatternConfig\n\n# Create specialized agents\nimage_captioner = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\",\n        api_key=os.getenv(\"OPENROUTER_API_KEY\")\n    ),\n    name=\"Captioner\",\n    goal=\"Creates detailed image captions\",\n    instruction=\"Generate detailed, accurate captions for images.\"\n)\n\nobject_detector = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"gemini-3-pro-preview\",\n        provider=\"google\",\n        api_key=os.getenv(\"GOOGLE_API_KEY\")\n    ),\n    name=\"ObjectDetector\",\n    goal=\"Identifies objects in images\",\n    instruction=\"List all objects visible in images with confidence scores.\"\n)\n\nscene_analyzer = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"claude-opus-4-6\",\n        provider=\"anthropic\",\n        api_key=os.getenv(\"ANTHROPIC_API_KEY\")\n    ),\n    name=\"SceneAnalyzer\",\n    goal=\"Analyzes overall scene context\",\n    instruction=\"Analyze the overall scene, context, and relationships.\"\n)\n\nsynthesizer = Agent(\n    model_config=ModelConfig(\n        type=\"api\",\n        name=\"anthropic/claude-opus-4.6\",\n        provider=\"openrouter\",\n        api_key=os.getenv(\"OPENROUTER_API_KEY\")\n    ),\n    name=\"Synthesizer\",\n    goal=\"Synthesizes analysis from specialists\",\n    instruction=\"Combine insights from specialists into comprehensive report.\"\n)\n\n# Pipeline topology\ntopology = PatternConfig.pipeline(\n    stages=[\n        {\"name\": \"analysis\", \"agents\": [\"Captioner\", \"ObjectDetector\", \"SceneAnalyzer\"]},\n        {\"name\": \"synthesis\", \"agents\": [\"Synthesizer\"]}\n    ],\n    parallel_within_stage=True  # Parallel analysis\n)\n\n# Execute\nresult = await Orchestra.run(\n    task={\n        \"content\": \"Provide comprehensive analysis of these images\",\n        \"images\": [\"./photos/scene1.jpg\", \"./photos/scene2.jpg\"]\n    },\n    topology=topology\n)\n</code></pre>"},{"location":"guides/multimodal-agents/#best-practices","title":"\ud83d\udccb Best Practices","text":""},{"location":"guides/multimodal-agents/#1-image-format-and-size","title":"1. Image Format and Size","text":"<pre><code># \u2705 GOOD - Optimize images before sending\nfrom PIL import Image\n\ndef optimize_image(image_path: str, max_size: tuple = (2048, 2048)) -&gt; str:\n    \"\"\"Resize large images to reduce API costs.\"\"\"\n    img = Image.open(image_path)\n\n    if img.size[0] &gt; max_size[0] or img.size[1] &gt; max_size[1]:\n        img.thumbnail(max_size, Image.Resampling.LANCZOS)\n\n        # Save to temp location\n        output_path = f\"./outputs/optimized_{Path(image_path).name}\"\n        img.save(output_path, optimize=True, quality=85)\n        return output_path\n\n    return image_path\n\n# \u274c BAD - Sending huge images wastes tokens and money\ntask = {\n    \"content\": \"Analyze this image\",\n    \"images\": [\"./huge_8k_photo.jpg\"]  # 8000x6000 pixels!\n}\n</code></pre>"},{"location":"guides/multimodal-agents/#2-provide-context","title":"2. Provide Context","text":"<pre><code># \u2705 GOOD - Clear context\ntask = {\n    \"content\": \"\"\"Analyze these medical X-rays and identify:\n    1. Any abnormalities\n    2. Potential diagnoses\n    3. Recommended follow-up tests\n\n    Images are: chest X-ray (front), chest X-ray (side)\"\"\",\n    \"images\": [\"./xray_front.jpg\", \"./xray_side.jpg\"]\n}\n\n# \u274c BAD - Vague context\ntask = {\n    \"content\": \"Look at these\",\n    \"images\": [\"./xray_front.jpg\", \"./xray_side.jpg\"]\n}\n</code></pre>"},{"location":"guides/multimodal-agents/#3-handle-tool-errors-gracefully","title":"3. Handle Tool Errors Gracefully","text":"<pre><code>from marsys.environment.tool_response import ToolResponse, ToolResponseContent\n\n# \u2705 GOOD - Robust error handling with ToolResponse\ndef tool_read_file(file_path: str) -&gt; ToolResponse:\n    \"\"\"Read file with proper error handling.\"\"\"\n    try:\n        if not Path(file_path).exists():\n            return ToolResponse(\n                content=f\"Error: File not found: {file_path}\",\n                metadata={\"error\": \"file_not_found\"}\n            )\n\n        # Process file and return multimodal content\n        return ToolResponse(\n            content=[\n                ToolResponseContent(text=f\"Reading: {file_path}\"),\n                ToolResponseContent(image_path=file_path) if is_image(file_path) else None,\n            ],\n            metadata={\"file\": file_path}\n        )\n\n    except Exception as e:\n        return ToolResponse(\n            content=f\"Error processing file: {str(e)}\",\n            metadata={\"error\": \"processing_failed\"}\n        )\n\n# \u274c BAD - Unhandled exceptions crash workflow\ndef tool_read_file(file_path: str) -&gt; ToolResponse:\n    file = open(file_path)  # Raises FileNotFoundError\n    return ToolResponse(content=file.read())\n</code></pre>"},{"location":"guides/multimodal-agents/#4-clean-up-temporary-files","title":"4. Clean Up Temporary Files","text":"<pre><code># \u2705 GOOD - Clean up after processing with ToolResponse\nimport tempfile\nimport shutil\nfrom marsys.environment.tool_response import ToolResponse, ToolResponseContent\n\ndef tool_process_pdf(pdf_path: str) -&gt; ToolResponse:\n    \"\"\"Process PDF with cleanup.\"\"\"\n    temp_dir = Path(tempfile.mkdtemp(prefix=\"pdf_\"))\n\n    try:\n        # Extract pages to temp_dir\n        image_paths = extract_pdf_pages(pdf_path, temp_dir)\n\n        # Build multimodal content\n        content_blocks = [\n            ToolResponseContent(text=f\"Processed PDF: {len(image_paths)} pages\")\n        ]\n        for i, img_path in enumerate(image_paths, 1):\n            content_blocks.append(ToolResponseContent(text=f\"Page {i}:\"))\n            content_blocks.append(ToolResponseContent(image_path=img_path))\n\n        return ToolResponse(\n            content=content_blocks,\n            metadata={\"pages\": len(image_paths)}\n        )\n\n    finally:\n        # Clean up after a delay (allow time for processing)\n        import threading\n        def cleanup():\n            time.sleep(60)  # Wait 60s\n            shutil.rmtree(temp_dir, ignore_errors=True)\n\n        threading.Thread(target=cleanup, daemon=True).start()\n\n# \u274c BAD - Temp files accumulate\ndef tool_process_pdf(pdf_path: str) -&gt; ToolResponse:\n    temp_dir = \"./outputs/pdf_\" + str(uuid.uuid4())\n    extract_pdf_pages(pdf_path, temp_dir)\n    # Never cleaned up!\n</code></pre>"},{"location":"guides/multimodal-agents/#configuration","title":"\u2699\ufe0f Configuration","text":""},{"location":"guides/multimodal-agents/#memory-management","title":"Memory Management","text":"<p>Vision models use more tokens due to image encoding:</p> <pre><code>from marsys.agents import Agent\n\n# Configure memory retention\nvision_agent = Agent(\n    model_config=vision_model_config,\n    name=\"VisionAgent\",\n    goal=\"Analyze images and visual artifacts\",\n    instruction=\"Provide concise, evidence-based analysis of the supplied images.\",\n    memory_retention=\"single_run\",  # Clear after each run\n    max_tokens=4000  # Higher limit for vision\n)\n</code></pre>"},{"location":"guides/multimodal-agents/#cost-optimization","title":"Cost Optimization","text":"<pre><code>from marsys.coordination.config import ExecutionConfig\n\n# Limit steps to control costs\nresult = await Orchestra.run(\n    task=vision_task,\n    topology=topology,\n    max_steps=20,  # Prevent runaway costs\n    execution_config=ExecutionConfig(\n        step_timeout=60.0,  # Timeout per step\n        convergence_timeout=300.0\n    )\n)\n</code></pre>"},{"location":"guides/multimodal-agents/#debugging","title":"\ud83d\udd0d Debugging","text":""},{"location":"guides/multimodal-agents/#check-image-encoding","title":"Check Image Encoding","text":"<pre><code># Verify images are being added to memory\nagent = vision_agent\nmessages = agent.memory.retrieve_all()\n\nfor msg in messages:\n    if hasattr(msg, 'images') and msg.images:\n        print(f\"Message {msg.message_id} has {len(msg.images)} images\")\n</code></pre>"},{"location":"guides/multimodal-agents/#inspect-tool-results","title":"Inspect Tool Results","text":"<pre><code>from marsys.environment.tool_response import ToolResponse\n\n# Check if tool is returning ToolResponse correctly\nresult = tool_read_file(\"test.pdf\")\nprint(f\"Result type: {type(result)}\")\n\nif isinstance(result, ToolResponse):\n    print(f\"Content type: {type(result.content)}\")\n    print(f\"Has images: {result.has_images()}\")\n    if isinstance(result.content, list):\n        text_count = sum(1 for c in result.content if c.type == \"text\")\n        image_count = sum(1 for c in result.content if c.type == \"image\")\n        print(f\"Text blocks: {text_count}, Image blocks: {image_count}\")\n    print(f\"Metadata: {result.metadata}\")\nelse:\n    print(\"Warning: Tool should return ToolResponse for multimodal content\")\n</code></pre>"},{"location":"guides/multimodal-agents/#next-steps","title":"\ud83d\udea6 Next Steps","text":"<ul> <li> <p> Messages</p> <p>Learn about multimodal message structure</p> </li> <li> <p> Tools</p> <p>Create custom multimodal tools</p> </li> <li> <p> Orchestra API</p> <p>Complete API reference for multimodal tasks</p> </li> <li> <p> Examples</p> <p>More multimodal examples</p> </li> </ul> <p>Ready for Vision!</p> <p>You now have everything you need to build powerful multimodal agents that can reason about visual content alongside text.</p>"},{"location":"guides/specialized-tools/","title":"Specialized Tool Classes","text":"<p>MARSYS provides specialized tool classes that encapsulate domain-specific functionality for agents. These tool classes provide structured APIs, error handling, and configuration management.</p>"},{"location":"guides/specialized-tools/#overview","title":"Overview","text":"<p>Tool classes provide:</p> <ul> <li>Structured Output: Consistent Dict/JSON responses for easy parsing</li> <li>Error Handling: Comprehensive error classification and recovery</li> <li>Configuration: Environment variables or explicit parameters</li> <li>Security: Validation, timeouts, output size limits</li> <li>Agent Integration: Methods to generate wrapped functions for agents</li> </ul>"},{"location":"guides/specialized-tools/#available-tool-classes","title":"Available Tool Classes","text":""},{"location":"guides/specialized-tools/#fileoperationtools","title":"FileOperationTools","text":"<p>High-level file system operations with type-aware handling.</p> <p>Capabilities: Read, write, edit (unified diff), search content, find files, list directories</p> <p>Key Features: - Type-aware file reading (Python, JSON, PDF, Markdown, images) - Unified diff editing for precise changes - Ripgrep-based content search - Glob/regex file finding - Run filesystem boundaries and mounts</p> <p>See Run Filesystem for virtual path semantics.</p> <pre><code>from pathlib import Path\nfrom marsys.environment.file_operations import FileOperationTools, FileOperationConfig\nfrom marsys.environment.filesystem import RunFileSystem\n\nfs = RunFileSystem.local(run_root=Path(\"/project\"))\nconfig = FileOperationConfig(run_filesystem=fs)\nfile_tools = FileOperationTools(config)\n\n# Get tools dict for agent\ntools = file_tools.get_tools()\n</code></pre> <p>Use with: FileOperationAgent, or custom agents needing file operations</p> <p>Read Full Documentation \u2192</p>"},{"location":"guides/specialized-tools/#shelltools","title":"ShellTools","text":"<p>Safe shell command execution with validation and specialized helpers.</p> <p>Capabilities: Execute commands, grep, find, sed, awk, tail, head, wc, diff, streaming execution</p> <p>Key Features: - Command validation with blocked dangerous patterns - Whitelisting support for production - Timeout enforcement - Output size limits (prevents memory exhaustion) - Specialized helper methods for common operations</p> <pre><code>from marsys.environment.shell_tools import ShellTools\n\nshell_tools = ShellTools(\n    working_directory=\"/project\",\n    allowed_commands=[\"grep\", \"find\", \"wc\"],  # Whitelist\n    timeout_default=30\n)\n\n# Get tools dict for agent\ntools = shell_tools.get_tools()\n</code></pre> <p>Use with: FileOperationAgent (optional), or custom agents needing shell access</p>"},{"location":"guides/specialized-tools/#codeexecutiontools","title":"CodeExecutionTools","text":"<p>Safe Python and shell execution toolkit for agent workflows.</p> <p>Capabilities: <code>python_execute</code>, <code>shell_execute</code></p> <p>Key Features: - Resource limits (timeout, output size, memory, CPU) - Optional persistent Python sessions (<code>session_persistent_python=True</code>) - Security controls for shell patterns and Python modules - Network disabled by default (<code>allow_network=False</code>) - Virtual output path support via run filesystem (<code>output_virtual_dir</code>, default <code>./outputs</code>)</p> <pre><code>from pathlib import Path\nfrom marsys.environment.code import CodeExecutionConfig, CodeExecutionTools\nfrom marsys.environment.filesystem import RunFileSystem\n\nfs = RunFileSystem.local(run_root=Path(\"./runs/run-20260206\"))\n\nconfig = CodeExecutionConfig(\n    run_filesystem=fs,\n    timeout_default=30,\n    max_memory_mb=1024,\n    allow_network=False,\n    session_persistent_python=True,\n)\n\ncode_tools = CodeExecutionTools(config)\ntools = code_tools.get_tools()  # {\"python_execute\": ..., \"shell_execute\": ...}\n</code></pre> <p>Use with: CodeExecutionAgent, DataAnalysisAgent, or custom agents requiring controlled execution</p>"},{"location":"guides/specialized-tools/#searchtools","title":"SearchTools","text":"<p>Multi-source search across web and scholarly databases.</p> <p>Capabilities: DuckDuckGo, Google, arXiv, Semantic Scholar, PubMed search</p> <p>Key Features: - API key validation at initialization - Only exposes tools with valid credentials - Optional API keys for higher rate limits (Semantic Scholar, PubMed) - Configurable result limits (max 20 per query)</p> <pre><code>from marsys.environment.search_tools import SearchTools\n\nsearch_tools = SearchTools(\n    google_api_key=os.getenv(\"GOOGLE_SEARCH_API_KEY\"),\n    google_cse_id=os.getenv(\"GOOGLE_CSE_ID_GENERIC\")\n)\n\n# Get tools (validates API keys, raises ValueError if missing)\ntry:\n    tools = search_tools.get_tools(tools_subset=[\"duckduckgo\", \"arxiv\"])\nexcept ValueError as e:\n    print(f\"Missing required API keys: {e}\")\n</code></pre> <p>Use with: WebSearchAgent, or custom agents needing search capabilities</p>"},{"location":"guides/specialized-tools/#browseragent","title":"BrowserAgent","text":"<p>Browser automation through the BrowserAgent class with Playwright integration.</p> <p>Capabilities: Navigate, click, type, screenshot, JavaScript execution, element extraction</p> <p>Key Features: - Two modes: PRIMITIVE (content extraction) and ADVANCED (visual interaction) - Vision-based interaction with auto-screenshot - Built-in browser tools - Download discovery via <code>list_downloads</code> (see BrowserAgent docs)</p> <pre><code>from marsys.agents import BrowserAgent\nfrom marsys.models import ModelConfig\n\n# Create BrowserAgent with built-in browser tools\nbrowser_agent = await BrowserAgent.create_safe(\n    model_config=ModelConfig(\n        type=\"api\",\n        provider=\"openrouter\",\n        name=\"anthropic/claude-opus-4.6\",\n        temperature=0.3\n    ),\n    name=\"web_scraper\",\n    mode=\"primitive\",  # or \"advanced\" for visual interaction\n    goal=\"Web automation agent\",\n    instruction=\"You are a web automation specialist. Navigate websites, extract content, and interact with web pages as instructed.\",\n    headless=True\n)\n\n# Browser tools are automatically available to the agent\nresult = await browser_agent.run(\"Navigate to example.com and extract content\")\n\n# Always cleanup\nawait browser_agent.cleanup()\n</code></pre> <p>Note: Browser tools are accessed through BrowserAgent, not a separate BrowserTools class.</p> <p>See BrowserAgent Documentation \u2192</p>"},{"location":"guides/specialized-tools/#comparison","title":"Comparison","text":"Tool Class Operations API Keys Security Features Output Format FileOperationTools 6 file ops None Run filesystem boundaries, path validation Dict with success/content ShellTools 10 commands None Blocked patterns, whitelist, timeout Dict with success/output CodeExecutionTools Python + shell execution None Resource limits, module/pattern blocking, network controls ToolResponse (text + optional images) SearchTools 5 sources None requiredGoogle optional API key validation, rate limits JSON string BrowserAgent built-ins Browser control None Timeout, mode restrictions Dict/JSON depending on operation"},{"location":"guides/specialized-tools/#integration-patterns","title":"Integration Patterns","text":""},{"location":"guides/specialized-tools/#pattern-1-using-with-agents","title":"Pattern 1: Using with Agents","text":"<p>All tool classes provide <code>get_tools()</code> method that returns a dict of wrapped functions:</p> <pre><code>from marsys.agents import Agent\nfrom marsys.environment.code import CodeExecutionTools\nfrom marsys.environment.file_operations import FileOperationTools\nfrom marsys.environment.shell_tools import ShellTools\n\nfile_tools = FileOperationTools()\nshell_tools = ShellTools()\ncode_tools = CodeExecutionTools()\n\n# Combine tools from multiple classes\ntools = {}\ntools.update(file_tools.get_tools())\ntools.update(shell_tools.get_tools())\ntools.update(code_tools.get_tools())\n\nagent = Agent(\n    model_config=config,\n    goal=\"File operations specialist\",\n    instruction=\"...\",\n    tools=tools\n)\n</code></pre>"},{"location":"guides/specialized-tools/#pattern-2-conditional-tool-loading","title":"Pattern 2: Conditional Tool Loading","text":"<p>Enable tools based on configuration:</p> <pre><code>from marsys.environment.code import CodeExecutionConfig, CodeExecutionTools\nfrom marsys.environment.search_tools import SearchTools\nfrom marsys.environment.shell_tools import ShellTools\n\ntools = {}\n\n# Always include file operations\ntools.update(file_tools.get_tools())\n\n# Conditionally add shell tools\nif enable_shell:\n    shell_tools = ShellTools(\n        allowed_commands=allowed_commands if production else None\n    )\n    tools.update(shell_tools.get_tools())\n\n# Conditionally add code execution tools\nif enable_code_execution:\n    code_tools = CodeExecutionTools(\n        CodeExecutionConfig(session_persistent_python=enable_persistent_python)\n    )\n    tools.update(code_tools.get_tools())\n\n# Conditionally add search tools (validates API keys)\nif has_search_api_keys:\n    try:\n        search_tools = SearchTools(google_api_key=api_key, google_cse_id=cse_id)\n        tools.update(search_tools.get_tools(tools_subset=[\"google\", \"arxiv\"]))\n    except ValueError:\n        logger.warning(\"Search tools not available - missing API keys\")\n</code></pre>"},{"location":"guides/specialized-tools/#pattern-3-custom-tool-subset","title":"Pattern 3: Custom Tool Subset","text":"<p>Select specific tools from a class:</p> <pre><code>from marsys.environment.code import CodeExecutionTools\nfrom marsys.environment.search_tools import SearchTools\n\n# FileOperationTools: get only read/write tools\nall_file_tools = file_tools.get_tools()\nread_write_only = {\n    k: v for k, v in all_file_tools.items()\n    if k in [\"read_file\", \"write_file\"]\n}\n\n# SearchTools: get only scholarly sources\nsearch_tools = SearchTools()\nscholarly_only = search_tools.get_tools(tools_subset=[\"arxiv\", \"semantic_scholar\", \"pubmed\"])\n\n# CodeExecutionTools: keep only Python execution\ncode_tools = CodeExecutionTools()\npython_only = {\n    k: v for k, v in code_tools.get_tools().items()\n    if k == \"python_execute\"\n}\n</code></pre>"},{"location":"guides/specialized-tools/#pattern-4-tool-configuration","title":"Pattern 4: Tool Configuration","text":"<p>Configure tool behavior through initialization:</p> <pre><code>from pathlib import Path\nfrom marsys.environment.code import CodeExecutionConfig, CodeExecutionTools\nfrom marsys.environment.file_operations import FileOperationTools, FileOperationConfig\nfrom marsys.environment.filesystem import RunFileSystem\nfrom marsys.environment.search_tools import SearchTools\nfrom marsys.environment.shell_tools import ShellTools\n\n# FileOperationTools: restrict to specific run root\nfs = RunFileSystem.local(run_root=Path(\"/app/data\"))\nconfig = FileOperationConfig(run_filesystem=fs)\nfile_tools = FileOperationTools(config)\n\n# ShellTools: production whitelist\nshell_tools = ShellTools(\n    allowed_commands=[\"grep\", \"find\", \"wc\", \"ls\"],\n    blocked_patterns=[\"rm -rf /\", \"sudo\", \"mv /\"],  # Additional blocks\n    timeout_default=10  # Shorter timeout\n)\n\n# CodeExecutionTools: persistent Python + stricter limits\ncode_tools = CodeExecutionTools(\n    CodeExecutionConfig(\n        timeout_default=20,\n        max_output_bytes=500_000,\n        max_memory_mb=1024,\n        allow_network=False,\n        session_persistent_python=True,\n    )\n)\n\n# SearchTools: explicit API keys (override env vars)\nsearch_tools = SearchTools(\n    google_api_key=\"explicit_key_here\",\n    google_cse_id=\"explicit_cse_id_here\",\n    semantic_scholar_api_key=\"explicit_key_here\"\n)\n</code></pre>"},{"location":"guides/specialized-tools/#creating-custom-tool-classes","title":"Creating Custom Tool Classes","text":"<p>To create your own tool class, follow these patterns:</p>"},{"location":"guides/specialized-tools/#1-class-structure","title":"1. Class Structure","text":"<pre><code>from typing import Dict, Callable, Any\nfrom pathlib import Path\n\nclass MyToolClass:\n    \"\"\"Custom tool class for domain-specific operations.\"\"\"\n\n    def __init__(\n        self,\n        config_param: str,\n        optional_param: Optional[int] = None\n    ):\n        \"\"\"Initialize with configuration.\"\"\"\n        self.config_param = config_param\n        self.optional_param = optional_param or 10\n\n        # Validate configuration\n        self._validate_config()\n\n    def _validate_config(self):\n        \"\"\"Validate configuration at initialization.\"\"\"\n        if not self.config_param:\n            raise ValueError(\"config_param is required\")\n\n    def get_tools(self) -&gt; Dict[str, Callable]:\n        \"\"\"Return wrapped tool functions for agent integration.\"\"\"\n        return {\n            \"my_tool\": self.my_tool_operation,\n            \"another_tool\": self.another_operation\n        }\n\n    async def my_tool_operation(\n        self,\n        param: str,\n        **kwargs\n    ) -&gt; Dict[str, Any]:\n        \"\"\"\n        Tool operation with structured output.\n\n        Returns:\n            Dict with success, result, and optional error fields\n        \"\"\"\n        try:\n            # Perform operation\n            result = self._do_work(param)\n\n            return {\n                \"success\": True,\n                \"result\": result,\n                \"metadata\": {\"param\": param}\n            }\n        except Exception as e:\n            return {\n                \"success\": False,\n                \"error\": str(e),\n                \"error_type\": type(e).__name__\n            }\n</code></pre>"},{"location":"guides/specialized-tools/#2-structured-output","title":"2. Structured Output","text":"<p>Always return Dict with consistent structure:</p> <pre><code># Success response\n{\n    \"success\": True,\n    \"result\": &lt;data&gt;,\n    \"metadata\": {...}  # Optional\n}\n\n# Error response\n{\n    \"success\": False,\n    \"error\": &lt;error_message&gt;,\n    \"error_type\": &lt;exception_type&gt;,\n    \"details\": {...}  # Optional\n}\n</code></pre>"},{"location":"guides/specialized-tools/#3-validation","title":"3. Validation","text":"<p>Validate inputs and configuration:</p> <pre><code>def _validate_params(self, param: str) -&gt; None:\n    \"\"\"Validate parameters before execution.\"\"\"\n    if not param:\n        raise ValueError(\"param cannot be empty\")\n\n    if len(param) &gt; 1000:\n        raise ValueError(\"param too long (max 1000 chars)\")\n</code></pre>"},{"location":"guides/specialized-tools/#4-error-handling","title":"4. Error Handling","text":"<p>Catch and classify errors:</p> <pre><code>try:\n    result = await self._perform_operation(param)\n    return {\"success\": True, \"result\": result}\nexcept FileNotFoundError as e:\n    return {\n        \"success\": False,\n        \"error\": f\"File not found: {e}\",\n        \"error_type\": \"FileNotFoundError\",\n        \"recoverable\": True\n    }\nexcept PermissionError as e:\n    return {\n        \"success\": False,\n        \"error\": f\"Permission denied: {e}\",\n        \"error_type\": \"PermissionError\",\n        \"recoverable\": False\n    }\nexcept Exception as e:\n    return {\n        \"success\": False,\n        \"error\": f\"Unexpected error: {e}\",\n        \"error_type\": type(e).__name__,\n        \"recoverable\": False\n    }\n</code></pre>"},{"location":"guides/specialized-tools/#best-practices","title":"Best Practices","text":""},{"location":"guides/specialized-tools/#1-use-tool-classes-for-consistency","title":"1. Use Tool Classes for Consistency","text":"<p>\u2705 DO: Use tool classes for structured, tested functionality <pre><code>file_tools = FileOperationTools()\ntools = file_tools.get_tools()\n</code></pre></p> <p>\u274c DON'T: Create ad-hoc tool functions without structure <pre><code>def my_read_file(path):\n    with open(path) as f:\n        return f.read()  # No error handling, no structured output\n</code></pre></p>"},{"location":"guides/specialized-tools/#2-validate-configuration-early","title":"2. Validate Configuration Early","text":"<p>Validate at initialization, not at tool invocation:</p> <pre><code>class MyTools:\n    def __init__(self, api_key: str):\n        if not api_key:\n            raise ValueError(\"API key required\")  # Fail fast\n        self.api_key = api_key\n</code></pre>"},{"location":"guides/specialized-tools/#3-provide-helpful-error-messages","title":"3. Provide Helpful Error Messages","text":"<pre><code># \u2705 Helpful\nraise ValueError(\n    \"Google Search requires GOOGLE_SEARCH_API_KEY and GOOGLE_CSE_ID_GENERIC. \"\n    \"Get from: https://developers.google.com/custom-search/v1/overview\"\n)\n\n# \u274c Vague\nraise ValueError(\"Missing API key\")\n</code></pre>"},{"location":"guides/specialized-tools/#4-use-type-hints","title":"4. Use Type Hints","text":"<pre><code>async def search(\n    self,\n    query: str,\n    max_results: int = 10\n) -&gt; Dict[str, Any]:\n    \"\"\"Type hints improve IDE support and clarity.\"\"\"\n    ...\n</code></pre>"},{"location":"guides/specialized-tools/#5-document-return-formats","title":"5. Document Return Formats","text":"<pre><code>async def my_tool(self, param: str) -&gt; Dict[str, Any]:\n    \"\"\"\n    Perform operation.\n\n    Args:\n        param: Input parameter\n\n    Returns:\n        Dict with:\n            - success (bool): Operation success\n            - result (Any): Operation result if successful\n            - error (str): Error message if failed\n    \"\"\"\n</code></pre>"},{"location":"guides/specialized-tools/#environment-variables","title":"Environment Variables","text":"<p>Tool classes commonly use environment variables for API keys:</p> Tool Class Environment Variables Required SearchTools <code>GOOGLE_SEARCH_API_KEY</code> (optional)<code>GOOGLE_CSE_ID_GENERIC</code> (optional)<code>SEMANTIC_SCHOLAR_API_KEY</code> (optional)<code>NCBI_API_KEY</code> (optional) None (DuckDuckGo is free) FileOperationTools None No ShellTools None No CodeExecutionTools None No BrowserAgent built-ins None No <p>Setup guides: - Google Custom Search - Semantic Scholar API</p>"},{"location":"guides/specialized-tools/#related-documentation","title":"Related Documentation","text":"<ul> <li>Built-in Tools Guide - Simple function-based tools</li> <li>Specialized Agents - Agents using these tool classes</li> <li>Custom Tool Development - Creating your own tools</li> <li>Agent Development - Building agents with tools</li> </ul>"},{"location":"guides/specialized-tools/#support","title":"Support","text":"<p>For issues or questions: - GitHub Issues: Report bugs or request features - Examples: Check <code>examples/tools/</code> for usage patterns - Tests: Check <code>tests/environment/</code> for integration examples</p>"},{"location":"guides/steering-and-error-recovery/","title":"Steering and Error Recovery","text":"<p>Intelligent guidance and error recovery system for agent retries in MARSYS.</p>"},{"location":"guides/steering-and-error-recovery/#overview","title":"\ud83c\udfaf Overview","text":"<p>The Steering System provides transient, context-aware prompts to guide agents during error recovery and retries, without polluting agent memory. It works in conjunction with the validation system to deliver targeted, error-specific guidance.</p> <p>Key Features:</p> <ul> <li>\u2705 Error-Aware Prompts: Different messages for different error types</li> <li>\u2705 Transient Guidance: Steering messages don't persist in agent memory</li> <li>\u2705 Automatic Categorization: ValidationProcessor classifies errors at source</li> <li>\u2705 Configurable Modes: Control when guidance is injected</li> <li>\u2705 Statistics Tracking: Monitor steering injection patterns</li> <li>\u2705 User Feedback Integration: Clear error context on human intervention</li> </ul>"},{"location":"guides/steering-and-error-recovery/#architecture","title":"\ud83c\udfd7\ufe0f Architecture","text":"<pre><code>graph TB\n    subgraph \"Error Detection\"\n        Agent[Agent Response] --&gt; VP[ValidationProcessor]\n        VP --&gt; Cat[Categorize Error]\n        Cat --&gt; EC[ErrorContext]\n    end\n\n    subgraph \"Error Context Storage\"\n        EC --&gt; BE[BranchExecutor]\n        BE --&gt; Store[agent_retry_info]\n    end\n\n    subgraph \"Steering Injection\"\n        Store --&gt; SE[StepExecutor]\n        SE --&gt; SM[SteeringManager]\n        SM --&gt; Prompt[Error-Specific Prompt]\n        Prompt --&gt; Agent2[Agent Retry]\n    end\n\n    subgraph \"Success &amp; Cleanup\"\n        Agent2 --&gt; Valid{Valid?}\n        Valid --&gt;|Yes| Clear[Clear Error Context]\n        Valid --&gt;|No| EC\n    end\n\n    style VP fill:#6bcf7f\n    style SM fill:#4fc3f7\n    style Clear fill:#81c784</code></pre>"},{"location":"guides/steering-and-error-recovery/#components","title":"\ud83d\udce6 Components","text":""},{"location":"guides/steering-and-error-recovery/#validationerrorcategory","title":"ValidationErrorCategory","text":"<p>Error categories for targeted steering prompts.</p> <p>Location: <code>src/marsys/coordination/validation/types.py</code></p> <pre><code>from marsys.coordination.validation import ValidationErrorCategory\n\nclass ValidationErrorCategory(Enum):\n    \"\"\"Categories of validation errors for targeted steering.\"\"\"\n    FORMAT_ERROR = \"format_error\"           # JSON structure, parsing errors\n    PERMISSION_ERROR = \"permission_error\"   # Agent permission denied\n    ACTION_ERROR = \"action_error\"           # Invalid action type\n    API_TRANSIENT = \"api_transient\"         # Rate limit, timeout, network\n    API_TERMINAL = \"api_terminal\"           # Auth failure, invalid model\n    TOOL_ERROR = \"tool_error\"               # Tool execution failure\n    UNKNOWN = \"unknown\"\n</code></pre>"},{"location":"guides/steering-and-error-recovery/#steeringmanager","title":"SteeringManager","text":"<p>Centralized steering prompt construction.</p> <p>Location: <code>src/marsys/coordination/steering/manager.py</code></p> <pre><code>from marsys.coordination.steering import SteeringManager, SteeringContext, ErrorContext\n\n# Initialize (automatically done by StepExecutor)\nsteering_manager = SteeringManager()\n\n# Get steering prompt\nprompt = steering_manager.get_steering_prompt(context)\n\n# Get statistics\nstats = steering_manager.get_stats()\n# {\n#     \"total_injections\": 15,\n#     \"by_mode\": {\"error\": 10, \"auto\": 3, \"always\": 2},\n#     \"by_category\": {\n#         \"format_error\": 8,\n#         \"permission_error\": 3,\n#         \"action_error\": 2\n#     }\n# }\n</code></pre>"},{"location":"guides/steering-and-error-recovery/#configuration","title":"\u2699\ufe0f Configuration","text":""},{"location":"guides/steering-and-error-recovery/#steering-modes","title":"Steering Modes","text":"<p>Control when steering guidance is injected:</p> <pre><code>from marsys.coordination import Orchestra\nfrom marsys.coordination.config import ExecutionConfig\n\n# Mode 1: \"error\" - Only inject when error occurred (DEFAULT, minimum interference)\nresult = await Orchestra.run(\n    task=\"Your task\",\n    topology=topology,\n    execution_config=ExecutionConfig(\n        steering_mode=\"error\"  # Only on validation/API errors\n    )\n)\n\n# Mode 2: \"auto\" - Inject on any retry (balanced)\nresult = await Orchestra.run(\n    task=\"Your task\",\n    topology=topology,\n    execution_config=ExecutionConfig(\n        steering_mode=\"auto\"  # On all retries, error-specific when available\n    )\n)\n\n# Mode 3: \"always\" - Inject on every step (maximum guidance)\nresult = await Orchestra.run(\n    task=\"Your task\",\n    topology=topology,\n    execution_config=ExecutionConfig(\n        steering_mode=\"always\"  # Every step, even without errors\n    )\n)\n</code></pre> <p>Mode Comparison:</p> Mode When Injected Use Case Interference Level <code>\"error\"</code> Only when error occurred Production, well-tested agents Minimal <code>\"auto\"</code> Any retry (error or exception) Development, debugging Balanced <code>\"always\"</code> Every agent step Training new agents, testing Maximum"},{"location":"guides/steering-and-error-recovery/#error-categories-prompts","title":"\ud83c\udfaf Error Categories &amp; Prompts","text":""},{"location":"guides/steering-and-error-recovery/#format_error","title":"FORMAT_ERROR","text":"<p>Triggered by: - Empty or None responses - Invalid JSON structure - Missing required fields - Parsing failures</p> <p>Steering Prompt: <pre><code>Your previous response had an incorrect format.\n\nRespond with a single JSON object in a markdown block:\n```json\n{\n  \"thought\": \"your reasoning\",\n  \"next_action\": \"invoke_agent\",\n  \"action_input\": {...}\n}\n</code></pre></p> <p>Available actions: 'invoke_agent', 'final_response', 'tool_calls' <pre><code>**Example:**\n```python\n# Agent returns invalid JSON\n{\"thought\": \"I'll analyze\", next_action: invoke_agent}  # Missing quotes\n\n# ValidationProcessor detects FORMAT_ERROR\n# SteeringManager provides JSON structure reminder\n# Agent retries with correct format\n</code></pre></p>"},{"location":"guides/steering-and-error-recovery/#permission_error","title":"PERMISSION_ERROR","text":"<p>Triggered by: - Invoking unavailable agents - Using <code>final_response</code> without User access - Topology violations</p> <p>Steering Prompt: <pre><code>Permission denied: Agent DataAnalyzer cannot invoke: ReportWriter\n\nYou can only use these actions: invoke_agent\n\nPlease choose a valid action from the list above.\n</code></pre></p> <p>Example: <pre><code># Agent tries to invoke unavailable agent\n{\"next_action\": \"invoke_agent\", \"action_input\": \"ReportWriter\"}\n\n# ValidationProcessor checks topology, finds PERMISSION_ERROR\n# SteeringManager shows available agents\n# Agent retries with valid agent\n</code></pre></p>"},{"location":"guides/steering-and-error-recovery/#action_error","title":"ACTION_ERROR","text":"<p>Triggered by: - Missing <code>next_action</code> field - Invalid action type - Unsupported action</p> <p>Steering Prompt: <pre><code>Invalid action: unknown_action\n\nValid actions for this agent: invoke_agent, tool_calls, final_response\n\nPlease use one of the valid actions.\n</code></pre></p>"},{"location":"guides/steering-and-error-recovery/#api_transient","title":"API_TRANSIENT","text":"<p>Triggered by: - Rate limit errors (429) - Timeout errors - Network errors - Server errors (500-504)</p> <p>Steering Prompt: <pre><code>Previous API call failed: Rate Limit Error. Retrying automatically.\n\nPlease proceed with your intended action.\n</code></pre></p> <p>Note: Minimal guidance for API errors (no format instructions).</p>"},{"location":"guides/steering-and-error-recovery/#api_terminal","title":"API_TERMINAL","text":"<p>Triggered by: - Authentication failures - Invalid API keys - Insufficient credits - Invalid model names</p> <p>Steering Prompt: <pre><code>Critical API error: Authentication failed\n\nThis error typically requires configuration changes. Please check your API settings.\n</code></pre></p>"},{"location":"guides/steering-and-error-recovery/#tool_error","title":"TOOL_ERROR","text":"<p>Triggered by: - Tool execution failures - Invalid tool arguments - Tool not found</p> <p>Steering Prompt: <pre><code>Tool execution failed: Function 'search' not found\n\nTry a different tool or approach.\n</code></pre></p>"},{"location":"guides/steering-and-error-recovery/#lifecycle","title":"\ud83d\udd04 Lifecycle","text":""},{"location":"guides/steering-and-error-recovery/#1-error-detection-categorization","title":"1. Error Detection &amp; Categorization","text":"<pre><code># ValidationProcessor validates agent response\nvalidation = await validator.process_response(\n    raw_response=agent_response,\n    agent=agent,\n    branch=branch,\n    exec_state=exec_state\n)\n\n# ValidationProcessor sets error_category\nif not validation.is_valid:\n    validation.error_category = ValidationErrorCategory.FORMAT_ERROR.value\n    validation.error_message = \"Invalid JSON structure\"\n    validation.retry_suggestion = \"Ensure proper JSON formatting\"\n</code></pre>"},{"location":"guides/steering-and-error-recovery/#2-error-context-storage","title":"2. Error Context Storage","text":"<pre><code># BranchExecutor stores error context for next attempt\nif not validation.is_valid:\n    branch.agent_retry_info[agent_name] = {\n        \"category\": validation.error_category,  # From ValidationProcessor\n        \"error_message\": validation.error_message,\n        \"retry_suggestion\": validation.retry_suggestion,\n        \"retry_count\": retry_count + 1,\n        \"failed_action\": parsed_response.get(\"next_action\")\n    }\n</code></pre>"},{"location":"guides/steering-and-error-recovery/#3-steering-injection","title":"3. Steering Injection","text":"<pre><code># StepExecutor retrieves error context and calls SteeringManager\nerror_context_dict = context.metadata.get(\"agent_error_context\")\n\nif error_context_dict:\n    error_context = ErrorContext(\n        category=ValidationErrorCategory(error_context_dict['category']),\n        error_message=error_context_dict['error_message'],\n        retry_suggestion=error_context_dict.get('retry_suggestion'),\n        retry_count=error_context_dict['retry_count']\n    )\n\n# Build steering context\nsteering_ctx = SteeringContext(\n    name=agent_name,\n    available_actions=[\"invoke_agent\", \"final_response\"],\n    error_context=error_context,\n    is_retry=True,\n    steering_mode=\"error\"\n)\n\n# Get prompt from SteeringManager\nsteering_prompt = steering_manager.get_steering_prompt(steering_ctx)\n\n# Inject as transient message (not persisted to memory)\nrun_context[\"steering_prompt\"] = steering_prompt\n</code></pre>"},{"location":"guides/steering-and-error-recovery/#4-agent-retry","title":"4. Agent Retry","text":"<pre><code># Agent receives steering as last user message\n# Steering is transient - not added to permanent memory\nagent_response = await agent.run_step(request, run_context)\n</code></pre>"},{"location":"guides/steering-and-error-recovery/#5-success-cleanup","title":"5. Success &amp; Cleanup","text":"<pre><code># On successful validation\nif validation.is_valid:\n    # Clear error context\n    if agent_name in branch.agent_retry_info:\n        del branch.agent_retry_info[agent_name]\n    logger.debug(f\"Cleared error context for {agent_name}\")\n\n# On user feedback\nif step_result.metadata.get(\"clear_error_context\"):\n    # User provided feedback - clear ALL error contexts\n    branch.agent_retry_info.clear()\n    logger.info(\"Cleared all error context after user feedback\")\n</code></pre>"},{"location":"guides/steering-and-error-recovery/#logging-statistics","title":"\ud83d\udcca Logging &amp; Statistics","text":""},{"location":"guides/steering-and-error-recovery/#automatic-logging","title":"Automatic Logging","text":"<p>SteeringManager logs all injections at INFO level:</p> <pre><code>INFO - Steering injected for DataAnalyzer (mode=error, category=format_error, retry=1)\nINFO - Steering injected for ReportWriter (mode=auto, category=permission_error, retry=2)\nINFO - Steering injected for Coordinator (mode=always, generic)\nINFO - Cleared all error context after user feedback\n</code></pre>"},{"location":"guides/steering-and-error-recovery/#statistics-collection","title":"Statistics Collection","text":"<pre><code># Access steering statistics\nstats = step_executor.steering_manager.get_stats()\n\nprint(f\"Total injections: {stats['total_injections']}\")\nprint(f\"By mode: {stats['by_mode']}\")\nprint(f\"By category: {stats['by_category']}\")\n\n# Example output:\n# Total injections: 15\n# By mode: {'error': 10, 'auto': 3, 'always': 2}\n# By category: {'format_error': 8, 'permission_error': 3, 'action_error': 2}\n</code></pre>"},{"location":"guides/steering-and-error-recovery/#best-practices","title":"\ud83c\udf93 Best Practices","text":""},{"location":"guides/steering-and-error-recovery/#1-use-error-mode-in-production","title":"1. Use \"error\" Mode in Production","text":"<pre><code># \u2705 GOOD - Minimal interference for production\nconfig = ExecutionConfig(steering_mode=\"error\")\n\n# \u274c BAD - Too much guidance in production\nconfig = ExecutionConfig(steering_mode=\"always\")\n</code></pre>"},{"location":"guides/steering-and-error-recovery/#2-monitor-steering-statistics","title":"2. Monitor Steering Statistics","text":"<pre><code># Track steering patterns to identify problem areas\nstats = steering_manager.get_stats()\n\nif stats['by_category'].get('permission_error', 0) &gt; 5:\n    logger.warning(\"High permission errors - check topology configuration\")\n\nif stats['by_category'].get('format_error', 0) &gt; 10:\n    logger.warning(\"High format errors - improve agent prompts\")\n</code></pre>"},{"location":"guides/steering-and-error-recovery/#3-clear-context-on-user-feedback","title":"3. Clear Context on User Feedback","text":"<pre><code># User feedback supersedes all previous errors\n# System automatically clears error context when user interacts\n\n# UserNodeHandler signals cleanup\nreturn StepResult(\n    name=\"User\",\n    response=user_response,\n    success=True,\n    metadata={\"clear_error_context\": True}  # Automatic cleanup\n)\n</code></pre>"},{"location":"guides/steering-and-error-recovery/#4-provide-specific-error-messages","title":"4. Provide Specific Error Messages","text":"<pre><code># \u2705 GOOD - Specific error for better steering\nif not invocations:\n    return ValidationResult(\n        is_valid=False,\n        error_message=\"Missing invocations for agent invocation\",\n        retry_suggestion=\"You indicated 'invoke_agent' but didn't specify which agent.\",\n        error_category=ValidationErrorCategory.FORMAT_ERROR.value\n    )\n\n# \u274c BAD - Generic error\nreturn ValidationResult(\n    is_valid=False,\n    error_message=\"Invalid response\"\n)\n</code></pre>"},{"location":"guides/steering-and-error-recovery/#advanced-usage","title":"\ud83d\udd27 Advanced Usage","text":""},{"location":"guides/steering-and-error-recovery/#custom-steering-modes","title":"Custom Steering Modes","text":"<p>For advanced use cases, you can extend SteeringManager:</p> <p><pre><code>from marsys.coordination.steering import SteeringManager\n\nclass CustomSteeringManager(SteeringManager):\n    \"\"\"Custom steering with domain-specific logic.\"\"\"\n\n    def _build_error_prompt(self, context):\n        \"\"\"Override to add custom error handling.\"\"\"\n        error = context.error_context\n\n        # Custom logic for your domain\n        if error.category == ValidationErrorCategory.FORMAT_ERROR:\n            if \"medical\" in context.agent_name.lower():\n                return self._medical_format_prompt(context)\n\n        # Fallback to default\n        return super()._build_error_prompt(context)\n\n    def _medical_format_prompt(self, context):\n        \"\"\"Domain-specific prompt for medical agents.\"\"\"\n        return \"\"\"\nYour previous response had an incorrect medical report format.\n\nPlease use this structure:\n```json\n{\n  \"diagnosis\": \"...\",\n  \"treatment\": \"...\",\n  \"confidence\": 0.95\n}\n</code></pre> \"\"\" <pre><code>### Conditional Steering\n\n```python\n# Apply different steering modes based on agent type\nif agent.name.startswith(\"Experimental_\"):\n    steering_mode = \"always\"  # More guidance for experimental agents\nelif agent.name in critical_agents:\n    steering_mode = \"error\"  # Minimal interference for critical path\nelse:\n    steering_mode = \"auto\"  # Balanced for others\n\nconfig = ExecutionConfig(steering_mode=steering_mode)\n</code></pre></p>"},{"location":"guides/steering-and-error-recovery/#troubleshooting","title":"\ud83d\udea6 Troubleshooting","text":""},{"location":"guides/steering-and-error-recovery/#issue-too-much-steering","title":"Issue: Too Much Steering","text":"<p>Symptom: Agents receive guidance on every step</p> <p>Solution: <pre><code># Change mode from \"always\" to \"error\"\nconfig = ExecutionConfig(steering_mode=\"error\")\n</code></pre></p>"},{"location":"guides/steering-and-error-recovery/#issue-not-enough-guidance","title":"Issue: Not Enough Guidance","text":"<p>Symptom: Agents fail repeatedly without help</p> <p>Solution: <pre><code># Use \"auto\" mode for more guidance\nconfig = ExecutionConfig(steering_mode=\"auto\")\n\n# Or check if errors are being categorized\nlogger.setLevel(logging.DEBUG)  # See steering injection logs\n</code></pre></p>"},{"location":"guides/steering-and-error-recovery/#issue-stale-error-context","title":"Issue: Stale Error Context","text":"<p>Symptom: Old error messages persist</p> <p>Solution: <pre><code># Error context should auto-clear on success\n# If not, check:\n# 1. Is validation.is_valid being set correctly?\n# 2. Is error_context being cleared in BranchExecutor?\n# 3. Are you using User node feedback to clear context?\n\n# Manual reset (for debugging only)\nbranch.agent_retry_info.clear()\n</code></pre></p>"},{"location":"guides/steering-and-error-recovery/#issue-wrong-error-category","title":"Issue: Wrong Error Category","text":"<p>Symptom: Steering provides incorrect guidance</p> <p>Solution: <pre><code># ValidationProcessor should set error_category\n# Ensure error messages are specific:\n\n# \u2705 GOOD - Clear permission error\n\"Agent DataAnalyzer cannot invoke: ReportWriter\"\n\n# \u274c BAD - Ambiguous error\n\"Invalid response\"\n\n# Check categorization logic in ValidationProcessor\n</code></pre></p>"},{"location":"guides/steering-and-error-recovery/#api-reference","title":"\ud83d\udccb API Reference","text":""},{"location":"guides/steering-and-error-recovery/#steeringcontext","title":"SteeringContext","text":"<pre><code>@dataclass\nclass SteeringContext:\n    agent_name: str\n    available_actions: List[str]\n    error_context: Optional[ErrorContext] = None\n    is_retry: bool = False\n    steering_mode: str = \"error\"\n</code></pre>"},{"location":"guides/steering-and-error-recovery/#errorcontext","title":"ErrorContext","text":"<pre><code>@dataclass\nclass ErrorContext:\n    category: ValidationErrorCategory\n    error_message: str\n    retry_suggestion: Optional[str] = None\n    retry_count: int = 0\n    classification: Optional[str] = None  # For API errors\n    failed_action: Optional[str] = None\n</code></pre>"},{"location":"guides/steering-and-error-recovery/#steeringmanager-methods","title":"SteeringManager Methods","text":"<pre><code>class SteeringManager:\n    def get_steering_prompt(self, context: SteeringContext) -&gt; Optional[str]:\n        \"\"\"Get steering prompt for given context.\"\"\"\n\n    def get_stats(self) -&gt; dict:\n        \"\"\"Get steering injection statistics.\"\"\"\n\n    def _build_error_prompt(self, context: SteeringContext) -&gt; str:\n        \"\"\"Build error-category-specific prompt.\"\"\"\n\n    def _build_generic_prompt(self, context: SteeringContext) -&gt; str:\n        \"\"\"Build generic steering prompt.\"\"\"\n</code></pre>"},{"location":"guides/steering-and-error-recovery/#next-steps","title":"\ud83d\ude80 Next Steps","text":"<ul> <li> <p> Error Handling</p> <p>Comprehensive error handling system</p> </li> <li> <p> Configuration</p> <p>Complete configuration reference</p> </li> <li> <p> Validation</p> <p>Response validation system</p> </li> <li> <p> User Recovery</p> <p>Human-in-the-loop error handling</p> </li> </ul> <p>Steering System Ready!</p> <p>You now understand MARSYS steering and error recovery. Use error-specific guidance to improve agent reliability and reduce retry failures.</p>"},{"location":"legal/LICENSING/","title":"Licensing Guide for MARSYS","text":"<p>This document provides comprehensive information about MARSYS licensing, copyright ownership, and contributor requirements.</p>"},{"location":"legal/LICENSING/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Overview</li> <li>Apache License 2.0</li> <li>Copyright Ownership</li> <li>Contributor License Agreement (CLA)</li> <li>FAQ for Contributors</li> <li>FAQ for Users</li> <li>Future Licensing Plans</li> </ol>"},{"location":"legal/LICENSING/#overview","title":"Overview","text":"<p>MARSYS (Multi-Agent Reasoning Systems) is open-source software licensed under the Apache License 2.0.</p>"},{"location":"legal/LICENSING/#quick-facts","title":"Quick Facts","text":"<ul> <li>License: Apache License 2.0</li> <li>Copyright Holder: Marsys Project (original author: rezaho)</li> <li>Contributor Agreement: CLA required (automatic via CLA Assistant)</li> <li>Cost: Free for all use cases</li> <li>Commercial Use: Fully permitted</li> <li>Source Code: Openly available on GitHub</li> </ul>"},{"location":"legal/LICENSING/#apache-license-20","title":"Apache License 2.0","text":""},{"location":"legal/LICENSING/#what-is-apache-20","title":"What is Apache 2.0?","text":"<p>The Apache License 2.0 is one of the most popular permissive open-source licenses. It allows you to:</p> <p>\u2705 Use MARSYS for any purpose (personal, commercial, production) \u2705 Modify the source code to fit your needs \u2705 Distribute MARSYS and your modifications \u2705 Sublicense your modifications (can use different license for your additions) \u2705 Include in proprietary/closed-source projects</p>"},{"location":"legal/LICENSING/#requirements","title":"Requirements","text":"<p>When using MARSYS, you must:</p> <p>\ud83d\udccb Include the License - Include a copy of the Apache 2.0 license \ud83d\udccb Preserve Copyright Notices - Keep existing copyright notices intact \ud83d\udccb State Modifications - Document significant changes you make \ud83d\udccb Include NOTICE file - If one exists (not currently applicable)</p>"},{"location":"legal/LICENSING/#patent-grant","title":"Patent Grant","text":"<p>Apache 2.0 includes an explicit patent grant: - Contributors grant you a license to any patents covering their contributions - Protection against patent litigation - If you sue over patents, your license terminates</p>"},{"location":"legal/LICENSING/#full-license-text","title":"Full License Text","text":"<p>Read the full Apache 2.0 license: LICENSE</p>"},{"location":"legal/LICENSING/#copyright-ownership","title":"Copyright Ownership","text":""},{"location":"legal/LICENSING/#who-owns-marsys","title":"Who Owns MARSYS?","text":"<p>Copyright Holder: Marsys Project Original Author: rezaho (reza@marsys.ai)</p> <p>The copyright is held solely by the original author. This is clearly documented in: - LICENSE - Apache 2.0 with copyright notice - COPYRIGHT - Explicit ownership statement - AUTHORS - Attribution with ownership clarification</p>"},{"location":"legal/LICENSING/#what-about-contributors","title":"What About Contributors?","text":"<p>Contributors: - \u2705 Get attribution in the AUTHORS file - \u2705 Retain ownership of their original contribution - \u2705 Can use their code elsewhere under Apache 2.0 - \u274c Do NOT acquire copyright ownership of MARSYS - \u274c Do NOT gain the right to relicense the project</p> <p>See COPYRIGHT for detailed information.</p>"},{"location":"legal/LICENSING/#contributor-license-agreement-cla","title":"Contributor License Agreement (CLA)","text":""},{"location":"legal/LICENSING/#what-is-a-cla","title":"What is a CLA?","text":"<p>A Contributor License Agreement (CLA) is a legal document that contributors sign to grant specific rights to the project maintainer.</p>"},{"location":"legal/LICENSING/#why-marsys-requires-a-cla","title":"Why MARSYS Requires a CLA","text":"<p>The CLA serves several purposes:</p> <ol> <li>Legal Protection: Ensures contributors have the right to contribute their code</li> <li>Patent Grant: Contributors grant a patent license for their contributions</li> <li>Sublicensing Rights: Allows the project to offer different licenses if needed</li> <li>Licensing Flexibility: Allows dual-licensing in the future while keeping the core open-source</li> </ol>"},{"location":"legal/LICENSING/#what-rights-does-the-cla-grant","title":"What Rights Does the CLA Grant?","text":"<p>When you sign the CLA, you grant:</p>"},{"location":"legal/LICENSING/#copyright-license","title":"Copyright License","text":"<ul> <li>Perpetual, worldwide, non-exclusive license</li> <li>Permission to use, modify, reproduce, distribute</li> <li>Sublicensing rights (critical for dual-licensing)</li> </ul>"},{"location":"legal/LICENSING/#patent-license","title":"Patent License","text":"<ul> <li>Perpetual, worldwide, non-exclusive patent license</li> <li>Covers patents you own that are infringed by your contribution</li> <li>Irrevocable (unless we sue you for patent infringement)</li> </ul>"},{"location":"legal/LICENSING/#assignment-rights","title":"Assignment Rights","text":"<ul> <li>Rights can be assigned to \"successors and assigns\"</li> <li>No additional signature required from you</li> </ul>"},{"location":"legal/LICENSING/#what-rights-do-you-keep","title":"What Rights Do You Keep?","text":"<p>You retain: - \u2705 Ownership of your original contribution - \u2705 Right to use your code in other projects - \u2705 Attribution in the AUTHORS file - \u2705 Ability to contribute the same code to other projects</p>"},{"location":"legal/LICENSING/#how-to-sign-the-cla","title":"How to Sign the CLA","text":"<p>It's automatic! No paperwork, no email exchanges.</p> <ol> <li>Open a pull request to MARSYS</li> <li>CLA Assistant bot comments with a link</li> <li>Click the link and review the CLA</li> <li>Click \"I Agree\"</li> <li>Your PR is automatically unblocked</li> </ol> <p>One-time process - covers all future contributions.</p>"},{"location":"legal/LICENSING/#cla-documents","title":"CLA Documents","text":"<ul> <li>Full CLA Text: docs/CLA.md</li> <li>Setup Guide: docs/CLA_SETUP_GUIDE.md</li> </ul>"},{"location":"legal/LICENSING/#faq-for-contributors","title":"FAQ for Contributors","text":""},{"location":"legal/LICENSING/#q-do-i-lose-ownership-of-my-code","title":"Q: Do I lose ownership of my code?","text":"<p>No. You retain ownership of your contribution. You grant a license, not a transfer of ownership.</p>"},{"location":"legal/LICENSING/#q-can-i-still-use-my-code-elsewhere","title":"Q: Can I still use my code elsewhere?","text":"<p>Yes. You can use your contribution in other projects, including commercial ones.</p>"},{"location":"legal/LICENSING/#q-why-does-the-project-need-sublicensing-rights","title":"Q: Why does the project need sublicensing rights?","text":"<p>Sublicensing rights enable: - Future dual-licensing (free open-source + paid commercial) if needed - Sustainable development and flexibility for the project</p>"},{"location":"legal/LICENSING/#q-what-if-i-dont-want-to-sign-the-cla","title":"Q: What if I don't want to sign the CLA?","text":"<p>Your contribution cannot be merged without signing the CLA. However: - You can still fork the project - You can use MARSYS under Apache 2.0 - You can submit bug reports and suggestions</p>"},{"location":"legal/LICENSING/#q-can-the-cla-be-changed-later","title":"Q: Can the CLA be changed later?","text":"<p>Existing CLAs remain valid. New contributors would sign an updated CLA if changes are made.</p>"},{"location":"legal/LICENSING/#q-do-i-need-a-lawyer-to-review-the-cla","title":"Q: Do I need a lawyer to review the CLA?","text":"<p>The CLA is based on widely-used templates (similar to Google's and Apache Foundation's). However, if you have concerns, consult with a lawyer.</p>"},{"location":"legal/LICENSING/#q-what-if-im-contributing-on-behalf-of-my-employer","title":"Q: What if I'm contributing on behalf of my employer?","text":"<p>If your employer owns the IP to your work, they need to sign a Corporate CLA. Contact reza@marsys.ai for the corporate CLA template.</p>"},{"location":"legal/LICENSING/#faq-for-users","title":"FAQ for Users","text":""},{"location":"legal/LICENSING/#q-can-i-use-marsys-commercially","title":"Q: Can I use MARSYS commercially?","text":"<p>Yes. Apache 2.0 fully permits commercial use at no cost.</p>"},{"location":"legal/LICENSING/#q-do-i-need-to-open-source-my-project-if-i-use-marsys","title":"Q: Do I need to open-source my project if I use MARSYS?","text":"<p>No. Apache 2.0 is permissive, not copyleft. You can use MARSYS in proprietary projects.</p>"},{"location":"legal/LICENSING/#q-do-i-need-to-pay-for-marsys","title":"Q: Do I need to pay for MARSYS?","text":"<p>No. MARSYS is free for all use cases.</p>"},{"location":"legal/LICENSING/#q-can-i-modify-marsys","title":"Q: Can I modify MARSYS?","text":"<p>Yes. You can modify MARSYS and distribute your modifications.</p>"},{"location":"legal/LICENSING/#q-do-i-need-to-include-the-apache-20-license","title":"Q: Do I need to include the Apache 2.0 license?","text":"<p>Yes. Include a copy of the license and preserve copyright notices.</p>"},{"location":"legal/LICENSING/#q-can-i-sell-products-built-with-marsys","title":"Q: Can I sell products built with MARSYS?","text":"<p>Yes. You can build and sell commercial products using MARSYS.</p>"},{"location":"legal/LICENSING/#q-what-are-my-obligations","title":"Q: What are my obligations?","text":"<ul> <li>Include the Apache 2.0 license</li> <li>Preserve copyright notices</li> <li>Document significant modifications (recommended)</li> </ul>"},{"location":"legal/LICENSING/#future-plans","title":"Future Plans","text":"<p>MARSYS may explore dual-licensing options in the future to support sustainable development while keeping the core framework free and open-source under Apache 2.0.</p>"},{"location":"legal/LICENSING/#contact","title":"Contact","text":"<p>For licensing questions: - Email: reza@marsys.ai - GitHub Discussions: Ask questions - GitHub Issues: Report licensing issues</p>"},{"location":"legal/LICENSING/#related-documents","title":"Related Documents","text":"<ul> <li>LICENSE - Full Apache 2.0 license text</li> <li>COPYRIGHT - Copyright ownership details</li> <li>AUTHORS - Contributor attribution</li> <li>CONTRIBUTING.md - Contribution guidelines</li> <li>CLA.md - Full Contributor License Agreement</li> <li>CLA_SETUP_GUIDE.md - CLA Assistant setup</li> </ul> <p>Last Updated: January 2025 License Version: Apache License 2.0 Copyright: 2025 Marsys Project</p>"},{"location":"project/overview/","title":"Project","text":"<p>Learn about the MARSYS framework project, roadmap, and community.</p>"},{"location":"project/overview/#mission-vision","title":"\ud83c\udfaf Mission &amp; Vision","text":""},{"location":"project/overview/#mission","title":"Mission","text":"<p>Democratize advanced multi-agent AI systems by providing a comprehensive framework that enables developers to build, deploy, and scale collaborative AI agents with ease.</p>"},{"location":"project/overview/#vision","title":"Vision","text":"<p>Become the leading open-source framework for building intelligent, collaborative multi-agent systems that enhance human productivity and solve complex real-world problems.</p>"},{"location":"project/overview/#core-values","title":"Core Values","text":"<ul> <li>\ud83c\udf1f Accessibility: Multi-agent AI for developers of all skill levels</li> <li>\ud83d\udd12 Reliability: Reliable, robust solutions</li> <li>\ud83c\udfa8 Flexibility: Support diverse use cases and deployments</li> <li>\ud83d\ude80 Innovation: Push boundaries of multi-agent systems</li> <li>\ud83e\udd1d Community: Foster inclusive, vibrant community</li> </ul>"},{"location":"project/overview/#project-status","title":"\ud83d\udcca Project Status","text":""},{"location":"project/overview/#current-version-01-beta","title":"Current Version: 0.1-beta","text":"<ul> <li> <p> Core Features</p> <p>\u2705 Agent framework with pure execution model \u2705 Multi-model support (OpenAI, Anthropic, Google, etc.) \u2705 Advanced memory management \u2705 Browser automation capabilities \u2705 Topology-driven coordination \u2705 State persistence &amp; checkpointing \u2705 Testing framework</p> </li> <li> <p> In Progress</p> <p>\ud83d\udea7 Streaming response support \ud83d\udea7 Distributed execution \ud83d\udea7 Advanced monitoring dashboard \ud83d\udea7 Visual workflow designer</p> </li> <li> <p> Planned</p> <p>\ud83d\udccb Real-time collaboration \ud83d\udccb Mobile SDK \ud83d\udccb Cloud-native deployment \ud83d\udccb Auto-scaling agents \ud83d\udccb ML-based optimization</p> </li> <li> <p> Achievements</p> <p>\ud83c\udfc6 Active development \ud83c\udfc6 Growing community \ud83c\udfc6 Comprehensive documentation \ud83c\udfc6 Multiple language models</p> </li> </ul>"},{"location":"project/overview/#roadmap","title":"\ud83d\uddfa\ufe0f Roadmap","text":""},{"location":"project/overview/#q4-2025-performance-scale","title":"Q4 2025 - Performance &amp; Scale","text":"<ul> <li> Performance optimization suite</li> <li> Distributed agent execution</li> <li> Advanced caching strategies</li> <li> Resource pooling improvements</li> <li> Benchmark suite</li> </ul>"},{"location":"project/overview/#q1-2026-developer-experience","title":"Q1 2026 - Developer Experience","text":"<ul> <li> Visual workflow designer</li> <li> Interactive debugging tools</li> <li> Code generation assistant</li> <li> Migration tools</li> <li> Plugin system</li> </ul>"},{"location":"project/overview/#statistics","title":"\ud83d\udcc8 Statistics","text":""},{"location":"project/overview/#framework-metrics","title":"Framework Metrics","text":"<ul> <li>Lines of Code: 50,000+</li> <li>Test Coverage: 95%+</li> <li>Dependencies: &lt; 20 core</li> <li>Response Time: &lt; 100ms overhead</li> <li>Memory Usage: &lt; 200MB baseline</li> </ul>"},{"location":"project/overview/#community-metrics","title":"Community Metrics","text":"<ul> <li>GitHub Stars: 2,500+</li> <li>Contributors: 50+</li> <li>Discord Members: 1,000+</li> <li>Weekly Downloads: 10,000+</li> <li>Production Deployments: 100+</li> </ul>"},{"location":"project/overview/#architecture-highlights","title":"\ud83c\udfd7\ufe0f Architecture Highlights","text":"<pre><code>graph TB\n    subgraph \"MARSYS Architecture\"\n        O[Orchestra&lt;br/&gt;Coordination Layer]\n        T[Topology&lt;br/&gt;Graph System]\n        E[Execution&lt;br/&gt;Engine]\n        A[Agents&lt;br/&gt;Pure Functions]\n        M[Memory&lt;br/&gt;Management]\n        S[State&lt;br/&gt;Persistence]\n    end\n\n    O --&gt; T\n    O --&gt; E\n    E --&gt; A\n    A --&gt; M\n    E --&gt; S\n\n    style O fill:#4fc3f7\n    style T fill:#29b6f6\n    style A fill:#e1f5fe</code></pre>"},{"location":"project/overview/#key-innovations","title":"Key Innovations","text":"<ul> <li>Pure Agent Execution: Side-effect free agent logic</li> <li>Dynamic Branching: Runtime parallel execution</li> <li>Topology-Driven Routing: Graph-based coordination</li> <li>Centralized Validation: Single point for response processing</li> <li>Branch Isolation: True parallel execution with isolation</li> </ul>"},{"location":"project/overview/#team-contributors","title":"\ud83d\udc65 Team &amp; Contributors","text":""},{"location":"project/overview/#core-team","title":"Core Team","text":"<ul> <li>Project Lead: Framework architecture and vision</li> <li>Tech Leads: Core system development</li> <li>Community Managers: Community engagement</li> <li>Documentation Team: Guides and tutorials</li> </ul>"},{"location":"project/overview/#contributors","title":"Contributors","text":"<p>We welcome contributions from everyone! See our Contributing Guide to get started.</p>"},{"location":"project/overview/#special-thanks","title":"Special Thanks","text":"<ul> <li>OpenAI, Anthropic, Google for AI models</li> <li>The open-source community</li> <li>Early adopters and testers</li> <li>Documentation contributors</li> </ul>"},{"location":"project/overview/#success-stories","title":"\ud83c\udf1f Success Stories","text":"<p>Coming soon - Share your MARSYS success story with us!</p>"},{"location":"project/overview/#license","title":"\ud83d\udcdc License","text":"<p>MARSYS is released under the Apache License 2.0.</p> <p>This permissive license allows you to: - \u2705 Use MARSYS for commercial purposes - \u2705 Modify and distribute the code - \u2705 Use MARSYS in proprietary applications - \u2705 Patent use protection</p> <p>See LICENSE for full details.</p>"},{"location":"project/overview/#partnerships","title":"\ud83e\udd1d Partnerships","text":""},{"location":"project/overview/#technology-partners","title":"Technology Partners","text":"<ul> <li>Cloud Providers: AWS, GCP, Azure integration</li> <li>Model Providers: OpenAI, Anthropic, Google partnerships</li> <li>Tool Ecosystem: Playwright, LangChain compatibility</li> </ul>"},{"location":"project/overview/#academic-partners","title":"Academic Partners","text":"<ul> <li>Research collaborations with universities</li> <li>Student projects and thesis work</li> <li>Academic licensing program</li> </ul>"},{"location":"project/overview/#news-updates","title":"\ud83d\udcf0 News &amp; Updates","text":""},{"location":"project/overview/#recent-releases","title":"Recent Releases","text":"<ul> <li>v1.0.0 - Production release with state management</li> <li>v0.9.0 - Browser automation support</li> <li>v0.8.0 - Topology patterns library</li> <li>v0.7.0 - Memory management system</li> </ul>"},{"location":"project/overview/#upcoming-events","title":"Upcoming Events","text":"<ul> <li>MARSYS Conference 2025 - Annual user conference</li> <li>Workshop Series - Monthly online workshops</li> <li>Hackathon - Build with MARSYS competition</li> </ul>"},{"location":"project/overview/#learning-resources","title":"\ud83c\udf93 Learning Resources","text":""},{"location":"project/overview/#official-resources","title":"Official Resources","text":"<ul> <li>Documentation</li> <li>Tutorials</li> <li>API Reference</li> <li>Examples</li> </ul>"},{"location":"project/overview/#community-resources","title":"Community Resources","text":"<ul> <li>YouTube Channel</li> <li>Blog</li> <li>Discord Server</li> <li>Stack Overflow Tag</li> </ul>"},{"location":"project/overview/#comparison","title":"\ud83d\udcca Comparison","text":""},{"location":"project/overview/#marsys-vs-alternatives","title":"MARSYS vs Alternatives","text":"Feature MARSYS LangChain AutoGen Custom Multi-Agent \u2705 Native \u26a0\ufe0f Limited \u2705 Yes \u274c DIY Production Ready \u26a0\ufe0f Beta \u26a0\ufe0f Partial \u26a0\ufe0f Beta \u274c Varies State Management \u2705 Built-in \u274c External \u26a0\ufe0f Basic \u274c DIY Browser Automation \u2705 Native \u274c No \u274c No \u274c DIY Topology System \u2705 Advanced \u274c No \u26a0\ufe0f Basic \u274c DIY Learning Agents \u2705 Yes \u26a0\ufe0f Limited \u274c No \u274c DIY"},{"location":"project/overview/#next-steps","title":"\ud83d\udea6 Next Steps","text":"<ul> <li> <p> GitHub</p> <p>Star the repository</p> </li> <li> <p>:material-discord:{ .lg .middle } Join Discord</p> <p>Connect with community</p> </li> <li> <p> Read Docs</p> <p>Learn the framework</p> </li> <li> <p> Contribute</p> <p>Help build MARSYS</p> </li> </ul> <p>Stay Updated</p> <p>Subscribe to our newsletter for updates, tutorials, and community highlights.</p> <p>Join Us!</p> <p>MARSYS is more than a framework - it's a community building the future of multi-agent AI. Join us on this exciting journey!</p>"},{"location":"use-cases/","title":"Use Cases","text":"<p>Real-world applications and practical examples of MARSYS in action.</p>"},{"location":"use-cases/#application-categories","title":"\ud83c\udfaf Application Categories","text":"<ul> <li> <p> Research &amp; Analysis</p> <p>Multi-agent research systems</p> <ul> <li>Academic research automation</li> <li>Market intelligence gathering</li> <li>Competitive analysis</li> <li>Technical documentation</li> </ul> </li> <li> <p> Business Automation</p> <p>Enterprise workflow automation</p> <ul> <li>Customer service systems</li> <li>Sales pipeline automation</li> <li>HR screening processes</li> <li>Document processing</li> </ul> </li> <li> <p> Development &amp; DevOps</p> <p>Software development assistance</p> <ul> <li>Code review automation</li> <li>Test generation</li> <li>Documentation writing</li> <li>CI/CD optimization</li> </ul> </li> <li> <p> Data &amp; Analytics</p> <p>Data processing pipelines</p> <ul> <li>ETL workflows</li> <li>Report generation</li> <li>Anomaly detection</li> <li>Predictive analytics</li> </ul> </li> </ul>"},{"location":"use-cases/#featured-use-cases","title":"\ud83d\udcca Featured Use Cases","text":""},{"location":"use-cases/#1-ai-research-assistant","title":"1. AI Research Assistant","text":"<p>Multi-agent system for comprehensive research and analysis.</p> <pre><code>from marsys.coordination import Orchestra\nfrom marsys.coordination.topology.patterns import PatternConfig\n\n# Research team with specialized agents\ntopology = PatternConfig.hub_and_spoke(\n    hub=\"ResearchCoordinator\",\n    spokes=[\"WebSearcher\", \"PaperAnalyzer\", \"FactChecker\", \"ReportWriter\"],\n    parallel_spokes=True\n)\n\nresult = await Orchestra.run(\n    task=\"Research latest advances in quantum computing\",\n    topology=topology\n)\n</code></pre> <p>Key Features: - Parallel information gathering - Source validation - Comprehensive report generation - Citation management</p> <p>View Full Implementation \u2192</p>"},{"location":"use-cases/#2-customer-support-platform","title":"2. Customer Support Platform","text":"<p>Intelligent multi-tier support system with escalation.</p> <pre><code>topology = {\n    \"agents\": [\"User\", \"L1Support\", \"L2Support\", \"TicketManager\"],\n    \"flows\": [\n        \"User &lt;-&gt; L1Support\",\n        \"L1Support -&gt; L2Support\",  # Escalation\n        \"L2Support -&gt; TicketManager\",\n        \"TicketManager -&gt; User\"\n    ]\n}\n\nresult = await Orchestra.run(\n    task=\"Customer issue: Cannot login to account\",\n    topology=topology\n)\n</code></pre> <p>Key Features: - Automatic issue categorization - Smart escalation routing - Knowledge base integration - Ticket tracking</p> <p>View Full Implementation \u2192</p>"},{"location":"use-cases/#3-code-review-assistant","title":"3. Code Review Assistant","text":"<p>Automated code review with multiple specialized reviewers.</p> <pre><code># Specialized code reviewers\ntopology = PatternConfig.pipeline(\n    stages=[\n        {\"name\": \"syntax\", \"agents\": [\"SyntaxChecker\"]},\n        {\"name\": \"security\", \"agents\": [\"SecurityAuditor\"]},\n        {\"name\": \"performance\", \"agents\": [\"PerformanceAnalyzer\"]},\n        {\"name\": \"style\", \"agents\": [\"StyleReviewer\"]},\n        {\"name\": \"summary\", \"agents\": [\"ReviewSummarizer\"]}\n    ],\n    parallel_within_stage=False\n)\n\nresult = await Orchestra.run(\n    task=f\"Review this code:\\n{code_content}\",\n    topology=topology\n)\n</code></pre> <p>Key Features: - Multi-aspect code analysis - Security vulnerability detection - Performance optimization suggestions - Style guide compliance</p> <p>View Full Implementation \u2192</p>"},{"location":"use-cases/#4-financial-analysis-system","title":"4. Financial Analysis System","text":"<p>Real-time market analysis and reporting.</p> <pre><code>from marsys.agents import Agent, AgentPool\nfrom marsys.models import ModelConfig\n\n# Create model config\nconfig = ModelConfig(\n    type=\"api\",\n    provider=\"openrouter\",\n    name=\"anthropic/claude-opus-4.6\",\n    temperature=0.3\n)\n\n# Create pool for parallel analysis\nanalyst_pool = await AgentPool.create_async(\n    agent_class=Agent,\n    num_instances=5,\n    model_config=config,\n    goal=\"Analyze financial markets and trends\",\n    instruction=\"You are a financial analyst. Analyze market data and provide insights.\",\n    name=\"FinancialAnalyst\"\n)\n\ntopology = {\n    \"agents\": [\"MarketMonitor\", \"AnalystPool\", \"RiskAssessor\", \"ReportGenerator\"],\n    \"flows\": [\n        \"MarketMonitor -&gt; AnalystPool\",\n        \"AnalystPool -&gt; RiskAssessor\",\n        \"RiskAssessor -&gt; ReportGenerator\"\n    ]\n}\n</code></pre> <p>Key Features: - Real-time market data processing - Parallel sector analysis - Risk assessment - Automated report generation</p> <p>View Full Implementation \u2192</p>"},{"location":"use-cases/#5-content-generation-pipeline","title":"5. Content Generation Pipeline","text":"<p>Multi-stage content creation and optimization.</p> <pre><code>topology = PatternConfig.pipeline(\n    stages=[\n        {\"name\": \"research\", \"agents\": [\"TopicResearcher\"]},\n        {\"name\": \"outline\", \"agents\": [\"OutlineCreator\"]},\n        {\"name\": \"writing\", \"agents\": [\"ContentWriter\", \"TechnicalWriter\"]},\n        {\"name\": \"editing\", \"agents\": [\"Editor\", \"FactChecker\"]},\n        {\"name\": \"seo\", \"agents\": [\"SEOOptimizer\"]},\n        {\"name\": \"publishing\", \"agents\": [\"Publisher\"]}\n    ],\n    parallel_within_stage=True\n)\n</code></pre> <p>Key Features: - Research-backed content - Multiple writing styles - Fact verification - SEO optimization</p> <p>View Full Implementation \u2192</p>"},{"location":"use-cases/#industry-applications","title":"\ud83c\udfe2 Industry Applications","text":""},{"location":"use-cases/#healthcare","title":"Healthcare","text":"<ul> <li>Clinical Decision Support: Multi-agent diagnosis assistance</li> <li>Patient Triage: Automated symptom assessment and routing</li> <li>Medical Research: Literature review and analysis</li> <li>Drug Discovery: Compound analysis and prediction</li> </ul>"},{"location":"use-cases/#finance","title":"Finance","text":"<ul> <li>Trading Systems: Market analysis and execution</li> <li>Risk Management: Portfolio assessment and optimization</li> <li>Fraud Detection: Transaction monitoring and alerting</li> <li>Compliance: Regulatory report generation</li> </ul>"},{"location":"use-cases/#education","title":"Education","text":"<ul> <li>Personalized Tutoring: Adaptive learning systems</li> <li>Curriculum Development: Content generation and organization</li> <li>Assessment Creation: Test and quiz generation</li> <li>Student Support: 24/7 assistance and guidance</li> </ul>"},{"location":"use-cases/#legal","title":"Legal","text":"<ul> <li>Contract Analysis: Review and risk assessment</li> <li>Legal Research: Case law and precedent search</li> <li>Document Generation: Automated drafting</li> <li>Compliance Monitoring: Regulatory tracking</li> </ul>"},{"location":"use-cases/#e-commerce","title":"E-commerce","text":"<ul> <li>Product Recommendations: Personalized shopping assistance</li> <li>Inventory Management: Demand prediction and ordering</li> <li>Customer Service: Order tracking and support</li> <li>Review Analysis: Sentiment and feedback processing</li> </ul>"},{"location":"use-cases/#implementation-patterns","title":"\ud83d\udca1 Implementation Patterns","text":""},{"location":"use-cases/#pattern-1-research-synthesis","title":"Pattern 1: Research &amp; Synthesis","text":"<pre><code># Hub-and-spoke for coordinated research\ntopology = PatternConfig.hub_and_spoke(\n    hub=\"Coordinator\",\n    spokes=[\"Researcher1\", \"Researcher2\", \"Synthesizer\"],\n    parallel_spokes=True\n)\n</code></pre>"},{"location":"use-cases/#pattern-2-quality-assurance","title":"Pattern 2: Quality Assurance","text":"<pre><code># Pipeline for sequential validation\ntopology = PatternConfig.pipeline(\n    stages=[\n        {\"name\": \"input\", \"agents\": [\"Validator\"]},\n        {\"name\": \"process\", \"agents\": [\"Processor\"]},\n        {\"name\": \"verify\", \"agents\": [\"Verifier\"]},\n        {\"name\": \"output\", \"agents\": [\"Formatter\"]}\n    ]\n)\n</code></pre>"},{"location":"use-cases/#pattern-3-decision-making","title":"Pattern 3: Decision Making","text":"<pre><code># Mesh for collaborative decisions\ntopology = PatternConfig.mesh(\n    agents=[\"Analyst1\", \"Analyst2\", \"Analyst3\", \"DecisionMaker\"],\n    fully_connected=True\n)\n</code></pre>"},{"location":"use-cases/#pattern-4-escalation-system","title":"Pattern 4: Escalation System","text":"<pre><code># Hierarchical for tiered support\ntopology = PatternConfig.hierarchical(\n    tree={\n        \"Manager\": [\"Supervisor1\", \"Supervisor2\"],\n        \"Supervisor1\": [\"Agent1\", \"Agent2\"],\n        \"Supervisor2\": [\"Agent3\", \"Agent4\"]\n    }\n)\n</code></pre>"},{"location":"use-cases/#performance-metrics","title":"\ud83d\udcc8 Performance Metrics","text":""},{"location":"use-cases/#research-assistant-performance","title":"Research Assistant Performance","text":"<ul> <li>Speed: 10x faster than manual research</li> <li>Coverage: Analyzes 100+ sources in parallel</li> <li>Accuracy: 95% fact verification rate</li> <li>Cost: 80% reduction vs human researchers</li> </ul>"},{"location":"use-cases/#customer-support-metrics","title":"Customer Support Metrics","text":"<ul> <li>Response Time: &lt; 2 seconds initial response</li> <li>Resolution Rate: 85% first-contact resolution</li> <li>Satisfaction: 4.8/5 average rating</li> <li>Cost Savings: 70% reduction in support costs</li> </ul>"},{"location":"use-cases/#code-review-statistics","title":"Code Review Statistics","text":"<ul> <li>Review Speed: 5 minutes per 1000 lines</li> <li>Bug Detection: 90% of common issues caught</li> <li>False Positives: &lt; 5% rate</li> <li>Developer Time Saved: 2 hours per review</li> </ul>"},{"location":"use-cases/#getting-started","title":"\ud83d\ude80 Getting Started","text":""},{"location":"use-cases/#choose-your-use-case","title":"Choose Your Use Case","text":"<ol> <li>Identify your business problem</li> <li>Select appropriate pattern</li> <li>Define agent specializations</li> <li>Configure topology</li> <li>Deploy and iterate</li> </ol>"},{"location":"use-cases/#quick-start-templates","title":"Quick Start Templates","text":"<ul> <li>Research System Template</li> <li>Support System Template</li> <li>Analysis Pipeline Template</li> <li>Content System Template</li> </ul>"},{"location":"use-cases/#best-practices","title":"Best Practices","text":"<ul> <li>Start simple, add complexity gradually</li> <li>Monitor agent performance metrics</li> <li>Implement proper error handling</li> <li>Use appropriate timeout configurations</li> <li>Enable state persistence for long tasks</li> </ul>"},{"location":"use-cases/#resources","title":"\ud83d\udcd6 Resources","text":""},{"location":"use-cases/#example-code","title":"Example Code","text":"<p>All examples available in examples/real_world/</p>"},{"location":"use-cases/#documentation","title":"Documentation","text":"<ul> <li>Architecture Overview</li> <li>Agent Development</li> <li>Topology Patterns</li> <li>API Reference</li> </ul>"},{"location":"use-cases/#community-examples","title":"Community Examples","text":"<ul> <li>Community Showcase</li> <li>Share Your Use Case</li> </ul>"},{"location":"use-cases/#next-steps","title":"\ud83c\udfaf Next Steps","text":"<ul> <li> <p> Quick Start</p> <p>Build your first system</p> </li> <li> <p> Tutorials</p> <p>Step-by-step guides</p> </li> <li> <p> API Reference</p> <p>Complete documentation</p> </li> <li> <p> Support</p> <p>Get help and support</p> </li> </ul> <p>Ready to Build!</p> <p>Choose a use case that matches your needs and start building. Each example includes complete code and deployment instructions.</p> <p>Pro Tip</p> <p>Start with a proven pattern and customize it for your specific needs. The examples provide excellent starting points for most applications.</p>"}]}